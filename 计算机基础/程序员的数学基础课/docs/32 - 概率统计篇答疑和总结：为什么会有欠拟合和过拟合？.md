你好，我是黄申。

在概率统计这个模块中，我们讲了很多监督式机器学习相关的概念。你可能对朴素贝叶斯、决策树、线性回归这类监督式算法中的一些概念还是不太清楚。比如说，为什么要使用大量的文档集合或者语料库来训练一个朴素贝叶斯模型呢？这个过程最后得到的结果是什么？为什么训练后的结果可以用于预测新的数据？这里面其实涉及了很多模型拟合的知识。

为了帮助你更好地理解这些内容，今天我就来说说监督式学习中几个很重要的概念：拟合、欠拟合和过拟合，以及如何处理欠拟合和过拟合。

## 拟合、欠拟合和过拟合

每种学习模型都有自己的假设和参数。虽然朴素贝叶斯和决策树都属于分类算法，但是它们各自的假设和参数都不相同。朴素贝叶斯的假设是贝叶斯定理和变量之间的独立性，而决策树的假设是集合的纯净程度或者混乱程度。我们这里所说的参数，是指根据模型假设和训练样本推导出来的数据，例如朴素贝叶斯中的参数是各种先验概率和条件概率，而决策树的参数是各个树结点以及结点上的决策条件。

了解了什么是模型的假设和参数，我们来看看什么是模型的**拟合**（Model Fitting）。在监督式学习中，我们经常提到“训练一个模型”，其实更学术的说法应该是“拟合一个模型”。
<div><strong>精选留言（20）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/13/44/42/af72265f.jpg" width="30px"><span>冰冷的梦</span> 👍（11） 💬（1）<div>老师，贝叶斯以后我已经基本看不懂了。。。我应该是缺少概率统计相关知识的基础吧？</div>2019-03-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/01/b9/73435279.jpg" width="30px"><span>学习学个屁</span> 👍（4） 💬（1）<div>我感觉我得多刷几遍才能理解了，看一遍会忘记的，太难了。</div>2020-01-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/5b/6f/113e24e6.jpg" width="30px"><span>阿信</span> 👍（4） 💬（1）<div>概率统计这一模块的收获：
理解了信息熵、信息增益相关概念。第26讲信息熵，测试武侠人物的思路，给我现在工作上的一个复杂问题提供了一些新的思路来进行适当简化</div>2019-07-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/42/df/a034455d.jpg" width="30px"><span>罗耀龙@坐忘</span> 👍（3） 💬（1）<div>茶艺师学编程

在学校学到贝叶斯定理，都觉得已经很难了。但现在，除了贝叶斯，还学到了决策树、信息增益、卡方检验、显著性检验、方差分析等等，这样跟着老师一路走来，感觉还是能抓到一点东西。那就是：

事情没有绝对，不是非黑即白。说是靠谱，得算出有多大概率的靠谱；说不靠谱，也得上说有多大概率的不靠谱。

大家都说这是不确定世界，但我们也不是束手无策，至少能把概率给算（模拟）出来，再根据算出的结果，把我们能做的事情做好。

谢谢黄老师的讲解。</div>2020-04-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/64/9b/d1ab239e.jpg" width="30px"><span>J.Smile</span> 👍（2） 💬（1）<div>要点总结：
欠拟合问题，产生的主要原因是特征维度过少，拟合的模型不够复杂，无法满足训练样本，最终导致误差较大。
---解决办法：我们就可以增加特征维度，让输入的训练样本具有更强的表达能力。


   过拟合问题产生的主要原因则是特征维度过多，导致拟合的模型过于完美地符合训练样本，但是无法适应测试样本或者说新的数据。
---解决办法：所以我们可以减少特征的维度，从另一个角度来看，过拟合表示模型太复杂，而相对的训练数据量太少。因此我们也可以增加训练样本的数据量，并尽量保持训练数据和测试数据分布的一致性</div>2020-02-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/23/f8/24fcccea.jpg" width="30px"><span>💢 星星💢</span> 👍（2） 💬（1）<div>老师其实你讲的相比外面那些讲数学的资料，相比而言容易理解太多了，而且我脑袋里已经有个概念了，但是很容易忘记，尤其是那些数学公式，估计是没有真真的理解还有实践吧。老师这门课已经让我树立了新的概念了，算是进入了一个新的领域，以后需要多看几遍。谢谢老师的付出，目前只看到这里。</div>2019-11-15</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/ROiaQ2u90nCO1CQV4Qfo8chdZqOTibcqtTpOwdcWDuicZjXN3x2CbXx6icne0895ViaXAVR3Riap2TuTrXePU3Lv1A5Q/132" width="30px"><span>Geek_b5a671</span> 👍（1） 💬（1）<div>学到很多东西，特别是在概率基础(下)，看了4遍，基本上搞懂了这些，然后包括信息熵，信息增益这些，也有了进一步的理解，以前对这些只是知道个概念，现在有了初步的认识了，知道是怎么回事了。</div>2020-03-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/6c/76/c543d3a2.jpg" width="30px"><span>燕然君</span> 👍（1） 💬（2）<div>这拟合的过程，就是数学建模的过程吗</div>2019-07-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/f5/ea/faf489e4.jpg" width="30px"><span>Dale</span> 👍（0） 💬（1）<div>个人的最大的感觉是，“简单的”概率可以帮我们解决复杂的问题——人们会根据自己的过往经验对未知或者未来的事物进行一定程度的推测，但这种推测或可靠或不可靠，大多取决于个人的经验、能力和判断；机器学习则是把这种推测依据以及推测过程完全用数字度量了出来，将“以古鉴今”的思想运用到了极致！</div>2021-02-07</li><br/><li><img src="" width="30px"><span>常振华</span> 👍（0） 💬（1）<div>收获是，知道了哪类问题可以用什么思路去分析解决，至于具体细节，当遇到实际问题时再去深入细化即可</div>2020-10-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/01/9c/1a750bc7.jpg" width="30px"><span>l c</span> 👍（0） 💬（1）<div>真的是一个很棒的概率论+传统统计+基础机器学习的复习，我本科是学经济的，后来转读计算机科学之后感觉机器学习方面的很多东西都与统计相关但是也无法理出一个清晰的脉络。
被老师理了一遍感觉清楚多了，受益良多。</div>2020-08-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/7e/a6/4e331ef4.jpg" width="30px"><span>骑行的掌柜J</span> 👍（0） 💬（1）<div>终于把概率统计这部分知识撸了一遍 感谢黄老师用相对浅显的方式讲出数据挖掘算法里面的数学原理 让我再次有了新的领悟  剩下的就是还要反复研读这部分再多练习一些实战来加深理解 
PS:之前接触到了交叉验证的问题，写了一篇博客来记录😀https:&#47;&#47;blog.csdn.net&#47;weixin_41013322&#47;article&#47;details&#47;105437409 
各位有兴趣可以看看</div>2020-06-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1c/2e/12/26cba5b8.jpg" width="30px"><span>虔诚</span> 👍（0） 💬（1）<div>很有趣的图像解释。在老师的专栏下最大收获是读懂了这些概率论的概念。读书的时候上数据挖掘课过拟合图要交叉验证，随机森林的死记硬背真的很头疼。还是我读书的时候没开窍啊哈哈哈!赞一个</div>2020-06-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/7d/a7/83d372e0.jpg" width="30px"><span>Sophie</span> 👍（0） 💬（1）<div>感想是终于把这些基本概念捋清了！</div>2020-05-19</li><br/><li><img src="" width="30px"><span>Paul Shan</span> 👍（2） 💬（0）<div>适度拟合就是在训练偏差和模型的复杂度取得平衡，以求得最小误差的过程。模型参数要反应训练样本中的信息才能预测，模型参数又不能过度反应训练样本的信息，毕竟真实样本和训练样本有差异，如何能恰如其分地用好训练样本，是机器学习的关键。</div>2019-09-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg" width="30px"><span>建强</span> 👍（1） 💬（0）<div>概率和统计，是数据建模的基础和重要依据。</div>2020-08-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/85/a1/2442332c.jpg" width="30px"><span>郭俊杰</span> 👍（1） 💬（0）<div>学习了，现在本人水平有限，提不出有水准的问题，等深入了，再提问，哈哈。</div>2020-05-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/b6/70/33e87a4f.jpg" width="30px"><span>时熵</span> 👍（0） 💬（0）<div>学习完了概率和统计模块，你觉得自己最大的收获和感触是什么？===》俺觉得这些内容比较像玄学，只能给个大概的推测。学过的各种东西，心理都会嘀咕一下，这样计算真的靠谱么</div>2024-12-30</li><br/><li><img src="" width="30px"><span>013923</span> 👍（0） 💬（0）<div>复习大学里学过的课程</div>2022-09-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/ac/96/46b13896.jpg" width="30px"><span>williamcai</span> 👍（0） 💬（0）<div>我感觉都是在复习大学的知识，因为用的少，忘记的也快</div>2022-07-04</li><br/>
</ul>