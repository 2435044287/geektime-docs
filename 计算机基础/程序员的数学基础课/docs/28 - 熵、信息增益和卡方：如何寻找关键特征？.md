你好，我是黄申。今天我们来说说特征选择。

我们已经讨论过信息熵和信息增益在决策树算法中的重要作用。其实，它们还可以运用在机器学习的其他领域，比如特征选择。你可能对“特征选择”这个名词不太熟悉，没有关系，我先花点时间，给你介绍一下什么是特征选择，以及机器学习为什么需要这个步骤。

## 什么是特征选择？

在编程领域中，机器学习已经有了十分广泛的应用，它主要包括监督式学习（Supervised Learning）和非监督式的学习（Unsupervised Learning）。监督式学习，是指通过训练资料学习并建立一个模型，并依此模型推测新的实例，主要包括分类（Classification）和回归（Regression）。

无论是在监督学习还是非监督学习中，我们都可以使用特征选择。不过，我今天要聊的特征选择，会聚焦在监督式学习中的特征处理方法。因此，为了说清楚特征选择是什么，以及为什么要进行这个步骤，我们先来看看监督式机器学习的主要步骤。

机器学习的步骤主要包括数据的准备、特征工程、模型拟合、离线和在线测试。测试过程也许会产生新的数据，用于进一步提升模型。在这些处理中，特征工程是非常重要的一步。

“特征”（Feature），是机器学习非常常用的术语，它其实就是可用于模型拟合的各种数据。前面讲朴素贝叶斯分类时，我解释了如何把现实世界中水果的各类特征转化为计算机所能理解的数据，这个过程其实就是最初级的特征工程。当然，特征工程远不止原始特征到计算机数据的转化，还包括特征选择、缺失值的填补和异常值的去除等等。这其中非常重要的一步就是特征选择。
<div><strong>精选留言（14）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg" width="30px"><span>建强</span> 👍（7） 💬（1）<div>基尼指数也可以用于特征选择，公式的图没法贴出来，基尼指数越低，纯度越高，特征对于分类越有区分价值。公式大致如下：
Gini(P, Dfi) = p(fi) * Gini(Dfi) + p(-fi) * Gini(-Dfi)，Dfi表示特征fi，-fi和-Dfi表示不出现数据特征，而单个数据特征的Gini指数公式大致如下：
Gini(Dfi) = 1-sum(1..m)[p(Cj | Dfi)]^2，其中，sum表示连加，就是公式中的西格码，(1..m)表示含有数据特征的m个分类，Cj表示第j个分类，只能这样大致表示下。
这样的理解是否正确，请老师指正。</div>2020-06-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（6） 💬（1）<div>老师，你好。关于使用卡方检验来进行特征选择，能否在答疑课的时候，给个具体例子讲解下？</div>2019-02-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/bc/96/c679bb3d.jpg" width="30px"><span>总统老唐</span> 👍（4） 💬（1）<div>黄老师，关于使用卡方检验做特征选择，按照文中的讲法，实际上是检测的某个特征 fi 和 某个类 cj 的相关性，但是我们面对的实际情况是有 m 个特征，n 个类，那么：
1，是不是代表要做 m×n 次计算？
2，即便计算结果表明 fi 和 cj 类相关性很高，也有可能 fi 和 ck类 相关性很低，那这个结果对是否选取 fi 作为整体n个类的特征有什么指导意义呢？</div>2019-12-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/6c/69/d5a28079.jpg" width="30px"><span>Bora.Don</span> 👍（4） 💬（1）<div>老师，您好，感觉最近几节课您讲了很多概念，很多公式，可是运用上的实例似乎有点少，第一遍看懂了，可是过两天估计就忘记了，能否提供一下代码？这样可以自己动手操作一遍，非常感谢</div>2019-03-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/7e/31/dba044fa.jpg" width="30px"><span>zhulihui</span> 👍（3） 💬（1）<div>老师好，想问个问题，一定要做特征选择么，能说说特征选择的必要性么。如果把所有特征都扔到模型会有什么副作用</div>2019-03-21</li><br/><li><img src="" width="30px"><span>13311195819</span> 👍（3） 💬（2）<div>老师您用的什么画图软件，看起来画图很漂亮；我在网上找了好久找不到</div>2019-02-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/9a/89/babe8b52.jpg" width="30px"><span>A君</span> 👍（2） 💬（1）<div>随机森林模型也有对特征对分类的重要性进行排序的功能，它是否也是用卡方公式算出来的？</div>2020-07-23</li><br/><li><img src="" width="30px"><span>Paul Shan</span> 👍（2） 💬（1）<div>本文先引入了条件熵，条件熵只反映了特征和全局数据的相关性，并没有考虑不在条件分类下的情况。例如癌症筛查，只给没有癌症标签的分类器，全局准确度很高，因为患癌毕竟是小概率事件。为了解决这个问题，引入了条件分类下的信息增益。这种情况下，只给没有癌症的分类器就现形了，信息增益为零。
和条件分类下的信息增益类似，卡方检验用联合概率来简化计算，目的还是计算相关性。我感觉卡方检验和相关系数非常类似，请问老师为什么不直接用相关系数检验相关性，卡方检验相对于相关系数有什么好处？</div>2019-09-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/2d/26/abb7bfe3.jpg" width="30px"><span>William</span> 👍（2） 💬（1）<div>老师，在计算信息增益的公式中，P(cj|Dfi)和P(cj|Dfi)【带横杠】中的cj的含义应该是不同的吧？前者是出现fi特征的数据集合中第j个分类，后者是未出现fi特征的数据集合中第j个数据的分类。</div>2019-08-20</li><br/><li><img src="" width="30px"><span>013923</span> 👍（1） 💬（1）<div>谢谢老师！</div>2022-09-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/d9/a1/1b3b7cb5.jpg" width="30px"><span>闪光辉</span> 👍（1） 💬（1）<div>为什么不少地方卡方的计算公式=sum((A-T)^2&#47;T) 的区别是什么（备注：A是实际值，T是理论值），其区别是什么</div>2019-03-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/a9/90/0c5ed3d9.jpg" width="30px"><span>颇忒妥</span> 👍（0） 💬（1）<div>老师，您好，本文中是否隐含了这么一种假设：本文中提到的特征维度的取值是否都是二元的？所以才能用Dfi和Dfi(非)表达公式。如果某个特征维度的取值可以是多个，那又该怎么做？</div>2021-08-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/42/df/a034455d.jpg" width="30px"><span>罗耀龙@坐忘</span> 👍（2） 💬（0）<div>茶艺师学编程

思考题，试试用基尼系数来特征选择（试着写公式）

基尼系数，简单来说就是考察一个集合的纯度，系数越小，表示该集合的纯度越高。

要进行特征选择，就是考察在使用某特征对集合划分后，其纯度提升了多少，选择其中提升幅度大的。

那么其公式简单为：

原集合的基尼系数—使用特征划分后集合的基尼系数的和

把不同的特征带进去，计算后的值从高到低排序，取排位靠前的。</div>2020-04-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/c0/15/be72b945.jpg" width="30px"><span>端点星好运</span> 👍（2） 💬（0）<div>一说自己会概率，上帝就发笑 ...</div>2019-07-11</li><br/>
</ul>