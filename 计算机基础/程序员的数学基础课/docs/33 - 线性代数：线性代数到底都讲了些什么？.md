你好，我是黄申。

通过第二模块的学习，我想你对概率统计在编程领域，特别是机器学习算法中的应用，已经有了一定理解。概率统计关注的是随机变量及其概率分布，以及如何通过观测数据来推断这些分布。可是，在解决很多问题的时候，我们不仅要关心单个变量之间的关系，还要进一步研究多个变量之间的关系，最典型的例子就是基于多个特征的信息检索和机器学习。

在信息检索中，我们需要考虑多个关键词特征对最终相关性的影响，而在机器学习中，无论是监督式还是非监督式学习，我们都需要考虑多个特征对模型拟合的影响。在研究多个变量之间关系的时候，线性代数成为了解决这类问题的有力工具。

另一方面，在我们日常生活和工作中，很多问题都可以线性化，小到计算两个地点之间的距离，大到计算互联网中全部网页的PageRank。所以，为了使用编程来解决相应的问题，我们也必须掌握一些必要的线性代数基础知识。因此，我会从线性代数的基本概念出发，结合信息检索和机器学习领域的知识，详细讲解线性代数的运用。

关于线性代数，究竟都需要掌握哪些方面的知识呢？我们今天就来看一看，让你对之后一段时间所要学习的知识有个大体的了解。

## 向量和向量空间

我们之前所谈到的变量都属于**标量**（Scalar）。它只是一个单独的数字，而且不能表示方向。从计算机数据结构的角度来看，标量就是编程中最基本的变量。这个很好理解，你可以回想一下刚开始学习编程时接触到的标量类型的变量。
<div><strong>精选留言（26）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/bc/a0/97c7679b.jpg" width="30px"><span></span> 👍（9） 💬（1）<div>之前对线代的认识，熟记各种性质和概念，细心保证计算不出错。模糊的知道三维几何变换。
我觉得从算题来说，求特征值比较难。
大量高阶幂矩阵乘法，会带来计算量大的问题。</div>2019-03-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/ec/2e/49d13bd2.jpg" width="30px"><span>SMTCode</span> 👍（8） 💬（2）<div>回想大学的那些岁月，数学基础课遇到的都是很厉害的老师：高数是数学系的教授亲自教的，讲解深入透彻；概率是军校外聘的教授教的，也非常专业；线代是一个退休的老教授，依然热爱三尺讲台，有幸得到了他的教导。现在感叹自己蹉跎了那些岁月。没有学扎实，出来混，早晚都要还的。加油吧～</div>2019-12-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/7e/a6/4e331ef4.jpg" width="30px"><span>骑行的掌柜J</span> 👍（6） 💬（1）<div>之前没有学过线性代数（大学文科😂） 最近开始系统的学习这块 因为在做机器学习的时候会遇到特征的选择和降维、建模这些操作 觉得还是要多了解一些底层的数学原理才能更好的优化模型 
感觉线代没有我想象中那么难  哈哈哈可能是老师们都讲的比较好吧 期待后面
PS：看到评论有个说国外的教授讲线代不错的 我告诉你是Gilbert Strang教授的《Introduction to Linear Algebra》 真的不错这门课 特地买了第五版书来看 配合这个专栏简直绝配🧐</div>2020-06-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/d3/c0/d38daa2d.jpg" width="30px"><span>yaya</span> 👍（6） 💬（1）<div>对线代的基础特征向量，矩阵分解有一定了解，我觉得矩阵就是为了便于书写这样排列的，本质还是运算，不过便于观看和书写，后来计算机中便于存储，后来便于并行，不过矩阵有其特质，这是和它展开的运算式不同的地方</div>2019-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/83/dd/86468048.jpg" width="30px"><span>九夏对三冬</span> 👍（2） 💬（1）<div>请问下黄老师，向量能内嵌向量吗？像对象内嵌对象一样</div>2021-04-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/85/a1/2442332c.jpg" width="30px"><span>郭俊杰</span> 👍（2） 💬（1）<div>大学上的专科，只学了高数，没有学线代，这次补上。哈哈，ML工作中太常用了。</div>2020-05-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/a9/f6/1cdb3d52.jpg" width="30px"><span>乐达</span> 👍（2） 💬（1）<div>线性代数印象最深的是矩阵，感觉矩阵代表了线性代数。这部分最难的就是各种公式的应用和计算。</div>2020-03-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1c/f9/69/384e33e6.jpg" width="30px"><span>Zeal</span> 👍（2） 💬（1）<div>矩阵乘法，不管对于机器，还是学习的人，都应该是直接写出来的。而不是死记只能计算一个位置的“点乘”公式……</div>2020-03-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/ac/96/46b13896.jpg" width="30px"><span>williamcai</span> 👍（1） 💬（1）<div>工作好多年了，许多知识都忘记了，在工作中用的比较少，我觉得最难的是在实际问题能想到线性代数的使用</div>2022-07-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/e0/13/b5972df3.jpg" width="30px"><span>牛杰</span> 👍（1） 💬（1）<div>黄老师的新书已买，非常棒！有代码实现。感谢您的经验分享，让我搞民航业务的也能入门AI世界，再次感谢！</div>2021-03-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/88/19/225b0b0b.jpg" width="30px"><span>李阳</span> 👍（1） 💬（1）<div>理解矩阵从矩阵对向量的变换这个角度来看，会比较好理解，因为矩阵本身代表了一种变换，从矩阵的四个字空间开始可以一步一步进入内核来看到底矩阵的本质是啥。https:&#47;&#47;warden2018.github.io&#47;warden2018.github.io&#47;archive&#47;</div>2020-10-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/d4/44/0ec958f4.jpg" width="30px"><span>Eleven</span> 👍（1） 💬（1）<div>这是因为，如果我们把某个向量中的元素看作坐标轴上的坐标，那么这个向量就可以看作空间中的一个点。以原点为起点，以向量代表的点为终点，就能形成一条有向直线。

黄老师，这句话我不是很能理解，比如向量x包含{x1, x2, ...xn}，那向量中的元素看作坐标轴上的坐标，向量可以看作是空间中的一个点？如果向量中有很多元素那不是有很多维？</div>2020-05-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/92/6d/becd841a.jpg" width="30px"><span>escray</span> 👍（1） 💬（1）<div>大学本科的时候学过线性代数，但是当时是比较懵懂的。读研的时候旁听了几节课，到后来稍微复杂一点的时候就放弃了，因为当时以为只有做图形学的或者是图像的才需要学习线性代数，没想到后来机器学习也需要这个，当然现在也没有从事相关的工作。

之前看到有国外大学的线性代数公开课，据说讲的很好，但是一直没有看。

我觉的线性代数最难的部分还是在于后面的向量空间、矩形变化和奇异值分解，我感觉这一部分似乎需要一些空间想象力，一旦超过二维，我的想象力就不够了。另外一方面，线性代数中的计算一般不会太难，但是比较复杂，需要细致和耐心，这对我来说也算一个难点。

希望这次能再探线性代数。</div>2019-10-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/93/ec/985675c8.jpg" width="30px"><span>小高</span> 👍（1） 💬（1）<div>线代对于我来说，是一片森林，进去了就不知道怎么出来.....跟着老师好好学习！加油！</div>2019-03-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/87/eb/20492a37.jpg" width="30px"><span>一路向北</span> 👍（1） 💬（1）<div>大学学完线代后，就没有碰过这门课，当时学的也是一头雾水，只是感觉很有用，但是到底干嘛用，不知道。</div>2019-03-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/50/99/44378317.jpg" width="30px"><span>李皮皮皮皮皮</span> 👍（1） 💬（1）<div>线代概念很多，而且定义复杂。特别是到空间那一块。更重要的是不明白实际含义，空记公式和理论，考完试就还给老师了👨‍🏫</div>2019-03-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/0c/0f/93d1c8eb.jpg" width="30px"><span>mickey</span> 👍（1） 💬（1）<div>之前对线代的认识，是在二维空间对点的操作。
觉得最难的是，各种概念、计算、变换、图形的实际意义。</div>2019-03-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/87/c9/f4b81a34.jpg" width="30px"><span>999</span> 👍（0） 💬（1）<div>对线性代数有了新的理解</div>2020-03-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/7d/6b/648c30bc.jpg" width="30px"><span>予悠悠</span> 👍（0） 💬（1）<div>之前一直不理解向量为什么叫向量，不理解一个数组（我之前对向量的理解）为什么会有方向。听了老师这堂课，终于明白是在空间中理解向量。但感觉还是理解的很有限，要赶紧学习之后的课程。</div>2019-04-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/90/d0/48037ba6.jpg" width="30px"><span>李跃爱学习</span> 👍（25） 💬（0）<div>1. 在研究多个变量之间关系的时候，线性代数成为了解决这类问题的有力工具
2. 向量和向量空间
    1. 标量（Scalar），它只是一个单独的数字，而且不能表示方向
    2. 向量（Vector），也叫做矢量，它代表一组数字，并且这些数字时有序排列的
    3. 向量和标量最大的区别在于，向量除了拥有数值的大小，还拥有方向
        1. 为什么这么一串数字能表示方向？
        2. 这是因为，如果我们把向量中的元素看成坐标轴上的坐标，那么这个向量就可以看作空间中的一个点，以原点为起点，以向量代表的点为重点，就能形成一条有向的直线。
        3. 以上处理就给向量赋予了代数的含义，使得计算的过程中更加直观。
            1. 向量空间
            2. 向量夹角
            3. 矩阵特征值
    4. 自然界物体的属性转换为用数字表达，向量的每个元素代表一维特征，而元素的值代表相应特征的值，我们称这类向量为特征向量（Feature Vector）
        1. 这个和矩阵的特征向量（Eigenvector）是两码事
3. 向量的运算
    1. 标量和向量之间可以进行运算，把标量和向量中的每个元素进行运算
    2. 向量和向量之间运算需要先定义向量空间
    3. 向量空间
        1. 空间由无穷多个的位置点组成
        2. 这些点之间存在相对的关系
        3. 可以在空间中定义任意两点之间的长度，以及任意两点之间的角度
        4. 这个空间的点可以进行移动
        5. 定义运算
            1. 加法：首先两个向量需要维度相同，然后是对应的元素相加
            2. 乘法（点乘）：向量之间的乘法默认是点乘，点乘的作用是把相乘的两个向量转换成了标量。它有具体的几何含义。我们会用点乘来计算向量的长度以及两个向量的夹角。向量之间的夹角和距离又在向量空间模型（Vector Space Model）中发挥了重要作用。信息检索和机器学习等领域利用了向量空间模型来计算不同对象之间的相似程度
            1. 距离
            2. 夹角
4. 矩阵（Matrix）
    1. 矩阵由多个长度相等的向量组成
        1. 向量其实也是一个特殊的矩阵
        2. 从数据结构角度看，向量是一维数组，那矩阵就是二维数组
        3. 如果二维数组里面大多数元素都是0，我们称这个矩阵很稀疏（Sparse）
            1. 我们可以使用哈希表的链地址法表示稀疏矩阵
        4. 单位矩阵（identity Matrix）：所有沿主对角线的元素都是1，其他位置的元素都是0，通常我们只考虑单位矩阵为方阵的情况（即行数和列数相等）
    2. 矩阵的几何意义是坐标变换
        1. 特征向量
        2. 特征值
        3. 如果一个矩阵存在特征向量和特征值，那么这个矩阵的特征向量就表示了它在空间中最主要的运动方向
    3. 矩阵的运算
        1. 标量和矩阵之间的运算，把标量和矩阵中的每个元素进行运算
        2. 矩阵和矩阵之间
            1. 加法：首先保证参与运算的两个矩阵具有相同的行维度和列维度，我们就可以把对应的元素两两相加
            2. 乘法：假设X为i*k的矩阵，Y为k*j的矩阵，首先X的列数必须要和Y的行数相等，计算X的行向量与Y的列向量的点乘
            3. 转置（transposition）：将矩阵内的元素行索引和纵索隐呼唤，转置N*M的矩阵得到M*N的矩阵
            4. 求逆矩阵：逆矩阵*原始矩阵，结果是单位矩阵
            5. 求特征值
            6. 求奇异值
</div>2019-07-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/42/df/a034455d.jpg" width="30px"><span>罗耀龙@坐忘</span> 👍（3） 💬（0）<div>茶艺师学编程

终于来到了线性代数了。

在大学学习的时候，知道这玩意能把一次方程转换成一个向量，能把多元一次方程组转换为一个矩阵，觉得这东西有意思。

然而在矩阵的变换、计算中迷失了自己，至今。</div>2020-04-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/93/cd/dbafc7d1.jpg" width="30px"><span>全麦小面包</span> 👍（2） 💬（0）<div>在《学霸的黑科技系统》这本小说里，有一个&quot;商人过河数学建模&quot;的问题。希望看了您的线性代数篇，能理解这个问题的解法。先立个flag~</div>2022-07-29</li><br/><li><img src="" width="30px"><span>013923</span> 👍（1） 💬（0）<div>复习一遍大学课程</div>2022-09-14</li><br/><li><img src="" width="30px"><span>Paul Shan</span> 👍（1） 💬（0）<div>向量是一组长度（维度）固定的有序数值序列。长度固定和有序两个特点让向量和特定维度空间中的点一一对应。任意两个点的差值就可以定义一个从减数到被减数的方向。这些空间都有一个特殊的点，就是在所有维度的分量是零的点，也就是原点。任意点减去原点就是他自己，每个点也一一对应于一个方向。这样向量既可以定义n维空间的点，又可以定义n维空间的一个方向。向量的加减法用的是平行四边形法则。点乘放映了两个向量大小和夹角余弦的关系。把现实世界物体的特征值向量化，就是建立特征值的过程。叉乘是构建一个和两个已知向量都垂直的向量。

矩阵是描述坐标轴（一组向量）变换的过程。矩阵的特征值，如果没记错的话，描述的是坐标伸缩的比例。矩阵的加减法和向量类似。矩阵的乘法，把左边的矩阵看成行向量的集合，把右边矩阵看成列向量的集合，然后求出笛卡尔积得出向量对，然后对这个向量对求点乘，得出标量，行列组合这些标量，得到结果矩阵。
矩阵的转置，就是把矩阵行列交换得到的新矩阵。
单位阵相当于1的作用，逆矩阵相当于倒数的概念。
矩阵有稀疏和不稀疏之风，为了充分利用存储空间，前者一般用索引的方法处理（哈希表或者链表），后者一般用数组存储。
</div>2019-09-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/97/18/a5218104.jpg" width="30px"><span>🐾</span> 👍（1） 💬（0）<div>重新复习了一下大学的数学～</div>2019-09-13</li><br/><li><img src="" width="30px"><span>wuhaungvvv1122</span> 👍（0） 💬（0）<div>测试手动-评论评论</div>2023-12-08</li><br/>
</ul>