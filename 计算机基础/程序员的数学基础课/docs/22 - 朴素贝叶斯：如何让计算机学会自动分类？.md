你好，我是黄申。今天我们来聊聊朴素贝叶斯。

在开始正式的内容之前，我想问你一个问题，你是如何区分苹果、甜橙和西瓜的？你可能要说了，这个问题还用得着讲吗？是不是你们博士都喜欢将简单的问题复杂化？还真不是，如果你将计算机想象成一个两三岁的孩子，你会怎么教一个孩子区分这些水果呢？

比如我曾经就和一个小朋友有过这样一段对话：

小朋友：黄叔叔，你和我讲讲，什么样的水果才是苹果呀？

我：圆形的、绿色的水果。

小朋友：那西瓜也是圆形的、绿色的呀？

我：嗯……苹果也有可能是黄色或红色的，但西瓜不是。

小朋友：那甜橙也是圆形的、黄色的呀？

我：好吧，你看到的大部分情况下的甜橙都是黄色的，而苹果只有很少情况（少数品种）是黄色的。而且你还可以尝尝，它们的味道也是不同的。

![](https://static001.geekbang.org/resource/image/0e/db/0e626ddb70a0f4c7133e0a54d18c8fdb.png?wh=1026%2A368)

哈哈，你是不是觉得想要描述清楚，并没有想象中的那么容易？但是，在这个对话中，有两点我觉得你需要关注一下：

- 我使用了“可能”“大部分情况”“很少情况”等等这种词语，这些词包含了**概率**的概念；
- 我使用了**多个条件**来判断一个水果属于哪个类别。

基于此，我接下来就要聊聊，我们是如何通过数学的思想和方法，系统性地解决这个问题的。其中，**朴素贝叶斯**（Naive Bayesian）就提供了一个切实可行的方案。不过，在深入了解它之前，我们还需要做点准备工作。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/02/92/3d545582.jpg" width="30px"><span>山中清泉明月照</span> 👍（17） 💬（8）<div>p(c|f1,f2)=p(c|f1)*p(c|f2)&#47;p(c) 应该是这样子吧</div>2019-07-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/6c/69/d5a28079.jpg" width="30px"><span>Bora.Don</span> 👍（15） 💬（2）<div>感觉老师讲得特别好,谢谢老师!同时还在极客上购买了人工智能和数据分析的课程,都讲了朴素贝叶斯,在这讲得最明白</div>2019-03-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/85/ae/abb7bfe3.jpg" width="30px"><span>机智的捞球布</span> 👍（12） 💬（5）<div>请问老师：
P(c|fi)的值不也是可以直接从训练样本中统计出来的么，为什么要用贝叶斯定理转换成p(fi|c) * p(c) &#47; p(fi)， 用另外三个统计值计算出来呢。</div>2019-06-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/ed/4e/ef406442.jpg" width="30px"><span>唯她命</span> 👍（9） 💬（1）<div>朴素贝叶斯  必须各个特征相互独立的吗？</div>2019-02-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/69/39/ab99b850.jpg" width="30px"><span>邓艺晋_Jim</span> 👍（8） 💬（4）<div>为何三个概率加起来不是等于1，新来的水果不是苹果就是橙子或者西瓜啊，另外想问极客的机器学习课程在哪里有，谢谢</div>2019-03-25</li><br/><li><img src="" width="30px"><span>201200986</span> 👍（6） 💬（1）<div>终于明白朴素贝叶斯在分类中的原理了，给定的训练集其实包含训练集中每个类别的概率 每个特征的概率以及在已知类别下特征的条件概率，最终可以利用贝叶斯求得在给定特征下类别的概率，从而根据特征求得其属于哪个分类。不知道我这个理解对不对？</div>2020-03-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/03/f1/1382a981.jpg" width="30px"><span>temool</span> 👍（6） 💬（1）<div>越看到后面越吃力，前面的也要再重新捋一遍</div>2019-02-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/9a/89/babe8b52.jpg" width="30px"><span>A君</span> 👍（3） 💬（1）<div>哦log原来是用于将计算机无法处理的小数转成绝对值大于1的数</div>2020-06-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/be/22/8bb1640f.jpg" width="30px"><span>oillie</span> 👍（2） 💬（1）<div>垃圾邮件可以用贝叶斯分类</div>2020-02-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/23/1f/6452b2e8.jpg" width="30px"><span>刘清斌</span> 👍（2） 💬（1）<div>老师，这一讲真的很清楚明白，比其他的书籍和教程讲的形象和容易理解</div>2019-10-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/f8/d0/ecc68a4f.jpg" width="30px"><span>🐻🔫🐸</span> 👍（2） 💬（1）<div>太牛逼了，以前看过数学之美，就立志以后得安排一下数学，这次看老师的文章，真正意义上进行正面接触了，而且讲的相当接地气，易于理解。👍🏻</div>2019-07-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/91/00/2007d2f3.jpg" width="30px"><span>zhengfan</span> 👍（1） 💬（1）<div>黄老师您好。
问题较多，列举如下：
1. 例子中列举的属性很多，但是只使用了两个参与贝叶斯公式计算，得到分类预测结果依然被认为是有效的，是因为假定了属性正交吗？
2. 为什么参与计算的属性越多，所有分类的预测概率越低？似乎有点反直觉。难道这样获得预测结果只是定序而非定量？
3. 为什么不同分类的概率之和不是全集呢？</div>2020-04-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/f2/aa/32fc0d54.jpg" width="30px"><span>失火的夏天</span> 👍（1） 💬（1）<div>之前拉下的，现在回来补一补，概率统计居然有这么大的作用，我已经决定把大学里概率论与数理统计那本书翻出来重新复习了，O(∩_∩)O哈哈~</div>2019-12-29</li><br/><li><img src="" width="30px"><span>Paul Shan</span> 👍（1） 💬（1）<div>我个人觉得联合分布是贝叶斯公式的枢纽，由已知的条件概率求出联合分布，再由联合分布求出待求的条件概率，老师这样理解正确吗，多谢！</div>2019-09-02</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJman25D8Jlr6P6AIhumWr2CNqZPvXl8JJLc3yOvvTlWFDVuKbYpNXgKib6y1Sa0HApwvz1xM6MBjw/132" width="30px"><span>大秦岭</span> 👍（1） 💬（1）<div>看了两边，照猫画虎了好几遍，貌似懂了，继续加油中........
谢谢老师~</div>2019-06-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/1d/32/005c7ba4.jpg" width="30px"><span>大熊</span> 👍（1） 💬（1）<div>重点还是对贝叶斯公式的理解，后面的都是基于公式的变形</div>2019-05-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/7d/6b/648c30bc.jpg" width="30px"><span>予悠悠</span> 👍（1） 💬（2）<div>老师朴素贝叶斯和逻辑回归有什么区别呢？</div>2019-05-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/f8/c8/9611d2c4.jpg" width="30px"><span>刘超</span> 👍（1） 💬（1）<div>         老师，有个问题，我感觉好像只要用朴素的方法，不用贝叶斯公式就能得到结果了。
          但是有的地方结果又不对。比如在计算p(西瓜的时候|o)，前面部分p(西瓜|shape-2)和贝叶斯算的一样，但是p(西瓜|taste-2)算出来的是0。</div>2019-04-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/3f/2b/966c348b.jpg" width="30px"><span>zzz</span> 👍（1） 💬（1）<div>请问“支持模糊分类”是什么意思呢，是当算出的多个分类概率差不多时？</div>2019-04-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1c/f7/62/947004d0.jpg" width="30px"><span>www</span> 👍（0） 💬（1）<div>看懂了，长这么大终于看懂了！</div>2021-08-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/f4/49/2b938b4f.jpg" width="30px"><span>北极的大企鹅</span> 👍（0） 💬（1）<div>又遇到我们公司博士啦
这样的概率是多少呢</div>2021-03-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/e0/13/b5972df3.jpg" width="30px"><span>牛杰</span> 👍（0） 💬（1）<div>看了第三遍，总算弄清楚原理了，非常感谢生动的讲解！</div>2020-12-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/20/fd/a8/ab2041ef.jpg" width="30px"><span>刘桃花</span> 👍（0） 💬（1）<div>老师，您在分类算法对比那里讲的特别有用，学到了</div>2020-10-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/9a/89/babe8b52.jpg" width="30px"><span>A君</span> 👍（0） 💬（1）<div>我想请问老师，模糊分类是什么意思，能举点例子么</div>2020-06-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg" width="30px"><span>建强</span> 👍（0） 💬（1）<div>思考题：除了文本分类，朴素贝叶斯还可用于垃圾邮件过滤，垃圾短信过滤，以及文字广告过滤等。</div>2020-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/29/c3/791d0f5e.jpg" width="30px"><span>渣渣辉</span> 👍（0） 💬（1）<div>例子中的p(apple)p(oragne)p(watermelon) 不应该是相同概率吗</div>2020-03-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/95/c5/397b3d01.jpg" width="30px"><span>so敏仪</span> 👍（0） 💬（1）<div>听君一席话，胜读十年书 这钱花得值了 谢谢老师浅入深出的讲解</div>2019-11-15</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/eyKgpIVFSDQBia7SJRVUKFh5qgwc3ohzEPSKvchLf9ZvwIO9CrS470ER7OhNzWTs0svECHCBiarQTa41BO3Hf0DA/132" width="30px"><span>Temme</span> 👍（0） 💬（1）<div>关于评论中的证明我还是不太明白，如果
p(c)*p(f1|c)*p(f2|f1,c)=p(c)*p(f1|c)*p(f2|c)成立，
那么p(f2|f1,c)=p(f2|c)怎么通过条件独立的前提得出的？
而且证出的结论也和文中的不一样
结论是p(c)*p(f1|c)*p(f2|c)&#47;p(f1)*p(f2),
而文中的换算下来p(c)*p(f1|c)*p(c)*p(f2|c)&#47;p(f1)*p(f2),
不知道是我哪里搞错了</div>2019-07-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/5b/6f/113e24e6.jpg" width="30px"><span>阿信</span> 👍（0） 💬（1）<div>P(c|o) = P(c|(fi, fj)) = P(c|fi) * P(c|fj)，
这一步的推导，是基于上面朴素贝叶斯假设得到的。
如苹果中口味是甜、形状是圆的概率：P(甜的、圆的)=P(甜的) * P(圆的)，口味、形状对分析的对象属于苹果的概率是独立的。即不考虑一个苹果既是圆的又是甜的。虽然和实际不符，但这就是朴素的表现。

黄老师，上面这样理解对吗</div>2019-06-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/18/d0/49b06424.jpg" width="30px"><span>qinggeouye</span> 👍（0） 💬（1）<div>「如果一个分类的应用场景中，待分类对象的属性值大部分都是离散的（或者很容易转化为离散的）、需要支持模糊分类，并且需要快速可靠的实时分类，那么这种场景通常就非常适合使用朴素贝叶斯方法。」

比如，花朵分类（属于哪一种花），花的属性有花瓣颜色、花瓣形状、花瓣大小、花瓣数量等..</div>2019-03-04</li><br/>
</ul>