你好，我是黄申。

上一节，我通过问卷调查的案例，给你解释了信息熵和信息增益的概念。被测者们每次回答一道问题，就会被细分到不同的集合，每个细分的集合纯净度就会提高，而熵就会下降。在测试结束的时候，如果所有被测者都被分配到了相应的武侠人物名下，那么每个人物分组都是最纯净的，熵值都为0。于是，测试问卷的过程就转化为“如何将熵从3.32下降到0”的过程。

由于每道问题的区分能力不同，而我们对问题的选择会影响熵下降的幅度。这个幅度就是信息增益。如果问卷题的顺序选择得好，我们可以更快速地完成对用户性格的判定。这一节我们就继续这个话题，看看如何获得一个更简短的问卷设计，把这个核心思想推广到更为普遍的决策树分类算法中。

## 如何通过信息熵挑选合适的问题？

为了实现一个更简短的问卷，你也许很自然地就想到，每次选择问题的时候，我们可以选择信息增益最高的问题，这样熵值下降得就最快。这的确是个很好的方法。我们来试一试。

我们现在开始选择第一个问题。首先，依次计算“性别”“智商”“情商”“侠义”和“个性”对人物进行划分后的信息增益。我们得到如下结果：

![](https://static001.geekbang.org/resource/image/9f/11/9f135e031841f15012ed997a1dd30a11.png?wh=1276%2A156)

显然，第一步我们会选择“侠义”，之后用户就会被细分为3组。

![](https://static001.geekbang.org/resource/image/7c/42/7cd2a03c7b5fd5f6b94e69c89b70c142.png?wh=1278%2A446)![](https://static001.geekbang.org/resource/image/a1/b8/a12483f003569c79899c143d28c332b8.png?wh=1272%2A400)![](https://static001.geekbang.org/resource/image/09/10/0957e7645a48a21e9409886963270b10.png?wh=1274%2A388)

针对第一组，我们继续选择在当前这组中，区分力最强、也是信息增益最高的问题。根据计算的结果我们应该选择有关“性别”的问题，然后进一步地细分。后续的步骤依次类推，直到所有人物都被分开，对于第二组和第三组我们也进行同样地操作。整个过程稍微有点复杂，为了帮你理解，我把它画成了一个图。
<div><strong>精选留言（22）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/e8/87/89561ed0.jpg" width="30px"><span>Peng</span> 👍（13） 💬（2）<div>开始看不懂了，我再多看几遍试试。</div>2019-03-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/3c/4f/979bdccc.jpg" width="30px"><span>lifes a Struggle</span> 👍（5） 💬（1）<div>知道了，老师的案例中个体都是一个单独的分类，所有在原始集合中可以采用-n*(Pi*log(2,Pi))的形式进行信息熵的计算。如果存在分类的数据不均匀，通过各个分类的信息熵求和即可。</div>2019-08-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/bc/96/c679bb3d.jpg" width="30px"><span>总统老唐</span> 👍（3） 💬（1）<div>既然每次都是分解成左右两个子树，为什么CART算法公式中的m不直接写成2</div>2019-12-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/36/3f/95a9a40a.jpg" width="30px"><span>张九州</span> 👍（3） 💬（1）<div>计算整个数据集基尼指数，pj是什么 如何计算？</div>2019-09-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg" width="30px"><span>建强</span> 👍（2） 💬（1）<div>根据信息增益划分的原理，简单写了一个python程序计算了一下问题期望数，程序输出结果如下：
选择信息增益小的问题对人物分类，问题数的期望值=3.7
选择信息增益大的问题对人物分类，问题数的期望值=2.8

程序代码如下：
import pandas as pd
# 初始化10个武侠人物的属性
p = { &#39;性别&#39;:[&#39;男&#39;,&#39;男&#39;,&#39;男&#39;,&#39;男&#39;,&#39;男&#39;,&#39;女&#39;,&#39;女&#39;,&#39;女&#39;,&#39;女&#39;,&#39;女&#39;]
             ,&#39;智商&#39;:[&#39;高&#39;,&#39;高&#39;,&#39;高&#39;,&#39;高&#39;,&#39;中&#39;,&#39;高&#39;,&#39;高&#39;,&#39;高&#39;,&#39;高&#39;,&#39;中&#39;]
             ,&#39;情商&#39;:[&#39;高&#39;,&#39;高&#39;,&#39;中&#39;,&#39;中&#39;,&#39;高&#39;,&#39;高&#39;,&#39;中&#39;,&#39;中&#39;,&#39;中&#39;,&#39;中&#39;]
             ,&#39;侠义&#39;:[&#39;高&#39;,&#39;中&#39;,&#39;低&#39;,&#39;中&#39;,&#39;高&#39;,&#39;低&#39;,&#39;高&#39;,&#39;高&#39;,&#39;低&#39;,&#39;中&#39;]
             ,&#39;个性&#39;:[&#39;开朗&#39;,&#39;拘谨&#39;,&#39;开朗&#39;,&#39;拘谨&#39;,&#39;开朗&#39;,&#39;开朗&#39;,&#39;开朗&#39;,&#39;拘谨&#39;,&#39;开朗&#39;,&#39;开朗&#39;]}
name = [&#39;A&#39;,&#39;B&#39;,&#39;C&#39;,&#39;D&#39;,&#39;E&#39;,&#39;F&#39;,&#39;G&#39;,&#39;H&#39;,&#39;I&#39;,&#39;J&#39;]
knight = pd.DataFrame(data=p,index=name)

# 定义问题类型及增益大小
problem_type = {&#39;性别&#39;:1,&#39;智商&#39;:0.72,&#39;情商&#39;:0.97,&#39;侠义&#39;:1.58,&#39;个性&#39;:0.88}

# 计算测试问题的期望值
def get_exp_problems(knight, problem_type):
#BEGIN

    result = {}
    sub_knight = [(knight,0)]
    temp_sub_knight = []

    for pt in problem_type:

        #用某一个问题类型对每一组侠客进行划分
        for sub in sub_knight:
            temp_sub = sub[0].groupby(by = [pt])

            #该问题没有将该组侠客进行划分，放入中间结果，继续下一组划分
            if len(temp_sub) &lt;= 1:
                temp_sub_knight.append((sub[0],sub[1]))
                continue

            # 对划分后的结果进行处理
            for label, member in temp_sub:
                list_member = list(member.index)
                if len(list_member) == 1:
                    result[list_member[0]] = sub[1] + 1
                else:
                    temp_sub_knight.append((member, sub[1]+1))

        sub_knight.clear()
        sub_knight.extend(temp_sub_knight)
        temp_sub_knight.clear()

    # 计算问题数的期望值
    exp = 0
    for k in result:
        exp += result[k]&#47;len(name)

    return exp
#END

def main():
    problem = dict(sorted(problem_type.items(), key=lambda x: x[1], reverse=False))
    print(&#39;选择信息增益小的问题对人物分类，问题数的期望值={}&#39;.format(round(get_exp_problems(knight, problem),2)))

    problem = dict(sorted(problem_type.items(), key=lambda x: x[1], reverse=True))
    print(&#39;选择信息增益大的问题对人物分类，问题数的期望值={}&#39;.format(round(get_exp_problems(knight, problem),2)))

if __name__ == &#39;__main__&#39;:
    main()</div>2020-06-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/18/d0/49b06424.jpg" width="30px"><span>qinggeouye</span> 👍（2） 💬（2）<div>某个特征 T 取值越多，数据集 P 划分时分组越多，划分后的「信息熵」越小，「信息增益」越大。「分裂信息」是为了解决某个特征 T 取值过多，造成机器学习过拟合，而引入的一种惩罚项，惩罚取值多的特征。

老师，「基尼指数」没怎么看明白，第一个式子中「n 为集合 P 中所包含的不同分组或分类的数量」该怎么理解？求和符号后面的 pi 是什么含义？谢谢～</div>2019-03-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/a2/aa/bf65e8be.jpg" width="30px"><span>Thinking</span> 👍（2） 💬（1）<div>建议老师每堂课后能配多几个具有代表性的，针对性的练习题辅助理解概念和公式。</div>2019-02-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/ad/50/3cb818e8.jpg" width="30px"><span>灰太狼</span> 👍（1） 💬（4）<div>老师，基尼系数公式里的pi是指分组i在集合P中的概率吗？</div>2020-03-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/23/f8/24fcccea.jpg" width="30px"><span>💢 星星💢</span> 👍（1） 💬（1）<div>老师随机森林有没有好的文章推荐，另外老师有没有公众号，或者其他方式可以白嫖看您的文章呢，当然也期待老师出新的专栏，虽然这个专栏对于我来说已经是新的挑战。但是非常喜欢读老师的文章。</div>2019-11-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/6a/8e/7b6ea886.jpg" width="30px"><span>Joe</span> 👍（1） 💬（2）<div>老师，请问有没有相关代码实现的方式，能否给出参考链接。</div>2019-02-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/4f/40/6cfa75cb.jpg" width="30px"><span>哈达syn$</span> 👍（0） 💬（0）<div>王天一喜欢用足球举例子，黄申喜欢武侠小说呀</div>2020-05-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/75/be/6f3ab95e.jpg" width="30px"><span>拉普达</span> 👍（0） 💬（1）<div>期望是3.8次 </div>2020-03-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/28/17/2ee45db9.jpg" width="30px"><span>abson</span> 👍（0） 💬（1）<div>老师，有个疑问，像前几篇文章讲隐马尔科夫、信息熵和本节讲的决策树，数据是怎么来的，用什么方法去统计才能拿到相对偏差较少的数据</div>2019-08-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/48/30/77c6c4ec.jpg" width="30px"><span>动摇的小指南针</span> 👍（0） 💬（1）<div>基尼系数中，基于特征T划分出来的子集m中，m的每个子集又有n个不同的分组。请问这个n是根据什么来进行划分的呢</div>2019-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/6c/69/d5a28079.jpg" width="30px"><span>Bora.Don</span> 👍（0） 💬（1）<div>老师，你好，既然CART算法是二叉树，那么在计算基尼指数的时候，n和m是不是就是定值：2？
CART算法又是如何保证是二叉树的呢？CART算法没看懂</div>2019-03-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/44/42/af72265f.jpg" width="30px"><span>冰冷的梦</span> 👍（0） 💬（1）<div>老师，什么是过拟合啊？</div>2019-03-12</li><br/><li><img src="" width="30px"><span>Paul Shan</span> 👍（9） 💬（0）<div>信息增益，新分类的引入导致熵的减少。
信息增益率，计算熵的时候还考虑了多个子项的数目。在计算分组后集合的熵，采用加权平均之后，还要除以，集合分组不同数目引入的熵。
Gini指数是一种新的计算混乱度的方法，熵是基于对数加权的，Gini指数是基于平方的相反数求和再加一。Gini指数求导以后是线性的，随着概率减少变化度比熵更敏感（熵的导数是对数），也就更惩罚小概率事件。

</div>2019-09-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/42/df/a034455d.jpg" width="30px"><span>罗耀龙@坐忘</span> 👍（2） 💬（0）<div>茶艺师学编程

1、思考题：按照最少信息增益来划分，用户回答题目的期望是多少？

0.2*2+0.1*3+0.4*4+0.1*5+0.2*6=4

（换成人话，就是10个人，有两人要回答两题，有一人要回答三题，有四人要回答四题，有一人要回答五题，有两人要回答六题，他们的期望就是四题）

2、关于ID3和C4.5算法：

两者都是罗斯•昆兰（Ross Quinlan）的作品，ID3决策树诞生于1986年，在7年后（1993年）罗斯就推出了它的改进版C4.5算法，后者被称为数据挖掘十大算法之一。
</div>2020-04-19</li><br/><li><img src="" width="30px"><span>013923</span> 👍（1） 💬（0）<div>学完一章，谢谢老师！</div>2022-09-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/7e/a6/4e331ef4.jpg" width="30px"><span>骑行的掌柜J</span> 👍（0） 💬（0）<div>思考题：“如果每次都选择使得信息增益最小的问题”
我算出来结果是 期望值是3.9。。。跟楼上两个哥们的不一样。。。（因为A、C、D、F、H都要问四轮；B、E、J都要三轮；G、I 要问五轮）不过都是在4的附近</div>2020-06-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/64/9b/d1ab239e.jpg" width="30px"><span>J.Smile</span> 👍（0） 💬（0）<div>要点总结：
CART算法和 ID3、C4.5 相比，主要有两处不同：
在分类时，CART 不再采用信息增益或信息增益率，而是采用基尼指数（Gini）来选择最好的特征并进行数据的划分；
在 ID3 和 C4.5 决策树中，算法根据特征的属性值划分数据，可能会划分出多个组。
而 CART 算法采用了二叉树，每次把数据切成两份，分别进入左子树、右子树。</div>2020-02-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/3c/4f/979bdccc.jpg" width="30px"><span>lifes a Struggle</span> 👍（0） 💬（0）<div>老师，请问一下，当原始集合中的数据，本身是分布不均匀的，这个时候该如何计算它的信息熵呢？如：集合｛A,A,A,B,B,C｝</div>2019-08-07</li><br/>
</ul>