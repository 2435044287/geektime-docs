你好，我是黄申。

之前我们讲过如何让计算机理解现实世界中的事物，方法是把事物的各种特性转为机器所能理解的数据字段。而这些数据字段，在机器学习里通常被称为特征。有了特征，我们不仅可以刻画事物本身，还能刻画不同事物之间的关系。

上一个模块我们只是了解了监督式学习，重点考察了特征和分类标签之间的关系。但是在信息检索和非监督式学习中，我们更关注的是不同事物之间的相似程度。这就需要用到线性代数中的向量空间模型了。

提到向量空间模型，你可能对其中的概念有点陌生，所以我会从向量空间的基本概念开始说起，讲到向量空间模型的相关知识，最后再讲讲它是如何应用在不同的编程中的。

## 什么是向量空间？

上一节，我讲到了向量和向量空间的一些基本概念。为了帮助你更好地理解向量空间模型，我这里给出向量和向量空间的严格定义。

首先假设有一个数的集合$F$，它满足“$F$中任意两个数的加减乘除法（除数不为零）的结果仍然在这个$F$中”，我们就可以称$F$为一个“域”。我们处理的数据通常都是实数，所以这里我只考虑实数域。而如果域$F$里的元素都为实数，那么$F$就是实数域。
<div><strong>精选留言（24）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/14/77/da/54c663f3.jpg" width="30px"><span>Wing·三金</span> 👍（8） 💬（1）<div>欧式距离的平方=25+16+196=237
欧式距离为根号 237≈15.4

cos=（-6-3-48）&#47; （√（9+1+64）*√（4+9+36））=（-57）&#47; （7*√74）≈-0.95

另外似乎有个小错误：在总结前有个公式 1&#47;(1-ED)，当ED从 0-正无穷 变化时，公式的值域是负无穷到正无穷除去0。可以考虑换成 MinMax 等方法归一化。</div>2019-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/f8/f6/3e2db176.jpg" width="30px"><span>七月有风</span> 👍（4） 💬（3）<div>二维三维空间很好理解，也可以借助图形理解，四维五维也有这种图形吗？还是只是我们假象出来的，在这儿有点转不过来</div>2019-07-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg" width="30px"><span>JustDoDT</span> 👍（3） 💬（1）<div>这节讲的太好了，值得分享给身边的从业者。</div>2020-02-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/70/ca/deb1a067.jpg" width="30px"><span>YiFān.W</span> 👍（2） 💬（1）<div>那这个向量应当包括字典中所有的词条吧？实际情况中岂不是非常非常大</div>2019-03-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/0c/0f/93d1c8eb.jpg" width="30px"><span>mickey</span> 👍（2） 💬（1）<div>欧氏距离：√237
夹角余弦：-57&#47;√(74*49)</div>2019-03-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/50/99/44378317.jpg" width="30px"><span>李皮皮皮皮皮</span> 👍（2） 💬（1）<div>V是Fn的子集，Fn是F中的n维向量。那怎么会有标量属于V呢？不太明白😢</div>2019-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/92/7f/e531ea14.jpg" width="30px"><span>栗景树</span> 👍（1） 💬（1）<div>因为我们处在三维空间，图形化的信息表达最多只能到三维，三维以上的空间，画不出来，在大脑里模拟出来的形状还是基于三维，想出来也还是不对的，只能靠数学推导。</div>2022-01-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/09/d6/5f366427.jpg" width="30px"><span>码农Kevin亮</span> 👍（1） 💬（1）<div>请问老师，不同的距离的应用场景有什么区别与讲究呢？</div>2020-07-29</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIzGGthScz54sECZJKX3lgyjCATkgrvSt5N3eOsYB34jibCr3SkAX88QaZ5IVmME9Ec7VdkQGwRSPw/132" width="30px"><span>哈哈哈</span> 👍（0） 💬（1）<div>切比雪夫距离公式感觉写错了？ 我查阅其他资料 应该是 MAX(| X1 - X2 |, | Y1 - Y2 |) 吧？</div>2021-06-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/25/60/5f/cd5e6b64.jpg" width="30px"><span>观众</span> 👍（0） 💬（1）<div>什么是n维空间？</div>2021-03-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg" width="30px"><span>建强</span> 👍（0） 💬（1）<div>思考题：
以下算式中，square函数计算一个数的平方，sqrt函数计算一个数的平方根, arccos函数是反余弦函数。

计算两个向量的欧氏距离：
ed = sqrt(square(3+2) + square(-1-3) + square(8+6)) = 15.39

计算两个向量的夹角：
cosθ = (3*(-2) + (-1)*3 + 8*(-6)) &#47; sqrt((9 + 1 + 64) * (4 + 9 + 36)) = -0.9466
θ = arccos(cosθ) = 2.81</div>2020-08-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/d4/44/0ec958f4.jpg" width="30px"><span>Eleven</span> 👍（0） 💬（1）<div>ED(x,y,z)=平方根(3-(-2))^2+(-1-3)^2+(8-(-6))^2=平方根237</div>2020-08-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/7e/a6/4e331ef4.jpg" width="30px"><span>骑行的掌柜J</span> 👍（0） 💬（1）<div>一下子补了好多向量的知识 刺激 </div>2020-06-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/b5/98/ffaf2aca.jpg" width="30px"><span>Ronnyz</span> 👍（0） 💬（1）<div>欧式距离：√257
夹角余弦：-57&#47;(√74*√49)</div>2019-10-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/18/d0/49b06424.jpg" width="30px"><span>qinggeouye</span> 👍（0） 💬（1）<div>向量 a = [3, -1,  8] ，b = [-2, 3, -6] 
欧氏距离 ED(a, b) = 开根号(25+16+196) 
夹角余弦 Cosine(a, b) = (-6 -3 -48)&#47;开根号(74*49)</div>2019-03-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/6a/8e/7b6ea886.jpg" width="30px"><span>Joe</span> 👍（0） 💬（3）<div>切比雪夫的公式写错了吧，不是x y之间相减，应该是x和x，y和y之间差的最大值。</div>2019-03-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/42/df/a034455d.jpg" width="30px"><span>罗耀龙@坐忘</span> 👍（5） 💬（0）<div>茶艺师学编程

作业：计算坐标（3，-1,8）和（-2，3，-6）的欧氏距离与夹角余弦

没什么好说的，直接代入文中黄老师给出的公式。

两个坐标的距离：
[(3+2)^2+(-1-3)^2+(8+6)^2]^(1&#47;2)=237^(1&#47;2)≈15.3948

两个坐标的夹角余弦：

（我是这么记公式的，就是【两个坐标的点乘】除以【两个坐标各自与原点的欧氏距离的乘积再开平方】，范围也就是[1，-1]）

-57&#47;（74*49）^(1&#47;2)=-57&#47;3626^(1&#47;2)≈-0.9466</div>2020-04-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/64/9b/d1ab239e.jpg" width="30px"><span>J.Smile</span> 👍（2） 💬（0）<div>	要点总结：
       向量空间的封闭性
	向量之间的距离：曼哈顿距离、欧式距离、切比雪夫距离、闵式距离
	向量的长度：即向量的模，一般用欧氏距离表示。
	范数：满足非负性、齐次性、三角不等式
		L1范数：是为x向量各个元素绝对值之和，对应于向量x和原点之间的曼哈顿距离。
		L2范数：它是x向量各个元素平方和的1&#47;2​次方，对应于向量x和原点之间的欧氏距离。
		Lp范数：为 x 向量各个元素绝对值 p 次方之和的 1&#47;p 次方，对应于向量 x 和原点之间的闵氏距离。
		L∞范数：为 x 向量各个元素绝对值最大那个元素的绝对值，对应于向量 x 和原点之间的切比雪夫距离。

	向量之间的夹角计算相似性：余弦公式
	欧氏距离ED计算相似性</div>2020-02-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/71/22/ef806458.jpg" width="30px"><span>Monica</span> 👍（2） 💬（0）<div>欧式距离=√（x1-y1）²+（x2-y2）²+（x3-y3）²=√（3+2）²+（-1-3）²+（8+6）²=√237
夹角余弦 = 向量点积&#47; (向量长度的叉积) = ( x1x2 + y1y2 + z1z2) &#47; ( √(x1²+y1²+z1² ) x √(x2²+y2²+z2² ) )=(-6-3-48)&#47;（√（9+1+64）*√（4+9+36））=（-57）&#47; （7*√74）</div>2019-04-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/b6/70/33e87a4f.jpg" width="30px"><span>时熵</span> 👍（0） 💬（0）<div> 1&#47;(ED+1) 这种归一化：这个是说对原向量x和y乘以标量 1&#47;(ED+1)，得到两个新的向量x&#39;和y‘。然后再用x&#39;和y&#39;来计算余弦值的意思么？</div>2025-01-10</li><br/><li><img src="" width="30px"><span>013923</span> 👍（0） 💬（0）<div>学完一章，谢谢！</div>2022-09-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/9a/89/babe8b52.jpg" width="30px"><span>A君</span> 👍（0） 💬（0）<div>向量空间模型，通过计算特征向量间的距离或夹角大小，来将那些距离短夹角小的向量进行聚类。</div>2020-12-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/d4/44/0ec958f4.jpg" width="30px"><span>Eleven</span> 👍（0） 💬（0）<div>欧式距离：√(3-(-2))^2 + (-1 -3)^2 + (8-(-6))^2＝√237
夹角余弦：(3 * (-2)) + (-1 * (-3))+(8 * (-6))&#47;(3^2 + (-1^2) + 8^2) * ((-2)^2 + (-3)^2 + (-6)^2) = -57&#47;√(74*49)
</div>2020-06-02</li><br/><li><img src="" width="30px"><span>Paul Shan</span> 👍（0） 💬（0）<div>向量空间满足加法和标量乘法的封闭性
两个向量空间中点的距离有曼哈顿距离，欧式距离，切比雪夫距离，闵可夫斯基距离。这些距离都可以用向量差的某个函数表示。曼哈顿距离就是向量差的各个分量绝对值之和。欧式距离是各个分量平方和的开方。切比雪夫距离是分量绝对值的最大值，闵可夫斯基距离分量绝对值的p次方之和再开p次方。其中闵可夫斯基距离最为通用，p取1就是曼哈顿距离，p取2就是欧式距离，p取正无穷就是切比雪夫距离，p取零0（这里定义0的0次方为0）,就是非零分量的个数。
范数可以用闵可夫斯基的p值来定义。
向量的夹角用两个向量单位化以后的点积来定义。放映了两个向量在空间中角度的关系，可以看作两个向量在单位向量球面的投影和原点组成的三角形，在原点这个角的余弦。这个量和矢量的长度无关（为零和不为零还是有关的），只和矢量的角度有关。
欧式距离也可以表示两个向量的差异。

</div>2019-09-23</li><br/>
</ul>