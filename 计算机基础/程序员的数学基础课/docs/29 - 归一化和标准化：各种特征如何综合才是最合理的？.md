你好，我是黄申，今天我来说说特征值的变换。

上一节我讲了如何在众多的特征中，选取更有价值的特征，以提升模型的效率。特征选择是特征工程中的重要步骤，但不是全部。今天，我来说说特征工程中的另一块内容，数值变换。也就是说，我们可以使用统计中的数据分布，对连续型的数值特征进行转换，让多个特征的结合更有效。具体怎么理解呢？我下面就来详细讲一讲。

## 为什么需要特征变换？

我们在很多机器学习算法中都会使用特征变换。我使用其中一种算法线性回归作为例子，来解释为什么要进行数值型特征的变换。

我们之前介绍的监督式学习会根据某个样本的一系列特征，最后判定它应该属于哪个分类，并给出一个离散的分类标签。除此之外，还有一类监督式学习算法，会根据一系列的特征输入，给出连续的预测值。

举个例子，房地产市场可以根据销售的历史数据，预估待售楼盘在未来的销售情况。如果只是预估卖得“好”还是“不好”，那么这个粒度明显就太粗了。如果我们能做到预估这些房屋的售价，那么这个事情就变得有价值了。想要达成这个预测目的的过程，就需要最基本的**因变量连续回归分析**。

因变量连续回归的训练和预测，和分类的相应流程大体类似，不过具体采用的技术有一些不同。它采用的是研究一个或多个随机变量$y\_{1}$，$y\_{2}$，…，$y\_{i}$与另一些变量$x\_{1}$，$x\_{2}$，…，$x\_{k}$之间关系的统计方法，又称**多重回归分析**。
<div><strong>精选留言（16）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/12/69/4d/81c44f45.jpg" width="30px"><span>拉欧</span> 👍（9） 💬（1）<div>标准化和归一化未必能提高模型的准确度，但是会提高可解释性，是不是这个意思？</div>2019-02-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/6a/8e/7b6ea886.jpg" width="30px"><span>Joe</span> 👍（7） 💬（2）<div>之前做机器学习算法的时候，采用特征缩放处理特征，能有效提高学习收敛效果。公式：x’=(x-x_mean)&#47;(xmax-xmin)。不是单纯的归一，也保留了不同类别x之间的权重。</div>2019-02-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/ad/50/3cb818e8.jpg" width="30px"><span>灰太狼</span> 👍（5） 💬（2）<div>归一化和标准化在使用中分别适合什么场景呢</div>2020-03-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/7e/a6/4e331ef4.jpg" width="30px"><span>骑行的掌柜J</span> 👍（3） 💬（1）<div>黄老师终于讲了理论后 上代码了 😂不过黄老师 我还了解到有种叫PCA降维的方法 他跟标准化之间有联系吗？是需要先标准话再PCA降维？谢谢</div>2020-06-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/10/57/1adfd4f7.jpg" width="30px"><span>追梦</span> 👍（3） 💬（1）<div>老师，这如果是部署到线上模型，这些预处理应该怎么变化呢</div>2020-01-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/1d/32/005c7ba4.jpg" width="30px"><span>大熊</span> 👍（3） 💬（1）<div>以前用归一的时候都没考虑噪音的影响，今天get到了，nice</div>2019-05-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/18/d0/49b06424.jpg" width="30px"><span>qinggeouye</span> 👍（3） 💬（1）<div>思考题：

&quot;&quot;&quot;
测试数据集 test.csv
测试数据的目标值 submission_example.csv
&quot;&quot;&quot;
df_test = pd.read_csv(&quot;&#47;Users&#47;qinggeouye&#47;Desktop&#47;GeekTime&#47;MathematicProgrammer&#47;29_featureTrans&#47;test.csv&quot;)
expected_test = pd.read_csv(&quot;&#47;Users&#47;qinggeouye&#47;Desktop&#47;GeekTime&#47;MathematicProgrammer&#47;29_featureTrans&quot;
                            &quot;&#47;submission_example.csv&quot;)[&#39;medv&#39;]

# 归一化 预测结果
minMaxScaler_test = MinMaxScaler()
df_test_normalized = minMaxScaler_test.fit_transform(df_test.astype(dtype=float))
df_test_features_normalized = df_test_normalized[:, :]
predicted_normalized = regression_normalized.predict(df_test_features_normalized)
print(&quot;归一化预测结果与实际值的均方根误差：%s&quot; % np.sqrt(np.mean((predicted_normalized - expected_test) ** 2)))

# 标准化 预测结果
standardScaler_test = StandardScaler()
standardScaler_test.fit(df_test.astype(dtype=float))
df_test_standardized = standardScaler_test.transform(df_test.astype(dtype=float))
df_test_features_standardized = df_test_standardized[:, :]
predicted_standardized = regression_standardized.predict(df_test_features_standardized)
print(&quot;标准化预测结果与实际值的均方根误差：%s&quot; % np.sqrt(np.mean((predicted_standardized - expected_test) ** 2)))

# 预测结果，两种特征转换预测结果相差无几，但与实际值相差较大
归一化预测结果与实际值的均方根误差：22.40003520184502
标准化预测结果与实际值的均方根误差：22.785218713879576</div>2019-03-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/5b/6f/113e24e6.jpg" width="30px"><span>阿信</span> 👍（2） 💬（1）<div>特征值处理，能加快收敛速度、降噪、标准化输出，这种好理解。但为什么会影响分析结果</div>2019-07-05</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKia6PQiaF3N9KvzbloVvicY9fQz3vs8C82ykfOTgNeMqpRAJxCICQgpIMFFTtQ2DrHej7IeFlcG9tdQ/132" width="30px"><span>Geek_a50e46</span> 👍（1） 💬（1）<div>老师，那是不是标准化就没有缺点了？是不是可以完全用标准化替代归一化了呢？</div>2020-02-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/d9/5d/dd0eb7e0.jpg" width="30px"><span>春节十二响</span> 👍（0） 💬（1）<div>我对特征标准化的理解是，初始的特征数据不是纯数字，而是有量纲的，直接进行运算会搞出类似5m+6kg这样逻辑意义错误的操作。所以特征标准化实现的第一个效果是去量纲，把特征变成纯数字;第二个效果就是把不同特征投射到相近的数量级上，好做比较，也避免一些算法需要计算距离时，某个特征占得权重过大</div>2021-04-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/9a/89/babe8b52.jpg" width="30px"><span>A君</span> 👍（0） 💬（1）<div>权重原来指的是衡量自变量对因变量产生正影响还负影响，权重的绝对值越大，表示该自变量对因变量的影响也越大。</div>2020-07-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/85/a1/2442332c.jpg" width="30px"><span>郭俊杰</span> 👍（0） 💬（1）<div>讲的很明白，thanks.</div>2020-05-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/5c/02/e7af1750.jpg" width="30px"><span>teddytyy</span> 👍（0） 💬（1）<div>为啥age一直是正相关特征？</div>2019-12-19</li><br/><li><img src="" width="30px"><span>Paul Shan</span> 👍（4） 💬（0）<div>归一化是按比例变化到［0,1］的区间里。
标准化是假设分布为正态分布，将数据变换为均值为0,方差为1的正态分布。
将所有数据按照统一尺度处理，有利于比较模型中的权重大小。
</div>2019-09-13</li><br/><li><img src="" width="30px"><span>013923</span> 👍（1） 💬（0）<div>学习了，谢谢老师！</div>2022-09-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/42/df/a034455d.jpg" width="30px"><span>罗耀龙@坐忘</span> 👍（0） 💬（0）<div>茶艺师学编程

今天讲了特征变换的其中两种操作，一个是归一法，另一个是Z分数标准化（基于正态分布）。

我试着这么理解：

前者是把自变量变换在[0,1]之间，后者则是把自变量按照距离“平均值”的远近重新“排位”。

我感觉归一法就好像是对一张图片进行拉伸操作。而Z分数标准化，就是在放着铁粉的纸下面放上一根磁铁，轻轻抖动几下，看着原本散落的铁粉在磁铁的作用下排列出“磁感线”的图案。

……不知道我这么理解对不对，请大家指点。</div>2020-04-21</li><br/>
</ul>