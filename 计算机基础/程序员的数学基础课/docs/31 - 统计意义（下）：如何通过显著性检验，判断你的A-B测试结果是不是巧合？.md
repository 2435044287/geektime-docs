你好，我是黄申，今天我们接着来聊显著性检验。

上一节，我介绍了差异显著性检验的概念，它是指从统计的角度来说，差异的产生有多大的概率、是不是足够可信。这点和数值差异的大小是有区别的。既然我们不能通过差异的大小来推断差异是否可信，那么有没有什么方法，可以帮助我们检验不同数据分布之间，是否存在显著差异呢？具体的方法有不少，比如方差分析（F检验）、t检验、卡方检验等等。我这里以方差分析为例，来讲这个方法是如何帮助我们解决AB测试中的问题。

## 方差分析

**方差分析**（Analysis of Variance, ANOVA），也叫**F检验**。这种方法可以检验两组或者多组样本的均值是否具备显著性差异。它有四个前提假设，分别是：

- 随机性：样本是随机采样的；
- 独立性：来自不同组的样本是相互独立的；
- 正态分布性：组内样本都来自一个正态分布；
- 方差齐性：不同组的方差相等或相近。

根据第三个前提，我们假设数据是正态分布，那么分布就有两个参数，一个是平均数，一个是方差。如果我们仅仅知道两个分组的平均值，但并不知道它们的方差相差多大，那么我们所得出的两个分布是否有显著差异的结论就不可靠了。

为了突出重点，我们先假设咱们的数据都符合上述四个前提，然后我来详细讲解一下方差分析的主要思想。最后，我会通过Python语言来验证各个假设和最终的F检验结果。
<div><strong>精选留言（13）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/12/69/c6/513df085.jpg" width="30px"><span>强哥</span> 👍（10） 💬（1）<div>我们这面的ab test计算显著性用的是t检验，不知道跟f检验的区别是什么？对于非参数检验的方法可以用bootstraping吧！分析师对这方面比较有研究</div>2019-03-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/42/df/a034455d.jpg" width="30px"><span>罗耀龙@坐忘</span> 👍（6） 💬（3）<div>茶艺师学编程

老师，我是这么理解方差分析的：

对于要考察的数据（符合正态分布），要想得出差异具有显著性，那么SSM&#47;分布自由度要比SSE&#47;误差自由度大上不少才行（分子比分母大不少）。

有意义的数据要比噪音要多，不然事情就是随机漫步或者是偶然（没有为什么）发生的。

不知道我这样子理解有没有问题?</div>2020-04-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/48/30/77c6c4ec.jpg" width="30px"><span>动摇的小指南针</span> 👍（4） 💬（1）<div>方差检验的前提是符合正态分布，那么针对用户转化率算法a和b而言，怎么理解这种分布呢，是指在某种用户特征分类的x坐标上，转化效果y坐标符合正态分布吗？</div>2019-05-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/0c/0f/93d1c8eb.jpg" width="30px"><span>mickey</span> 👍（3） 💬（1）<div>请问，显著性水平α为什么要取0.05？</div>2019-02-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/c1/1f/cc77944d.jpg" width="30px"><span>叮当猫</span> 👍（2） 💬（1）<div>请问F检验临界值表是怎么计算出来的？</div>2019-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/0c/0f/93d1c8eb.jpg" width="30px"><span>mickey</span> 👍（2） 💬（1）<div>算法a所导致的平均转化率要比算法b的相对高出约2% 是怎么计算出来的？</div>2019-02-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/d3/c0/d38daa2d.jpg" width="30px"><span>yaya</span> 👍（2） 💬（1）<div>笔记：两组样本的差异可能是由
1.采样造成的差异
2.数据分布不同造成的差异
如果要判断更多的是由哪种差异造成的，可以计算他们的比值。
采样的差异计算    各个数据到每个分布中心的距离和比如对第j水平来说，就是数据到j水平的距离，所有采样的差异就是所有水平的差异之和
分布造成的差异计算，就是各水平均值到所有均值的差异和
这两个差异我能理解，但是他们对应的量纲应该是不同的，就是他们不是同一基准下的差异但是为什么引入自由度就可以了呢？采样差异的自由度计算为什么要保证各水平均值不变，我没能理解</div>2019-02-25</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKSEVQdSoW2SxDVJOWaZ8dFZniaAG6pP8x3aYAMMbZtBSO9PYhI9ibUNmpNVsSHocnX4vXbL6LgJTaA/132" width="30px"><span>arcsinx</span> 👍（0） 💬（1）<div>老师，p&gt;0.05 可以接受原假设吗？我记得一般是反证，使p&lt;0.05之后拒绝原假设？</div>2021-07-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/0c/f0/27cc1584.jpg" width="30px"><span>撒冷之王</span> 👍（0） 💬（1）<div>你好， 例子中自变量数目 m = s-1 = 1;  不是太明白为什么 m 是根据 s-1 算出来的呢？ 如果是文中的例子，自变量数目不就是“不同的算法” 这一个自变量吗（m = 1 就直接得出了）</div>2021-07-21</li><br/><li><img src="" width="30px"><span>Geek3340</span> 👍（0） 💬（1）<div>1.H0是一定要用均值进行假设，而且一定是假设两组或者多组均值相等，是原假设吗？H1是不相等吗？ 2. “虽然算法a所导致的平均转化率要比算法b的相对高出约2%”，如果10天的平均值是0.298对比0.292，哪里来的高出2%呢？3. 如果方差分析，结果表明差异没有显著性，那下一步需要找其他什么分析方法来检验a&#47;b测试哪个好呢？ 4. 如何判断两组或多组数据一定是正态分布？如果不是正态分布，那怎么办呢？</div>2021-05-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/4d/9e/bfd34ad2.jpg" width="30px"><span>wuqg</span> 👍（0） 💬（1）<div>老师，除了pvalue还有置信区间来分析ab测试，您也给讲讲吧。</div>2020-12-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg" width="30px"><span>建强</span> 👍（1） 💬（0）<div>简单写了一个Python程序，实现了SST、SSM、SSE、F值的计算，P值就不知道怎么算了，程序代码如下：
# 方差分析
import pandas as pd
import numpy as np

class VarianceAnaly:
    def __init__(self,sampledata):
        self.sampledata = sampledata
        total_sum = 0
        total_count = 0
        for col in list(self.sampledata.columns):
            total_sum += self.sampledata[col].sum()
            total_count += self.sampledata[col].count()
        self.total_var = np.round(total_sum &#47; total_count,4)

    def sst(self):
        result = pd.DataFrame(index=self.sampledata.index, columns = self.sampledata.columns)
        total_sum = 0
        for col in list(result.columns):
            result[col] = (self.sampledata[col] - self.total_var) ** 2
            total_sum += result[col].sum()
        return np.round(total_sum,6)

    def ssm(self):
        total_sum = 0
        for col in list(self.sampledata.columns):
            total_sum += ((self.sampledata[col].mean() - self.total_var) ** 2) * self.sampledata[col].count()
        return np.round(total_sum,6)

    def sse(self):
        total_sum = 0
        for col in list(self.sampledata.columns):
            total_sum += sum((self.sampledata[col] - self.sampledata[col].mean()) ** 2)
        return np.round(total_sum,6)

    # 计算样本的F值
    def f_value(self):
        total_columns = len(self.sampledata.columns)
        total_sample_nums = sum(self.sampledata.count())
        f = self.ssm() * (total_sample_nums - total_columns) &#47; (self.sse() * (total_columns - 1))
        return np.round(f,6)

def test():
    sampledata = pd.DataFrame({&#39;algo_a&#39;:[0.29,0.36,0.32,0.29,0.34,0.24,0.27,0.29,0.31,0.27],
                               &#39;algo_b&#39;:[0.29,0.33,0.31,0.30,0.31,0.26,0.25,0.30,0.28,0.29]})
    test_var = VarianceAnaly(sampledata)
    print(&#39;sst=&#39;,test_var.sst())
    print(&#39;ssm=&#39;,test_var.ssm())
    print(&#39;sse=&#39;,test_var.sse())
    print(&#39;F=&#39;,test_var.f_value())

if __name__ == &#39;__main__&#39;:
    test()</div>2020-07-26</li><br/><li><img src="" width="30px"><span>Paul Shan</span> 👍（0） 💬（0）<div>F值反应了不同样本的差异是否由系统因素引起，而非采样的随机性引起的参数。
F值可以由样本的观察值计算得到。</div>2019-09-17</li><br/>
</ul>