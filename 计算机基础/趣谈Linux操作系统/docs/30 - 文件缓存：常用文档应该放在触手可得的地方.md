上一节，我们讲了文件系统的挂载和文件的打开，并通过打开文件的过程，构建了一个文件管理的整套数据结构体系。其实到这里，我们还没有对文件进行读写，还属于对于元数据的操作。那这一节，我们就重点关注读写。

## 系统调用层和虚拟文件系统层

文件系统的读写，其实就是调用系统函数read和write。由于读和写的很多逻辑是相似的，这里我们一起来看一下这个过程。

下面的代码就是read和write的系统调用，在内核里面的定义。

```
SYSCALL_DEFINE3(read, unsigned int, fd, char __user *, buf, size_t, count)
{
	struct fd f = fdget_pos(fd);
......
	loff_t pos = file_pos_read(f.file);
	ret = vfs_read(f.file, buf, count, &pos);
......
}


SYSCALL_DEFINE3(write, unsigned int, fd, const char __user *, buf,
		size_t, count)
{
	struct fd f = fdget_pos(fd);
......
	loff_t pos = file_pos_read(f.file);
    ret = vfs_write(f.file, buf, count, &pos);
......
}
```

对于read来讲，里面调用vfs\_read-&gt;\_\_vfs\_read。对于write来讲，里面调用vfs\_write-&gt;\_\_vfs\_write。

下面是\_\_vfs\_read和\_\_vfs\_write的代码。

```
ssize_t __vfs_read(struct file *file, char __user *buf, size_t count,
		   loff_t *pos)
{
	if (file->f_op->read)
		return file->f_op->read(file, buf, count, pos);
	else if (file->f_op->read_iter)
		return new_sync_read(file, buf, count, pos);
	else
		return -EINVAL;
}


ssize_t __vfs_write(struct file *file, const char __user *p, size_t count,
		    loff_t *pos)
{
	if (file->f_op->write)
		return file->f_op->write(file, p, count, pos);
	else if (file->f_op->write_iter)
		return new_sync_write(file, p, count, pos);
	else
		return -EINVAL;
}
```

上一节，我们讲了，每一个打开的文件，都有一个struct file结构。这里面有一个struct file\_operations f\_op，用于定义对这个文件做的操作。\_\_vfs\_read会调用相应文件系统的file\_operations里面的read操作，\_\_vfs\_write会调用相应文件系统file\_operations里的write操作。

## ext4文件系统层
<div><strong>精选留言（24）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/4a/2c/f8451d77.jpg" width="30px"><span>石维康</span> 👍（40） 💬（1）<div>查看文件缓存:通过free命令中的buff&#47;cache一栏的信息即可看到文件缓存的用量。
清除缓存：sync; echo 1 &gt; &#47;proc&#47;sys&#47;vm&#47;drop_caches</div>2019-06-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/5e/96/a03175bc.jpg" width="30px"><span>莫名</span> 👍（17） 💬（1）<div>“ext4_direct_IO 最终会调用到 __blockdev_direct_IO-&gt;do_blockdev_direct_IO，这就跨过了缓存层，直接到了文件系统的设备驱动层。” 觉得这个说法并不准确，绕过缓存，但并没有直接到达设备驱动层，而是通用块层，主要用于io合并之类操作，然后才是设备驱动层。</div>2019-07-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/a0/3f/06b690ba.jpg" width="30px"><span>刘桢</span> 👍（12） 💬（3）<div>打卡，今年12月冲北邮！</div>2019-06-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/63/9d/a5c2fe8c.jpg" width="30px"><span>马媛媛</span> 👍（10） 💬（1）<div>请问 ext4的Journal 模式有什么优势呢，有日志逐条落盘的这个开销，为啥write不直接落盘呢？</div>2019-06-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/44/a7/171c1e86.jpg" width="30px"><span>啦啦啦</span> 👍（7） 💬（3）<div>老师，我想问下，在学习mysql实战45讲这个课程里面，讲了数据库也有脏页和干净页，以及如何将脏页刷回磁盘的几个时机，请问这个机制是和本节课讲的操作系统的机制是一回事吗？谢谢老师</div>2019-07-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/86/fa/4bcd7365.jpg" width="30px"><span>玉剑冰锋</span> 👍（4） 💬（1）<div>请教老师个问题1.系统默认脏页多长时间或者数量是多少的时候触发事件？2.如果脏页在回写过程中出现故障如何保证数据完整性？3.这里只是提到ext4，其他文件系统跟ext4相比原理一样吗？比如xfs？</div>2019-06-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/a5/98/a65ff31a.jpg" width="30px"><span>djfhchdh</span> 👍（1） 💬（1）<div>free命令查看缓存</div>2019-06-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/0b/6f/68cd0614.jpg" width="30px"><span>brian</span> 👍（0） 💬（1）<div>缓存I&#47;O 内核缓存区 等于 内核缓冲区么 ？ 缓存，缓冲含义不是不同的吗？</div>2020-05-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/74/c9/d3439ca4.jpg" width="30px"><span>why</span> 👍（21） 💬（2）<div>- 系统调用层和虚拟文件系统层
    - 调用 read&#47;write 进行读写 → vfs_read&#47;write → __vfs_read&#47;write
    - 打开文件时创建 struct file, 其中有 file_operations, 虚拟文件系统调用 operations 中的 read&#47;write
- ext4 文件系统层
    - 调用到 generic_file_read&#47;write_iter,  其中判断是否需要使用缓存
    - 缓存, 即内存中一块空间, 可分为两类 I&#47;O
        - 缓存 I&#47;O: 默认模式, 读操作先检测缓存区中是否有, 若无则从文件系统读取并缓存; 写操作直接从用户空间赋值到内核缓存中, 再由 OS 决定或用户调用 sync 写回磁盘
        - 直接 I&#47;O: 程序直接访问磁盘, 不经过缓存
    - 直接 I&#47;O 过程:
        - 读: 若设置了 IOCB_DIRECT, 调用 address_space 的 direct_io 直接读取硬盘( 文件与内存页映射) ; 若使用缓存也要调用 address_sapce 进行文件与内存页的映射
        - 写: 若设置了 IOCB_DIRECT, 调用块设备驱动直接写入磁盘
    - 带缓存写过程
        - 在 while 循环中, 找出写入影响的页, 并依次写入, 完成以下四步
            - 每一页调用 write_begin 做准备
            - 将写入内容从用户态拷贝到内核态
            - 调用 write_end 完成写入
            - 查看脏页 (未写入磁盘的缓存) 是否过多, 是否需要写回磁盘
        - write_begin 做准备
            - ext4 是日志文件系统, 通过日志避免断电数据丢失
            - 文件分为元数据和数据, 其操作日志页分开维护
                - Journal 模式下: 写入数据前, 元数据及数据日志必须落盘, 安全但性能差
                - Order 模式下: 只记录元数据日志, 写日志前, 数据必须落盘, 折中
                - Writeback 模式下: 仅记录元数据日志, 数据不用先落盘
            - write_begin 准备日志, 并得到应该写入的缓存页
            - 内核中缓存以页为单位, 打开文件的 file 结构中用 radix tree 维护文件的缓存页
        - iov_iter_copy_from_user_atomic 拷贝内容, kmap_atomic 将缓存页映射到内核虚拟地址; 将拥护他数据拷贝到内核态; kunmap_aotmic 解映射
        - write_end, 先完成日志写入 并将缓存设置为脏页
        - 调用 balance_dirty_pages_ratelimited 若发先脏页超额, 启动一个线程执行回写.
            - 回写任务 delayed_work 挂在 bdi_wq  队列, 若delay 设为 0, 马上执行回写
            - bdi = backing device info 描述块设备信息, 初始化块设备时回初始化 timer, 到时会执行写回函数
        - 另外其他情况也会回写
            - 用户调用 sync 或内存紧张时, 回调用 wakeup_flusher_threads 刷回脏页
            - 脏页时间超过 timer, 及时回写
    - 带缓存读
        - generic_file_buffered_read 从 page cache 中判断是否由缓存页
            - 若没则从文件系统读取并预读并缓存, 再次查找缓存页
            - 若有, 还需判断是否需要预读, 若需要调用 page_cache_async_readahead
            - 最后调用 copy_page_to_user 从内核拷贝到用户空间</div>2019-06-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/ce/c6/958212b5.jpg" width="30px"><span>sugar</span> 👍（4） 💬（1）<div>看完了老师讲的文件系统的几节，收获颇丰。但如果想要自己去实践一下，很想知道有没有像wireshark那样的网络抓包工具一样底层的 可以针对文件系统，磁盘物理结构进行监控 分析的工具呢？google了一番没找到...</div>2019-06-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/8e/bb/c039dc11.jpg" width="30px"><span>garlic</span> 👍（3） 💬（0）<div>free 查看Cache分配使用情况，其中 page cache是针对 file systems ， buffer是针对 block devices 两者是在不同时期不同场景下涉及的缓存机制，kernel2.4版本之前是分开的，并存的。之后版本进行了融合， 清除缓存可以操作 &#47;proc&#47;sys&#47;vm&#47;drop_caches， 学习笔记https:&#47;&#47;garlicspace.com&#47;2021&#47;03&#47;30&#47;%e6%9f%a5%e8%af%a2%e5%92%8c%e6%b8%85%e9%99%a4%e6%96%87%e4%bb%b6%e7%b3%bb%e7%bb%9f%e7%bc%93%e5%ad%98&#47;</div>2021-04-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/39/fa/a7edbc72.jpg" width="30px"><span>安排</span> 👍（3） 💬（0）<div>打卡，每天课程发出后及时看完</div>2019-06-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/22/89/73397ccb.jpg" width="30px"><span>响雨</span> 👍（2） 💬（0）<div>缓存利用局部性原理提高数据的读写速度，同时日志系统能够使随机读写变为顺序读写，也能提高速度。</div>2020-12-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1a/51/b8/f76b15a1.jpg" width="30px"><span>sundy</span> 👍（1） 💬（0）<div>这一大段大段的代码真的没有太大意义</div>2024-08-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/22/f4/9fd6f8f0.jpg" width="30px"><span>核桃</span> 👍（1） 💬（0）<div>这里建议作者明确说一下bio的概念，不管是直接io还是走缓存，最后都是会封装成一个bio请求到block层的。

另外，这里有一句说法，所有的异步IO 都是直接IO，这点可以关联起来看</div>2021-05-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/aa/21/6c3ba9af.jpg" width="30px"><span>lfn</span> 👍（1） 💬（0）<div>2019-12-14，打卡。</div>2019-12-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/fd/80/52763d62.jpg" width="30px"><span>周平</span> 👍（1） 💬（0）<div>老师讲的很清晰，方便以后查看和复习</div>2019-06-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/0f/ab/9748f40b.jpg" width="30px"><span>微秒</span> 👍（1） 💬（0）<div>打卡，慢慢看，虽然不是很懂。</div>2019-06-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/fd/08/c039f840.jpg" width="30px"><span>小鳄鱼</span> 👍（0） 💬（0）<div>第二遍： 与CPU的回写（高速缓存）策略不同的是，CPU是第二次使用脏Cache Line时立即回写。而这里，要达到一定数量的脏页才回写。为此，还需要配合更多的触发回写：长时间未回写，缓存空间紧张，用户主动sync
此外，回写采用的是异步线程，也可能导致数据丢失。因此还提供了日志。默认策略是：order。
这一切都是为了性能服务的。但这个日志策略，还考虑了数据安全跟机制性能，没有把路封死。让用户自行选择！在开发基础设施的过程中，就应该同时考虑多种场景，不帮用户选择，让他自己选择？</div>2022-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/14/50/c23cf47d.jpg" width="30px"><span>李</span> 👍（0） 💬（0）<div>不知道老师还会解答不？我有个疑问

mmap 和write 写的区别，按原理，mmap少了一次用户到内核的数据拷贝，应该快一些。
但我发现写数据比较大的情况下， mmap比write反而慢了。
不知道这个是什么原因？


</div>2020-10-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/58/62/346dd248.jpg" width="30px"><span>Q罗</span> 👍（0） 💬（0）<div>元数据和数据有什么区别？</div>2020-06-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/11/e7/044a9a6c.jpg" width="30px"><span>book尾汁</span> 👍（0） 💬（0）<div>跟前面讲的映射文件到内存弄混了，
映射文件到内存是 先把用户态虚拟地址跟file关联，缺页时从缓存中或者新建页，然后加入页表，然后用kmap_atomic将物理页映射到内核虚拟地址，在将文件内容写入虚拟地址， 
这篇文章里的写的系统调用里，写入到文件的缓存中去，跟文件映射时候的缓存是一类缓存吗，都是address_space里的吗</div>2020-04-19</li><br/><li><img src="" width="30px"><span>201200986</span> 👍（0） 💬（0）<div>free命令可以查看，echo 3 &gt; &#47;proc&#47;sys&#47;vm&#47;drop_caches可以清除</div>2020-03-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/ac/96/46b13896.jpg" width="30px"><span>williamcai</span> 👍（0） 💬（3）<div>脏页在缓存中，如果掉电了，怎么保证回写到硬盘</div>2019-10-14</li><br/>
</ul>