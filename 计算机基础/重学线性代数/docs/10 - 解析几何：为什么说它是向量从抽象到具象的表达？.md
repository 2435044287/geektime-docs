你好，我是朱维刚。欢迎你继续跟我学习线性代数，今天我们要讲的内容是“解析几何”。

前面所有章节我们都是围绕向量、矩阵，以及向量空间来展开的。但这一节课有点不一样，我要讲的是解析几何，它使得向量从抽象走向了具象，让向量具有了几何的含义。比如，计算向量的长度、向量之间的距离和角度，这在机器学习的主成分分析PCA中是非常有用的。

## 范数

讲解析几何我们得从“范数”开始讲起。

因为很多人看到几何向量的第一反应就是，它是从原点开始的有向线段，并且向量的长度是这个有向线段的终端和起始端之间的距离。而范数，就是被用来度量某个向量空间或矩阵中的每个向量的长度或大小的。

现在，我们先来看一下范数的数学定义：一个向量空间$V$上的一个范数就是一个函数，它计算$V$中的每一个向量$x$的长度，用符号来表示的话就是：$\\|x\\| \\in R$，它满足三种性质：

1. 正齐次性： 如果输入参数扩大正$λ$倍，其对应的函数也扩正大倍。设$λ \\in R$，$x \\in V$，$\\|\\lambda x\\|=|\\lambda|\\|x\\|$；
2. 次可加性：类似三角不等式，两边之和大于第三边。设$x,y \\in V$，$\\|x+y\\| \\leq\\|x\\|+\\|y\\|$；
3. 正定性：向量$x$的长度一定大于等于零。$\\|x\\| \\geq 0$。
<div><strong>精选留言（3）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/18/61/a3/48bae4df.jpg" width="30px"><span>Dr.z</span> 👍（1） 💬（1）<div>老师 问一下
Φ2=Φ∘Φ=Φ
这里的空心圆 代表了什么操作？</div>2020-08-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（0） 💬（1）<div>请教老师两个问题，

1. 对称正定矩阵在深度学习中，被用来获取最小化损失函数。是因为正定矩阵可逆来求解吗？麻烦老师具体说一下
2. 投影矩阵P和SVM算法里的支持向量到超平面的距离看着蛮相似的，不知道这么理解是否正确？</div>2020-08-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/ec/3e/885ec1d2.jpg" width="30px"><span>宋不肥</span> 👍（0） 💬（0）<div>其实通过内积就可以得到距离和方向，利用这个关系就有了核化法。要是老师能在讲深一点就好了</div>2020-08-27</li><br/>
</ul>