你好，我是陈皓，网名左耳朵耗子。

我们知道，在多线程情况下访问一些共享资源需要加锁，不然就会出现数据被写乱的问题。在分布式系统下，这样的问题也是一样的。只不过，我们需要一个分布式的锁服务。对于分布式的锁服务，一般可以用数据库DB、Redis和ZooKeeper等实现。不管怎么样，分布式的锁服务需要有以下几个特点。

- **安全性（Safety）**：在任意时刻，只有一个客户端可以获得锁（**排他性**）。
- **避免死锁**：客户端最终一定可以获得锁，即使锁住某个资源的客户端在释放锁之前崩溃或者网络不可达。
- **容错性**：只要锁服务集群中的大部分节点存活，Client就可以进行加锁解锁操作。

# Redis的分布式锁服务

这里提一下，避免死锁的问题。下面以Redis的锁服务为例（参考 [Redis的官方文档](https://redis.io/topics/distlock) ）。

我们通过以下命令对资源加锁。

```
SET resource_name my_random_value NX PX 30000
```

解释一下：

- `SET NX` 命令只会在 `key` 不存在的时候给 `key` 赋值，`PX` 命令通知Redis保存这个key 30000ms。
- `my_random_value` 必须是全局唯一的值。这个随机数在释放锁时保证释放锁操作的安全性。
- PX 操作后面的参数代表的是这个key的存活时间，称作锁过期时间。
- 当资源被锁定超过这个时间时，锁将自动释放。
- 获得锁的客户端如果没有在这个时间窗口内完成操作，就可能会有其他客户端获得锁，引起争用问题。

这里的原理是，只有在某个key不存在的情况下才能设置（set）成功该key。于是，这就可以让多个进程并发去设置同一个key，只有一个进程能设置成功。而其它的进程因为之前有人把key设置成功了，而导致失败（也就是获得锁失败）。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/bb/c9/37924ad4.jpg" width="30px"><span>天天向上</span> 👍（17） 💬（3）<div>分布式锁 应该是 先获取锁 再进行业务操作 属于悲观锁 而用乐观锁代替 又演变为cas代替 这样合适吗？ 其实悲观和乐观 核心是面对的并发度不一样，如果在大并发下用乐观锁 应该失败的几率会增大，用悲观锁避免大量失败，但是会block！麻烦耗子哥 指导指导</div>2018-05-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/f8/ba/d28174a9.jpg" width="30px"><span>Geek_zbvt62</span> 👍（11） 💬（1）<div>皓哥，这篇文章前半段一直到cas之前基本是在说redlock，后面说到fence和cas，恰恰是redlock争论当中反方的观点---如果你想锁的资源，能提供给你cas功能，那还要分布式锁干嘛？这也是我的疑问，我觉得是悖论
在我使用consul时，我发现，如果我要锁住一个资源，理论上100%安全的必要条件是，我的资源就是那个锁本身，在consul就是那个资源只能是锁住key对应的value。consul本身也提供cas，但对客户端来说，没加锁的代码容易写
但换成其他资源，这个悖论就显现出来了。我的想法对么？</div>2018-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/18/ba/fb86482f.jpg" width="30px"><span>yun</span> 👍（36） 💬（15）<div>对资源修改，用cas而不是分布式锁，我反对
1:前提是共享资源的修改得提供cas,比如我要更新hdfs,然后再在hbase上更新meta,为了保证一致性，要用分布式锁
2，资源一存储在hbase,支持cas,资源二redis上，二者都支持cas,服务更新数据时要更新二者，服务是多个进城并发干，为了保证一致性，得有分布式锁，单个数据库的cas不行

cas和分布式锁是两个完全不同的东西，cas像是单机的乐观锁，能用cas的话，不用分布式式锁，那不废话吗？能单机干的，谁会上分布式
你跨多个服务，搞一个cas,试试？

文中的令牌和cas，他们间确实类似。但是分布式锁中带令牌，就是为了解决，客户端认为占有锁，到实际锁过期的问题，此时没必要对比cas

</div>2019-06-19</li><br/><li><img src="" width="30px"><span>Randy</span> 👍（28） 💬（13）<div>现实生活中也有不需要更新某个数据的场景，只是为了同步或是互斥一下不同机器上的线程，这时候像 Redis 这样的分布式锁服务就有意义了
这句没明白，如果要进行互斥或同步操作，那就是要对同一个资源进行写操作，如果只是读操作那就不需要锁保护了，那分布式锁的意义是什么？</div>2018-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/9f/32/277b55a9.jpg" width="30px"><span>林子</span> 👍（15） 💬（1）<div>如果用cas方式或者叫乐观锁来修改数据库中表（共享资源），会出现脏读问题，耗子叔，这点没提到。</div>2018-07-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/3a/d3/c273ee50.jpg" width="30px"><span>程序员Artist</span> 👍（12） 💬（6）<div>redis锁timeout确实是个问题，配合存储的版本控制一起做能解决数据准确问题。但是说存储上cas可以代替分布式锁，就不对了。分布式锁锁住的是计算过程和更新存储两件事，而cas只能管更新存储这一件事，也就是二者就不是一个级别的东西。再说锁住计算过程这件事在正常情况下是没有问题的，而当出现极端异常下的超时问题时，出现了同时计算，出现了冗余计算，这完全可以接受。</div>2019-06-26</li><br/><li><img src="" width="30px"><span>黄宸</span> 👍（6） 💬（1）<div>看完本章有点疑问，对于一般性的数据库修改都是有锁的，所以不存在并发问题，没必要用cas。而文中的redis分布式锁在使用过程中使用nx，px 实现了占位和过期的操作，从而达到分布式锁的效果。其中说到如果先持到锁的服务在一次执行中时间超时，锁释放；其他发现未执行完成，服务再次抢锁，此时存在两个服务都获得同一把锁，这时如果会出现更新覆盖的问题，个人觉得不能理解为分布式锁的问题，应该是程序设计上要考虑重复执行，或者如何去规避重复执行，或者执行补偿的问题。</div>2020-02-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/00/8e/ebe3c8ea.jpg" width="30px"><span>董泽润</span> 👍（4） 💬（0）<div>https:&#47;&#47;github.com&#47;dongzerun&#47;dlock
这是我在用的，redis lua 实现，和耗子叔的相似</div>2018-06-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/05/e5/aa579968.jpg" width="30px"><span>王磊</span> 👍（4） 💬（1）<div>皓哥，有个问题想确认下，redlock是要求各个节点独立部署，都是master,那么这样的部署方式是否就限定这N台Redis不能同时作为缓存服务器了?</div>2018-06-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/63/3c/b4cfbce9.jpg" width="30px"><span>华烬</span> 👍（4） 💬（1）<div>数据库用timestamp的判断是否冲突是有风险的吧</div>2018-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/ed/84/0b8e2d25.jpg" width="30px"><span>邓志国</span> 👍（4） 💬（0）<div>CAS代替分布式锁需要考虑数据库的隔离性，级别比较低的CAS不安全</div>2018-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/2d/ca/02b0e397.jpg" width="30px"><span>fomy</span> 👍（3） 💬（0）<div>支付回调返回就是使用的分布式锁来实现的，容许有一些错误的出现，但是实现起来会更简单一些。
Redis分布式锁是可以实现大粒度的锁，不需要考虑每一个点的更新插入都满足幂等性，实现起来更加简单快捷。小并发量时使用会更快捷。
数据库乐观锁只有在数据库操作时满足幂等性，但是其他redis、mongodb等的都是不可回滚的，所以这些场景下必须使用Redis分布式锁。可能更适合大并发量访问时候的。</div>2019-08-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/73/16/595b0342.jpg" width="30px"><span>slark</span> 👍（2） 💬（0）<div>数据库、Redis、Zookeeper，这三种是比较常见的分布式锁方式。
文章提到了一些锁可能会遇到的问题，给出了一些建议和思考，网友们的留言也建议要读一读，因为文章也不一定就都是完全试用任何场景的，比如数据库当锁可能会导致数据库性能问题</div>2020-02-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/ce/be/5cf3f1a0.jpg" width="30px"><span>junshuaizhang</span> 👍（2） 💬（1）<div>有两个问题
1.ABA问题文中没有介绍咋处理。
2.对于用库存当version虽然解决了并发问题，但是对实际性能影响太大。</div>2019-12-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/42/4f/ff1ac464.jpg" width="30px"><span>又双叒叕是一年啊</span> 👍（2） 💬（0）<div>发现了一篇 好文 https:&#47;&#47;juejin.im&#47;post&#47;5bbb0d8df265da0abd3533a5#heading-23 </div>2019-06-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/bd/68/3fd6428d.jpg" width="30px"><span>Cutler</span> 👍（2） 💬（0）<div>用过redis和etcd的分布式锁，用分布式锁的场景有两个，一个是定时任务，一个是阻止客户端的重复提交。</div>2019-04-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/14/ee/d72a8222.jpg" width="30px"><span>攻城拔寨</span> 👍（2） 💬（0）<div>锁还是感觉zk专业一点</div>2018-11-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/84/04/aceac3b5.jpg" width="30px"><span>流迷的咸菜</span> 👍（2） 💬（0）<div>文中说的RedLock应该是单节点的lock的实现吧？分布式的应该如下吧？
1. It gets the current time in milliseconds.
2. It tries to acquire the lock in all the N instances sequentially, using the same key name and random value in all the instances. During step 2, when setting the lock in each instance, the client uses a timeout which is small compared to the total lock auto-release time in order to acquire it. For example if the auto-release time is 10 seconds, the timeout could be in the ~ 5-50 milliseconds range. This prevents the client from remaining blocked for a long time trying to talk with a Redis node which is down: if an instance is not available, we should try to talk with the next instance ASAP.
3. The client computes how much time elapsed in order to acquire the lock, by subtracting from the current time the timestamp obtained in step 1. If and only if the client was able to acquire the lock in the majority of the instances (at least 3), and the total time elapsed to acquire the lock is less than lock validity time, the lock is considered to be acquired.
4. If the lock was acquired, its validity time is considered to be the initial validity time minus the time elapsed, as computed in step 3.
5. If the client failed to acquire the lock for some reason (either it was not able to lock N&#47;2+1 instances or the validity time is negative), it will try to unlock all the instances (even the instances it believed it was not able to lock).</div>2018-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/59/37/bd2de0a4.jpg" width="30px"><span>edisonhuang</span> 👍（1） 💬（0）<div>当我们需要对资源做互斥访问时，分布式服务也像单机服务一般，需要对资源加锁。分布式锁需要保证安全性，避免死锁和容错性</div>2019-07-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/fa/fb/ef99d6ca.jpg" width="30px"><span>tiger</span> 👍（1） 💬（0）<div>MySQL的事务在第一个事务获取共享锁之后，再获取排他锁的过程中，其它的事务也在等待获取排他锁，于是产生了死锁，这个可以通过重入锁解决，为什么MySQL没有这么做呢?</div>2018-07-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/c8/8f/e13a6552.jpg" width="30px"><span>polk</span> 👍（1） 💬（0）<div>首先不应该把锁的压力给数据库，数据库的性能相比redis差很多。
然后redis的那个潜在问题，把锁的timeout设置成http的timout，不就可以解决了。
我的理解是否有问题？</div>2018-07-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/8c/8f/64854769.jpg" width="30px"><span>prajba</span> 👍（1） 💬（0）<div>去年参与的自动化平台项目里用到了ZooKeeper悲观锁，回想起来当时并没有特别关注死锁问题，实现方式牺牲了故障情况下的一致性。</div>2018-04-19</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTI2oY8ENiaMbvm3OzHheCwibR5ArwgicrqvWAnzXxcmMYoFia9FfhIneXAf1kGXwRyWKaoHVJplCAhsfw/132" width="30px"><span>lyz</span> 👍（0） 💬（0）<div>会不会从性能角度采用分布式锁来代替数据库的cas操作</div>2023-07-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/92/6d/becd841a.jpg" width="30px"><span>escray</span> 👍（0） 💬（0）<div>感觉使用数据库对应记录带版本信息的乐观锁实现起来比较简单，其实以前不觉得字段的更新时间戳或者版本号有什么用，这回明白了。

如果最后的结论是不需要分布式锁——用来修改某个共享源的时候，那么就需要使用 CAS 无锁方式来更新数据。

在不同进程间同步或互斥的时候，可能需要分布式锁，那么可以考虑使用 Redis 或 ZooKeeper 来实现。

有一个疑惑，这个时候，Redis 或者 ZooKeeper 可能会成为单点瓶颈么？当然，他们俩都是高可用的。

看到留言里面出现了比较激烈的争论，于是硬着头皮去看了关于 RedLock 的 Distributed Locks with Redis，前半段能看差不多，后半段看懵了。

然后看了酷壳上的的《无锁队列的实现》以及留言里面提到的掘金上的文章。

虽然都看不太懂，但是推荐阅读顺序应该是：《无锁队列的实现》、Distributed Locks with Redis、《再有人问你分布式锁，这篇文章扔给他》</div>2023-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/4c/7e/4771d8a4.jpg" width="30px"><span>彭发红</span> 👍（0） 💬（0）<div>锁的设计原则
互斥：同一时刻临界区中最多存在一个线程
前进（Progress）: 如果一个线程想要进入临界区，那么它最终会成功
有限等待：如果一个线程i处于入口区，那么在i的请求被接受之前，其它线程进入临界区的时间是有限制的。尝试获取，减少上下文切换，提升效率
无忙等待（可选）： 如果一个进程在等待进入临界区，那么它可用进入之前被挂起</div>2023-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/70/40/ce062d99.jpg" width="30px"><span>丝竹乱耳</span> 👍（0） 💬（1）<div>Client B 重新申请到了这个锁。Client A 的解锁请求到达，将 Client B 锁定的 key 解锁。Client C 也获得了锁。Client B 和 Client C 同时持有锁。
这里写的不过， 因为 value 值不一样， 不能讲B的锁解锁。除非，你是相同的value, 这和你的假设违背。
这么多人，没人发现吗？


这里写的有问题。 
</div>2022-08-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/cc/de/e28c01e1.jpg" width="30px"><span>剑八</span> 👍（0） 💬（0）<div>分布式锁一般用于互斥多线程，一个作用是保证资源不被多线程并发操作道致问题。还有一种情况如缓存击穿的时候，可以加锁保证db不被打满</div>2022-04-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/e5/f2/791d0f5e.jpg" width="30px"><span>技术</span> 👍（0） 💬（0）<div>如果客户端处理时间如果大于上锁时间，导致锁已经被释放掉, 造成多个client获取到锁怎么办呢</div>2022-03-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/cb/d5/fab32cf7.jpg" width="30px"><span>卖藥郎</span> 👍（0） 💬（0）<div>etcd是分布式锁不错的选择</div>2021-11-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/b1/81/13f23d1e.jpg" width="30px"><span>方勇(gopher)</span> 👍（0） 💬（0）<div>锁被滥用在开发中很常见，大部分开发更习惯于悲观锁。之前评审的时候一个流程加了6把锁！的确很多场景采用CAS就足够了！</div>2021-11-05</li><br/>
</ul>