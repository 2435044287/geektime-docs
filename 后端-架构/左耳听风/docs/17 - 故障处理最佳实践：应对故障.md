你好，我是陈皓，网名左耳朵耗子。

或多或少我们都会经历线上的故障。在我的职业生涯中，就经历过很多的线上故障。老实说，线上故障是我们技术人员成长中必须要经历的事。从故障中我们可以吸取到很多教训，也能让我们学到很多书本上学不到的知识。坑踩多了，我们会变得越来越有经验，也就成为老司机了。

不过，我看到很多公司处理线上故障的方式并不科学，而且存在很多问题，所以，今天这节课就来分享一些我的经验。这些经验主要来自亚马逊和阿里这两家互联网公司，以及我个人的经验总结。希望这套方法能够对你有帮助。

# 故障发生时

在故障发生时，最重要的是快速恢复故障。而快速恢复故障的前提是快速定位故障源。因为在很多分布式系统中，一旦发生故障就会出现“多米诺骨牌效应”。也就是说，系统会随着一个故障开始一点一点地波及到其它系统，而且这个过程可能会很快。一旦很多系统都在报警，要想快速定位到故障源就不是一件简单的事了。

在亚马逊内部，每个开发团队至少都会有一位oncall的工程师。在oncall的时候，工程师要专心处理线上故障，轮换周期为每人一周。一旦发生比较大的故障，比如，S1全部不可用，或S2某功能不可用，而且找不到替代方案，那么这个故障就会被提交到一个工单系统里。几乎所有相关团队oncall的工程师都会被叫到线上处理问题。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/47/35/89726f5f.jpg" width="30px"><span>左耳朵</span> 👍（124） 💬（3）<div>自动地图生成一般用APM式的系统。开源的可以看看zipkin</div>2017-12-05</li><br/><li><img src="https://wx.qlogo.cn/mmopen/vi_32/DYAIOgq83eptCuRBA5qaBLSeWiadmRtibDATwbTCGbaedich6E4krkBr52YDc8RtCibz8Dz69txWJlLhG3IYozpcJg/132" width="30px"><span>paul.yang</span> 👍（24） 💬（1）<div>耗子叔，我是个自学转行做后端的程序员。最近在日活快接近2亿的一个后端团队里面犯了个错误导致某一个功能20分钟不可用，受到了打击，我微博给你留了言，希望能跟你交流下，寻求指导帮助。希望你能看到我的微博留言，呵呵的卫国杨</div>2018-07-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/7b/73/e5b46aa9.jpg" width="30px"><span>kimi</span> 👍（163） 💬（1）<div>2013 年，应该是 8 月吧，和耗子哥一起处理巨石塔上千台服务器宕机的故障，搞到凌晨三四点</div>2017-12-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/4a/cf/5cbccd62.jpg" width="30px"><span>ibrothergang</span> 👍（61） 💬（5）<div>“请你来聊聊，你所经历过的线上故障，以及有哪些比较好的故障处理方法。”

我是一名移动端开发的工程师。移动端的开发工作和前端(线上环境)开发还是有一点区别的。移动端的开发一般在上线前会做测试，严重的问题一般在测试过程就解决了，很少情况发版后出现大面积的奔溃情况。但是线上环境不一样，线上环境发版的周期会大大短于客户端，很多的活动都会频繁的上线和下线。影响的范围也大于移动端。

遇到过最严重的一次事故是由于服务端的修改引起了移动端的奔溃。而且这个奔溃发生在 app 启动的时候。也就是说用户点了应用图标，起来马上就又闪退了。当时的 app 设计是起来后会去请求服务端的相关配置信息，相信很多的 app 也是这么做的。造成这个故障的原因是由于 app 对异常的处理不够完备，服务器端又恰巧修改了配置数据，导致 app 端拿到了一个引起奔溃的数据结果。后来因为是上班时间，发现问题后大家都在，及时恢复了服务端数据，遏制了事态的进一步发展，但是已经出现奔溃的用户由于在重新请求服务端数据前就奔溃了，只能通过发布新版本解决这个问题。

一旦服务端和移动端相互影响(往往是服务端影响移动端)引起的奔溃，往往是比较严重的，很多时候不得不通过发布新版本才能解决问题。所以移动端一定要做好服务端的异常处理。</div>2017-11-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/f3/0d/6caad172.jpg" width="30px"><span>金胖子</span> 👍（56） 💬（1）<div>最典型的一次，项目组成员在测试版本中加了sleep来debug，结果上线的时候就把版本发布到生产，直接影响我第二天下午没能去看变形金刚</div>2018-02-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/1b/03/4d5c017f.jpg" width="30px"><span>艺漫漫</span> 👍（28） 💬（0）<div>每次线上故障处理都是知识体系验证和应用的战场。

2020-03-20&#47;21这两天处理了2个p1级别的问题，一个问题导致几乎所有竞价服务宕机了，这个问题是因为redis内存使用达到机器的限制上限被杀了，导致使用该redis的server重启异常，立即处理操作是rm rdb后重启redis，后续预防措施是增加redis内存和cpu使用监控。另一个问题是所有订单竞价异常，查了很久，定位到直接原因是预算同步机制变慢导致订单因为预算问题不竞价，根本原因是大数据包导致网络延时，进而导致预算同步变慢。查找2问题的过程很值得记录：根据其他服务处理时间监控，发现其他非竞价模块处理时间也严重变慢，进而使用iftop观察网络吞吐，发现有一个server1的入口带宽异常，而server1上的服务处理时间正常，最后根据这台server1上redis的cpu使用率和slowlog找到一条高达13M的异常数据。
</div>2020-03-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/f0/3e/ea2c1d43.jpg" width="30px"><span>晏</span> 👍（12） 💬（2）<div>出现故障时，最重要的不是 debug 故障，而是尽可能地减少故障的影响范围，并尽可能快地修复问题。</div>2018-07-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/9c/e9/5ba8b1a3.jpg" width="30px"><span>郭新鹏</span> 👍（11） 💬（1）<div>代码逻辑错误，导致查看分享的人能看到分享者所有信息，记录的上一个人的cookie.

Session存储在redis,  flush db。所有用户重新登陆</div>2018-06-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/d9/71/9c134b18.jpg" width="30px"><span>李印</span> 👍（11） 💬（2）<div>楼上的，类似工具:鹰眼，watchMan,京东的CallGraph</div>2018-05-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/51/29/24739c58.jpg" width="30px"><span>凉人。</span> 👍（8） 💬（0）<div>在bd实习的时候，有个很小的独立项目
项目中使用到容器和分布式文件系统，有种情况，当容器心跳检测时，如果检测失败，容器实例将产生漂移，漂移的过程会删除原容器的数据，所以产生一个情况，就是分布式文件系统里的数据都被删除。
导师和leader们快速定位了问题，数据也在是采用move的方式删除，很庆幸数据恢复了。也知道了一个项目的伟大是由一群有预见性的大佬们，和一堆可靠的同事们一起完成的。</div>2021-04-01</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLndPicaib35sSOgGib8iafFBq8B0hoBO3Bfp3QViblYQ669lRFjPD1RSX2rDibmElID00l5oWokhuZBJnw/132" width="30px"><span>Geek_7b1383</span> 👍（7） 💬（0）<div>故障源团队恢复系统：
重启和限流---可用性的问题，不是功能性的问题。
回滚操作---解决新代码的 bug
降级操作---挂一个停止服务的故障公告，主要是不要把事态扩大。
紧急更新---尤其需要强大的自动化测试和自动化发布系统
故障前的准备工作:
以用户功能为索引的服务和资源的全视图。
在地图中设置关键指标，以及运维流程和方案。
设定故障等级。
故障演练。
灰度系统

降级操作，除了皓哥这种，是否有一种业务配合降级譬如风险降级，通过开关避开相关校验，通过补偿措施解决线上故障</div>2020-04-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/9f/32/277b55a9.jpg" width="30px"><span>林子</span> 👍（5） 💬（1）<div>自动生成地图那是有什么工具推荐的吗？同问耗子哥</div>2017-12-01</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erdpKbFgRLnicjsr6qkrPVKZcFrG3aS2V51HhjFP6Mh2CYcjWric9ud1Qiclo8A49ia3eZ1NhibDib0AOCg/132" width="30px"><span>西北偏北</span> 👍（4） 💬（1）<div>凡事预则立，故障诊断和处理不是依赖人员的瞎猜，盲查，而是要在故障前就想好对应的预案，基础系统的研发支持，日志埋点等等。毕竟线上不方便像本地一样debug</div>2019-05-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/6e/49/abb7bfe3.jpg" width="30px"><span>小桥流水</span> 👍（4） 💬（1）<div>自动生成地图那是有什么工具推荐的吗？</div>2017-11-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/59/37/bd2de0a4.jpg" width="30px"><span>edisonhuang</span> 👍（3） 💬（0）<div>故障应对方法，分别包括故障发生时的恢复措施，自己故障发生前可做的准备。
故障发生时最重要的是限制故障影响的范围，尽最大可能保障服务的可用性，包括转发和限流，回滚，降级，服务重启，紧急更新，紧急发布等。
故障发生前应做好防范，需要以用户功能为索引建立全站服务和资源的地图，利用地图为各个服务生成关键性指标，并建立一套自动化运维的方案和工具。为故障设立等级，知道故障时我在哪，严重程度，进行必要的故障演练，做灰度发布等</div>2019-05-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/f0/3e/ea2c1d43.jpg" width="30px"><span>晏</span> 👍（3） 💬（0）<div>故障前的准备工作:
以用户功能为索引的服务和资源的全视图。
在地图中设置关键指标，以及运维流程和方案。
设定故障等级。
故障演练。
</div>2018-07-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/46/11/1cf8c174.jpg" width="30px"><span>小沫</span> 👍（3） 💬（0）<div>之前有一次线上系统出现故障，导致工单无法处理。原因是北向接口服务出现故障，定位起来不太方便。因为接口为集群部署（使用F5）当时没有好的运维工具，只能模拟请求接口，经过一轮验证后才发现接口故障点。想问下耗子叔，对于你文章中说的自动生成地图那是有什么工具推荐的吗？</div>2017-11-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/b1/81/13f23d1e.jpg" width="30px"><span>方勇(gopher)</span> 👍（2） 💬（0）<div>目前在做微服务治理云平台，涉及发布，熔断限流，故障演练相关！在尝试混沌工程！目前遇到的难题是告警收敛</div>2021-10-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/b9/19/f4ef2c9a.jpg" width="30px"><span>秦穆之</span> 👍（2） 💬（0）<div>根据过往的经验来看，首先进行在服务稳定版本上的性能压测和全链路压测，掌握服务本身以及上下游的性能瓶颈和各项指标的情况。其次，针对故障类型预备各种预案，包括但不限于（定位问题，扩容，上下线，主备切换，数据源切换，数据预热等）一定要具体到操作流程。预案可以不复杂，但是一定要有效。然后就是故障演习，多模拟一些场景，熟练一下操作，规范一下流程，完善一下预案。最后，临阵时，要冷静，要对服务的各项指标了然于胸。指标出现异常，要及时处理，不能等到出了问题才开始修补。</div>2020-03-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/fa/03/eba78e43.jpg" width="30px"><span>风清扬</span> 👍（1） 💬（0）<div>我从事推荐系统工程侧开发、运维、测试、上线，遇到的故障多是业务侧改动测试不充分导致，遇到问题最快的处理方式就是回退到上一个版本。
如果是服务器故障，一般会遇到机器不足,cpu跑的比较高，这个时候就直接扩容，如果遇到单机故障，可以通过监控系统看到哪台机器出问题，先把机器隔离了，再拉运维和硬件同事排查。</div>2023-07-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/37/72/a0/6efd6bbd.jpg" width="30px"><span>melody_code</span> 👍（1） 💬（0）<div>事前想办法设置屏障降发生，发生后快止损。从事前、事中、事后节点去review现有的机制流程、预案是否能在故障发生时有效运转，具体点从事故感知、止损、定位、复盘、验证，链路看是否都有有效的机制手段。</div>2023-05-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/0c/7e/64ebc2c6.jpg" width="30px"><span>枫笑天涯</span> 👍（1） 💬（0）<div>添加apm系统时也要注意，这种系统的漏洞和bug也可能导致生产服务不可用</div>2020-12-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/a0/a4/b060c723.jpg" width="30px"><span>阿斯蒂芬</span> 👍（1） 💬（0）<div>曾经线上的MongoDB集群间歇性挂掉节点，急于恢复重启过几次，后来排查得知是从节点部署到同一个物理机上导致该物理机压力过大，，说到底就是拓扑结构有问题。那时候也没什么可视化监控，真是原始，都靠人工一步步查。其实一些健康检查的指标，即使没有开箱即用的集成产品，自己做一些也是可以的，归根结底还是对故障不够重视。至于文档，手册类的，大家都知道它是好东西，但很多时候大家都不愿意去写或者写了就不维护了，也是个难题。</div>2020-06-11</li><br/><li><img src="" width="30px"><span>oci</span> 👍（1） 💬（0）<div>听老师分享，就是一种享受</div>2020-03-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/d8/4f/65abc6f0.jpg" width="30px"><span>KaitoShy</span> 👍（1） 💬（0）<div>遇到的故障还是蛮多的，由于网站是PHP在请求过密的时候，出现502</div>2019-03-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/d4/44/0ec958f4.jpg" width="30px"><span>Eleven</span> 👍（1） 💬（0）<div>故障发生时，我们公司一般按照顺序：重启和限流、紧急更新、版本回退、服务降级.</div>2019-02-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/96/ce/8c3bdbe5.jpg" width="30px"><span>Geek_fb3db2</span> 👍（1） 💬（0）<div>咨询下耗子叔 文章提到的降级限流有没有有什么成熟的解决方案 目前项目中领导提到了 但是不知道如何做</div>2018-11-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/ed/97/0356ef1e.jpg" width="30px"><span>永立</span> 👍（1） 💬（0）<div>技术不太够，这章很多内容看的不是很懂。</div>2018-09-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/e4/c7/7f8be879.jpg" width="30px"><span>山哥</span> 👍（1） 💬（0）<div>大佬，CMDB的服务视图能发出来看下？</div>2018-07-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/08/7f/a0b0ac74.jpg" width="30px"><span>KingPoker</span> 👍（1） 💬（0）<div>去年生产遇到不少问题，处理了几次，越来越有思路。
文章提到的各种工程化的管理，还需要很长的路</div>2018-06-17</li><br/>
</ul>