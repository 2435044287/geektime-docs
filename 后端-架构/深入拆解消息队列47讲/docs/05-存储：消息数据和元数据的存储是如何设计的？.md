你好，我是文强。今天我们讲消息队列的存储模块。

存储模块作为消息队列高吞吐、低延时、高可靠特性的基础保证，可以说是最核心的模块。从技术架构的角度来看，存储模块包含**功能实现和性能优化**两个方面，我们今天先聊存储模块的功能设计和实现。

上节课我们讲过，存储模块的主流程是数据的写入、存储、读取、过期。读写、持久化存储是基本功能，但因为消息队列独有的产品特性，主要被用来当缓冲分发，它的数据存储是临时的，数据持久化存储后，在一定的时间或操作后，需要能自动过期删除。

那对于消息队列这样有特殊需求的存储模块，我们在实现功能的时候要注意哪些事情呢？带着这个问题，我们开始今天的学习。

首先，一个前置信息你要清楚，消息队列中的数据一般分为**元数据和消息数据**。元数据是指Topic、Group、User、ACL、Config等集群维度的资源数据信息，消息数据指客户端写入的用户的业务数据。下面我们先来看元数据信息的存储。

## 元数据信息的存储

元数据信息的特点是数据量比较小，不会经常读写，但是需要保证数据的强一致和高可靠，不允许出现数据的丢失。同时，元数据信息一般需要通知到所有的Broker节点，Broker会根据元数据信息执行具体的逻辑。比如创建Topic并生成元数据后，就需要通知对应的Broker执行创建分区、创建目录等操作。
<div><strong>精选留言（14）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/cb/92/cfc1cfd3.jpg" width="30px"><span>贝氏倭狐猴</span> 👍（7） 💬（1）<div>老师您好，咨询一个问题：原文“纵观业界主流消息队列，三种方案都有在使用，RabbitMQ 选择的是第一个方案，Kafka 和 RocketMQ 选择的是第二种方案，Pulsar 选择的是第三种方案。不同消息队列的方案选择，主要都是考虑架构设计和组件开发时业务场景的影响。我个人觉得第三种比较合理。”问题是kafka里新group不是也可以消费其他group已经ackknowledged的消息么？那是不是也是第三种方案呢？</div>2023-07-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/0c/c2/bad34a50.jpg" width="30px"><span>张洋</span> 👍（6） 💬（1）<div>关于顺序写和随机写有一些问题？Kafka在分区特别多的时候，如果同时写的操作特别多的时候就有可能退化到随机写，但是RocketMq 在写数据的时候（如果Topic queue特别多的情况下）也要写索引文件（ConsumerQueue，IndexFile等等）,虽然是定时刷新的，如果与数据文件同时写的情况下，也有肯能存在退化到随机写的可能，不过这种概率要比Kafka低的多不知道这样理解对吗？</div>2023-07-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2e/e3/d9/a8b50c2d.jpg" width="30px"><span>勋</span> 👍（6） 💬（1）<div>老师您好，我问问，不理解dubbo和gRpc的区别，为什么不选dubbo，而是选gRpc作为RPC框架。

按我的理解

1. 序列化
      1. dubbo默认采用java原生序列化框架、json序列化框架。
      2. gRpc默认采用protoBuf框架，提高传输效率。
2. 语言支持
      1. dubbo跨语言支持较弱。
      2. gRpc支持多种语言。
3. 协议
      1. dubbo支持多种协议，http协议、dubbo协议等
      2. gRpc 默认为http2协议。http2协议支持NIO模式

问题：
为啥选gRPC而不是dubbo，dubbo也是基于NIO的多路复用的Reactor模型，也不差，是因为协议不高效、语言支持不够？还是其他原因，麻烦老师解答下。

 
</div>2023-07-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/0a/a4/828a431f.jpg" width="30px"><span>张申傲</span> 👍（4） 💬（2）<div>每个分区独立一个文件存储，在分区数量较多时会退化成全局磁盘随机I&#47;O，这也是Kafka在多Partition时吞吐量大幅下降的原因~</div>2023-06-30</li><br/><li><img src="" width="30px"><span>Geek_8562b2</span> 👍（3） 💬（2）<div>老师，为什么Kafka分区过多会导致顺序读写变为随机读写</div>2023-07-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/18/4f/9e4d5591.jpg" width="30px"><span>翡翠虎</span> 👍（1） 💬（1）<div>存储部分，嗅到了一点 bitcask 的味道，感觉很接近</div>2023-06-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/3c/fa/e2990931.jpg" width="30px"><span>文敦复</span> 👍（0） 💬（1）<div>文中提到：（对所有分区公用1个单文件的情况下）缺点是同一个分区的数据一般会在文件中的不同目录。 这个“目录”是不是指文件不同位置的意思？</div>2023-07-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/72/e2/9a19b202.jpg" width="30px"><span>阳阳</span> 👍（0） 💬（1）<div>如果能添加实战的内容就更好了。</div>2023-07-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg" width="30px"><span>aoe</span> 👍（0） 💬（2）<div>MQ 的 Topic、Partition 和 MySQL 的服务层、存储引擎层有点像</div>2023-06-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/28/43/5062a59b.jpg" width="30px"><span>shan</span> 👍（2） 💬（0）<div>总结

元数据的存储一般有两种方式：
1. 基于第三方组件存储，一般会选用此种方式，比如Kafka Zookeeper版本。RocektMQ早期使用Zookeeper，后来选择自己实现注册中心NameServer的方式来替代来替代ZooKeeper；
优点：集成方便，降低开发难度和工作成本。
缺点：增加部署和运维的难度，而且第三方组件自身稳定性会增加系统风险。
2. 在集群内部存储，在集群内部实现类似第三方组件一样的元数据服务，比如Kafka去ZooKeeper的版本。
优点是运维部署成本低，缺点是开发成本高，与方式一的优缺点刚好相反。

消息数据的存储

存储结构
一般会消息指定一个Topic，每个Topic下面又划分为多个分区（kafka叫partition，RocketMQ叫MessageQueue），一般有以下两种存储方式：
1. 每个分区对应一个文件，存储每个分区上的消息，Kafka采用的这种方式实现；
优点：同一个分区的消息顺序写入同一个文件中，数据存储连续，读写性能都较好。
缺点：分区太多占用太多的系统FD资源，硬盘层面会出现大量随机写的情况，导致写入性能下降，并且管理复杂；
2. 每个节点上所有分区的消息都存储在同一个文件，不过需要创建索引文件，记录每条消息在文件中的偏移量，以便快速定位到消息的内容，RocketMQ采用的此种方式；
缺点：同一个分区的消息被打乱，在读取的时候，无法利用顺序读的优势，影响读取性能。
优点：管理简单，不会占用太多FD资源，并且写入是顺序写，性能比较高。

数据分段
数据分段指的是文件的大小，比如默认1G一个文件，超出1G的时候会新建一个文件，分为了多个文件的时候，读取数据需要先定位文件，定位方式有两种：
1. 根据偏移量定位，通过记录每个文件的起始偏移量、中止偏移量等信息来定位；
2. 根据索引定位，维护一个单独的索引文件，记录消息在文件的哪个位置，RocketMQ和RabbitMQ采用的是这种方式；

消息数据存储格式
消息数据存储格式指消息是以什么格式写入到文件中的，里面都包含什么信息。一般会包含通用信息（时间戳、CRC、长度等）和业务信息（事务、系统标记等）两部分。

数据清理机制
数据清理一般有以下三种实现方式：
1. 消费完成执行ACK删除：当客户端成功消费数据后，服务端标记删除；
2. 根据时间和保留大小删除：消息被消费后不会被立刻删除，服务端根据消息的保留策略，开启异步线程进行清理；
3. ACK机制和过期机制相结的方式；
RabbitMQ 选择的是第一个方案，Kafka 和 RocketMQ 选择的是第二种方案，Pulsar 选择的是第三种方案。</div>2023-09-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/0a/a4/828a431f.jpg" width="30px"><span>张申傲</span> 👍（2） 💬（0）<div>强哥讲的真好~</div>2023-06-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/e7/8e/318cfde0.jpg" width="30px"><span>Spoon</span> 👍（0） 💬（0）<div>根据偏移量定位，当一个分区的消息A被拆分到不同的两个文件中时，这个案例可以详细说一下吗？</div>2024-03-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/04/0d/3dc5683a.jpg" width="30px"><span>柯察金</span> 👍（0） 💬（2）<div>有一点很不解：
kafka 分区太多，读写的时候导致随机 io 严重。但是 rocket mq，分区都是写到一个文件，写的随机 io 不严重，但是每个分区的数据交织在一个文件的不同位置，那读的时候不是很严重的随机 io 嘛

很难说哪个更好呢</div>2024-03-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/5f/b9/6dbac933.jpg" width="30px"><span>Faddei</span> 👍（0） 💬（0）<div>老师你好，这节课提到两张存储方案，每个 Partition&#47;Queue 单独一个存储文件，每台节点上所有 Partition&#47;Queue 的数据都存储在同一个文件。</div>2024-03-28</li><br/>
</ul>