你好，我是蒋德钧。

在使用主从集群时，我曾遇到过这样一个问题：我们的主从集群有1个主库、5个从库和3个哨兵实例，在使用的过程中，我们发现客户端发送的一些数据丢失了，这直接影响到了业务层的数据可靠性。

通过一系列的问题排查，我们才知道，这其实是主从集群中的脑裂问题导致的。

所谓的脑裂，就是指在主从集群中，同时有两个主节点，它们都能接收写请求。而脑裂最直接的影响，就是客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端会往不同的主节点上写入数据。而且，严重的话，脑裂会进一步导致数据丢失。

那么，主从集群中为什么会发生脑裂？脑裂为什么又会导致数据丢失呢？我们该如何避免脑裂的发生呢？这节课，我就结合我遇见的这个真实问题，带你一起分析和定位问题，帮助你掌握脑裂的成因、后果和应对方法。

## 为什么会发生脑裂？

刚才我提到，我最初发现的问题是，在主从集群中，客户端发送的数据丢失了。所以，我们首先要弄明白，为什么数据会丢失？是不是数据同步出了问题？

### 第一步：确认是不是数据同步出现了问题

在主从集群中发生数据丢失，最常见的原因就是**主库的数据还没有同步到从库，结果主库发生了故障，等从库升级为主库后，未同步的数据就丢失了。**
<div><strong>精选留言（26）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/49/a5/e4c1c2d4.jpg" width="30px"><span>小文同学</span> 👍（83） 💬（1）<div>穿插使用 CAP 理论来分析一下课程的内容：
1. redis 集群允许脑裂存在，其实是一种可用性高的特征，但不保证数据一直。
2. redis 通过设置两个参数，一定程度上其实是在降低可用性，以提供数据一致性。
3. 为什么愿意降低可用性？因为那部分的数据会因为主从切换而丢失，所以宁愿不可用。</div>2020-12-10</li><br/><li><img src="" width="30px"><span>Geek_d1eece</span> 👍（2） 💬（1）<div>老师用的画图工具叫什么？</div>2020-11-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/90/8a/288f9f94.jpg" width="30px"><span>Kaito</span> 👍（304） 💬（24）<div>假设我们将 min-slaves-to-write 设置为 1，min-slaves-max-lag 设置为 15s，哨兵的 down-after-milliseconds 设置为 10s，哨兵主从切换需要 5s。主库因为某些原因卡住了 12s，此时，还会发生脑裂吗？主从切换完成后，数据会丢失吗？

主库卡住 12s，达到了哨兵设定的切换阈值，所以哨兵会触发主从切换。但哨兵切换的时间是 5s，也就是说哨兵还未切换完成，主库就会从阻塞状态中恢复回来，而且也没有触发 min-slaves-max-lag 阈值，所以主库在哨兵切换剩下的 3s 内，依旧可以接收客户端的写操作，如果这些写操作还未同步到从库，哨兵就把从库提升为主库了，那么此时也会出现脑裂的情况，之后旧主库降级为从库，重新同步新主库的数据，新主库也会发生数据丢失。

由此也可以看出，即使 Redis 配置了 min-slaves-to-write 和 min-slaves-max-lag，当脑裂发生时，还是无法严格保证数据不丢失，它只能是尽量减少数据的丢失。

其实在这种情况下，新主库之所以会发生数据丢失，是因为旧主库从阻塞中恢复过来后，收到的写请求还没同步到从库，从库就被哨兵提升为主库了。如果哨兵在提升从库为新主库前，主库及时把数据同步到从库了，那么从库提升为主库后，也不会发生数据丢失。但这种临界点的情况还是有发生的可能性，因为 Redis 本身不保证主从同步的强一致。

还有一种发生脑裂的情况，就是网络分区：主库和客户端、哨兵和从库被分割成了 2 个网络，主库和客户端处在一个网络中，从库和哨兵在另一个网络中，此时哨兵也会发起主从切换，出现 2 个主库的情况，而且客户端依旧可以向旧主库写入数据。等网络恢复后，主库降级为从库，新主库丢失了这期间写操作的数据。

脑裂产生问题的本质原因是，Redis 主从集群内部没有通过共识算法，来维护多个节点数据的强一致性。它不像 Zookeeper 那样，每次写请求必须大多数节点写成功后才认为成功。当脑裂发生时，Zookeeper 主节点被孤立，此时无法写入大多数节点，写请求会直接返回失败，因此它可以保证集群数据的一致性。

另外关于 min-slaves-to-write，有一点也需要注意：如果只有 1 个从库，当把 min-slaves-to-write 设置为 1 时，在运维时需要小心一些，当日常对从库做维护时，例如更换从库的实例，需要先添加新的从库，再移除旧的从库才可以，或者使用 config set 修改 min-slaves-to-write 为 0 再做操作，否则会导致主库拒绝写，影响到业务。</div>2020-11-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/43/79/18073134.jpg" width="30px"><span>test</span> 👍（14） 💬（1）<div>课后问题：仍然可能会发生数据丢失。究其原因是redis内部没有共识算法保证数据同步，写数据的时候只是写入主库即可返回成功，数据同步到从库是通过异步处理的。</div>2020-11-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/d4/f3/129d6dfe.jpg" width="30px"><span>李二木</span> 👍（13） 💬（0）<div>最欣赏的是排查分析问题的过程。</div>2020-11-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/ec/a7/7d44c655.jpg" width="30px"><span>snailshen</span> 👍（9） 💬（0）<div>老师您好，防止脑裂我认为有2点需要注意：
1可以考虑把多个sentinel节点部署到不同的机房，减少由于网络原因导致的误判。
2.redis master主节点主机，避免高负载，部署时留有一些冗余

关于min-slaves-to-write，min-slaves-max-lag这两个配置，主要是解决主从同步数据一致性问题的，尽量减少主从同步的数据不一致，我觉得不能从根本上通过这两个参数解决脑裂。比如master和slave的网络很好，那么这两个参数失效，如果这个时候3个sentinel节点的到master的网络都异常并且这些节点到slave网络良好，那么一样会触发主从切换，造成脑裂。我是这样理解的，希望老师指正！</div>2020-11-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/92/6d/becd841a.jpg" width="30px"><span>escray</span> 👍（5） 💬（0）<div>其实我不太关心脑裂，但是我对于发现数据丢失之后的故障排查思路比较感兴趣。

1. 确认数据同步是否有问题，检查主从库复制进度差值（master_repl_offset 和 slave_repl_offset）
2. 排查客户端日志，发现脑裂
3. 发现原主库假故障导致脑裂

利用 min-slaves-to-write 和 min-slaves-max-lag 两个配置项搭配使用，可以避免脑裂。参考文中的例子，min-slaves-to-write 设置为 1，就是说只要有一个从库无法在 min-slaves-max-lag 的时间内发送代表主从复制完成的 ACK 消息，原主库就不能再接收客户端请求了。

假设从库有 K 个，那么 min-slaves-to-write 就设置为 K&#47;2+1，其实超过半数的从库，再结合哨兵机制的 quorum，就可以避免脑裂。

对于课后题，按照题目的条件，min-slaves-to-write 设为 1，min-slaves-max-lag 设为 15s，哨兵 down-after-milliseconds 设置为 10s，哨兵主从切换 5s，主库卡住 12s，我觉的可能不会发生脑裂。

主库卡住 12s，哨兵已经判定原主库下线了，而因为 min-slave-to-write 和 min-slaves-max-lag 的设置，只有超过 15s，才会拒绝原主库接受客户端请求，也就是说从第 12s 到 15s 之间，原主库可以接受客户端请求，而 15s 后，主从切换完成，新主库开始接收客户端请求，而原主库在 12s 后接收的请求可以同步到新主库。

看了课代表的答案，其实我也纠结，原主库从 12s 到 15s 接收到的请求能否同步到新主库。

课代表对于只有一个从库，且设置了 min-slave-to-write 为 1 的时候，运维操作注意事项的提醒很有价值。</div>2021-04-02</li><br/><li><img src="" width="30px"><span>我很迪奥</span> 👍（4） 💬（11）<div>不太明白为什么需要引入min-slaves-to-write，min-slaves-max-lag这两个参数来避免脑裂，为什么不在哨兵认为主库客观下线的时候，就禁止主库的写操作。</div>2020-12-21</li><br/><li><img src="" width="30px"><span>与君共勉</span> 👍（3） 💬（1）<div>min-slaves-max-lag是不是一般要设置成比down-after-milliseconds小的值最好？</div>2020-11-04</li><br/><li><img src="" width="30px"><span>Geek_3d51a3</span> 👍（2） 💬（0）<div>redis执行slave of之后，就变成了只读实例，写入会报错</div>2021-02-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/7f/91/962eba1a.jpg" width="30px"><span>唐朝首都</span> 👍（2） 💬（0）<div>Redis无法完全避免脑裂的产生，因为其不保证主从的强一致，所以必然有产生脑裂的可能性。</div>2020-11-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/41/6c/687c5dfb.jpg" width="30px"><span>叶子。</span> 👍（2） 💬（2）<div>老师可否讲讲 Cluster模式下的脑裂？</div>2020-11-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/4d/5f/835a9d46.jpg" width="30px"><span>信念</span> 👍（1） 💬（2）<div>Min-slave-max-lag和down-after-milliseconds设置成一样的值是不是就可以了，在准备开始切换的时候，就不让主库接受命令了，这样做可以吗？</div>2021-10-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/d8/02/c749e2c7.jpg" width="30px"><span>天空</span> 👍（1） 💬（2）<div>很奇怪啊，为什么已经发生了切换，原主库还提供服务</div>2021-03-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/a4/27/15e75982.jpg" width="30px"><span>小袁</span> 👍（1） 💬（1）<div>如果这么容易引起脑裂（仅仅是参数配置不合理），redis有做一些基础的检查检测这些问题么？要去翻客户端日志再结合原理发现问题，这本身就不够友好了</div>2020-12-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/ba/08/35dcf833.jpg" width="30px"><span>子谦</span> 👍（0） 💬（0）<div>新版redis的配置项已经改为min-replicas-to-write和min-replicas-max-lag。另外，注释中是这样说的&quot;Setting one or the other to 0 disables the feature&quot;。也就是说如果将min-replicas-to-write设为1，则关闭这个功能。所以现在最新的版本如果想要开启，则至少设为2？</div>2023-12-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/31/7b/be/791d0f5e.jpg" width="30px"><span>Geek_595be5</span> 👍（0） 💬（0）<div>请教一下，我理解主库cup满了或者超负载不支持心跳，这种情况一般本身也不支持处理已后续的客户端请求吧？通过限制不支持心跳期间处理请求（卡主期间）貌似意义不大
文中也是描述了是后续cpu降下来之后可以继续处理请求了，应该是防止的选举期间，原主库可用的情况下，如何避免处理请求</div>2023-12-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/9a/ab/fd201314.jpg" width="30px"><span>小耿</span> 👍（0） 💬（0）<div>请问老师，为何主库被哨兵判断下线以后还能继续接收客户端的命令？</div>2023-09-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/55/85/16dc433c.jpg" width="30px"><span>几多对</span> 👍（0） 💬（1）<div>老师,主从加上VIP飘移还会发生脑裂吗?</div>2023-07-26</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/dr34H3hOMVsibL0XV1iaBWFiaTnYssX8sNjmJDpiaBUVv2X39nFzDjNpe288cKkZfH3P9sVRxZ1lzYZEcRR3vJNYtA/132" width="30px"><span>Benson_Geek</span> 👍（0） 💬（0）<div>一路被误导过来，还以为从标记了主是客观下线后，旧主就不能再接受数据了。。。
原来这时候旧主还可以接受数据啊。。。</div>2021-11-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/fe/a2/5252a278.jpg" width="30px"><span>对方正在输入。。。</span> 👍（0） 💬（0）<div>zk选举时的令牌，就会保证不会发生爆裂</div>2021-09-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/bc/25/1c92a90c.jpg" width="30px"><span>tt</span> 👍（0） 💬（1）<div>老师您好，我回头看的时候，结合第8课，产生了一个问题，切换主库完成后，如果客户端订阅了哨兵的新主库切换事件的话，是不是就不会发生脑裂了？或者应该是主库切换有一个过程，这个过程完成之前，还是会发生数据的丢失？</div>2021-09-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/d9/ff/b23018a6.jpg" width="30px"><span>Heaven</span> 👍（0） 💬（0）<div>这是必然的,因为,假设10s后哨兵达成了客观下线,那么会进行主从切换的操作,但是这个时候,主库还没达到min-slaves-max-lag时间,这时候还是可以接受客户端请求的,故可能导致了脑裂问题</div>2021-08-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/27/4b/e49c82d0.jpg" width="30px"><span>Rover</span> 👍（0） 💬（1）<div>哨兵模式下客户端连接的不是哨兵节点信息嘛，既然发生了切换，那么通过哨兵节点获得的主库应该是切换后的，为何客户端还会写到原主库？
哪位老哥解释下</div>2021-06-08</li><br/><li><img src="" width="30px"><span>yzz</span> 👍（0） 💬（2）<div>老师您好，针对您分析的脑裂的产生原因，我有一个疑问：您在前面分析问题的过程中排除了主从库之间复制进度不一致的问题，既然主从库之间是完全同步的，那主库重新变为可用之后写入的数据应该已经同步到从库了，那么经过主从切换后，数据是不是也不应该丢呢？</div>2020-12-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/dd/9b/0bc44a78.jpg" width="30px"><span>yyl</span> 👍（0） 💬（0）<div>生产环境更为复杂，Redis跨机器多实例部署，网络状况抖动时，应该还是会出现脑裂问题，感觉无法完全避免啊</div>2020-11-07</li><br/>
</ul>