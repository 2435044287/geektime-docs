你好，我是蒋德钧。

咱们的课程已经更新9讲了，这段时间，我收到了很多留言。很多同学都认真地回答了课后思考题，有些回答甚至可以说是标准答案。另外，还有很多同学针对Redis的基本原理和关键机制，提出了非常好的问题，值得好好讨论一下。

今天，我就和你聊一聊课后题答案，并且挑选一些典型问题，集中进行一次讲解，希望可以解决你的困惑。

## 课后思考题答案

### [第1讲](https://time.geekbang.org/column/article/268262)

**问题：和跟Redis相比，SimpleKV还缺少什么？**

@曾轼麟、@Kaito 同学给出的答案都非常棒。他们从数据结构到功能扩展，从内存效率到事务性，从高可用集群再到高可扩展集群，对SimpleKV和Redis进行了详细的对比。而且，他们还从运维使用的角度进行了分析。我先分享一下两位同学的答案。

@曾轼麟同学：

> 1. 数据结构：缺乏广泛的数据结构支持，比如支持范围查询的SkipList和Stream等数据结构。
> 2. 高可用：缺乏哨兵或者master-slave模式的高可用设计；
> 3. 横向扩展：缺乏集群和分片功能；
> 4. 内存安全性：缺乏内存过载时的key淘汰算法的支持；
> 5. 内存利用率：没有充分对数据结构进行优化，提高内存利用率，例如使用压缩性的数据结构；
> 6. 功能扩展：需要具备后续功能的拓展；
> 7. 不具备事务性：无法保证多个操作的原子性。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/41/5e/9d2953a3.jpg" width="30px"><span>zhou</span> 👍（43） 💬（6）<div>感谢老师的答疑，明白了写时复制的底层原理。之前一直以为主进程有写操作时，fork 出来的子进程会复制一份物理内存数据过来，实际上只会复制一份页表，相对于内存数据，页表数据小很多。</div>2020-08-26</li><br/><li><img src="" width="30px"><span>袁东昊的电信手机</span> 👍（21） 💬（1）<div>请问下老师：目前使用比较多的都是Redis Cluster模式，RedisCluster模式已经可以自己选主了，为什么还还这么多研究Redis Sentinel。</div>2020-11-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/dd/9b/0bc44a78.jpg" width="30px"><span>yyl</span> 👍（2） 💬（1）<div>欢呼，有些地方自己理解的是正确的😎
晚上回去再核对一遍</div>2020-08-26</li><br/><li><img src="" width="30px"><span>赵茭茭</span> 👍（135） 💬（5）<div>前9讲 我一共学了 3遍 真的是每一次学习都理解不同 学的越来越深 真的是很棒的文章 比网上的博客强太多了 很系统</div>2020-12-05</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/jgEicJMDKtww4iayMAw247KHwX2N4g5xoGrW5pjVsgJhpibFgs79uVibjOTVuo1ia17XHyHzlk4xvJSP2OCE0AD14xg/132" width="30px"><span>Geek_8b8d3d</span> 👍（49） 💬（4）<div>我觉得基础篇就够我去面试了</div>2021-04-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/29/42/43d4b1a8.jpg" width="30px"><span>烫烫烫</span> 👍（13） 💬（7）<div>关于rehash的触发时机，装载因子&gt;=1和&gt;=5是不是太大了？当装载因子接近1的时候，冲突概率已经很严重了吧。我记得大部分语言（Java&#47;C&#47;C#&#47;Go）的哈希表扩容时机，装载因子都小于1。有老师或哪位同学能帮我解惑吗？</div>2020-11-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/23/5b/983408b9.jpg" width="30px"><span>悟空聊架构</span> 👍（12） 💬（0）<div>这个复盘总结得很棒，看完后建议回头再看下前面几篇。</div>2021-05-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2c/72/ad/e22c4507.jpg" width="30px"><span>阮华</span> 👍（9） 💬（4）<div>从5:30到现在9:36，一口气把这10课基础篇看完了，受益颇多，这一天学的比我前几年学的都深入。</div>2022-02-26</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/fyGStpP7R15BpL6fXiaCQk5dHtfbIkmpJ9QmgSibuwTQK6M1DibTxVttRFtztxdWiams0UOXM28GlQKmeNukRXLvBg/132" width="30px"><span>Geek_ee09b9</span> 👍（7） 💬（0）<div>学到这里,有点忘了再看一遍</div>2020-09-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/25/7f/473d5a77.jpg" width="30px"><span>曾轼麟</span> 👍（6） 💬（0）<div>谢谢老师的解答和认可</div>2020-08-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/f7/42/eb46c66a.jpg" width="30px"><span>keaper</span> 👍（5） 💬（3）<div>关于“采用渐进式 hash 时，如果实例暂时没有收到新请求，是不是就不做 rehash 了？”这个问题
在阅读源码中注意到 在定时任务中会 对redis的 数据字典（保存每个键值对数据的dict结构）和过期字典（保存每个键值对过期时间的dict）这两个dict结构进行rehash，那么对于Hash数据类型所对应的dict结构（执行&quot;HSET&quot;命令创建的dict结构），是否也会有这种后台定时rehash的机制呢？
希望老师和各位同学能解答一下。</div>2020-08-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/24/df/645f8087.jpg" width="30px"><span>Yayu</span> 👍（4） 💬（2）<div>请问老师，写时复制的实现机制这里，是不是少了一部分，子线程读取操作系统复制出来的“写”数据，写入到RDB 文件，否则更新的数据何时体现到RDB 文件中？</div>2020-09-01</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIXeicJJQk6sbWzIQfVRHoUIPkQYyXRFZ6V0O42ddCic9ypt0liciaPFwicicfpo5HJ3ibicNtL5wkXlcib5CQ/132" width="30px"><span>nwc</span> 👍（3） 💬（2）<div>为什么进行RDB文件生成和AOF重写的时候不能进行rehash操作，原因还是不清楚。
RDB的生成和AOF重写都是fork出来子进程来进行的，而且都是对内存中的数据进行备份；
但是rehash只是对全局hash表进行操作，不太清楚rehash会对RDB的生成和AOF的重写造成什么影响，感觉肯定不是因为rehash的资源占用。</div>2022-01-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/f3/69/7039d03f.jpg" width="30px"><span>渔村蓝</span> 👍（2） 💬（0）<div>replication buffer是在初始化的时候，从库与主库同步数据，每个从库启动时间不一样，初始化的时间也不一样，复制期间的增量数据就不一样，所以每个客户端都有1个replication buffer。repl_backlog_buffer 是在运行过程中，从库因为网络等原因与主库断开连接，无法同步到最新数据，但是记录了自己同步到哪了，在从库恢复网络后告诉主库自己复制到哪了，主库就从哪里开始继续发送写命令给从库，由于位置是从库指定的，所以大家共用1个就好了，数据都在那里</div>2021-11-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/20/36/5e/c1d63d93.jpg" width="30px"><span>张小帆</span> 👍（2） 💬（0）<div>感觉老师比自己思考的多很多 很棒</div>2020-08-26</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erJ33eSC72BTHlwIPBdSFNFuXgX4FDibW0AuFuHqyXndpAqUZN7RDYAP4QTZHdG55q8weWYt3BkrrQ/132" width="30px"><span>Geek_a25096</span> 👍（1） 💬（2）<div>当把书看完之后再来看这个简直不要太完美，讲的非常好</div>2021-06-25</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaELZPnUAiajaR5C25EDLWeJURggyiaOP5GGPe2qlwpQcm5e3ybib8OsP4tvddFDLVRSNNGL5I3SFPJHsA/132" width="30px"><span>null</span> 👍（1） 💬（1）<div>老师，您好！

如果装载因子小于 1，或者装载因子大于 1 但是小于5，
在进行 RDB 生成和 AOF 重写时，哈希表的 rehash 是被禁止的，这是为了避免对 RDB 和 AOF 重写造成影响。

1.为什么 RDB 和 AOF 重写时，禁止 rehash，是为了避免主线程大量的 cow 么？

2. 那如果是这个原因，为什么装载因子大于等于 5 时却不受这限制，在 RDB AOF 重写时允许 rehash？此时元素冲突更多，rehash 时 cow 不是更费资源么？

谢谢老师！</div>2021-05-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/96/47/93838ff7.jpg" width="30px"><span>青鸟飞鱼</span> 👍（1） 💬（0）<div>老师关于操作系统方面的解答太棒了</div>2020-11-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/7b/5f/3400d01b.jpg" width="30px"><span>Y、先生</span> 👍（1） 💬（1）<div>写时复制 如何把变更的数据同步到子进程的</div>2020-09-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/6c/b5/32374f93.jpg" width="30px"><span>可怜大灰狼</span> 👍（1） 💬（3）<div>问题：采用渐进式 hash 时，如果实例暂时没有收到新请求，是不是就不做 rehash 了？
翻了下代码dict.c&#47;dictRehashMilliseconds，发现每次都是先rehash100个槽，然后判断耗时有没有超过1ms。所以老师这句“每次执行时长不会超过 1ms”，准确来说应该是“尽量保证每次执行时间在1ms”。
附代码：
int dictRehashMilliseconds(dict *d, int ms) {
    long long start = timeInMilliseconds();
    int rehashes = 0;

    while(dictRehash(d,100)) {
        rehashes += 100;
        if (timeInMilliseconds()-start &gt; ms) break;
    }

    return rehashes;
}

有个问题：这种模式下，每次rehash100个槽。万一每个槽数据比较多，会不会对其他任务造成影响？还是估算过了rehash100个槽也不会有多少数据？</div>2020-08-26</li><br/><li><img src="" width="30px"><span>Geek_f7240f</span> 👍（0） 💬（0）<div>请问老师：关于replication buffer处，我还有个疑问。它主要用于主从全量复制，主库把所有数据都复制到从库。replication buffer目的在于：在主从全量复制期间，防止有新的数据写入或者删除，如果有这个情况发生，也要把新改动的数据同步到从库中，目的还是为了让主库中的所有数据都同步到从库。那既然如此，全量复制每个从库得到的主库的数据都是一样的是吗？如果一样，那为什么还要给每一个从库都对应一个replication buffer？</div>2023-06-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/e5/4f/731ef2c1.jpg" width="30px"><span>geektime_zpf</span> 👍（0） 💬（0）<div>老师好，第五讲，问题描述中说读写比例是8:2, 解答中估算在创建RDB过程中2G内存数据会有80%大小被修改。我的疑问是：读写比例、可能被修改的数据比例，两个比例值相同或相近，是否合理？</div>2023-06-27</li><br/><li><img src="" width="30px"><span>Geek_2f2f54</span> 👍（0） 💬（0）<div>这个课程真是太精彩了，老师和K神各显神通，只有一个服字，也更加坚定了向老师们学习的动力。</div>2023-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/f2/2e/cb647708.jpg" width="30px"><span>起风了</span> 👍（0） 💬（0）<div>这是我学习的第2遍</div>2023-03-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/22/28/e8/7734b8d3.jpg" width="30px"><span>P</span> 👍（0） 💬（0）<div>replication buffer和repl_backlog_buffer还是讲错了，经历过第一次全量复制后，平时replication buffer就是用来增量复制的。
等主从断开再恢复，才用的repl_backlog_buffer以方便找到位置。</div>2023-03-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/23/79/87/255c9d42.jpg" width="30px"><span>DropTower</span> 👍（0） 💬（0）<div>蒋老师真的讲的太好了,受益匪浅,不愧为中科院研究员,向大佬致敬和学习</div>2023-02-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/f7/ad/4fd4d867.jpg" width="30px"><span>数学汤家凤</span> 👍（0） 💬（0）<div>我没有在 redis.conf 找到 client_buffer 这个参数</div>2023-02-14</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ7Fd19uVrF8RmRg9ibNdHXEdFV7V8LypzrTZtWQibP8PaWjM054SghI8QJeIZaOQNsdY5zib5Yh2JwQ/132" width="30px"><span>Geek_LIAO</span> 👍（0） 💬（0）<div>1、replication buffer
主从同步时，为了保证主从库的数据一致性，主库会在内存中用专门的 replication buffer，记录 RDB 文件生成后收到的所有写操作。
当主库完成 RDB 文件发送后，就会把此时 replication buffer 中的修改操作发给从库，从库再重新执行这些操作。这样一来，主从库就实现同步了。

2、repl_backlog_buffer
repl_backlog_buffer 是一个环形缓冲区，主库会记录自己写到的位置，从库则会记录自己已经读到的位置。

3、replication buffer和repl_backlog_buffer与从库的对应关系
（1）每个从库对应一个主库上的replication buffer。
（2）所有从库都对应同一个主库上的repl_backlog_buffer。
在 Redis 服务器启动后，主库会记录自己写到的位置（master_repl_offset），从库则会记录自己已经读到的位置（slave_repl_offset）。所以，不同的从库在进行恢复时，会把自己的复制进度（slave_repl_offset）发给主库，主库就可以和它独立同步。</div>2022-11-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/37/32/2703ee16.jpg" width="30px"><span>明</span> 👍（0） 💬（0）<div>老师好，第四讲说bgrewritaof 是一处拷贝两处日志，但风险二写共享内存，这是不是存在冲突</div>2022-07-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/de/25/44662eb8.jpg" width="30px"><span>Miss</span> 👍（0） 💬（0）<div>实习一年不到的菜鸡，看完了前9讲，无论图还是讲解，着实牛！</div>2022-06-25</li><br/>
</ul>