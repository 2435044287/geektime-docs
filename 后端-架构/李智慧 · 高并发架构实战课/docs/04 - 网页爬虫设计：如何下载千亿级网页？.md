你好，我是李智慧。

在互联网早期，网络爬虫仅仅应用在搜索引擎中。随着大数据时代的到来，数据存储和计算越来越廉价和高效，越来越多的企业开始利用网络爬虫来获取外部数据。例如：获取政府公开数据以进行统计分析；获取公开资讯以进行舆情和热点追踪；获取竞争对手数据以进行产品和营销优化等等。

网络爬虫有时候也被称为网络机器人，或者网络蜘蛛。我们准备开发一个全网爬虫，爬取全（中文）互联网的公开网页，以构建搜索引擎和进行数据分析。爬虫名称为“Bajie（八戒）”。

Bajie的技术挑战包括：如何不重复地获取并存储全网海量URL？如何保证爬虫可以快速爬取全网网页但又不会给目标网站带来巨大的并发压力？接下来我们就来看看Bajie的需求与技术架构。

## 需求分析

Bajie的功能比较简单，这里不再赘述。

#### 性能指标估算

因为互联网网页会不断产生，所以全网爬虫Bajie也是一个持续运行的系统。根据设计目标，Bajie需要每个月从互联网爬取的网页数为20亿个，平均每个页面500KB，且网页需存储20年。

Bajie的存储量和TPS（系统吞吐量）估算如下。

- **每月新增存储量**  
  估计平均每个页面500KB，那么每个月需要新增存储1PB。

$\\small 20亿\\times500KB=1PB$
<div><strong>精选留言（13）</strong></div><ul>
<li><img src="" width="30px"><span>开心小毛</span> 👍（5） 💬（5）<div>想请问一下 ，如果“下载优先级队列”之间产生负载的不平衡怎么处理，比如说优先级为2的URL太多，以至于系统里其他的队列太空，队列2却太长被覆盖。</div>2022-03-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg" width="30px"><span>peter</span> 👍（14） 💬（1）<div>请教老师几个问题啊：
Q1：“可扩展”与“可伸缩”的区别是什么？
“可扩展”是指软件开发方面，“可伸缩”是指部署方面，即增删机器方面，对吗？
Q2：怎么知道目标服务器的负载能力？
Q3：爬虫如果不理会robots.txt，会怎么处理？
   Robots.txt中禁止爬取，是从技术的角度爬虫无法爬取吗？还是说技术上爬虫仍然可以爬取，但可能会被起诉？
Q4：HDFS出现之前，百度将爬取的网页存在什么系统？
   百度比HDFS出现的早，没有HDFS的时候网页是怎么存储的？
Q5：爬虫的爬取速度是可以控制的吗？
Q6：一个URL被正常处理完后，会从“待下载 URL 集合”中删除吗？
   如果会删除，删除后该URL会被丢弃还是保存到某个地方？
Q7：爬虫用什么开发？好像python居多，用Java可以吗？
Q8：“待下载 URL 集合”，用Java开发的话用什么JDK的哪种集合？
或者，虽然名字叫“集合”，但其实只是往文件中追加记录？
Q9：“待下载 URL 集合”，取出一个，添加多个，那这个文件岂不是越来越大，很快就会超出文件大小？(产生的多，处理的少，积压越来愈多)
Q10：“域名队列映射表”，根据具体域名还是域名类型来判断？互联网域名可太多了啊，怎么也列举不完啊。</div>2022-02-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/18/ee/a1ed60d1.jpg" width="30px"><span>ABC</span> 👍（6） 💬（1）<div>好几年前用Python写过一些爬虫，都是比较简单的。在搜索引擎这个方面，除了搜索引擎主动爬取网页，有的网站还会主动推送新内容给搜索引擎，比如国内某些新闻网站在某度基本是分钟级收录。</div>2022-03-18</li><br/><li><img src="https://wx.qlogo.cn/mmopen/vi_32/7F7TZwdDKVvlbGTqoH5y1h0c7DrzWVGsOia7xiaR4lxYGLyQiaaLNuFFib3aicm3xtwJA94PEKyrMj5ekglmbDzR9GQ/132" width="30px"><span>legendcq</span> 👍（6） 💬（4）<div>老师，如果用布隆过滤器去重，如何处理false positive的情况，是允许一定比例的重复数据吗？</div>2022-02-26</li><br/><li><img src="" width="30px"><span>Geek_xbye50</span> 👍（3） 💬（3）<div>老师，如果是热门网站，会不会造成这个队列的数据特别多严重倾斜，极端情况下，下载服务都在处理这个网站的数据，增加目标网站的负载同时增加自身ip被目标加入黑名单的风险？换句话说可以对热点网站处理存在对应限流策略？</div>2022-02-24</li><br/><li><img src="" width="30px"><span>Geek_38ba97</span> 👍（1） 💬（2）<div>请教老师个很困惑的问题
我很困惑为什么資料多說布隆过滤器只會重複crawl一些頁面？而不是会漏抓取某些页面？
为什么它不会丢失抓取某些页面？

例如，考虑一个已初始化的全 0 布隆过滤器位数组
step1：查询urlA返回false，所以存储urlA，抓取urlA。
step2：查询urlB返回false，所以存储urlB，抓取urlB。
step3：如果查询urlC时返回true，系统会认为urlC可能已经存在于集合中，所以不会存储urlC，也不会抓取urlC。 因此，urlC 就漏抓了。

以上是我的疑惑。 我理解有什么不对的地方吗？十分感謝</div>2023-05-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/f9/73/01eafd3c.jpg" width="30px"><span>singularity of space time</span> 👍（1） 💬（1）<div>想请问一下TPS如何控制，也即如何保证TPS在预估的800左右，而不会在某些突发情况下冲破峰值（比如在系统刚刚运行时），是采用类似漏桶、令牌桶这样的限流算法嘛？</div>2022-04-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/ba/66/7d9f45e7.jpg" width="30px"><span>太空牛仔</span> 👍（1） 💬（1）<div>下载优先级队列的数据都会流转到域名队列中，域名队列是通过轮询的方式发放给下载服务器，那不就失去了优先队列的优先权重吗？</div>2022-03-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/f1/fd/003cf398.jpg" width="30px"><span>Leader</span> 👍（0） 💬（4）<div>请问老师，如果网站内容有更新怎么办？如果重新爬取，跟去重算法冲突了怎么办？感觉去重算法这一块设计里讲的还是不够完整。</div>2022-03-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/4b/11/d7e08b5b.jpg" width="30px"><span>dll</span> 👍（0） 💬（1）<div>老师，有没有一些配套的demo code能够参考借鉴一下呢</div>2022-02-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/fa/80/246eadec.jpg" width="30px"><span>hdhdh</span> 👍（0） 💬（1）<div>老师，后续可否加上物理部署图，可能理解会更深刻一些，比如几个机房，每个机房怎么样的</div>2022-02-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/23/c2/5c/791d0f5e.jpg" width="30px"><span>易企秀-郭彦超</span> 👍（1） 💬（1）<div>如果网页内容是动态script渲染的 该如何爬取</div>2022-03-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/93/e2/1bde89e8.jpg" width="30px"><span>日月</span> 👍（0） 💬（0）<div>“URL 调度器需要从待下载 URL 集合中选取一部分 URL 进行排序”这个排序是为了什么呢</div>2024-07-06</li><br/>
</ul>