你好，我是胡夕。今天我要和你分享的内容是：生产者压缩算法面面观。

说起压缩（compression），我相信你一定不会感到陌生。它秉承了用时间去换空间的经典trade-off思想，具体来说就是用CPU时间去换磁盘空间或网络I/O传输量，希望以较小的CPU开销带来更少的磁盘占用或更少的网络I/O传输。在Kafka中，压缩也是用来做这件事的。今天我就来跟你分享一下Kafka中压缩的那些事儿。

## 怎么压缩？

Kafka是如何压缩消息的呢？要弄清楚这个问题，就要从Kafka的消息格式说起了。目前Kafka共有两大类消息格式，社区分别称之为V1版本和V2版本。V2版本是Kafka 0.11.0.0中正式引入的。

不论是哪个版本，Kafka的消息层次都分为两层：消息集合（message set）以及消息（message）。一个消息集合中包含若干条日志项（record item），而日志项才是真正封装消息的地方。Kafka底层的消息日志由一系列消息集合日志项组成。Kafka通常不会直接操作具体的一条条消息，它总是在消息集合这个层面上进行写入操作。

那么社区引入V2版本的目的是什么呢？V2版本主要是针对V1版本的一些弊端做了修正，和我们今天讨论的主题相关的修正有哪些呢？先介绍一个，就是把消息的公共部分抽取出来放到外层消息集合里面，这样就不用每条消息都保存这些信息了。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/13/a7/9a/495cb99a.jpg" width="30px"><span>胡夕</span> 👍（117） 💬（5）<div>刚刚看到4天前京东提的那个jira已经修复了，看来规避了broker端为执行校验而做的解压缩操作，代码也merge进了2.4版本。有兴趣的同学可以看一下：https:&#47;&#47;issues.apache.org&#47;jira&#47;browse&#47;KAFKA-8106</div>2019-06-26</li><br/><li><img src="" width="30px"><span>Geek_8441fd</span> 👍（58） 💬（6）<div>broker端校验可以分两步走。
第1步，message set 层面，增加一个 crc，这样可以不用解压缩，直接校验压缩后的数据。
如果校验不成功，说明message set 中有损坏的message；
这时，再做解压操作，挨个校验message，找出损坏的那一个。

这样的话，绝大部分情况下，是不用做解压操作的；只有在确实发生错误时，才需要解压。
请指正。</div>2019-06-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/a8/e2/f8e51df2.jpg" width="30px"><span>Li Shunduo</span> 👍（28） 💬（5）<div>假如一个消息集合里有10条消息，并且被压缩，但是消费端配置每次只poll 5条消息。这种情况下，消费端怎么解压缩？矛盾点是 如果只取5条消息，需要broker帮助解压缩；如果取整个消息集合10条消息，会有贷款等资源的浪费？</div>2019-06-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/06/81/28418795.jpg" width="30px"><span>衣申人</span> 👍（26） 💬（3）<div>老师，我看源码，broker在接收producer消息并落盘这块貌似没有用零拷贝啊！只有传输给consumer时用了，求解答</div>2019-12-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/8f/35/f1839bb2.jpg" width="30px"><span>风中花</span> 👍（21） 💬（2）<div>胡老师您好！ 我们已经学历10多节课了！ 针对我们得留言和反馈，不知道您有没有给我们一些后续得课程得学习建议和方法？我目前得学习就是您告诉我们得，我必须学会记住。但是看同学们得评论和反馈，我觉得貌似还有很多很多知识啊且不知也不懂，故有此一问！希望老师能给与一点一点学习建议？ 感谢老师</div>2019-06-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/88/26/b8c53cee.jpg" width="30px"><span>南辕北辙</span> 👍（17） 💬（3）<div>老师有一点不是很明白，在正常情况下broker端会原样保存起来，但是为了检验需要解压缩。该怎么去理解这个过程呢，broker端解压缩以后还会压缩还原吗？
这个过程是在用户态执行的吗，总感觉怪怪的</div>2019-06-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/16/e0/7abad3cc.jpg" width="30px"><span>星期八</span> 👍（16） 💬（2）<div>老师那再问一下，如果多条消息组成消息集合发送，那是什么条件控制消息发送，如果是一条又是什么条件控制触发发送的呢</div>2019-07-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/0e/61/ae68f8eb.jpg" width="30px"><span>dream</span> 👍（13） 💬（6）<div>老师，我对消息层次、消息集合、消息、日志项这些概念与它们之间的关系感觉很懵，
消息层次都分消息集合以及消息，消息集合中包含日志项，日志项中封装消息，
那么日志项中封装的是producer发送的消息吗？
一个日志项中会包含多条消息吗？
消息集合中消息项封装的的消息与消息层次包含的消息有什么关系呢？
这两个消息与producer发送的消息有什么关系呢？
一个消息集合对应是producer发送的一条消息还是多条消息呢？
最后，老师能不能详细说一下CRC校验，谢谢！</div>2019-06-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/25/7f/473d5a77.jpg" width="30px"><span>曾轼麟</span> 👍（11） 💬（4）<div>不认同，因为网络传输也会造成丢失，但是我建议可以在消息里面使用一种消耗较小的签名方式sign，比如多使用位移等方式，broke端也这么操纵，如果签名不一致证明有数据丢失，同时签名的方式可以避免CPU大量消耗</div>2019-06-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/88/26/b8c53cee.jpg" width="30px"><span>南辕北辙</span> 👍（9） 💬（3）<div>老师有一点有点迷惑，broker为了多版本消息兼容，意思是一份消息有多个版本存在吗，是这个意思吗？</div>2019-07-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/d5/68/2201b6b9.jpg" width="30px"><span>归零</span> 👍（8） 💬（2）<div>这节觉得老师讲的有点没看懂，前面说只有两个场景broker会解压，大部分场景是&quot;**Producer 端压缩、Broker 端保持、Consumer 端解压缩**。&quot; 后面又说每个压缩过的消息集合在 Broker 端写入时都要发生解压缩操作，目的就是为了对消息执行各种验证。这一块能再解释下吗？谢谢！</div>2020-12-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/48/3b/f28beddc.jpg" width="30px"><span>代码小生</span> 👍（7） 💬（1）<div>原来在 V1 版本中，每条消息都需要执行 CRC 校验，但是CRC在某些情况下会变化，所以crc拿到消息集和中更好，这个逻辑我没有明白呢，既然CRC会变，为了消息的正确性不更应该每条消息都校验吗？为什么说拿到消息集和中一次校验更好呢？</div>2019-09-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/23/ed/a4a774a8.jpg" width="30px"><span>What for</span> 👍（6） 💬（4）<div>老师您好，您的课程很棒，又很实用又有原理性的分析！
我想问一个问题，Producer 发送数据时以批次为单位，那么 batch 与 broker 端的消息集合又是怎么样的对应关系呢？每个消息集合的 record 数量是否固定呢？
就是说在 Producer 端即使消息并没有达到 batch.size 的数量，linger.ms 也可以让它发送一批数据，那 broker 在低峰期的时候收到一批数据之后是会写入缓存等凑够一定数量组成一个消息集合还是说会立即（或设置超时时间）组成一个消息集合写入磁盘？
谢谢！</div>2019-08-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/f1/25/6908f80a.jpg" width="30px"><span>juan</span> 👍（6） 💬（2）<div>如果在配置中不指定压缩算法，kafka有默认的压缩算法吗？</div>2019-07-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/11/7f/80d56c1c.jpg" width="30px"><span>莫问流年</span> 👍（5） 💬（1）<div>我觉得消息检验放在producer端是不合理的。首先，检验应该是消息接收方broker的责任，每个发送方不应该承担这种公共的检验工作，也不利于扩展。其次，发送方producer检验影响了producer的性能，而且并不能保证消息到达broker后依然正确。
另外，想请教下老师，broker对消息进行的检验一般有哪些？</div>2019-06-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/04/0d/3dc5683a.jpg" width="30px"><span>柯察金</span> 👍（4） 💬（1）<div>怎么样才能保持消息格式统一呢，只要集群中的 kafka 版本一致吗？</div>2019-06-27</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJIIibocUHNRgafeNUvibW0YI2v1qDaiaZCVQ37FcrMs0ettIDD0snhsy4Ac2ADnLmjM7KGNeznj2hrg/132" width="30px"><span>一十六夜</span> 👍（3） 💬（1）<div>老师，问一下，如果producer端设置了压缩，那么broker端不可避免的会解压缩，1、那么此时的解压缩和“Broker 端指定了和 Producer 端不同的压缩算法”以及“Broker 端发生了消息格式转换”这两种情况产生的解压缩有什么不同？2、这种会产生两次解压缩，还是只有一次解压缩呢？3、解压缩后会先做crc校验，然后再做其他转换么？</div>2020-03-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/62/dc/8876c73b.jpg" width="30px"><span>moooofly</span> 👍（3） 💬（1）<div>如果producer设置了compress.type，而broker没有设置，之后broker会解压消息，然后保存在disk上，那后续发送给 consumer 的消息是压缩过的，还是未压缩的？还是也要取决于 consumer 针对压缩的配置？</div>2020-03-05</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLl9nj9b6RydKADq82ZwOad0fQcvXWyQKk5U5RFC2kzHGI4GjIQsIZvHsEm7mFELgMiaGx3lGq9vag/132" width="30px"><span>咸淡一首诗</span> 👍（3） 💬（1）<div>老师，”在一个生产环境中，Kafka 集群中同时保存多种版本的消息格式非常常见。为了兼容老版本的格式，Broker 端会对新版本消息执行向老版本格式的转换” 这句话不是很理解，消息的不同版本是由生产者版本决定还是 broker 服务端的版本决定，只需要保证服务端版本一致就不会出现不同消息格式吗？另外，Broker 端对新版本消息执行向老版本格式的转换是消费者消费时触发的吗？其转换过程是先解压缩，然后压缩，最后交给老板消费者吗？</div>2020-02-24</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erYNqD6TIViagNYicZoykSo5WhJs1eu2auaMor17rEdMiaUgKxzibfegsicgTkHpk9JTXD1cFqzeOMWsdg/132" width="30px"><span>finger</span> 👍（3） 💬（1）<div>有个思路，可以在producer 压缩之后，将消息字节长度一并发送给broker，broker通过字节长度来判断是否发送网络丢包，实现数据完整性校验。</div>2019-12-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/a0/cb/aab3b3e7.jpg" width="30px"><span>张三丰</span> 👍（3） 💬（1）<div>下面这句话不太明白了，老师后边说实际上消费端接收消息的时候一定会解压的，因为需要对消息集合做CRC检验，文中有段话说只有两个例外情况是解压的，如果是这样的话，那到底是原封不动还是一定解压呢？

”其实大部分情况下 Broker 从 Producer 端接收到消息后仅仅是原封不动地保存而不会对其进行任何修改”

</div>2019-10-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/67/c5/63b09189.jpg" width="30px"><span>刘朋</span> 👍（3） 💬（1）<div>问题: 压缩&#47;解压缩格式类型保存位置表述不清晰
文内在解压缩时说,Kafka会将启用了哪些压缩算法封装进消息集合中,这样当Consumer读取到消息集合时,
它自然就知道了这些消息使用的是哪种压缩算法.但在文内压缩时说, V2版本是对整个消息集合进行压缩.

从字面意思来理解,Producer在对消息集合压缩前,已经将压缩格式封装到了消息集合中.Consumer是怎么获取的压缩格式类型?要获取压缩格式得先进行解压,然后才能获取压缩类型. 这前后表述有矛盾了,有待解惑.</div>2019-06-25</li><br/><li><img src="https://wx.qlogo.cn/mmopen/vi_32/DYAIOgq83eq4Qc6ian5Y9KT5tg88ickhBvictPKvu2CXrib8oxnXbrTLicGwIArskjxuWLQxMvniavPCibvWNgVK6ic19g/132" width="30px"><span>元气蛋蛋</span> 👍（2） 💬（1）<div>老师我想问一下，如果Broker端一定会解压缩，那么一定会将数据从内核态拷贝到用户态，那么Kafka是怎么实现内核态的零拷贝</div>2020-02-04</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKPmOyph1XeszC69tTLENkZFJqjJ7CqtxlSpNEiaonB9ebLnKEh8w7gk7TXQiay4JvA0fQtLYKw718Q/132" width="30px"><span>雨落漂洋</span> 👍（2） 💬（2）<div>何时会发生新版本消息向老版本消息的转换？这点不是很明白~</div>2019-11-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/98/0d/fb77a32c.jpg" width="30px"><span>Tim</span> 👍（2） 💬（1）<div>老师，这个导致不得不执行解压的消息校验，主要是要校验什么呢？根据什么逻辑校验呢？十分感谢老师</div>2019-09-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/8b/4b/15ab499a.jpg" width="30px"><span>风轻扬</span> 👍（2） 💬（1）<div>老师，追问一个问题。之前问过您关于使用key-ordering策略的问题。如果出现reblance，就可能导致消息丢失的问题。是不是说，如果使用key-ordering策略，就必须保证消费者组不能出现reblance？</div>2019-07-29</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/cabLXAUXiavXnEckAgo971o4l1CxP4L9wOV2eUGTyKBUicTib6gJyKV9iatM4GG1scz5Ym17GOzXWQEGzhE31tXUtQ/132" width="30px"><span>日就月将</span> 👍（1） 💬（1）<div>老师，为什么Broker端发生了消息格式转换会让kafka丧失zero copy特性，Broker端和Producer端使用不同的压缩算法也会出现这种情况吗？</div>2021-09-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/f2/79/b2012f53.jpg" width="30px"><span>余生</span> 👍（1） 💬（1）<div>我对两个版本分别做了一个简单的测试，结果显示，在相同条件下，不论是否启用压缩，V2 版本都比 V1 版本节省磁盘空间。当启用压缩时，这种节省空间的效果更加明显，就像下面这两张图展示的那样：-------未压缩，为何v2比v1也能节约很多空间?</div>2021-07-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/0b/ab/0e2857e5.jpg" width="30px"><span>Coding小先</span> 👍（1） 💬（1）<div>老师，公司没有用到 Kafka，怎么深入呢？目前来说，看了 Kafka 的一些源码，但还不够深入。Kafka 使用方面的话就会搭建和 producer 和 comsumer 的程序编写和简单的一些参数配置。</div>2020-11-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/64/86/f5a9403a.jpg" width="30px"><span>yang</span> 👍（1） 💬（1）<div>1. 看到有人说同一个recordBatch 是 同一个topic 下的消息。 我想问，同一个record Batch的消息不是同一个partition的吗？

2. broker端总是要对record batch做校验，也看到老师的第一条留言说那条jira已经修复了。
我想顺着这个说，broker端是做record batch级别的校验，record级别的校验能否留到consumer端做呢？ 毕竟broker 到 consumer 也有可能出错。</div>2020-07-28</li><br/>
</ul>