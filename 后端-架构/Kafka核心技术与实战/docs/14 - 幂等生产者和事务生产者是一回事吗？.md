你好，我是胡夕。今天我要和你分享的主题是：Kafka消息交付可靠性保障以及精确处理一次语义的实现。

所谓的消息交付可靠性保障，是指Kafka对Producer和Consumer要处理的消息提供什么样的承诺。常见的承诺有以下三种：

- 最多一次（at most once）：消息可能会丢失，但绝不会被重复发送。
- 至少一次（at least once）：消息不会丢失，但有可能被重复发送。
- 精确一次（exactly once）：消息不会丢失，也不会被重复发送。

目前，Kafka默认提供的交付可靠性保障是第二种，即至少一次。在专栏[第11期](https://time.geekbang.org/column/article/102931)中，我们说过消息“已提交”的含义，即只有Broker成功“提交”消息且Producer接到Broker的应答才会认为该消息成功发送。不过倘若消息成功“提交”，但Broker的应答没有成功发送回Producer端（比如网络出现瞬时抖动），那么Producer就无法确定消息是否真的提交成功了。因此，它只能选择重试，也就是再次发送相同的消息。这就是Kafka默认提供至少一次可靠性保障的原因，不过这会导致消息重复发送。

Kafka也可以提供最多一次交付保障，只需要让Producer禁止重试即可。这样一来，消息要么写入成功，要么写入失败，但绝不会重复发送。我们通常不会希望出现消息丢失的情况，但一些场景里偶发的消息丢失其实是被允许的，相反，消息重复是绝对要避免的。此时，使用最多一次交付保障就是最恰当的。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/11/5c/d7/e4673fde.jpg" width="30px"><span>October</span> 👍（40） 💬（3）<div>我所理解的kafka事务是这样的：生产者的事务能够保证一条消息仅仅会保存在kafka的某一个分区上，不会出现在多个分区上，另外，能够保证多条消息原子性的发送到多个分区。也就是说它只保证了从producer端到broker端消息不丢失不重复。但对于consumer端，由于偏移量的提交和消息处理的顺序有前有后，依然可能导致重复消费或者消息丢失消费，如果要实现消费者消费的精确一次，还需要通过额外机制在消费端实现偏移量提交和消息消费的事务处理。不知道自己理解的对不对，希望老师指正。</div>2019-07-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/0e/61/ae68f8eb.jpg" width="30px"><span>dream</span> 👍（30） 💬（4）<div>老师，请问一下，事务型 Producer 可以实现一组消息要么全部写入成功，要么全部失败，但是事务型 Producer 是具体怎么实现多分区以及多会话上的消息无重复的呢？

</div>2019-07-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/8f/35/f1839bb2.jpg" width="30px"><span>风中花</span> 👍（24） 💬（1）<div>我一直认为事务，不到必须时是不用得东西，那么我想知道，胡老师实际中，你们有用到过吗，在一些什么场景下使用？老师可以简单说下吗，谢谢</div>2019-07-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/e1/99/d08e2b5c.jpg" width="30px"><span>涛</span> 👍（17） 💬（1）<div>老师，kafka中的事务提交异常，broker端的数据还是会写入日志，相当于只是记录一下失败状态，在消费端通过隔离级别，来过滤掉出这部分消息，不进行消费。为什么事务异常了，还要将数据写入日志呢？直接删除掉不好吗？像DB那样。</div>2019-10-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/de/5d/3a75c20b.jpg" width="30px"><span>Geek_bd6gy9</span> 👍（13） 💬（2）<div>老师，有个地方很困惑，这句话“实际上即使写入失败，Kafka 也会把它们写入到底层的日志中，也就是说 Consumer 还是会看到这些消息”这是什么意思？明明写入都失败了，为什么还会写到底层的commit log中呢？那这里的写入失败是指写入磁盘失败么？麻烦老师解答一下，谢谢~~</div>2020-04-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/11/78/4f0cd172.jpg" width="30px"><span>妥协</span> 👍（12） 💬（1）<div>不启用幂等也可以保证同分区下无消息乱序的。——消息发送失败重发时，在broker端不会导致收到的顺序，和producer端发送顺序不一致吗？如果是的话，是类似TCP那种保证有序的机制吗？</div>2020-02-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/15/69/187b9968.jpg" width="30px"><span>南山</span> 👍（11） 💬（2）<div>老师，事务型producer不会重复发送消息吗？如果发送的这一批到broker了，但是broker返回的确认消息producer没有收到，再次尝试，broker会去重吗？或者consumer端会去重啊？</div>2019-11-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/ea/ae/0e056410.jpg" width="30px"><span>冉冉</span> 👍（10） 💬（1）<div>想问下老师一个关于消费者的问题，如果一个消费者组里有两个消费者c1，c2，一个topic有两个分区p1，p2，那c1永远从p1收消息，而不会收到生产者发到p2的消息对吗？</div>2020-04-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/b3/c5/7fc124e2.jpg" width="30px"><span>Liam</span> 👍（7） 💬（1）<div>retry的话producer会保证发送到同一个分区吧，不然幂等性就没法保证了</div>2019-07-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/11/78/4f0cd172.jpg" width="30px"><span>妥协</span> 👍（5） 💬（3）<div>重启之后标识producer的PID就变化了，broker就不认识了——这个是幂等性的另一个限制条件，无法实现夸会话的幂等性。我理解的是：一个幂等性的producer，只保证单分区的幂等性，而producer的消息会发给一个主题的多个分区，每个单分区都保证幂等性，其实就是实现了多分区的幂等性，只是无法实现跨会话的幂等性，不知道理解的对不对？</div>2020-03-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/df/e5/65e37812.jpg" width="30px"><span>快跑</span> 👍（5） 💬（2）<div>老师，你好
幂等性为什么只保证单分区有效？是因为下一次消息重试指不定发送到哪个分区么。如果这样的话是不是可以采用按消息键保序的方式？这样重试消息还发送到同一个分区。</div>2019-07-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4d/49/28e73b9c.jpg" width="30px"><span>明翼</span> 👍（5） 💬（2）<div>老师请教个问题啊，我们在一个生产环境是日志入kafka，然后读取kafka的数据入到es里面，由于数据比较多，所以入到kafka的数据可能要过半天到一天才可以处理完，结果发现一个很奇怪的现象就是kafka的入的数据越快，那么入es的速度也越快，本来怀疑是kafka数据在cache里面所以快的，但是我们的数据延迟了很久，不太可能在cache，而且通过读kafka的程序日志分析，读kafka环节一直很快，只是入es的时间有快又慢，这个可能是什么问题那？</div>2019-07-05</li><br/><li><img src="" width="30px"><span>奇奇</span> 👍（4） 💬（2）<div>事务还有用 冥等生产者没什么用，反正消费端都是有可能重复消费的，业务上必须做去重处理</div>2019-08-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/42/f3/1eb9b1e2.jpg" width="30px"><span>Geek_rebecca</span> 👍（3） 💬（1）<div>老师，kafka的幂等性仅限于单分区会话，producer重启PID会变。那是不是说明其实kafka还是不能保证不会重复消费消息，如果要做到不重复消费，只能consumer端的代码逻辑里面去重过滤。</div>2020-06-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/47/1b/64262861.jpg" width="30px"><span>胡小禾</span> 👍（2） 💬（2）<div>即使consumer读到了事务消息，但还是可能由于rebalance等原因导致重复消费的吧？</div>2020-05-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/48/67/128eda8f.jpg" width="30px"><span>席席</span> 👍（2） 💬（1）<div>胡老师，我是kafaka初学者，现在维护的web项目中有相关的代码，并非我写的而且我只是简单的看过，我该怎么在你的课程中获得对kafaka的理解，至少我下次需要使用kafaka时候我能知道该怎么去做，但是我听到现在也没觉得有太大收获，看了下面的课程貌似也不会对我有太大帮助。说话比较直接，但是需要胡老师解惑！</div>2020-05-11</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqjbwXwF3YUcSw7A8v6f0sAYzQMloOWg62aciaGfzZWibRw2jjTja1Vwh5CLVGZdseM6gSBnC1hRzEQ/132" width="30px"><span>firstblood</span> 👍（2） 💬（2）<div>老师您好，想问一下如果两个producer往相同的topic写入，可不可以用相同的transactional. id ？</div>2020-04-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/d7/39/6698b6a9.jpg" width="30px"><span>Hector</span> 👍（2） 💬（1）<div>kafka内部的事务是不是使用像mysql一样的一致性事务视图，使用的MVVC多版本控制吗？还是怎么实现的</div>2020-02-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/7b/79/df384bdc.jpg" width="30px"><span>修愿三秋</span> 👍（2） 💬（1）<div>你好，老师，幂等性producer能规避ABA问题吗？如果发送三条消息分别是A，B，A那broker保存的是ABA还是AB呢？</div>2019-10-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/bf/22/26530e66.jpg" width="30px"><span>趁早</span> 👍（2） 💬（1）<div>事务也是只针对同一个topic么</div>2019-07-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/d3/6e/281b85aa.jpg" width="30px"><span>永光</span> 👍（2） 💬（2）<div>幂等性 Producer，
1、只能保证单分区上的幂等性
2、只能实现单会话上的幂等性，不能实现跨会话的幂等性
3、重启了 Producer 进程之后，这种幂等性保证就丧失了
幂等性设置：props.put(“enable.idempotence”, ture)，或 props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG， true)。

问题：
1、kafka内部是怎样实现幂等性 Producer的呀？对性能有多大影响？
2、这种幂等性 Producer一般是什么场景会用到呀？</div>2019-07-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/5c/d7/e4673fde.jpg" width="30px"><span>October</span> 👍（2） 💬（4）<div>一个幂等性 Producer 能够保证某个主题的一个分区上不出现重复消息，也就是说同一条消息可能出现在不同的分区上，可是producer端没有收到broker的ack，就会重试，重试应该能保证同一条消息分区是不会改变的，为什么这条消息会出现在其他分区呢。</div>2019-07-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/47/6c/78184d19.jpg" width="30px"><span>非洲黑猴子</span> 👍（1） 💬（1）<div>胡老师您好，上面说到Broker多保存一些字段可以做到幂等，那如果消息被压缩了，要校验这些字段不得解压吗？这样效率岂不是会很低？是不是压缩和幂等不太能互相兼容啊？谢谢🙏</div>2021-06-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/f0/b0/f6a218c6.jpg" width="30px"><span>包子</span> 👍（1） 💬（1）<div>能不能讲讲开启idempotence的开销？</div>2021-05-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/fe/b4/295338e7.jpg" width="30px"><span>Allan</span> 👍（1） 💬（1）<div>每一节课真的都能收获到东西，kafka 11之前的就没办法保持精准一次语义了嘛？我理解到的事务是从关系型数据库来的，为了保证数据的完整正确，最经典的还是银行转账的案例。</div>2021-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/de/55/e417238c.jpg" width="30px"><span>木子三金</span> 👍（1） 💬（1）<div>胡老师你好，关于精确一次的保证我这里有些疑问，请帮忙指教。

1、“其次，它只能实现单会话上的幂等性，不能实现跨会话的幂等性。这里的会话，你可以理解为 Producer 进程的一次运行。当你重启了 Producer 进程之后，这种幂等性保证就丧失了。”
是否说如果2个生产者发送同一个消息是无法幂等呢？

2、 我理解幂等是保证消息不重复，事务是保证“批量消息”原子性写入不丢失。因为kafka本身已经保证当broker响应peoducer已提交后消息不丢失，如果我没有批量写入需求，是否就单独通过幂等保证精确一次呢？

3、“那么你可能会问，如果我想实现多分区以及多会话上的消息无重复，应该怎么做呢？答案就是事务（transaction）或者依赖事务型 Producer。这也是幂等性 Producer 和事务型 Producer 的最大区别！”这句话的意思是说事务本身已经保证了事务内所有消息的幂等性了么？</div>2020-12-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/84/19/7ed2ffa6.jpg" width="30px"><span>风</span> 👍（1） 💬（1）<div>老师,我看kafka消息发送都是攒一批分批发送的,请问这个是怎么控制什么时候发送给broker的？因为是走这种机制,是不是可能存在生产者后台线程一致轮询消息的发送状态</div>2020-11-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/b7/e9/5400cdf3.jpg" width="30px"><span>扬一场远远的风</span> 👍（1） 💬（1）<div>您好。Kafka是使用appen 追加写消息数据，如果在生产消息时自己指定时间戳，且存在后发送的消息时间戳小于先发送消息的时间戳，这时会有什么影响？另外再问一下，.timeindex文件为什么不设计成（时间戳，文件物理位置）[与位移索引文件一样（相对位移，文件物理位置）]？我理解，如果这样设计，根据时间查询数据应该会更快，相当于直接使用位移定位数据。</div>2020-05-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg" width="30px"><span>James</span> 👍（1） 💬（1）<div>请问老师,
事务生产者:
要么全部成功,要么失败;
除了程序抛出异常外导致失败回滚,
还有,比如ack收不到也会导致回滚吗,
还有其他失败导致回滚的例子吗.</div>2020-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/83/19/0a3fe8c1.jpg" width="30px"><span>Evan</span> 👍（1） 💬（1）<div>非常喜欢精确一次（exactly once）：消息不会丢失，也不会被重复发送。有点类似于：Flink的对流消费机制（exactly once）  但使用有限制就是当前会议和不能跨分区。</div>2020-04-02</li><br/>
</ul>