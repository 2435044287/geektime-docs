你好，我是胡夕。今天我要和你分享的主题是：如何配置Kafka无消息丢失。

一直以来，很多人对于Kafka丢失消息这件事情都有着自己的理解，因而也就有着自己的解决之道。在讨论具体的应对方法之前，我觉得我们首先要明确，在Kafka的世界里什么才算是消息丢失，或者说Kafka在什么情况下能保证消息不丢失。这点非常关键，因为很多时候我们容易混淆责任的边界，如果搞不清楚事情由谁负责，自然也就不知道由谁来出解决方案了。

那Kafka到底在什么情况下才能保证消息不丢失呢？

**一句话概括，Kafka只对“已提交”的消息（committed message）做有限度的持久化保证。**

这句话里面有两个核心要素，我们一一来看。

第一个核心要素是“**已提交的消息**”。什么是已提交的消息？当Kafka的若干个Broker成功地接收到一条消息并写入到日志文件后，它们会告诉生产者程序这条消息已成功提交。此时，这条消息在Kafka看来就正式变为“已提交”消息了。

那为什么是若干个Broker呢？这取决于你对“已提交”的定义。你可以选择只要有一个Broker成功保存该消息就算是已提交，也可以是令所有Broker都成功保存该消息才算是已提交。不论哪种情况，Kafka只对已提交的消息做持久化保证这件事情是不变的。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/10/92/760f0964.jpg" width="30px"><span>阳明</span> 👍（105） 💬（29）<div>总结里的的第二条ack=all和第六条的说明是不是有冲突</div>2019-06-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/5f/b2/c4780c10.jpg" width="30px"><span>曹伟雄</span> 👍（31） 💬（3）<div>单个 Consumer 程序使用多线程来消费消息说起来容易，写成代码却异常困难，因为你很难正确地处理位移的更新，也就是说避免无消费消息丢失很简单，但极易出现消息被消费了多次的情况。
关于这个问题，老师能否提供个java代码的最佳实践?  谢谢!</div>2019-06-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/f1/55/8ac4f169.jpg" width="30px"><span>陈国林</span> 👍（28） 💬（5）<div>老师好，请教一个问题，ack=1的时候，min.insync.replicas还会生效吗？或者说还有必要吗，感谢 🤝</div>2020-01-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/4d/5e/c5c62933.jpg" width="30px"><span>lmtoo</span> 👍（24） 💬（3）<div>最后一个问题，难道新增分区之后，producer先感知并发送数据，消费者后感知，消费者的offset会定位到新分区的最后一条消息？消费者没有提交offset怎么会从最后一条开始的呢？</div>2019-06-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c7/dc/9408c8c2.jpg" width="30px"><span>ban</span> 👍（23） 💬（7）<div>老师，
如果我有10个副本，isr=10，然后我配置ack=all，min.insync.replicas=5，
这时候这两个参数以谁为准，生产一个消息，必须是全部副本都同步才算提交，还是只要5个副本才算提交？</div>2019-08-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/45/26/f54c9888.jpg" width="30px"><span>redis</span> 👍（18） 💬（6）<div>你好胡老师，想问一下 kafka是在落地刷盘之后，同步副本成功后，才能会被消费吗？</div>2019-11-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/d3/6e/281b85aa.jpg" width="30px"><span>永光</span> 👍（17） 💬（6）<div>看了评论区回答还是不太理解，第二条ack=all与第六条min.insync.replicas 怎样协调工作的，总感觉是有冲突的。
问题是：
第二条的“已提交”和第六条的“已提交”是同一个意思吗？如果是同一个意思，那定义为什么不一样呀？

</div>2019-06-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/86/06/72b01bb7.jpg" width="30px"><span>美美</span> 👍（13） 💬（6）<div>胡老师 还有一种消息重复的情况希望帮忙分析下。producer发送消息后，broker成功写入消息了，但是ack因为网络问题没有到达producer，生产者可能会重试发送这条消息。
这种问题如何避免重复消费呢</div>2019-11-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/64/86/f5a9403a.jpg" width="30px"><span>yang</span> 👍（11） 💬（3）<div>老师，我针对您的提问思考并查阅了一下相关资料，说一下我的思考哈：

我们假设有且仅有一个producer只在这个consumer感知到之前，新的partition分区只写了那么几条记录，不会再有其他producer写数据到这个新的partition中。

新增partition的情况，rebalance时由于我们默认offset.auto.reset=lastest，因此在使用了这个默认配置之下，producer较consumer先感知到新的partition将数据发送到新的partition，而consumer之后才感知到这个consumer，此时由于这个新的partition的offset是第一次消费，没有已提交的offset，所以使用latest从最新的位移开始读取，也就是producer写入消息offset + 1的那个位置开始读取，因此也就读取不到数据。

latest：有提交位移就从提交位移开始处理，没有提交位移就从最新的位移开始处理。

earlist: 有提交位移就从提交位移开始处理，没有提交位移就从最早的位移开始处理。

current: 从当前的提交位移开始处理。

因此，碰到上述情况，我们可以使用seekToBegin从这个新分区的开始位置读即可。

我能想到的办法是，实现一个ConsumerRebalanceListener，重写onPartitionsAssigned方法，在这个方法里我们每次都从自己维护的数据库系统里取offset，能取到说明这个partition是之前就存在的，按已有的offset继续消费就可以了，没有取到的记录表示是新增的partition，那么就从0开始消费并且保存当前offset到数据库。不论是不是新的，都可以seek到指定的位置，只是我们有没有维护到这个partition的offset记录的区别。也就不用针对这个新分区指定offset.auto.rset=earlist了吧？

希望得到胡老师的交流哈~</div>2020-07-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/26/69/51d5e6bd.jpg" width="30px"><span>浪迹人生</span> 👍（11） 💬（4）<div>请问消息的createTimestamp 是在生产者服务器上生成的，还是在进入不同partition 后生成的？我能不能根据这个时间戳来判断不同分区的消息原始全局顺序？谢谢🙏</div>2019-11-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/1e/89/25b12054.jpg" width="30px"><span>Andy</span> 👍（10） 💬（2）<div>留言中ISR是什么？</div>2019-07-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/ee/92/18884647.jpg" width="30px"><span>毛毛鸦</span> 👍（9） 💬（2）<div>老师好，第七条没太理解啊， replication.factor 和 min.insync.replicas为什么不能相等呢，假如都是2，不可以吗，挂掉一个副本还有一个副本可用啊。</div>2020-02-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/df/e5/65e37812.jpg" width="30px"><span>快跑</span> 👍（8） 💬（5）<div>老师，你好。仔细阅读文稿后，仍有一些困惑
1、如果只用 send()方法（fire and forget），  即使配置retries，producer也是不知道消息状态，是不会重试的。所以说配置retries，要搭配send(msg, callback)，这么理解正确么？
2、配置了retries,   producer是怎么知道哪条消息发送失败了，然后重试</div>2019-06-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/be/0f/82db5e65.jpg" width="30px"><span>亮</span> 👍（7） 💬（2）<div>老师好，有个问题，就是：retries 和 send里面的callback，是什么关系？因为有说retries是kafka自动重试的次数，那么还要callback干吗，callback的意义在哪里呢？ 如果一定要坚持用send(callback)api，那么retries是用来干吗的呢？ 这两者之间的关系是什么呢？谢谢。</div>2019-11-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/6b/1b/4b397b80.jpg" width="30px"><span>蛮野</span> 👍（7） 💬（1）<div>acks=all表示消息要写入所有ISR副本，但没要求ISR副本有多少个。min.insync.replicas做了这样的保证

如果min.insync.replicas的参数设置比实际的isr副本多，producer的消息必须阻塞等broker的isr数量达到min.insync.replicas才提交成功吗</div>2019-09-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/5f/b2/c4780c10.jpg" width="30px"><span>曹伟雄</span> 👍（7） 💬（1）<div>老师你好，请教个问题。关于offset，有必要外部持久化记录吗？ 出问题后查出来继续消费。你说的更新offset是怎么处理? 是直接调用它的api更新吗？ 谢谢</div>2019-06-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4d/49/28e73b9c.jpg" width="30px"><span>明翼</span> 👍（7） 💬（3）<div>这个问题我想个办法就是程序停止再增加分区，如果不能停止那就找个通知机制了。请教一个问题min.insync.replicas这个参数如果设置成3，假设副本数设置为4，那岂不是只支持一台broker坏掉的情况？本来支持三台坏掉的，老师我理解的对不对</div>2019-06-27</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLl9nj9b6RydKADq82ZwOad0fQcvXWyQKk5U5RFC2kzHGI4GjIQsIZvHsEm7mFELgMiaGx3lGq9vag/132" width="30px"><span>咸淡一首诗</span> 👍（6） 💬（2）<div>老师，好，请教一个问题，如果acks=all，min.insync.replicas=2，如果持续高吞吐量导致ISR中只剩下leader，那么由于min.insync.replicas=2设置了最少需要写入2个副本，此时是不是该分区就写不进去了？</div>2020-04-08</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKtYGLkKnh186Ynyx3bPvOMI7ViaWia2l8DD8eomDkE6AKNwW7l1a00CiaaiaiapibZY5JlQlxqQEQuSYFg/132" width="30px"><span>Geek_986289</span> 👍（6） 💬（1）<div>设置 acks = all。表明所有副本 Broker 都要接收到消息，该消息才算是“已提交”。如果所有的Broker都要收到消息才能算作已提交，会不会对系统的吞吐量影响很大？另外这里的副本指的是不是仅仅是ISR?</div>2019-06-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/d6/df/1e4ecd94.jpg" width="30px"><span>AA</span> 👍（6） 💬（3）<div>如果consumer改用&quot;从最早位置&quot;读解决新加分区造成的问题，那会不会导致旧的分区里的已被消费过的消息重新全部被消费一次</div>2019-06-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/57/38/e5b8b766.jpg" width="30px"><span>杰锅不是锅</span> 👍（5） 💬（1）<div>老师，我想问个问题，假如一个topic有3个partion ，我有三个消费端去消费topic，这三个消费端，是怎么去对应三个partion?曾经在线上遇到过消费太慢，导致消息重新均衡，重复消费了，有好的解决方法吗？</div>2019-07-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/05/7f/a7df049a.jpg" width="30px"><span>Standly</span> 👍（5） 💬（1）<div>在“producer.send(msg, callback)的callback方法中重试，和设置retries参数重试，会不会冲突？2个都设置以哪个为准？</div>2019-06-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/e2/6e/0a300829.jpg" width="30px"><span>李先生</span> 👍（4） 💬（1）<div>胡哥，有两个问题：
1:kafka还使用了sendfile技术，能简单介绍下吗？
2:acks=all，只是保证消息被存储到所有broker的pagecache中就认为消息成功，如果再此时间点，所有broker全部异常停机，那么pagecache中的消息就不会被异步拉取到磁盘，当重启之后，消息就丢失了。这种情况如何考虑呢？</div>2020-04-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/dc/6a/85ab92ae.jpg" width="30px"><span>wei.li</span> 👍（4） 💬（1）<div>至少一次&#47;至多一次的语义是通过ack可retires参数配置吗？</div>2019-09-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/df/e5/65e37812.jpg" width="30px"><span>快跑</span> 👍（4） 💬（1）<div>老师，你好！
producer.send(msg, callback)中callback主要用来做什么？可以用来重新发送数据么？如果可以的话，跟producer的配置retries是不是功能重复了</div>2019-06-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/47/6c/78184d19.jpg" width="30px"><span>非洲黑猴子</span> 👍（3） 💬（0）<div>李玥老师聊消息队列的讲座里说不可以consumer自己建一个队列然后多线程来消费，因为那样一旦宕机就会丢失队列里的消息。这样线程池似乎也就不能用了，因为她里面就有一个LinkedBlockingQueue。请问胡老师两个问题： 
1. 单个Consumer所负担的消息太多怎么办？
2. 有没有什么方法可以让多线程处理单个Consumer的逻辑和代码变得简单优雅些？我能想到的是处理逻辑保证幂等，避免重复消费产生的影响。
谢谢🙏</div>2021-06-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/55/a9/5282a560.jpg" width="30px"><span>yic</span> 👍（3） 💬（4）<div>胡老师，课后题：
在消费者端管理每个partition的offset是否可以解决？如果消费者是集群形式，那可以公共缓存统一存储每个partition的offset。缓存中没有partition的offset记录，则从最新消息处开始读消息。</div>2020-01-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/fe/c1/6c99fff4.jpg" width="30px"><span>Jason_鹏</span> 👍（3） 💬（6）<div>有两个问题
1、acks=all 分区副本的个数为3，producer将消息发送给Leader分区后，两个Follower分区还未同步，或者由于网络延时问题迟迟没有同步，这时消息者是否可以消费Leader分区上的这条消息，如果可以话，就会出现producer因为超时没有接收到ack，进行重发消息，那消费者就会出现重复消费的情况

2、我们正常的线上环境，对于同一个主题有多台消费者机器，比如对于主题T1，现在的情况是消费者C1消费的分区是P1，消费者C2消费的分区是P2，P1，P2是主题T1的两个分区，这时候线上的发版，消费者C1和C2都会进行重启，重启后如果C1变成消费分区P2，C2变成消费分区P1，offset是记录在消费端，那会不会照成消息丢失的情况</div>2019-07-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/76/23/31e5e984.jpg" width="30px"><span>空知</span> 👍（3） 💬（2）<div>老师问下 
第7条 一个副本挂掉 整个分区不能用了 是因为每次都必须保证可用副本个数 必须跟提交时候一致 才可以正常使用,又没有冗余副本导致的嘛?</div>2019-06-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/d6/df/1e4ecd94.jpg" width="30px"><span>AA</span> 👍（3） 💬（7）<div>老师，最后一段新增分区导致消息全部丢失，这个不是很明白</div>2019-06-27</li><br/>
</ul>