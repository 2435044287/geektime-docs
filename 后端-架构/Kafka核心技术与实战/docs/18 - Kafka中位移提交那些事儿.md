你好，我是胡夕。今天我们来聊聊Kafka中位移提交的那些事儿。

之前我们说过，Consumer端有个位移的概念，它和消息在分区中的位移不是一回事儿，虽然它们的英文都是Offset。今天我们要聊的位移是Consumer的消费位移，它记录了Consumer要消费的下一条消息的位移。这可能和你以前了解的有些出入，不过切记是下一条消息的位移，而不是目前最新消费消息的位移。

我来举个例子说明一下。假设一个分区中有10条消息，位移分别是0到9。某个Consumer应用已消费了5条消息，这就说明该Consumer消费了位移为0到4的5条消息，此时Consumer的位移是5，指向了下一条消息的位移。

**Consumer需要向Kafka汇报自己的位移数据，这个汇报过程被称为提交位移**（Committing Offsets）。因为Consumer能够同时消费多个分区的数据，所以位移的提交实际上是在分区粒度上进行的，即**Consumer需要为分配给它的每个分区提交各自的位移数据**。

提交位移主要是为了表征Consumer的消费进度，这样当Consumer发生故障重启之后，就能够从Kafka中读取之前提交的位移值，然后从相应的位移处继续消费，从而避免整个消费过程重来一遍。换句话说，位移提交是Kafka提供给你的一个工具或语义保障，你负责维持这个语义保障，即如果你提交了位移X，那么Kafka会认为所有位移值小于X的消息你都已经成功消费了。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/13/d5/db/c45b90c8.jpg" width="30px"><span>水天一色</span> 👍（59） 💬（15）<div>消费者提了异步 commit 实际还没更新完offset，消费者再不断地poll，其实会有重复消费的情况吧？</div>2019-12-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/c4/92/338b5609.jpg" width="30px"><span>Roy Liang</span> 👍（44） 💬（4）<div>要彻底避免消息重复消费，这样是否可行？在consumer端进行幂等操作。这样kafka就可以设置自动提交位移了</div>2020-04-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c7/dc/9408c8c2.jpg" width="30px"><span>ban</span> 👍（25） 💬（8）<div>老师，你好。有个场景不太明白。我做个假设，比如说我的模式是自动提交，自动提交间隔是20秒一次，那我消费了10个消息，很快一秒内就结束。但是这时候我自动提交时间还没到（那是不是意味着不会提交offer），然后这时候我又去poll获取消息，会不会导致一直获取上一批的消息？

还是说如果consumer消费完了，自动提交时间还没到，如果你去poll，这时候会自动提交，就不会出现重复消费的情况。</div>2019-07-13</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLEYbNElGIxY6Le1rfiakWJecz8JIOp06Y9JQFR2YBn3T3gx3icI5CKxZNgxgqiaKbfVOicXquO3QBw9w/132" width="30px"><span>july</span> 👍（21） 💬（5）<div>老师你好，这里是否可以理解为 自动提交逻辑是在poll方法中，如果间隔大于最小提交间隔，就会运行逻辑进行offset提交，如果小于最小间隔，则忽略offset提交逻辑？也就是说上次poll 的数据即便处理结束，没有调用下一次poll，那么offset也不会提交？</div>2020-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/cd/2a/bdbed6ed.jpg" width="30px"><span>无菇朋友</span> 👍（17） 💬（6）<div>老师您好，有一个疑问，为什么poll之前的提交和按频率自动提交是一个时机，假如频率是5s提交一次，某两次poll之间的间隔是6s，这时候是怎么处理提交的？忘老师解答下，着实没想通这个地方</div>2019-07-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/d0/42/6fd01fb9.jpg" width="30px"><span>我已经设置了昵称</span> 👍（13） 💬（1）<div>auto.commit.interval.ms为5秒，且为自动提交
如果业务5秒内还没处理完，这个客户端怎么处理offset</div>2020-05-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/4d/5e/c5c62933.jpg" width="30px"><span>lmtoo</span> 👍（12） 💬（11）<div>对于手动同步和异步提交结合的场景，如果poll出来的消息是500条，而业务处理200条的时候，业务抛异常了，后续消息根本就没有被遍历过，finally里手动同步提交的是201还是000，还是501？</div>2019-07-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/d1/22/706c492e.jpg" width="30px"><span>Algoric</span> 👍（7） 💬（8）<div>自动提交一定不会消息丢失吗，如果每次poll的数据过多，在提交时间内没有处理完，这时达到提交时间，那么Kafka还是重复提交上次poll的最大位移吗，还是讲本次poll的消息最大位移提交？</div>2019-09-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/b3/c5/7fc124e2.jpg" width="30px"><span>Liam</span> 👍（6） 💬（4）<div>所以自动提交有2个时机吗？

1 固定频率提及，例如5s提及一次
2 poll新数据之前提交前面消费的数据</div>2019-07-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/aa/ff/e2c331e0.jpg" width="30px"><span>bbbi</span> 👍（5） 💬（1）<div>老师您好！有一个问题时。Kafka的offset是一个数字，那么这个数值最大时多少？有没有可能存在用完的情况？</div>2020-02-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/46/a9/70fa676f.jpg" width="30px"><span>Luke</span> 👍（4） 💬（1）<div>我的理解，不管怎样做，单靠Kafka无法保证消息不被重复消费，无论时候自动提交还是手动提交，同步提交还是异步提交，消息的下游消费都要做去重和幂等处理。除非能够保证消息的消费和位点的提交是一个原子操作。而这个原子性太难保证了，基本上又要引入分布式一致性的那一套东西了。</div>2020-10-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/f5/55/5ba20e79.jpg" width="30px"><span>不忘初心丶方得始终</span> 👍（4） 💬（1）<div>老师你好，问个问题，目前公司要用kafka同步老数据库数据，同步过程是按照老数据库的bin.log日志顺序进行同步，但是在同步过程中，有些表是有关联的，加入将数据放到多个分区，不同分区数据消费顺序不一样，就会导致数据同步出现关联问题，如果设置一个分区……这样又太慢，有什么好的建议吗？</div>2019-10-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/05/7f/a7df049a.jpg" width="30px"><span>Standly</span> 👍（4） 💬（4）<div>try {
        while (true) {
            ConsumerRecords&lt;String, String&gt; records = 
                        consumer.poll(Duration.ofSeconds(1));
            process(records); &#47;&#47; 处理消息
            commitAysnc(); &#47;&#47; 使用异步提交规避阻塞
        }
     } catch (Exception e) {
        handle(e); &#47;&#47; 处理异常
    } finally {
        try {
            consumer.commitSync(); &#47;&#47; 最后一次提交使用同步阻塞式提交
        } finally {
            consumer.close();
        }
    }
这段代码如果异常了，不就退出while循环了么？也就相当于消费者线程异常退出？</div>2019-07-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/80/bb/c0ed9d76.jpg" width="30px"><span>kursk.ye</span> 👍（4） 💬（3）<div>我现在有点糊涂了，kafka的offset是以broker发消息给consumer时，broker的offset为准；还是以consumer 的commit offset为准？比如，一个partition现在的offset是99，执行poll(10)方法时，broker给consumer发送了10条记录，在broker中offset变为109；假如 enable.auto.commit 为false，为手动提交consumer offset,但是cosumer在执行consumer.commitSync()或consumer.commitAsync()时进程失败，整个consumer进程都崩溃了；于是一个新的consumer接替原consumer继续消费，那么他是从99开始消费，还是从109开始消费？</div>2019-07-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/64/9b/d1ab239e.jpg" width="30px"><span>J.Smile</span> 👍（3） 💬（1）<div>老师，我真的遇到了无论是自动提交或者是手动提交，没有报错，但是消费位移就是没有增长，心塞塞！！！求助🆘</div>2020-07-21</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEIaTvOKvUt4WnuSjkBp0tjd6O6vvVyw5fcib3UgZibE8tz2ICbTfkwbzs8MHNMJjV6W2mLjywLsvBibg/132" width="30px"><span>火力全开</span> 👍（3） 💬（1）<div>请问老师Kafka能配置成每次连接只消费最新的消息吗？</div>2020-04-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/a8/e2/f8e51df2.jpg" width="30px"><span>Li Shunduo</span> 👍（3） 💬（1）<div>从文章看，无论是自动提交还是手动提交，都是有可能存在消息重复消费的。请问有没有办法通过offset管理避免重复消费呢？还是要借助外部的工具做消费前的检查。</div>2019-08-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/e9/0b/1171ac71.jpg" width="30px"><span>WL</span> 👍（3） 💬（1）<div>我感觉有点不是很理解消费者端的位移概念和消息在分区中的位移为啥不是一回事，我理像是一回事，因为消费者端把自己消费的位移提交到Broker的位移主题里不就定义了下次消费的起点了吗，为啥说不是一回事呢，有啥区别呢，请老师具体指导一下。</div>2019-07-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/a0/cb/aab3b3e7.jpg" width="30px"><span>张三丰</span> 👍（2） 💬（1）<div>老师，我有一个疑问，
由于位移提交是有序的，比如前5次的异步提交，其中第3次提交时候发生网络抖动，这个时候第3次的异步提交开始同步重试，但是第4次和第5次的已经异步提交成功，这个时候这个”同步重试“应该被忽略，否则位移数据将被覆盖了吧。</div>2021-05-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/d5/68/2201b6b9.jpg" width="30px"><span>归零</span> 👍（2） 💬（2）<div>consumer去拉消息的时候怎么知道位移的数据？是broker记录这个数据，还是本地存储的(同时异常重启后从broker获取)</div>2021-01-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/a0/cb/aab3b3e7.jpg" width="30px"><span>张三丰</span> 👍（2） 💬（1）<div>老师有两个地方搞不明白
1.spring boot kafkaTemplate提供重试功能，也就是同步和异步都支持重试，它怎么做到避免位移过期问题的？
2.手动提交不会出现重复消费的情况吗？重平衡不会影响手动提交吗？</div>2020-11-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/ff/35/b744c027.jpg" width="30px"><span>惜昔</span> 👍（2） 💬（6）<div>老师 手动提交位移的时候 如果一个某个消费者组的一个消费者实例从offset下标4开始消费的 但是消费者的消费逻辑比较重量级，处理的时间比较长，还没有提交。这时候另外一个消费者组的一个消费者实例来相同的分区来拿消息，会不会拿的是上一个消费者已经拿过的消费，从而重复消费？</div>2019-11-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/6d/cf/ec335526.jpg" width="30px"><span>jc9090kkk</span> 👍（2） 💬（6）<div>感觉老师分享，对于文章中的那个自动提交的例子有点疑惑，希望老师能解答一下：
auto.commit.interval.ms设置为5s，也就是说consumer每5秒才提交一次位移信息，那consumer如果每消费一条数据，但是没有达到自动提交的时间，这个位移信息该如何管理？consumer自己做维护吗？但是也需要跟broker端进行位移信息同步的吧？ 不然可能会造成数据的重复消费？还是每5s的提交和consumer自动提交的时候都会伴随位移信息的同步？是我的理解有问题吗？</div>2019-09-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/4f/a7/f7124e0f.jpg" width="30px"><span>李坤</span> 👍（2） 💬（1）<div>老师您好，异步提交重试时提交的位移值可能早已经“过期”或不是最新值了。什么情况下会出现呢？</div>2019-07-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/d0/42/6fd01fb9.jpg" width="30px"><span>我已经设置了昵称</span> 👍（2） 💬（3）<div>看下来感觉自动提交有两个提交方法，1.默认5秒一次，2.每次调用poll方法的时候。是这样吗？</div>2019-07-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/c3/09/027f2f17.jpg" width="30px"><span>estimator</span> 👍（1） 💬（1）<div>老师您好，如果异步提交位移成功了，但是由于网络抖动返回失败了。那么同步提交又会提交一次，这时就会丢消息吧。</div>2021-02-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/51/0d/fc1652fe.jpg" width="30px"><span>James</span> 👍（1） 💬（1）<div>如果数据是实时且非必须处理,比如的士实时坐标数据,可以判断时间是否实时来过滤,即使重复消费也不会再次消费这条数据,因为过期了..
如果是必须处理的数据只能通过查询数据处理来判断是否重复消费了.</div>2020-06-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/83/c9/5d03981a.jpg" width="30px"><span>thomas</span> 👍（1） 💬（1）<div>老师，若是多台机器，即使配置相同的groupID，是不是也会重复消费？位移其实是消费者在控制，customer_offset主题只是为了保持消费者位移的持久性</div>2020-05-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/f7/ee/6eeb58a3.jpg" width="30px"><span>calljson</span> 👍（1） 💬（1）<div>请教老师两个问题，
1.  consumer.close()会触发rebalance吗？
2. 一个consumer实例就是一个客户端吗？比如：线程池中new了两个consumer实例，是不是意味着开启了两个客户端？
麻烦老师解惑，谢谢您</div>2019-07-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/b3/c5/7fc124e2.jpg" width="30px"><span>Liam</span> 👍（1） 💬（1）<div>自动提交模式下，多线程消费，Kafka client 如何保证位移提交的正确性？</div>2019-07-16</li><br/>
</ul>