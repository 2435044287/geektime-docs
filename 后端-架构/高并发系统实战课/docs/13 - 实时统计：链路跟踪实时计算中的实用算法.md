你好，我是徐长龙。

前几节课我们了解了ELK架构，以及如何通过它快速实现一个定制的分布式链路跟踪系统。不过ELK是一个很庞大的体系，使用它的前提是我们至少要有性能很好的三台服务器。

如果我们的数据量很大，需要投入的服务器资源就更多，之前我们最大一次的规模，投入了大概2000台服务器做ELK。但如果我们的服务器资源很匮乏，这种情况下，要怎样实现性能分析统计和监控呢？

当时我只有两台4核8G服务器，所以我用了一些巧妙的算法，实现了本来需要大量服务器并行计算，才能实现的功能。这节课，我就给你分享一下这些算法。

我先把实时计算的整体结构图放出来，方便你建立整体印象。

![图片](https://static001.geekbang.org/resource/image/81/76/81a4f654a2f5b473d8f0f157a60af676.jpg?wh=1920x1234 "实时计算的整体结构图")

从上图可见，我们实时计算的数据是从Kafka拉取的，通过进程实时计算统计 Kafka的分组消费。接下来，我们具体看看这些算法的思路和功用。

## URL去参数聚合

做链路跟踪的小伙伴都会很头疼URL去参数这个问题，主要原因是很多小伙伴会使用RESTful方式来设计内网接口。而做链路跟踪或针对API维度进行统计分析时，如果不做整理，直接将这些带参数的网址录入到统计分析系统中是不行的。

同一个API由于不同的参数无法归类，最终会导致网址不唯一，而成千上万个“不同”网址的API汇总在一起，就会造成统计系统因资源耗尽崩掉。除此之外，同一网址不同的method操作在RESTful中实际也是不同的实现，所以同一个网址并不代表同一个接口，这更是给归类统计增加了难度。
<div><strong>精选留言（2）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/1d/e7/8e/318cfde0.jpg" width="30px"><span>Spoon</span> 👍（0） 💬（1）<div>还是以Restful API举例说明

GET geekbang.com&#47;user&#47;1002312&#47;info =&gt; geekbang.com&#47;user&#47;*num*&#47;info_GET
PUT geekbang.com&#47;user&#47;1002312&#47;info =&gt; geekbang.com&#47;user&#47;*num*&#47;info_PUT
DELETE geekbang.com&#47;user&#47;1002312&#47;friend&#47;123455 =&gt; geekbang.com&#47;user&#47;*num*&#47;friend&#47;*num*_DEL

method: GET&#47;PUT&#47;DELETE
url:geekbang.com&#47;user&#47;1002312&#47;info geekbang.com&#47;user&#47;1002312&#47;friend&#47;123455
time: 请求时间,秒

可以用大数据HIVE或者阿里的MaxCompute进行离线分析，这里以我司MaxCompute为例:
caoncat&#47;regexp_replace参考文档 https:&#47;&#47;help.aliyun.com&#47;document_detail&#47;48973.html
SELECT processed_url
    ,COUNT(*) As total_cnt
    ,MEDIAN(time) AS tp50_time
    ,AVG(time) As avg_time
FROM (
    SELECT concat(regexp_replace(url,&quot;\d&quot;,&quot;*num*&quot;),&quot;_&quot;,method) AS processed_url
        ,time
    FROM soure_data

) as temp_statistics
GROUP BY processed_url;

这里用离线数据分析的SQL举例，如果实时的类似
还有一种可以使用小时表同步方案做离线统计</div>2023-04-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/c6/20/124ae6d4.jpg" width="30px"><span>若水清菡</span> 👍（0） 💬（1）<div>对SQL不是很了解，接触到的SQL语句大致分为：增insert、删delete 、改update、查select这四类。其中查 select 的操作存在重复的可能性，如果是多人同时查询一个时间或者一个条件的数据，可以考虑根据select的参数聚合归类去重；增insert、删delete 、改update 都是原子操作，这三类操作都具有唯一性，可以提供语句操作模块，然后日志这边通过人工配置替换模板来聚合归类去重。</div>2023-01-23</li><br/>
</ul>