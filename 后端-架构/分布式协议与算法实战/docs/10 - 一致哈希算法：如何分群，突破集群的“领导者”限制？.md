你好，我是韩健。

学完前面几讲后，有些同学可能有这样的疑问：如果我们通过Raft算法实现了KV存储，虽然领导者模型简化了算法实现和共识协商，但写请求只能限制在领导者节点上处理，导致了集群的接入性能约等于单机，那么随着业务发展，集群的性能可能就扛不住了，会造成系统过载和服务不可用，这时该怎么办呢？

其实这是一个非常常见的问题。在我看来，这时我们就要通过分集群，突破单集群的性能限制了。

说到这儿，有同学可能会说了，分集群还不简单吗？加个Proxy层，由Proxy层处理来自客户端的读写请求，接收到读写请求后，通过对Key做哈希找到对应的集群就可以了啊。

是的，哈希算法的确是个办法，但它有个明显的缺点：当需要变更集群数时（比如从2个集群扩展为3个集群），这时大部分的数据都需要迁移，重新映射，数据的迁移成本是非常高的。那么如何解决哈希算法，数据迁移成本高的痛点呢？答案就是一致哈希（Consistent Hashing）。

为了帮你更好地理解如何通过哈希寻址实现KV存储的分集群，我除了会带你了解哈希算法寻址问题的本质之外，还会讲一下一致哈希是如何解决哈希算法数据迁移成本高这个痛点，以及如何实现数据访问的冷热相对均匀。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/aa/7a/ae8c247d.jpg" width="30px"><span>指尖以东</span> 👍（14） 💬（1）<div>最近一直在看hash，老师可否讲讲虚拟节点的算法怎么做才能做到均衡，不然加的节点还是可能冷热不均衡的</div>2020-05-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c3/5d/ced9b5c2.jpg" width="30px"><span>Michael Tesla</span> 👍（25） 💬（1）<div>老师，我觉得课后题的答案是：数据要同时写入当前集群和下一个集群。某个Raft集群挂掉后，原本路由到这个集群的请求，现在都到下一个Raft集群去了。只要下一个Raft集群保存了上一个集群的数据，即使某个集群挂了，整个系统还能正常提供服务。</div>2020-03-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/10/e8/ec11e306.jpg" width="30px"><span>Purson</span> 👍（18） 💬（1）<div>老师，consistent-hash.go 和 hash.go 算法希望能分享一下。另外有个问题，虚拟节点还是映射了实际节点，比如一个节点有4个虚拟节点，如果1个实际节点挂了，是不是意味着另外3个相关的虚拟节点挂了，这样一致性hash算法还是会有很多不命中的情况。</div>2020-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/2b/cf/bfb4d21f.jpg" width="30px"><span>星期一</span> 👍（16） 💬（3）<div>那TiDB 通过raft实现kv，region 来突破领导者单点问题，老师可以不可以串讲一下：TiDB、kafka、es 等常见分布式中间件  它们各自如何解决分布式的问题。</div>2020-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/03/1c/c9fe6738.jpg" width="30px"><span>Kvicii.Y</span> 👍（8） 💬（1）<div>4.当某一个节点故障了，该节点上的数据需要进行迁移吗？？感觉只是影响了瞬间的读写，raft选举会很快进行吧，恢复了之后就有正常了，选举期间的读写访问顺延到下一节点这个才需要具体实现吧？</div>2020-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/8d/ed/ea2cbf3a.jpg" width="30px"><span>Sinclairs</span> 👍（8） 💬（7）<div>针对多个 Raft 集群, 需要有一个路由系统, 客户端通过这个路由系统来读写数据..
1. 客户端写数据时, 根据哈希算法会得到一个值, 这个值可以落到集群A的哈希分片上, 假设集群B是集群A顺时针哈希分片后的下一个分片.
客户端写入数据时, 要保证集群A和集群B同时写入成功
2. 客户端读取数据时, 路由系统若检测到集群A不可用, 则去访问集群B, 也能获得数据.
集群A和相邻的集群B同时发生故障的概率是非常小的, 这样就能保证系统的稳定运行.</div>2020-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/86/e3/a31f6869.jpg" width="30px"><span> 尿布</span> 👍（7） 💬（1）<div>为什么一个节点可以算出多个hash值?</div>2020-03-12</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKhuGLVRYZibOTfMumk53Wn8Q0Rkg0o6DzTicbibCq42lWQoZ8lFeQvicaXuZa7dYsr9URMrtpXMVDDww/132" width="30px"><span>hello</span> 👍（7） 💬（4）<div>老师请教下，在环中加入节点以及去掉节点，那存储的数据是如何迁移到其它节点上的？</div>2020-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/f6/e3/e4bcd69e.jpg" width="30px"><span>沉淀的梦想</span> 👍（5） 💬（2）<div>当其中一个 Raft 集群领导者出现故障，读的时候还是可以从跟随者读，写的时候可以暂时先写到哈希环上的下一个集群中，等到重新选举领导者完成，再把数据捞回来。这么设计可以吗？</div>2020-03-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/19/49/83e9fa4b.jpg" width="30px"><span>Theodore</span> 👍（4） 💬（1）<div>解开了我多年的疑惑。我说一致性hash怎么解决迁移带来的问题，还是靠运维啊</div>2020-04-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/03/1c/c9fe6738.jpg" width="30px"><span>Kvicii.Y</span> 👍（4） 💬（1）<div>老师，
1.虚拟节点是要根据hash规则再做一次hash类似这样实现吗？
2.在这个例子中，节点A、B、C是不是就可以理解为三个Raft集群，每个集群上都分别有Leader，各自进行集群的维护操作呢？</div>2020-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/47/31/f35367c8.jpg" width="30px"><span>小晏子</span> 👍（4） 💬（2）<div>将数据按照某种方式分片然后按照一致性hash算法存放到不同的raft集群中，这样当某个集群出问题时，这部分分区数据会迁移到临近raft集群，保障了系统的稳定运行。理论上可行，可是实际中好像没有这样做的，管理多个raft集群感觉是个麻烦的事情。</div>2020-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/3b/7d/6376926b.jpg" width="30px"><span>吟游雪人</span> 👍（2） 💬（4）<div>多集群是多领导者节点么？多领导者不就脑裂了么？</div>2020-04-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/03/1c/c9fe6738.jpg" width="30px"><span>Kvicii.Y</span> 👍（2） 💬（1）<div>3.对2^32取模的过程是不是相当于计算hash环的索引，实际对key进行hash计算找位置时才是找真正的索引？</div>2020-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/7a/93/c9302518.jpg" width="30px"><span>高志强</span> 👍（2） 💬（1）<div>老师，consistent-hash.go 和 hash.go 算法在github上有代码么，想看看</div>2020-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1a/51/b8/f76b15a1.jpg" width="30px"><span>sundy</span> 👍（1） 💬（1）<div>老师 明明是取余%操作 为什么说是取模呢？</div>2020-06-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4d/49/28e73b9c.jpg" width="30px"><span>明翼</span> 👍（1） 💬（1）<div>老师我对一致hash算法搬迁数据量有疑问，比如文中三个节点变成四个节点假设数据是均衡的三个节点存数据为总得33.3%，调整数据大概只要调整第三个节点的一半即16%这个比您文中的要少，怎么回事，是不是hash不均衡造成的偏差那您又如何知道该如何均衡的那</div>2020-04-17</li><br/><li><img src="https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIQMh5jMlvAibnTgiaVXmsb333JBjpdvLVcptc232zQey5wkBOEPiauepQpv8UlRcOFqnTyhEQiadaHMA/132" width="30px"><span>winfield</span> 👍（1） 💬（3）<div>有个疑问，一致性哈希中引入虚拟节点能解决冷热不均的问题么，虚拟节点最后不还是映射到了实际节点上？请老师帮忙解答下，谢谢！</div>2020-04-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/1b/bb/4a749b6c.jpg" width="30px"><span>孙成子</span> 👍（1） 💬（1）<div>一致性HASH算法，为什么会出现不均匀的情况？  hash的目的就是打散数据。</div>2020-03-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/6e/4a/7af58dc7.jpg" width="30px"><span>gokunn</span> 👍（1） 💬（2）<div>老师，请问一下，一致性hash下的raft集群还是会有单点问题，如果某个热点key分到一个raft集群里面，这个key访问非常频繁，而这个raft集群性能不足怎么办</div>2020-03-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/30/c1/2dde6700.jpg" width="30px"><span>密码123456</span> 👍（1） 💬（1）<div>写的限制已经突破了，但是我们的系统也越来越复杂了。</div>2020-03-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/dd/51/a7e82963.jpg" width="30px"><span>波波</span> 👍（1） 💬（1）<div>老师，如果环中的某个节点挂了，数据迁移到另一个节点上，那如果这个故障的节点恢复回来了，按照一致性哈希算法，读取迁移后的数据是从恢复回来的节点读还是从迁移后的节点读啊？
</div>2020-03-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/82/3d/356fc3d6.jpg" width="30px"><span>忆水寒</span> 👍（1） 💬（1）<div>老师，你说的raft集群是每个节点一主多备吧。然后每个主节点和备节点之间通过选举产生主节点吧。
可以采用redis中哈希槽的概念。
首先每个raft节点都会缓存（动态更新）其他节点的通信数据，用于集群内相互通信。
当一个节点挂掉了，可以将自己对应的哈希槽数据迁移到其他节点。</div>2020-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/f8/ba/d28174a9.jpg" width="30px"><span>Geek_zbvt62</span> 👍（1） 💬（1）<div>基于虚拟节点的机制，可以设计成每个节点是自身负责这部分虚拟节点的leader，左右相邻的两个节点为follower。每个leader down掉了，左右两个follower选举出leader，接管之前的节点负责的虚拟节点，恰好自身也包含了这部分数据。</div>2020-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/2e/02/07ae4c9e.jpg" width="30px"><span>rm -rf/*</span> 👍（1） 💬（1）<div>老师：
    是不是就是  一个raft中的领导者做一致性hash的一个节点？？？</div>2020-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/30/3c/0668d6ae.jpg" width="30px"><span>盘胧</span> 👍（1） 💬（1）<div>这三个集群性能差不多，就分散。总觉得少了点啥？如果资源异构的场景呢？
总结下，
1.一致性哈希适合同类型的节点集群，可以支持弹性伸缩。
2.哈希算法适合比较稳定的场景，规模不容易改变的。</div>2020-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1c/cf/ef/2e545600.jpg" width="30px"><span>灰色的世界</span> 👍（0） 💬（1）<div>老师，跨网络中心的raft的集群设计有哪些关键点呢</div>2020-11-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/ae/8b/43ce01ca.jpg" width="30px"><span>ezekiel</span> 👍（0） 💬（1）<div>您好
为什么一定要为节点名称进行Hash？如果不进行Hash运算，直接在hash环上取值，在映射到节点上。节点不就可以均匀分布了吗？</div>2020-10-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/d9/ff/b23018a6.jpg" width="30px"><span>Heaven</span> 👍（0） 💬（1）<div>这个影响并不在于领导者的选举问题啊,而是数据能否再次获得问题,一个领导者节点挂了,能不能再拿到这个领导者在整个一致性hash系统的数据,如果能够拿到,那就相当于一次细微的迁移,并不会对整个系统的稳定运行产生什么影响,不能拿到,那才是真正的出问题了</div>2020-08-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/da/ec/779c1a78.jpg" width="30px"><span>往事随风，顺其自然</span> 👍（0） 💬（1）<div>有java版本的一致性hash代码？go看起来看不大明白</div>2020-03-19</li><br/>
</ul>