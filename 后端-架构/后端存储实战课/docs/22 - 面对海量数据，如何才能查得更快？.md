你好，我是李玥。

我们接着上节课的话题，来继续说海量数据。上节课我们讲了，如何来保存原始数据，那我们知道，原始数据的数据量太大了，能存下来就很不容易了，这个数据是没法直接来给业务系统查询和分析的。有两个原因，一是数据量太大了，二是也没有很好的数据结构和查询能力，来支持业务系统查询。

所以一般的做法是，用流计算或者是批计算，把原始数据再进行一次或者多次的过滤、汇聚和计算，把计算结果落到另外一个存储系统中去，由这个存储再给业务系统提供查询支持。这里的“流计算”，指的是Flink、Storm这类的实时计算，批计算是Map-Reduce或者Spark这类的非实时计算。

上节课我们说过，像点击流、监控和日志这些原始数据是“海量数据中的海量数据”，这些原始数据经过过滤汇总和计算之后，大多数情况下数据量会有量级的下降，比如说从TB级别的数据量，减少到GB级别。

有的业务，计算后的数据非常少，比如说一些按天粒度的汇总数据，或者排行榜类的数据，用什么存储都能满足要求。那有一些业务，没法通过事先计算的方式解决全部的问题。原始数据经过计算后产生的计算结果，数据量相比原始数据会减少一些，但仍然是海量数据。并且，我们还要在这个海量数据上，提供性能可以接受的查询服务。
<div><strong>精选留言（23）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/16/e7/76/79c1f23a.jpg" width="30px"><span>李玥</span> 👍（32） 💬（0）<div>Hi，我是李玥。

这里回顾一下上节课的思考题：

课后请你想一下，为什么 Kafka 能做到几倍于 HDFS 的吞吐能力，技术上的根本原因是什么？

答案：

这个问题的最根本原因是，对于磁盘来说，顺序读写的性能要远远高于随机读写，这个性能差距视不同的磁盘，大约在几十倍左右。Kafka是为顺序读写设计的，儿HDFS是为随机读写的设计的，所以在顺序写入的时候，Kafka的性能会更好。</div>2020-04-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1c/ed/e0/c63d6a80.jpg" width="30px"><span>1</span> 👍（10） 💬（3）<div>我对内存数据库有个疑问，是启动之后他会把放到硬盘的数据放到内存里？还是查询过一次之后把结果放到内存里</div>2020-04-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/b3/a7/d3ffc8ac.jpg" width="30px"><span>me不是一个人战斗</span> 👍（6） 💬（3）<div>之前介绍es的时候，也说过es作为分布式内存数据库，这个如何理解？es并没有像redis一样，把所以数据都存储在内存里，求解释，谢谢～</div>2020-05-04</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/ajNVdqHZLLBllicLBj61g1ibmCeWzLYpQYEteTOtAAAypoIg6CD19ibXQBbM09VsME9Ta1G8ubwk0ibjiacItavibaeg/132" width="30px"><span>seg-上海</span> 👍（4） 💬（4）<div>数据量没到PB的时候直接用ES,再大的话，估计得用MR了，但MR会不会太慢了</div>2020-04-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg" width="30px"><span>奕</span> 👍（34） 💬（2）<div>对于思考题，会选择 ES 作为存储系统，这里是因为是
1: 日志一般是根据时间线来保存的，而且不用保存历史的数据，只需要保存最近 15天或者 7天的数据就可以满足要求，数量量不是很大
2: 查看日志的时候一般都会使用全文搜索， ES 可以高效的支持全文搜索</div>2020-04-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/16/5b/83a35681.jpg" width="30px"><span>Monday</span> 👍（25） 💬（0）<div>本篇细细品尝了N遍，最后我们系统在达到mysql性能瓶颈的数量级（千万）时，我们引入了es。将部分查询接口由mysql转到es，数据实时同步使用canal，历史数据同步使用logstash。</div>2020-08-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/a5/98/a65ff31a.jpg" width="30px"><span>djfhchdh</span> 👍（5） 💬（0）<div>日志分为系统日志和业务服务日志。系统日志的格式较为一致，而业务服务的日志格式都不太一样。系统日志关乎服务器的运行状态，对实时性要求较高，日志量也很大，对存储系统的读写吞吐量要求比较大，可以选择Kafka存储，而查询和分析可以考虑es，按照时间段来查询。而业务日志可以采用HDFS来存储，用hive来查询分析。</div>2020-09-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/0c/0f/93d1c8eb.jpg" width="30px"><span>mickey</span> 👍（5） 💬（1）<div>思考题：存储全量程序日志，提供查询和分析服务，我会首先考虑使用时序数据库，比如InfluxDB、OpenTSDB。原因有两点：1）日志具有强时间轴性，且需要有非常好的写性能；2）日志需要提供查询分析，时序数据库能提供很好的读性能，也能提供很方便的查询和聚合数据的能力。</div>2020-04-23</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKhuGLVRYZibOTfMumk53Wn8Q0Rkg0o6DzTicbibCq42lWQoZ8lFeQvicaXuZa7dYsr9URMrtpXMVDDww/132" width="30px"><span>hello</span> 👍（5） 💬（1）<div>时序数据库，如Influxdb</div>2020-04-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（5） 💬（0）<div>我们采取的方式是，最近的三天日志存在es里，旧的数据存在S3，查询的时候使用spectrum</div>2020-04-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/37/29/b3af57a7.jpg" width="30px"><span>凯文小猪</span> 👍（3） 💬（0）<div>二刷打卡：
老师实际上讲了一个思路 就是对同一份数据 是可以路由多份到不同类型的存储结构:
1.对于线上普通查询 有两种方式：
  1） 传统mysql 这种一般是订单类查询 可以使用分库分表 或是mysql聚合表、redis聚合表抗一抗
  2）ES查询  ES的问题有两点：一是存在热点key问题 因为es是基于内存 所以一定会有命中率要求。二是ES天生不支持改动表结构 这个和日志文件只能递增是一样的。分页查询可以利用瀑布流 也就是snapshot来模拟。
2.实时计算
这种一般是要HDFS来支持 传统的java后端无能为力 ，这里要注意的是通常数据很脏 要洗数据才能开始计算
3.离线查询 
以点击流、或是物流来说 每日数据量在10TB以上 那么通常使用HSFS HBASE 一类来存储 ，但是他们的查询方式是有要求的 不可能如同mysql那么随意

以上是一个小结 这部分最大的问题除了存储介质选型要求设计人员很高的素质外 还有同一份数据在不同存储介质一致性问题，而这本身也是冗余带来的一致性问题。
我的思想是 考虑到不同存储介质之间写差异 我个人推荐使用财务冲账方式来处理 ，即对于正向流程可以正常处理 而出现逆向流程则通过反向订单方式 再生成一条记录将其中和掉。这样末端查询也可以保持多存储介质间数据一致性。

==================================
回答下思考题：
对于开发来说 通常查的是线上实时及近3天，7天内数据 所以我推荐是用EFK 同时每日需要将3天外或7天外数据将其清除 所以压力不大
对于运维来说 通常查的是实时数据 但是要求数据有关联 所以除了传统方式外 还需要用时序数据库来关联 得到整个站点的地图</div>2021-12-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/34/df/64e3d533.jpg" width="30px"><span>leslie</span> 👍（3） 💬（1）<div>DB和OPS从业多年越来越觉得很难单一用某套系统去解决问题，记得老师在消息队列的课程提及过；消息队列的作用是削峰填谷，最近在思考&quot;中台&quot;真实的作用是什么？是不是真的偶然？是不是就是由于现在单一无力解决而造就了中台的诞生。
mysql早期的分引擎处理其实比现在更合理，5.7开始读写都一套引擎反而限制了；虽然业界普遍认为8更好，可是个人觉得早期的做法避免了跨库；读写全部依赖一种东西是不可能真的做到平衡的。就像老师文中提及“需求决定数据库的选择”，日志系统其实合适的很多关键还是要看怎么操作；记得曾经听说过有一套数据库是基本不做DML的，只做查询性能极其好。
&quot;需求决定选择&quot;我觉得这才是现在对于DB这块最合理的选择。
谢谢老师的分享，期待后续的课程。</div>2020-04-16</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/aobibE2ABHn3njdaHBY23hcZcIs71aRahryuUDcLghQqTjmwghEIgKYelBERlNK881MP0oRpWGnrQdscD85dZ9g/132" width="30px"><span>云封</span> 👍（2） 💬（0）<div>老师你好，我想问下一个20多台greenplum的集群，一个表大概100亿的数据，通过手机号查找相关的联系人经常把表给整挂了。后来按照时间分片，查询性能也比较慢，老师有没有比较好的建议</div>2020-08-06</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/fcftgBsticCicEEkuzB0GTkHIocX62YVTSvnhR1c94sccj42lVaYXrmcZyhzUI3l9NcvuN1rXLhXt2eBrZZ0Tw7A/132" width="30px"><span>idiot</span> 👍（1） 💬（1）<div>lsm的关键不是算法复杂度，而是磁盘io，把多个随机写合并成批量写</div>2021-08-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/16/5b/83a35681.jpg" width="30px"><span>Monday</span> 👍（1） 💬（2）<div>第15章，得到MySQL适合TB级别以下
从这节课开始，我们课程将进入最后一部分“海量数据篇”，这节课也是我们最后一节主要讲 MySQL 的课程。解决海量数据的问题，必须要用到分布式的存储集群，因为 MySQL 本质上是一个单机数据库，所以很多场景下不是太适合存 TB 级别以上的数据。

本章，获得MySQL适合GB级别。。。
然后我们看有哪些可供选择的存储产品。如果你的系统的数据量在 GB 量级以下，MySQL 仍然是可以考虑的

是编辑写错了，还是我理解 错了？
</div>2021-01-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/34/f9/c46c0fff.jpg" width="30px"><span>Wind</span> 👍（1） 💬（2）<div>如果数据量不是太大，我会选ELK</div>2020-04-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/23/a1/b08f3ee7.jpg" width="30px"><span>何妨</span> 👍（1） 💬（0）<div>还是看量级,课程中已有说到，少－mysql,中－ES,多－HDFS</div>2020-04-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/81/8a/15a96a64.jpg" width="30px"><span>Gatsby</span> 👍（0） 💬（0）<div>es + kibana做实时查询
hive做离线数据分析查询</div>2022-07-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/77/49/445eea2d.jpg" width="30px"><span>SochiLee</span> 👍（0） 💬（0）<div>es作为数仓，合理吗？</div>2021-11-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/ae/cf/6186d936.jpg" width="30px"><span>辉度</span> 👍（0） 💬（0）<div>存储采取influxdb等列式数据库，压缩率高。且个时间强相关。

读时热点数据使用es，比如只保留30天。</div>2021-08-11</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoWfXendN7czHpsyaWKLPK6Na9P5czquJ7Wdre4TibZQ5SQib88edyuib3LpCVFkp0gII2wyvvR8tEIA/132" width="30px"><span>OM</span> 👍（0） 💬（0）<div>某些业务用oracle一体机或者国产一体机，无需怎么麻烦，10TB数据通过一体机的机制过滤成1TB，再10GB，再到用户是1GB的量，智能扫描，开源很多库还无法做到。</div>2021-08-08</li><br/><li><img src="" width="30px"><span>Grocker</span> 👍（0） 💬（0）<div>我所在的项目就是做报表系统的，目前用到了greenplum 和 elasticsearch</div>2020-06-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg" width="30px"><span>aoe</span> 👍（0） 💬（1）<div>这么大的数据，已经买不起硬盘存储了</div>2020-04-17</li><br/>
</ul>