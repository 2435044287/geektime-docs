我在开篇词讲到，任何新技术都不是凭空产生的，都是在既有技术的基础之上，进行了一些创新性的组合扩展，应用到一些合适的场景之中，然后爆发出来巨大的生产力。后面几篇我要讲的大数据技术，区块链技术都是如此。

大数据技术其实是分布式技术在数据处理领域的创新性应用，本质和我们此前讲到的分布式技术思路一脉相承：用更多的计算机组成一个集群，提供更多的计算资源，从而满足更大的计算压力要求。

前面我们讨论的各种分布式缓存、负载均衡、分布式存储等都是讲如何在高并发的访问压力下，利用更多的计算机满足用户的请求访问压力。而大数据技术讨论的是，如何利用更多的计算机满足大规模的数据计算要求。

大数据就是将各种数据统一收集起来进行计算，发掘其中的价值。这些数据，既包括数据库的数据，也包括日志数据，还包括专门采集的用户行为数据；既包括企业内部自己产生的数据，也包括从第三方采购的数据，还包括使用网络爬虫获取的各种互联网公开数据。

面对如此庞大的数据，如何存储，如何利用大规模的服务器集群处理计算大量的数据，就是大数据技术的核心关键。

## 分布式文件存储HDFS架构

大规模数据计算首先要解决的是大规模数据的存储问题。如何将数百T，数百P的数据存储起来，通过一个文件系统统一管理，这本身就是一个极大的挑战。
<div><strong>精选留言（10）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/13/75/dd/9ead6e69.jpg" width="30px"><span>黄海峰</span> 👍（2） 💬（1）<div>shuffle把相同key发送给同一个reduce，那岂不是还是要传输大量数据？还是实际是把相同key放到相同hdfs文件reduce进程读取？</div>2020-02-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/7a/f7/24df0ff9.jpg" width="30px"><span>Winon</span> 👍（0） 💬（2）<div>老师说的集群有标准吗？譬如，由两台相同功能组成的服务器提供服务，算集群吗？</div>2020-07-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/da/dd/1e5e7b0c.jpg" width="30px"><span>image</span> 👍（8） 💬（0）<div>Flink引擎是基于record，还是和spark streaming minibatch有较大区别的。</div>2020-03-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/92/6d/becd841a.jpg" width="30px"><span>escray</span> 👍（6） 💬（0）<div>大数据技术首先要有大数据，其次要有大规模的数据计算要求。

没有接触过大数据相关的项目，但是基本的概念还是有的。曾经在体制内工作过一段时间，很多项目也跟风大数据、云计算、人工智能……区块链也不能阻止他们。

不过在我看来，其实很多大数据项目压根就没有“大数据”，却寄希望于从一堆没有意义的数据中，找到“啤酒和尿布”；另一方面，文中说“大数据技术主要是为了满足大规模数据计算要求”，你能想象以前用纸质文件保存的数据，一上来就要“数据挖掘”么？

其实，在没有一个好的量化标准的情况下，大数据技术的投入产出比是没法计算的。相对于互联网大厂，有数据、有需求、有指标，一般的项目可以从简单架构开始，等到计算能力出现瓶颈在考虑大数据技术。</div>2020-10-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/f5/b9/888fe350.jpg" width="30px"><span>不记年</span> 👍（3） 💬（0）<div>交作业~
map程序: page_view行数据 -&gt; (userid , pageid + &quot;,&quot; + &quot;&quot;)
               user行数据 -&gt; (userid, &quot;&quot; + &quot;, &quot; +age)
reduce程序: （userid, [pageid + &quot;,&quot; + &quot;&quot;,  &quot;&quot; + &quot;, &quot; +age]） -&gt; (pageid , age)</div>2020-02-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/7b/0a/b65e1fae.jpg" width="30px"><span>不要挑战自己的智商</span> 👍（2） 💬（0）<div>spark会在data node做更多的内存运算，很多reduce的过程在data node里面就完成了，以word count 为例，对于每个word出现的次数，在每个data node里面就先分别计算好了。最后在把各个data node里面的结果相加就是了。对吧？
spark会优化和从新排列用户指令，来达到更更效率的运算。这点好像一些sql引擎也在做?

hadoop 是把reduce完全放在shuffle之后，这样在shuffle的过程中，需要通过网络移动更多数据。

</div>2020-08-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/47/6c/78184d19.jpg" width="30px"><span>非洲黑猴子</span> 👍（1） 💬（0）<div>MapReduce 程序可以自定义 Partitioner, 决定哪些相同的 key 去到哪些 Reducer. 这里使用自定义的分区器, 分别处理两张表的 userid, 对两张表的这个字段分别计算分区, 这样两张表中相同的 userid 的数据便会在同一个 Reducer 中相遇. 接下来的Reduce计算就方便了</div>2023-06-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/47/6c/78184d19.jpg" width="30px"><span>非洲黑猴子</span> 👍（0） 💬（0）<div>MapReduce 程序可以自定义 Partitioner, 决定哪些相同的 key 去到哪些 Reducer. 这里使用自定义的分区器, 分别处理两张表的 userid, 对两张表的这个字段分别计算分区, 这样两张表中相同的 userid 的数据便会在同一个 Reducer 中相遇. 接下来的Reduce计算就方便了</div>2023-06-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/63/ed/b5c9a1a7.jpg" width="30px"><span>特立独行的猪</span> 👍（0） 💬（0）<div>hive，map reduce，spark 的关系能讲得再细一些吗？flink能多讲一些就更好了</div>2021-02-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/51/de/990fd4f2.jpg" width="30px"><span>好好先生</span> 👍（0） 💬（0）<div>买下一门课！！！加油！！</div>2020-03-29</li><br/>
</ul>