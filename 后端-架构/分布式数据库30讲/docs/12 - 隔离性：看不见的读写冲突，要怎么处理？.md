你好，我是王磊，你也可以叫我Ivan。

我们今天继续聊读写冲突。上一讲我们谈的都是显式的读写冲突，也就是写操作和读操作都在同一时间发生。但其实，还有一种看不见的读写冲突，它是由于时间的不确定性造成的，更加隐蔽，处理起来也更复杂。

关于时间，我们在[第5讲](https://time.geekbang.org/column/article/274908)中已经做了深入讨论，最后我们接受了一个事实，那就是无法在工程层面得到绝对准确的时间。其实，任何度量标准都没有绝对意义上的准确，这是因为量具本身就是有误差的，时间、长度、重量都是这样的。

## 不确定时间窗口

那么，时间误差会带来什么问题呢？我们用下面这张图来说明。

![](https://static001.geekbang.org/resource/image/9a/74/9a6b93299744yye0cbfa6b00b9170474.jpg?wh=2700%2A915)

我们这里还是沿用上一讲的例子，图中共有7个数据库事务，T1到T7，其中T6是读事务，其他都是写事务。事务T2结束的时间点（记为T2-C）早于事务T6启动的时间点（记为T6-S），这是基于数据记录上的时间戳得出的判断，但实际上这个判断很可能是错的。

![](https://static001.geekbang.org/resource/image/ac/fe/acbce9810c15354948e4217ef37279fe.jpg?wh=2700%2A917)

为什么这么说呢？这是因为时间误差的存在，T2-C时间点附近会形成一个不确定时间窗口，也称为置信区间或可信区间。严格来说，我们只能确定T2-C在这个时间窗口内，但无法更准确地判断具体时间点。同样，T6-S也只是一个时间窗口。时间误差不能消除，但可以通过工程方式控制在一定范围内，例如在Spanner中这个不确定时间窗口（记为ɛ）最大不超过7毫秒，平均是4毫秒。
<div><strong>精选留言（14）</strong></div><ul>
<li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTK0Qwib3PcoRRxTZSoxAdJ1hELibJeoEqSKP6Ksyu0e7MrGickk1COuv6oQ1w9W2kqM8gUg0Oj057UBw/132" width="30px"><span>UTC+00:00</span> 👍（8） 💬（3）<div>关于思考题，我想老师的问题已经透露出了答案。时间误差是由多个独立时间源造成的。那么，在“单时间源”的情况下，就能够保证线性或因果一致性。但是，受限于单点，可用性和集群部署范围大大受限。关于可用性，TiDB是通过落盘全局时钟+多个PD构成Raft组来解决。集群部署范围，对于绝大多数公司的应用场景来说，都用不到全球化部署。
PS: 老师，TrueTime拼错了。</div>2020-09-06</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIdCoCuWIfSd0z2Xd2iaYtM15Io390aqkQwpicvezs6Oeh7O5jleM555EZcmA5ibs2Rgu8nlWE1nvqww/132" width="30px"><span>Geek_eo2sbf</span> 👍（6） 💬（5）<div>有个点看了几遍还是没能理解清楚：这个写等待与读等待  与  具体的事务类型（读写）有关系么：
Spanner的写等待只是针对写事务么，那读事务时怎么办？
CockroachDB的读等待只是在遇到读事务的时候才进行，那写事务的时候不管吗？</div>2020-09-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/3e/e9/116f1dee.jpg" width="30px"><span>wy</span> 👍（2） 💬（1）<div>老师，请教一个问题，如果是判断读写冲突的话，根据文中举的例子，直接标记写事务是否完成不就好了吗？为什么要通过时间戳去判断呢？</div>2021-01-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/e0/cf/43f201f2.jpg" width="30px"><span>幼儿编程教学</span> 👍（1） 💬（1）<div>请教老师。这个等待，是因为像上一篇文章中说的，因为操作了相同的数据，所以等待了呢？还是所有事务，不管是否操作相同数据，都要等待？如果不管内容，都要等待，那tps就有极限值了。

你在文章中说的，spanner，8ms，tps是125，就是同一块数据吧。所以，提交的时候，db还会校验，是否已有未提交的事务操作了相同的数据，是吧？</div>2020-11-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/fd/af/ca57c38b.jpg" width="30px"><span>贺</span> 👍（0） 💬（3）<div>读等待我很好理解，就是通过延迟以便能确定读到更新后的值。
但是写等待和我理解的不一样，我理解的是让写延迟提交，以便读取的事务确定能读到提交前的值，而不是提交后的值。
不知道我理解的哪里有问题？</div>2020-11-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/12/13/e103a6e3.jpg" width="30px"><span>扩散性百万咸面包</span> 👍（0） 💬（1）<div>理解了为什么普通读等待等一个误差就行，不理解Spanner要等2个。感觉老师这里还可以说的更详细点。

我的理解是，等的第一个误差是等所有预备时间戳都已经真正提交，第二个误差就是和之前介绍的一样。</div>2020-09-21</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIERY97h7dmXWic58E44CdCSx1NicA8oYfuFwgjbsZjAsfblib4551owRibW3zsfCa2K6WAibkzQ50qHmA/132" width="30px"><span>J</span> 👍（0） 💬（2）<div>老师写等待有个问题不能理解，文中写等待后TB是在S+E启动的，如果TB还是在S+X启动，且X&lt;E，当么当时TA还没落盘，就读不到数据。和之前没有写等待的情况是一样的</div>2020-09-16</li><br/><li><img src="" width="30px"><span>myrfy</span> 👍（0） 💬（2）<div>spanner的e为什么是4ms呢？如果误差区间在±7ms，可靠的时间窗口就应该是14ms了 所以怎么理解这个误差呢？</div>2020-09-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/5c/3e/a9c91e9f.jpg" width="30px"><span>武功不高</span> 👍（4） 💬（3）<div>跟谈恋爱一样，距离不一定产生美，但肯定容易引起误会……所以确定关系的两人尽量住的近点，同居最好，最大限度消除误会的可能😄</div>2020-09-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/01/eb/9f066505.jpg" width="30px"><span>叶东富</span> 👍（2） 💬（0）<div>commit-wait原理是事务T在S时刻提交写盘，但是暂时不汇报提交成功。等待e之后，再汇报提交成功，即S+e之后，T才结束。这种情况下，T之后的读，即S+e之后的读，能够确保读出S写入的结果，保证了线性一致性。
不是等待e之后再提交写盘，而是提交写盘后等待e再汇报事务T完成。</div>2021-09-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg" width="30px"><span>piboye</span> 👍（2） 💬（1）<div>commit wait是保障rc，因为只需要判断时间戳，可以不用管当前活跃事务，应该是更简洁稳定的实现。读等待是因为没有高精度的时钟，所以不能接受每个写2个时钟误差的延迟，只在有数据冲突的情况下重启后续事务。</div>2020-09-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/d5/33/d79fae5c.jpg" width="30px"><span>Hommin</span> 👍（0） 💬（0）<div>关于读等待的事务重启，如果是可重复读级别的数据库，且为多条SQL的事务，该怎么重启？比如SQL1查询了10行数据，业务处理，SQL2在读的时候遇到了不确定时间，那么该怎么办，因为SQL1的数据已经返回给了客户端进行业务处理。是数据库让整个事务失败吗？还是说本文说的根本不包含这类事务？</div>2021-10-14</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIW1BibJQzCibFKOKibhScYzjicVzFF9gIOECnnEUbg7PEZeLyegYtdZliapXrZtNEM6JwNpVRGKbdQicdQ/132" width="30px"><span>熊潇</span> 👍（0） 💬（0）<div>请问写等待那里，TA事务从S启动写入到延迟∈之后再启动写入是怎么消除不确定性的呢？TB事务的启动时间确保不早于S+∈才行吧，是TA延迟写如何达到这种效果的呢？</div>2020-11-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/bb/c9/37924ad4.jpg" width="30px"><span>天天向上</span> 👍（0） 💬（2）<div>所以，这一讲的前提是，集群部署(高大上点，全球部署)，且集群中有多个数据源，且各个数据源各自都要支持读写事务！
所以在各个数据源间，如何保证各个事务逻辑上的一致性，因果性？
而谷歌因为牛叉，可以保证在复杂集群环境下，各个数据源服务器时间误差在7毫秒平均4毫秒！所以他们可以按照这个可信区间，去落地读等待方案，还是写等待方案都可以
而其他公司保证不了这个基础设施的牛叉性，所以要用raft之类的协议弥补这个能力缺失，进而达到集群中事务后数据的一致性因果性的逻辑正确</div>2020-09-14</li><br/>
</ul>