单服务器无论如何优化，无论采用多好的硬件，总会有一个性能天花板，当单服务器的性能无法满足业务需求时，就需要设计高性能集群来提升系统整体的处理性能。

高性能集群的本质很简单，通过增加更多的服务器来提升系统整体的计算能力。由于计算本身存在一个特点：同样的输入数据和逻辑，无论在哪台服务器上执行，都应该得到相同的输出。因此高性能集群设计的复杂度主要体现在任务分配这部分，需要设计合理的任务分配策略，将计算任务分配到多台服务器上执行。

**高性能集群的复杂性主要体现在需要增加一个任务分配器，以及为任务选择一个合适的任务分配算法**。对于任务分配器，现在更流行的通用叫法是“负载均衡器”。但这个名称有一定的误导性，会让人潜意识里认为任务分配的目的是要保持各个计算单元的负载达到均衡状态。而实际上任务分配并不只是考虑计算单元的负载均衡，不同的任务分配算法目标是不一样的，有的基于负载考虑，有的基于性能（吞吐量、响应时间）考虑，有的基于业务考虑。考虑到“负载均衡”已经成为了事实上的标准术语，这里我也用“负载均衡”来代替“任务分配”，但请你时刻记住，**负载均衡不只是为了计算单元的负载达到均衡状态**。

今天我先来讲讲负载均衡的分类及架构，下一期会讲负载均衡的算法。

## 负载均衡分类

常见的负载均衡系统包括3种：DNS负载均衡、硬件负载均衡和软件负载均衡。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/87/57/645159ee.jpg" width="30px"><span>鹅米豆发</span> 👍（393） 💬（26）<div>       日活千万的论坛，这个流量不低了。
1、首先，流量评估。
       1000万DAU，换算成秒级，平均约等于116。
考虑每个用户操作次数，假定10，换算成平均QPS=1160。
       考虑峰值是均值倍数，假定10，换算成峰值QPS=11600。
       考虑静态资源、图片资源、服务拆分等，流量放大效应，假定10，QPS*10=116000。 
2、其次，容量规划。
       考虑高可用、异地多活，QPS*2=232000。
       考虑未来半年增长，QPS*1.5=348000。
3、最后，方案设计。
       三级导流。
       第一级，DNS，确定机房，以目前量级，可以不考虑。
       第二级，确定集群，扩展优先，则选Haproxy&#47;LVS，稳定优先则选F5。
       第三级，Nginx+KeepAlived，确定实例。</div>2018-06-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/38/57/a9f9705a.jpg" width="30px"><span>无聊夫斯基</span> 👍（89） 💬（4）<div>我还是不是很理解TPS和QPS具体的区别</div>2018-08-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/cf/bb/22af0e52.jpg" width="30px"><span>孙振超</span> 👍（57） 💬（2）<div>这篇文章最大的收获是分析问题的思路，从dau出发，结合业务的特点，计算出来总的qps和tps，而后再根据通常规律计算出qps和tps的峰值，加上一定的未来发展空间和高可用冗余，结合单机能够支撑的qps和tps量，就可以计算出来整个集群的规模，有了这些数据就可以制定出比较合理的负载均衡的策略，而不是无的放矢，凭空猜测。



</div>2018-07-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/ed/68/737f97c8.jpg" width="30px"><span>ant</span> 👍（34） 💬（4）<div>日活跃用户1000万应该就是国家级应用了，面向全国活跃或者全球用户，比如最大的Xxx网站github。这个时候钱应该都不是问题了。我觉得可以考虑异地多机房部署。这样导流之后每个机房的日活就少很多。其实我在想如果在每个机房不加入负载硬件用多个ngnix集群来实现，每个ngnix上会有我们自定义的路由算法。ngnix也架设多层，逐层导流，比如我们一个机房设计承受200万，那么我们可以架设3层ngnix，第一层基于自己的路由算法导流到第2层ngnix。第2层又导流到第3层。为了避免ngnix单点，每一层ngnix部署多。这样导流下流每台服务器所承认的访问不会很多。不知道这样的设计能不能达到要求，老师点评下</div>2018-06-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/ce/2b/a47a0936.jpg" width="30px"><span>何国平</span> 👍（21） 💬（2）<div>nginx也支持4层反向代理了</div>2018-06-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/a1/78/71d37164.jpg" width="30px"><span>老北</span> 👍（18） 💬（3）<div>千万日活，论坛的时间相对比较集中，同时在线预计会达到一百万。
这时候会有一半的人在操作(查看帖子之类)，每个用户操作可能会调用2-3个接口。那并发数大约就是50w*2.5=125w?

这时候nginx的5w并发就不行了。需要多个dns到不同主机，再进行nginx,lvs之类转发。
另外像tomcat一般支持2000左右连接数。这样就需要600多台tomcat？
总感觉哪里算的不对😂</div>2018-07-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/e7/83/d1ed920d.jpg" width="30px"><span>plflying</span> 👍（18） 💬（3）<div>1、首先分析论坛系统的需求：高可用、扩展性、常规安全性、高性能。以上需求优先级依次降低。
2、并发计算：
	1）、首先计算每秒并发量：1000万&#47;(10*60*60)=278qps. (此处每天按照10个小时计算)
   2）、计算每秒最大并发量：278*5=1390. （此处的5为经验值，按照论坛的用户使用特点多集中晚上小部分时段，该值已尽量取大。同时网上也有按照时间和并发数的二八原则计算，本人按照第一种计算）
3、容量规划：
	1、前端2台nginx负载均衡，利用keepalive保证高可用。同时可用做静态资源缓存服务器。
   2、后端tomcat部署应用，按照单台tomcat支撑1200并发，需要2台。考虑冗余，此处配置3台。
   3、考虑高性能应用可以集成缓存，也可以使用统一缓存。
   4、数据库采用mysql，使用2台进行主从复制和读写分离。一方面满足读多写少的应用场景，另一方面在1台出现故障时，能保证高可用。
以上内容请老师指正！</div>2018-06-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/f4/d9/e572ae4d.jpg" width="30px"><span>食指可爱多</span> 👍（15） 💬（2）<div>请问老师后面会有容量规划方面文章吗？日活用户1000w转换成日请求量（这一步我没啥经验），再计算平均qps，考虑请求的波峰波谷，波峰取qps均值的5倍。1000x10000x10*24*60*60x5~5700得到qps峰值5700。不考虑后端应用层和更下层数据库缓存这些，接入层一个nginx就可以搞定了？</div>2018-06-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/dd/2a/976a9aec.jpg" width="30px"><span>低调的大老刘</span> 👍（11） 💬（1）<div>华哥，看到很多DNS+Nginx做负载，但是这种方式没办法预防DDOS攻击，你的Ip都暴露了</div>2018-06-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/05/d8/cd269378.jpg" width="30px"><span>一叶</span> 👍（9） 💬（2）<div>dear 华哥：文中说的一般的linux服务器 nginx 5w&#47;s ，lvs 80w&#47;s，这个一般的linux服务器能再具体一点吗，比如你们通常用的多少核多少g内存呢？3Q</div>2018-09-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/09/cf/9196b53b.jpg" width="30px"><span>lawrence.peng</span> 👍（8） 💬（0）<div>老师，看了前面的文章的话，经常能看到你说，linux服务器 nginx 5w&#47;s ，lvs 80w&#47;s 等等，并且知道这些机器是当前主流的配置 32C 48G,要求我们要把这个性能指标背熟，目地是很明显的，为了做容量规划。但现在很多创业公司，基本上都是上云的，云主机的配置基本都是4C 8G,问题来了，怎么去做这个应用的容量规划呢？或者这些指标哪里能查阅吗？</div>2020-09-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/2d/30/b840bd9e.jpg" width="30px"><span>交叉路口</span> 👍（8） 💬（1）<div>论坛这种业务的接口响应应该比较短，预计平均100ms ，超时限制500ms 。日活千万，预计峰值QPS 4000&#47;s，按照超时500ms ，并发估算2000。采取dns+nginx 足够，具体实例根据 staging 压测来评估。dns 一是为了地理位置负载均衡，还有为了扩展性（客户端通过域名访问，后端需要拓展机器对客户端透明）。Nginx ：应用负载均衡，打到某个服务实例，利用其故障转移（可检测实例状态进行剔除）、并发限制等特性来保证服务稳定性，同时还可以利用它做其他事情（access log 做日志行为分析）。希望华哥指出不足😃</div>2018-06-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/6d/9e/6a82a5ea.jpg" width="30px"><span>good boby</span> 👍（5） 💬（1）<div>向后延伸：负载均衡还包括以下处理
1、集群调度平台（PaaS）平台，例如k8s 、docker， 可以实现动态扩容和缩减，根据事实的并发量进行处理，当然前提是包括Nginx、lvs、haproxy前端负载均衡器不能挂掉。
2、分布式框架。
例如：Spring Cloud 的ribbion、feign也可以从应用层面实现负载均衡。</div>2021-04-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/0c/94/56ea80f7.jpg" width="30px"><span>沐风</span> 👍（4） 💬（2）<div>并发测试如何来做，怎么知道自己设计的数据库，或者架构能支撑多少并发</div>2018-06-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/ce/3d/385b8263.jpg" width="30px"><span>星火燎原</span> 👍（4） 💬（1）<div>不差钱的话可以考虑文中DNS +F5+ ngnix ，一般这种日活还是考虑DNS+LVS+Nginx</div>2018-06-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/25/e6/a69cff76.jpg" width="30px"><span>lyshrine</span> 👍（3） 💬（1）<div>老师画的这些有服务器的图，是哪那个软件画的？还是libreoffice？</div>2018-10-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/f5/2f/56117bab.jpg" width="30px"><span>张玮(大圣)</span> 👍（3） 💬（1）<div>看了大家的各种计算，估容量，估机器，

想说的是：根据之前专栏讲到的单台高性能模式等知识，先把单台机器做到最优化，同时做好负载均衡层，然后进行压测，一步一步添加机器，均衡层 Nginx 够了，另外，要考虑成本啊，F5尽量不用，稳定性用双主克服下</div>2018-06-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/87/b5/dd0353f4.jpg" width="30px"><span>三水</span> 👍（3） 💬（1）<div>老师，流行的SLB还有HAProxy，我们用LVS做DNS的LB，Nginx和HAProxy做HTTP的LB。</div>2018-06-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/60/b7/4a665c73.jpg" width="30px"><span>小鬼爱风雪</span> 👍（2） 💬（1）<div>1000万日活跃用户，最差情况是1000万并发，如果分散一下，500万可以了，以此量级去分析，真实场景会按照千万级设计</div>2021-06-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/fe/83/df562574.jpg" width="30px"><span>慎独明强</span> 👍（2） 💬（1）<div>看到华哥这章收获很大，之前见过这些名词很多次，但就是没搞清楚。DNS层应该都会有，进行域名解析为具体的ip。回头又看了公司之前运维发布的文章，公司采用的是腾讯云的组件，原理差不多，第一层有高防组件WAF并将https拆包为http，第二层是CLB(集群负载均衡)组件，第三层就是自己公司搭建的10台Nginx(8核16g)来反向代理到自己公司对应的服务器。</div>2020-08-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4e/1b/f4b786b9.jpg" width="30px"><span>飞翔</span> 👍（2） 💬（1）<div>微服务的服务发现是不是也算一类负载均衡？</div>2019-07-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/18/cb/edb5a0a0.jpg" width="30px"><span>小橙橙</span> 👍（2） 💬（1）<div>老师，有个问题一直不是很清楚，如果用nginx轮询做负载均衡，下游某个服务挂掉了，那就会导致某些请求无法响应，这样的问题要如何解决呢？</div>2018-07-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/d1/c8/80b4011d.jpg" width="30px"><span>迟博🙈</span> 👍（2） 💬（1）<div>我看到好多评论说多多机房，请问一下多机房的数据一致一般怎么解决的？数据库通过专线组成跨dc的多主集群？这个后面会讲到吗？</div>2018-06-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/de/17/75e2b624.jpg" width="30px"><span>feifei</span> 👍（2） 💬（1）<div>日活跃用户千万，按14小时折算，每秒并发198，但这是平均，还有高峰时段，并发按平均并发5倍来估算，即每秒1千，然后来对比方案：

Dns负载，目前单机房能够满足，没跨机房的必要，dns目前不适用。
硬件负载，每秒几百万级的并非，很显然系统没有这么高的并发，硬件负载不适合。
软件负载，nginx单台能支持到5万的并发，当前系统,折算最高的并发也不过千级别。

经过方案的对比，软件负载使用nginx可以完全满足业务的要求，所以使用软件负载即可

</div>2018-06-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/ca/e4/f15a1cf0.jpg" width="30px"><span>三月沙@wecatch</span> 👍（2） 💬（2）<div>不考虑多机房，不考虑不同地区，一个配置好点的nginx 就够了，防止单点，可以再加一台</div>2018-06-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/fc/e5/605f423f.jpg" width="30px"><span>肖一林</span> 👍（2） 💬（1）<div>峰值大概就是5000&#47;s～20000&#47;s，要看论坛活跃度。所以一个ng就够了。dns负载均衡也不一定就要支持异地多活吧，同一个机房多台主机也是可以的，所以最多dns+ng就可以很完美。需要异地多活的项目应该非常少。</div>2018-06-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/dc/b7/e59c22f0.jpg" width="30px"><span>黄金的太阳</span> 👍（2） 💬（1）<div>假设论坛的用户平均分布在全国各地(东，西，南，北四个区域)，1000万的日活跃用户平均分散到每个区域后可近似估计并发量在2.5万～5万用户，可以采用两级嵌套的负载均衡架构
1.利用DNS达到四个地域的负载均衡
2.利用Nginx的方式达到本区域内的负载均衡
此方案未考虑西部地区用户少，东部地区用户多的情况，在并发量尚可接受的范围内，可以考虑将单台Nginx集群化以增强并发负载支持能力

不知道理解的对不对</div>2018-06-12</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIk46cor5XVFTPZbPOnb7pViabgy450pobo46hRHFQz5nR5ocYRKIzC8vShic36vwa553H4Vj50x5wA/132" width="30px"><span>冲</span> 👍（1） 💬（1）<div>老师问下这个Nginx 5w的并发是在什么条件下的，Nginx装在一个专门的服务器上，下面还需要多少个装接口的服务器？</div>2024-04-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/4b/d7/f46c6dfd.jpg" width="30px"><span>William Ning</span> 👍（1） 💬（1）<div>老师同学好，所以DNS负载均衡就是多机房部署，剩下的就交给域名服务商了？</div>2022-03-14</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erD9YTBibqNvibicyicp31gBdJLJ7KPTuePMeibNWKGv9PydRID0AwvtUYEIO6qpTvXQpxbktR8fuHkCaA/132" width="30px"><span>Geek_ebe1c1</span> 👍（1） 💬（2）<div>老师说明并发是qps么 </div>2019-09-25</li><br/>
</ul>