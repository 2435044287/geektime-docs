你好，我是陶辉。

上一讲介绍了广播与组播这种一对多通讯方式，从这一讲开始，我们回到主流的一对一通讯方式。

早些年我们谈到高并发，总是会提到C10K，这是指服务器同时处理1万个TCP连接。随着服务器性能的提升，近来我们更希望单台服务器的并发能力可以达到C10M，也就是同时可以处理1千万个TCP连接。从C10K到C10M，实现技术并没有本质变化，都是用事件驱动和异步开发实现的。[\[第5讲\]](https://time.geekbang.org/column/article/233629) 介绍过的协程，也是依赖这二者实现高并发的。

做过异步开发的同学都知道，处理基于TCP的应用层协议时，一个请求的处理代码必须被拆分到多个回调函数中，由异步框架在相应的事件生成时调用它们。这就是事件驱动方式，它通过减少上下文切换次数，实现了C10M级别的高并发。

不过，做应用开发的同学往往不清楚什么叫做“事件”，不了解处理HTTP请求的回调函数与事件间的关系。这样，在高并发下，当多个HTTP请求争抢执行时，涉及资源分配、释放等重要工作的回调函数，就可能在错误的时间被调用，进而引发一系列问题。比如，不同的回调函数对应不同的事件，如果某个函数执行时间过长，就会影响其他请求，可能导致大量请求出现超时而处理失败。

这一讲我们就来介绍一下，事件是怎样产生的？它是如何驱动请求执行的？多路复用技术是怎样协助实现异步开发的？理解了这些，你也就明白了这种事件驱动的解决方案，知道了怎么样实现C10M。
<div><strong>精选留言（20）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg" width="30px"><span>奕</span> 👍（31） 💬（3）<div>如果每个请求约 10KB，那么每秒大概有 1 万个请求到达、10 万个事件需要处理
-------------------------
这里为什么 1 万个请求会有 10万个事件呢？ 每一个 TCP 链接在服务端不就是会产生一个 读事件 吗？</div>2020-05-24</li><br/><li><img src="" width="30px"><span>myrfy</span> 👍（26） 💬（1）<div>我认为涉及到CPU密集计算，就不应该再考虑C10M的问题了。C10M我们可以放在例如网关等逻辑简单的地方，负责数据转发即可。真正的计算放在本地线程池是一种方法，但我更倾向于转发到额外的计算处理集群去处理。</div>2020-05-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/82/3d/356fc3d6.jpg" width="30px"><span>忆水寒</span> 👍（25） 💬（1）<div>我觉得myrfy的方案很好，如果计算密集型达到一定标准，则可以使用专门的集群去处理，甚至专用芯片。
我之前计算使用傅立叶变换需要计算大量的基带信号，我就是使用专用的FPGA芯片进行处理的。
如果计算量在本机可以做，则可以由专门的reactor线程收进来，其他reactor线程池去计算。
当然了，网络层还可以使用dpdk等技术优化，跳过协议栈直接得到数据。</div>2020-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/70/ad/cc353727.jpg" width="30px"><span>龙龙</span> 👍（9） 💬（1）<div>因此，哪怕有 1 千万并发连接，也能保证 1 万 RPS 的处理能力，这就是 epoll 能在 C10M 下实现高吞吐量的原因。
———————————————————-
老师，这段话我不太理解，1千万的并发连接，只有1万的RPS 这能算高吞吐量吗？相当于每秒只有1000个人中的1个人得到响应。还是我理解错了，您表述的是另一层意思？请老师释疑下，谢谢</div>2020-05-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（8） 💬（1）<div>老师，关于读事件和写事件有个疑问的地方，基于定义：读事件表示有到达的消息需要处理，而写事件表示可以发送消息。在三次握手里的SYN+ACK，客户端产生写事件，为什么不是读事件呢？先读到SYN+ACK然后触发写事件恢复ACK到服务端</div>2020-05-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/5f/83/bb728e53.jpg" width="30px"><span>Douglas</span> 👍（5） 💬（1）<div>前后矛盾：【网络报文到达后，内核就产生了读、写事件】 【当一个 HTTP 请求的大小超过 TCP 报文的最大长度时，请求会被拆分到多个报文中运输，在接收端的缓冲区中重组、排序。因此，并不是每个到达的 TCP 报文都能生成事件的】， 所以， 老师  生成事件的条件是什么？</div>2020-07-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/fc/75/d2f821b8.jpg" width="30px"><span>凌晨</span> 👍（4） 💬（1）<div>思考题正是我们目前项目遇到的问题，请老师指点一下：

简单描述下问题：我们在nginx中实现一个上传文件时同时计算文件sha256的功能，客户端会携带sha256值用于校验完整性（这个需求是死的，客户端不可能改）。计算sha256是CPU密集型操作，一定要考虑异步化，否则ngx worker进程会&quot;停顿&quot;，出现大量毛刺。

那么，异步化需要用线程池来承载，这里面临几个思考：
1. 考虑在worker进程中起线程池，那么该起多少个线程？ 对于nginx这种多进程架构来讲，一个worker起n个线程意味着总共会起 m * n 个线程，m是worker个数。对CPU来讲起太多线程也不是一个友好的方式。所以考虑是不是一个worker进程起1个线程足以，所有计算任务都委托给这个线程来执行，任务的投递、响应都往worker的epoll上模拟事件来完成。

2. 考虑在worker中选择一个特殊的worker进程来专门进行密集型计算任务，类似nginx中有单独的cache manager进程一样，然后在这个worker进程中起线程池，线程数等于CPU核数。但是这样的话意味着我要通过共享内存在worker之间共享数据，引来一些额外的复杂度（实际上目前我们已经实现了worker间的共享内存，有其他作用）

3. 不起线程了，而是将一个计算任务拆解为 n 个子任务串行计算，比如原来我要计算一个 1Mb 的数据的sha256，改为每次只计算4kb，计算完4kb之后封装一个epoll事件等待再次重入。这样会带来单个请求的时延增大，但整系统的吞吐量应该可以提升。

想知道老师意见是什么，有没有更推荐的方式？ 谢谢！</div>2020-05-15</li><br/><li><img src="" width="30px"><span>来可</span> 👍（3） 💬（3）<div>您好，看了您的其他回复，我没太明白拆成小任务多次执行的原因，这样做的好处是什么呢？</div>2020-05-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/51/29/24739c58.jpg" width="30px"><span>凉人。</span> 👍（3） 💬（1）<div>感觉c10k提升，绝大部分是在压榨性能上的提升。
单位时间处理数。
内存池。
非阻塞。
异步事件驱动。
都是精益求精。</div>2020-05-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/cb/92/cfc1cfd3.jpg" width="30px"><span>贝氏倭狐猴</span> 👍（2） 💬（2）<div>老师有个问题“通常要把大文件的读取，拆分成许多份，每份仅有几十 KB，降低单次操作的耗时“。能具体说下什么意思么？是1）还是2）？
1）客户端如果要读一个100MB大小的文件的1MB。则需要把100MB文件在存储时拆分成10个10MB的小文件，直接找到1MB对应的那个小文件读取？
2）客户端如果要读一个100MB大小的文件的1MB。则需要把1MB目标拆分成10个100KB的小目标，并发读取10个100KB个小目标</div>2020-06-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（2） 💬（1）<div>我的想法是采用线程池和队列加入到事件驱动框架里来处理CPU密集计算的请求。读事件是请求的读取，把读取的请求放到队列里，然后事件处理线程池从队列里取事件处理，处理完之后触发写事件（写网络或者写文件等）。因为是CPU密集计算，线程数量不能过多，一般为CPU核数的2倍。队列的长度可以稍微长点，来容纳不能及时处理的事件。</div>2020-05-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/dc/19/c058bcbf.jpg" width="30px"><span>流浪地球</span> 👍（1） 💬（1）<div>老师您好，关于这段描述理解不是很清楚：
但被动方到主动方的通道也需要关闭，所以此时被动方会产生读事件，提醒被动方调用 close 函数关闭连接。
此时，被动方此时应该不会再收到主动方的消息了，为什么产生的是读事件，而不是应该是写事件。
我理解是产生写事件，调用close函数返送fin包。
求解惑，谢谢。
</div>2020-05-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/60/71/895ee6cf.jpg" width="30px"><span>分清云淡</span> 👍（13） 💬（0）<div>见过的最详细、系统的关于写缓冲的分析：https:&#47;&#47;plantegg.github.io&#47;2019&#47;09&#47;28&#47;%E5%B0%B1%E6%98%AF%E8%A6%81%E4%BD%A0%E6%87%82TCP--%E6%80%A7%E8%83%BD%E5%92%8C%E5%8F%91%E9%80%81%E6%8E%A5%E6%94%B6Buffer%E7%9A%84%E5%85%B3%E7%B3%BB&#47;</div>2020-05-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/e1/e9/29b62c57.jpg" width="30px"><span>Bitstream</span> 👍（5） 💬（0）<div>关于思考题的一些想法：
（1）如果真的将一个任务定性为”计算密集型“，个人认为将任务放到独立的计算线程（或线程池）处理，可以充分利用多核cpu（单核cpu另说，现在常见于低端嵌入式平台）的并行计算能力，并且可以将线程绑定于特定cpu核，同时通过优化算法实现，充分利用cpu缓存以进一步提升性能。至于编程效率方面的开销，现在很多异步框架应该可以将类似的多线程计算完成事件”无缝“的融入到主事件循环中，所以编程应该不会特别痛苦，不过调试依然是个问题。
（2）从扩展角度考虑，将”计算密集型“任务独立出来，以后根据需要可以容易的修改为”异构“计算架构，比如将计算任务分发到GPU、FPGA、集群中处理，而对于分发出去的任务，主线&#47;进程仍然是监听并处理计算完成事件就可以了，程序的架构上没有太大变化。
（3）在同一线程中拆分为若干片段的方案，重度依赖于计算任务的业务特点。比如凌晨同学的计算sha256的计算任务，由于hash算法天然的可以反复以任意长度update的特点，这种拆分相对容易。问题是，为了保证单次计算的时间开销够短，每次update的数据块可能很小，在请求密集时或者单次上传文件较大时，需要有较大的接收缓冲区。另外，对于hash这种运算数据前后相关的算法，如果拆分的不合适，可能cpu缓存无法高效的使用（这个不确定，得看一下sha256的具体实现）。</div>2020-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/57/24/909bb6ef.jpg" width="30px"><span>RISE</span> 👍（3） 💬（0）<div>CPU密集计算的拆分个人认为可以使用协程或多线程先分而治之缩短执行时间，如果还不能满足要求的话可以考虑分发到集群中，或者干脆将计算任务进行有效的拆分，不要一次占用过多的CPU时间</div>2020-05-18</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoWfXendN7czHpsyaWKLPK6Na9P5czquJ7Wdre4TibZQ5SQib88edyuib3LpCVFkp0gII2wyvvR8tEIA/132" width="30px"><span>OM</span> 👍（0） 💬（0）<div>文章中提及:目前磁盘异步 IO 技术（参见[第 4 讲]）还不成熟，它绕过了 PageCache 性能损失很大。但实际生产中如oracle有关IO方面是采用异步IO的，其他数据库有些也采用异步IO，此异步IO与DB层的异步IO不同吗？麻烦陶老师解答下，感谢！</div>2021-07-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/f0/17/796a3d20.jpg" width="30px"><span>言十年</span> 👍（0） 💬（0）<div>鞭辟入里</div>2021-01-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/64/9b/d1ab239e.jpg" width="30px"><span>J.Smile</span> 👍（0） 💬（0）<div>真的挺受益的，偏偏都串联了自己的知识网络，感谢老师，继续干货！</div>2020-06-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/7f/91/962eba1a.jpg" width="30px"><span>唐朝首都</span> 👍（0） 💬（0）<div>文中在单线程10us处理事件，能够支持C10M的吞吐量，但是在实际项目的运行中事件没有这么快的处理能力，我了解的处理方式有Reactor Pattern，主线程不断循环轮训事件，将就绪的事件丢到Worker线程池中进行处理。</div>2020-05-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/39/fa/a7edbc72.jpg" width="30px"><span>安排</span> 👍（0） 💬（0）<div>思考题：可以弄一个计算线程池，多路复用只负责将网络事件收上来，然后交给线程池计算，这样多路复用的回调可以立刻返回并处理下一个事件回调。计算线程池弄一个eventfd，多路复用也监听这个eventfd，线程池算完了之后，通过eventfd通知多路复用。多路复用将计算结果写到socket缓冲区.</div>2020-05-15</li><br/>
</ul>