你好，我是志东，欢迎和我一起从零打造秒杀系统。

上节课我们详细探讨了秒杀的隔离策略，简单回顾一下，为了让秒杀商品不影响其他商品的正常销售，我们从多个角度详细介绍了隔离，特别是系统隔离层面，我们从流量的起始链路入手，介绍了各个链路不同的隔离方法。从这节课开始，我们将重点介绍流量的管控。

## 如何有效地管控流量？

通过对秒杀流量的隔离，我们已经能够把巨大瞬时流量的影响范围控制在隔离的秒杀环境里了。接下来，我们开始考虑隔离环境的高可用问题，通俗点说，普通商品交易流程保住了，现在就要看怎么把秒杀系统搞稳定，来应对流量冲击，让秒杀系统也不出问题。方法很多，有**流量控制、削峰、限流、缓存热点处理、扩容、熔断**等一系列措施。

这些措施都是我们在第二模块要重点讲解的技术手段，内容比较多，而且会有一些交叉，我会用三节课来分享。

这节课我们先来看流量控制。在库存有限的情况下，过多的用户参与实际上对电商平台的价值是边际递减的。举个例子，1万的茅台库存，100万用户进来秒杀和1000万用户进来秒杀，对电商平台而言，所带来的经济效益、社会影响不会有10倍的差距。相反，用户越多，一方面消耗机器资源越多；另一方面，越多的人抢不到商品，平台的客诉和舆情压力也就越大。当然如果为了满足用户，让所有用户都能参与，秒杀系统也可以通过堆机器扩容来实现，但是成本太高，ROI不划算，所以我们需要提前对流量进行管控。
<div><strong>精选留言（10）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/17/87/be/7466bf26.jpg" width="30px"><span>清风</span> 👍（28） 💬（4）<div>可以放在redis里，list分页取数据还是很快的，我们现在一个list就存了几百万的数据，速度还是可以的，如果想更快的话可以多用几个key，发送的时候可以用多线程</div>2021-10-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/ec/18/bf7254d3.jpg" width="30px"><span>肥low</span> 👍（0） 💬（3）<div>按id主键循环limit 100，顺序查出来再发送，还有就是当预约成功后，把预约提醒任务放到MQ里？</div>2021-10-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/44/d8/1a1761f9.jpg" width="30px"><span>James_Shangguan</span> 👍（4） 💬（0）<div>单sku 预约几百万用户，可以推测这张表的数据量肯定会很大，可以考虑分库分表优化；
单就本条SQL和发送推送的场景而言，可以考虑利用索引进行优化：
SELECT user_name FROM t_reserve_user WHERE sku_id = #{skuId} and id&gt;(#{page.index}-1)*#{page.step} limit #{page.step}
#{page.index}表示当前页码
如果这条SQL语句达不到要求还可以考虑添加一些索引。</div>2021-10-08</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKlicKgCNuhqMmpXJPzanXaXBuA1XaAHmNEM3PcDKVicSLK4NQaCjGJYOF0DCPMYI5tgMmo5hXbFPpg/132" width="30px"><span>kavi</span> 👍（2） 💬（0）<div>根据主键id 查询
select user_name from t_reserve_user where id &gt;? and id&lt;?  按规定的offset  查询
如:
offset =10000
1.select user_name from t_reserve_user where id &gt;0 and id&lt;=10000;
2.select user_name from t_reserve_user where id &gt;100000 and id&lt;20000;
</div>2021-11-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/df/6c/5af32271.jpg" width="30px"><span>Dylan</span> 👍（2） 💬（1）<div>where sku_id &gt; max_id。可以让sku_id是自增主键，每次查询下一页都带入上一页最大id。
另外是不是可以让ES去干这事情</div>2021-10-07</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/g5XHJelCh5eF71LMR2e7RaE0xRtibPT1yEtzGCyhjpicZPP2fYKyAPyUek2hkGtH8I1e2URPOK1ibOV0D87czpbew/132" width="30px"><span>faith</span> 👍（0） 💬（0）<div>reserve_info_{skuid}  这个缓存的value是不是可能存在多个reserve_info的情况，比如一个skuid有多个预约信息。</div>2025-02-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/c5/b2/5b339c64.jpg" width="30px"><span>K-Li</span> 👍（0） 💬（0）<div>直接离线任务提取出要发消息的用户就行了吧  然后定时任务读取离线任务处理后的数据进行发送。 发消息这个没有展示的意义吧？</div>2024-10-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/23/98/ad/f9d755f2.jpg" width="30px"><span>邓嘉文</span> 👍（0） 💬（0）<div>1. 什么是深度分页问题?

(1) MySQL 走 B+ 索引的复杂度为 O(log n), 所以 `where sku_id=#{skuId}` 的性能没问题的

(2) `limit #{page.beginIndex},#{page.step}` 会导致 MySQL 从第一条数据开始扫描, 扫描到 `beginIndex` 之后, 再取 `step` 条数据, 这个过程的复杂度为 O(n)

MYSQL 是基于硬盘的, 每页大小默认是 16KB, 也就是说每次读取的数据是 16KB, 如果顺序扫描 1000W 数据, 会产生大量的 IO, 就会非常慢

(你可以试试一些网站指定巨大偏移量的分页, 可能会卡死)

1. 解决方法

(1) 分库分表: MYSQL 单表推荐不要超过 500W 数据, 数据过大就应该分库分表

(2) 使用索引确定范围: job程序分页不是随机分页的, 一般是一页一页扫描, 可以使用上一次查询的索引最大值来规避数据的扫描, 例如:

```sql
select user_name from t_reserve_user where sku_id=#{skuId} and id&gt;#{lastId} limit #{page.step}
```

(3) 使用缓存: 例如 redis list 来分页

MYSQL 深度分页的性能慢主要有 2 个原因: 

* 1 是 O(n) 时间复杂度
* 2 是 多次磁盘 IO

使用内存, 比如 redis 可以规避多次磁盘 IO
</div>2023-08-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1a/7c/aa/cbb4a52e.jpg" width="30px"><span>白白</span> 👍（0） 💬（0）<div>如果非要用mysql的话 建立sku_id + user_name的联合索引   每次查询都记录下最后一个user_name  
select user_name from t_reserve_user where sku_id=#{skuId} and user_name &gt; ${userName} limit #{page.beginIndex},#{page.step} order by sku_id, user_name</div>2022-05-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/4a/e1/2a498473.jpg" width="30px"><span>李威</span> 👍（0） 💬（1）<div>请教老师，文中的“对于历史数据，也需要有个定时任务进行结转归档，以减轻数据库的压力”，这个“结转归档”具体是怎么做的？是说把历史的预约数据转存到其他地方进行冷备，然后把历史数据从预约表中删除掉是吗？</div>2021-10-21</li><br/>
</ul>