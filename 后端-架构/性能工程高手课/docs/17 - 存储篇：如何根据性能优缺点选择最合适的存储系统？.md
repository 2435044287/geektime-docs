你好，我是庄振运。

前面两讲我们讨论了CPU和内存，今天我们讨论第三个重要的主题：存储系统。现在是大数据时代，这些数据终归要保存到各种存储系统里面，以供读写和分析，因此讨论存储系统的性能问题就很有必要了。

狭义上的存储往往是硬件，比如磁盘、磁带还有固态硬盘。而广义上的存储系统除了指硬件的硬盘，还包括基于网络的存储系统，比如SAN（Storage Area Network, 存储区域网络）和NAS存储（Network Attached Storage，网络接入存储）。

各种存储系统各有优缺点，尤其是性能和成本，所以对不同的需求，我们要选择最合适的存储系统。

我们首先讲存储系统最重要的三大性能指标：IOPS、访问延迟和带宽，然后讲传统硬盘HDD（Hard Disk Drive）的性能。因为传统硬盘的特性相对简单直白（毕竟业界已经用了几十年了）。这之后再讲固态硬盘的性能（固态硬盘就是SSD，也叫Flash）。相对于传统硬盘，SSD的内部工作原理很不一样，这也就导致它们的性能特性大相径庭。 最后，我们再延伸到基于网络的存储系统，并且介绍几个常用的和存储相关的工具。

## 存储系统的三大性能指标

一个存储系统的性能最主要的是三个：**IOPS**、**访问延迟**、**吞吐率/带宽**。这三个指标其实是互相关联和影响的，但是我们一般还是分开来衡量。
<div><strong>精选留言（7）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/12/64/05/6989dce6.jpg" width="30px"><span>我来也</span> 👍（5） 💬（1）<div>基础知识也看的得很过瘾。
虽然之前也了解一些，但还没细化到平均延迟是哪个级别，相差多少倍。
就像cpu的各级缓存是几个时钟周期一样，之前可能只是感性的认识。
现在虽然也并没完全准确的记下来，但大致的毫秒和纳秒级别还是知道的。
等有必要深究了，再回过头来看，也是很好的。
感谢老师的整理。</div>2020-01-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/5b/08/b0b0db05.jpg" width="30px"><span>丁丁历险记</span> 👍（3） 💬（2）<div>我是来赏下诗的，就硬盘而言，目前我们只用ssd
“梅须逊雪三分白，雪却输梅一段香。”</div>2020-01-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/9b/ba/333b59e5.jpg" width="30px"><span>Linuxer</span> 👍（2） 💬（1）<div>有一个问题想请教如果是磁盘空间较宽裕，每次都是小数据量写入，是不是就不存在写入放大的问题了呢？因为现在很多方案都是元数据放在SSD(随机小数据量写入)，其他数据放在HDD(大量顺序数据写入)</div>2020-01-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/d7/aa/bd3f9ce5.jpg" width="30px"><span>森森不息</span> 👍（1） 💬（2）<div>讲的都太基础，最好有深入案例</div>2020-01-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/d8/94/c4536dd5.jpg" width="30px"><span>子荣</span> 👍（0） 💬（1）<div>“IO 带宽大约每秒 100MB，而随机 IOPS 一般是 100 左右”，上文不是说IOPS一般是针对4KB的IO而言吗，那100的IOPS，对应的是400KB，这和IO带宽100MB&#47;s也差太远了吧？</div>2020-06-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1c/f7/f6/8426cb1d.jpg" width="30px"><span>搬砖人</span> 👍（0） 💬（1）<div>测试案例1：
1. 启动一个FIO跑顺序写：fio -filename=&#47;dev&#47;sdg -direct=1 -iodepth=1 -rw=write -ioengine=libaio --bs=8k  -numjobs=1  -name=mytest
2. 启动一个FIO跑随机读：fio -filename=&#47;dev&#47;sdg -direct=1 -iodepth=1 -rw=randread -ioengine=libaio --bs=8k  -numjobs=1  -name=mytest
发现读的时延非常不稳定，每秒读IOPS平均只有10以下，读时延经常抖动至几百ms，如果顺序写的深度再加高一些，则读就会出现秒级时延

测试案例2：
1. 启动一个FIO跑随机写：fio -filename=&#47;dev&#47;sdg -direct=1 -iodepth=1 -rw=randwrite -ioengine=libaio --bs=8k  -numjobs=1  -name=mytest
2. 启动一个FIO跑随机读：fio -filename=&#47;dev&#47;sdg -direct=1 -iodepth=1 -rw=randread -ioengine=libaio --bs=8k  -numjobs=1  -name=mytest
发现读时延相对稳定，读写IOPS均可以达50左右，时延平均保持在20ms左右

机械盘的ioscheduler配置成deadline，none都有尝试过，发现对结果没什么改变

从测试结果来看，机械盘对于顺序写的行为是非常友好的，在这种情况，对于读的调度则变得非常不友好了，导致读的时延非常不稳定

所以我们想咨询一下：一边顺序写，一边随机读的场景下，有没有办法让读的性能保持跟稳定一些？或者有没有办法提升读的优先级？希望可以达到测试案例2的效果</div>2020-03-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/f2/ce/791d0f5e.jpg" width="30px"><span>张开元</span> 👍（0） 💬（0）<div>v</div>2022-10-16</li><br/>
</ul>