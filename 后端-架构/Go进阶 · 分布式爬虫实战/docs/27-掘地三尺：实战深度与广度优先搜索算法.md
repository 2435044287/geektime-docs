你好，我是郑建勋。

上节课，我们看到了如何在Go中创建高并发模型，这节课让我们回到项目中来，为爬虫项目构建高并发的模型。

要想构建高并发模型，我们首先要做的就是将一个大任务拆解为许多可以并行的小任务。比方说在爬取一个网站时，这个网站中通常会有一连串的URL需要我们继续爬取。显然，如果我们把所有任务都放入到同一个协程中去处理，效率将非常低下。那么我们应该选择什么方式来拆分出可以并行的任务，又怎么保证我们不会遗漏任何信息呢？

要解决这些问题，我们需要进行爬虫任务的拆分、并设计任务调度的算法。首先让我们来看一看两种经典的爬虫算法：深度优先搜索算法（Depth-First-Search，DFS）和广度优先搜索算法（Breadth-First Search，BFS）, 他们也是图论中的经典算法。

## 深度优先搜索算法

深度优先搜索算法是约翰·霍普克洛夫特和罗伯特·塔扬共同发明的，他们也因此在1986年共同获得计算机领域的最高奖：图灵奖。

以下图中的拓扑结构为例，节点A标识的是爬取的初始网站，在网站A中，有B、C两个链接需要爬取，以此类推。深度优先搜索的查找顺序是： 从 A 查找到 B，紧接着查找B下方的D，然后是E。查找完之后，再是C、F，最后是G。可以看出，深度优先搜索的特点就是“顺藤摸瓜”，一路向下，先找最“深”的节点。
<div><strong>精选留言（8）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/75/00/618b20da.jpg" width="30px"><span>徐海浪</span> 👍（0） 💬（1）<div>有个疑问，多个协程之间怎么协调等待时间？</div>2022-12-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/29/67/fc61a741.jpg" width="30px"><span>田小麦</span> 👍（6） 💬（0）<div>能把复杂问题简单化，也是学问。有种标题造火箭，内容提取干货很吃力</div>2023-02-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/5f/57/791d0f5e.jpg" width="30px"><span>Geek_8ed998</span> 👍（2） 💬（1）<div>又不标tag了，想到那写到那一段一段的</div>2023-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/8b/00/822434ab.jpg" width="30px"><span>小白</span> 👍（0） 💬（0）<div>tag v0.1.3</div>2024-04-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/f5/fd/6487f026.jpg" width="30px"><span>佩奇</span> 👍（0） 💬（0）<div>解析正文内容中包含阳台的正则表达式，会把右侧边栏的内容也解析进去，可以调整为下面的方式
```

const ContentRe = `&lt;div\s+class=&quot;topic-content&quot;&gt;(?s:.)*?&lt;&#47;div&gt;`

func GetContent(contents []byte, url string) collect.ParseResult {
	re := regexp.MustCompile(ContentRe)
	resultStr := re.FindString(string(contents))

	r2 := regexp.MustCompile(&quot;阳台&quot;)

	ok := r2.MatchString(resultStr)
	if !ok {
		return collect.ParseResult{
			Items: []interface{}{},
		}
	}

	result := collect.ParseResult{
		Items: []interface{}{url},
	}

	return result
}

```</div>2023-11-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/75/00/618b20da.jpg" width="30px"><span>徐海浪</span> 👍（0） 💬（0）<div>即使切换了User-Agent更换了IP，反爬虫还是可以根据其他(比如令牌)知道是同一个用户访问，这时就得用账号池了吧</div>2022-12-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/7b/4b/95812b15.jpg" width="30px"><span>抱紧我的小鲤鱼</span> 👍（0） 💬（0）<div>1. 递归主要会带来的效率问题，函数调用带来的额外开销（函数的入栈出栈），栈容量的限制（次数太多可能会stack overflow）
2. 使用UA池，随机选取一个？
</div>2022-12-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/0c/e1/f663213e.jpg" width="30px"><span>拾掇拾掇</span> 👍（0） 💬（0）<div>1.递归会导致栈溢出，而且递归一旦没写好就是死循环了
2.那就user_agent搞多一点，然后随机取</div>2022-12-10</li><br/>
</ul>