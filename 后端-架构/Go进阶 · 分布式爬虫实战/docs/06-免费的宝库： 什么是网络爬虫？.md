你好，我是郑建勋。

网络爬虫（Web Crawler）又称为网络蜘蛛（Web Spider），是一种自动获取互联网信息的网络机器人（Web Robot）。想想还真是非常形象，蜘蛛在相互连接的网站中，辛苦地从一个网站爬到另一个网站获取信息，又像一个不知疲倦的打工人。

互联网是一个充满了庞大免费数据的地方，但是数据本身并不产生价值，有价值的是从数据中提炼出来的知识与智慧。就像金块一样，这些零散的数据可以被收集、过滤、组合和提炼，生产出极具价值的产品。

凭借正确的知识、技能和一点点创造力，你可以构建一个以爬虫引擎为核心的价值数百亿的商业公司（想想今日头条是如何起家的），这是多么让人兴奋的领域呀。但是网络爬虫合法吗？这一领域需要掌握哪一些知识？基于爬虫可以构建哪些有用的产品？这节课，我们就来深入讨论一下网络爬虫这个领域。

## 网络爬虫合法吗？

近年来，不断出现爬虫相关的犯罪案件，所以很多人对爬虫敬而远之，甚至将它戏称为“面向监狱编程”。

> [全国首例短视频平台领域网络“爬虫”非法获取用户数据案宣判](https://finance.sina.com.cn/jjxw/2022-06-29/doc-imizmscu9213741.shtml)  
> [爬虫失控导致政府网站奔溃，CTO和程序员双双被判刑](https://www.163.com/dy/article/GV7DNQ7N05315PUD.html)  
> [新三板挂牌公司涉窃取30亿条个人信息，非法牟利超千万元](https://www.thepaper.cn/newsDetail_forward_2362227)

从各种爬虫犯罪的案例中，我们可以分析出触犯法律的主要原因：
<div><strong>精选留言（18）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/75/00/618b20da.jpg" width="30px"><span>徐海浪</span> 👍（5） 💬（1）<div>思考题:  有些信息是浏览器运行脚本生成的，不能通过简单的http请求获取。需要通过微型浏览器或者操作浏览器的程序(selenium)来处理。</div>2022-10-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/39/93/f0247cf8.jpg" width="30px"><span>一本书</span> 👍（0） 💬（1）<div>是不是因为脚本没有模拟浏览器的行为，在脚本里面加上一段话，告诉对方我是游览器就行了。</div>2022-10-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/35/77/95e95b32.jpg" width="30px"><span>木杉</span> 👍（0） 💬（1）<div>selenium 要讲一下吗?</div>2022-10-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/56/75/28a29e7c.jpg" width="30px"><span>安菲尔德</span> 👍（0） 💬（1）<div>网页数据异步获得？</div>2022-10-23</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEIqvYMQ1yscgB6xS4nDkoOuP6KiaCiaichQA1OiaQ9rFmNtT9icgrZxeH1WRn5HfiaibDguj8e0lBpo65ricA/132" width="30px"><span>Geek_crazydaddy</span> 👍（0） 💬（1）<div>这得具体情况具体分析了，总得方向还是服务端对客户端信息进行验证了，比ua,refer这些</div>2022-10-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/0c/e1/f663213e.jpg" width="30px"><span>拾掇拾掇</span> 👍（0） 💬（1）<div>是user angent原因？
</div>2022-10-22</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eraXQHCYIwibtgsdzrWrgnR8MicTuPN0u4EszjbGLATmpW8DSZd7bapAUjpFO4iaTydtNpEKiaQ5QzEDQ/132" width="30px"><span>bluesky</span> 👍（0） 💬（2）<div>感谢大佬对知识的分享,购买课程主要想学习爬虫和go语言,对爬虫和go语言都是小白,分享一下对这个问题的看法:通过浏览器可以获取网页信息,通过程序不能获取,根本原因就是web服务器识别出了程序访问的方式,这可能有很多原因,比如作者提到的一系列的反爬虫机制.比如header信息,登陆限制,ip拦截等等</div>2022-10-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/16/5c/d0476f9f.jpg" width="30px"><span>运维夜谈</span> 👍（0） 💬（2）<div>我们在爬取网页的时候，常常会出现通过浏览器能够正常获取网页信息，但是通过程序访问的方式就无法获取网页信息，你知道可能是什么原因吗？
可能是：1、没有添加正确的请求头；2、网页数据可能是动态加载的；3、网页进行了重定向。
不知道说得对不对？</div>2022-10-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/16/5c/d0476f9f.jpg" width="30px"><span>运维夜谈</span> 👍（0） 💬（1）<div>一般我们从网页上收集的数据是 HMTL 格式的（当然，有时候我们也希望搜集 CSS 文件、js 文件，以及图片、音频、视频等各种形式的文件）
这一句的 HMTL 写错了。</div>2022-10-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/44/d8/708a0932.jpg" width="30px"><span>李一</span> 👍（5） 💬（0）<div>通过浏览器能够正常获取网页信息，但是通过程序访问的方式就无法获取网页信息：
1. 服务器通过userAgent对访问者工具进行验证。
2.网页有可能通过ajax这种异步加载的机制加载页面数据</div>2022-10-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/ce/6d/530df0dd.jpg" width="30px"><span>徐石头</span> 👍（2） 💬（0）<div>通过浏览器能获得，通过程序访问无法获得，有可能是数据是从ajax请求得到，不是服务端直接渲染页面，现在主流前端框架vue从服务端取到数据，绑定在虚拟dom上</div>2022-10-22</li><br/><li><img src="" width="30px"><span>Geek_c7822e</span> 👍（1） 💬（0）<div>我来说一种情况吧，有的网站得做会话保持才能爬取，比如先访问A页面，此时会得到一个cookie，此cookie所关联的session中存储了关键信息，此时访问B页面就能够正确拿到数据，这种需要在两个页面中需要使用同一个sessionid才能拿到目标数据。

反爬技术千万种，但网页终究还是通过http的文本传输协议，理论上一切请求都能够模仿出来，进而通过爬虫进行获取，有时候需要花大量的时间研究目标数据的请求链路，其中可能会包含js，加密、签名、css伪装等等。</div>2022-11-26</li><br/><li><img src="" width="30px"><span>wendy</span> 👍（1） 💬（0）<div>👏🏻👏🏻</div>2022-10-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/7b/4b/95812b15.jpg" width="30px"><span>抱紧我的小鲤鱼</span> 👍（1） 💬（0）<div>网站对浏览器做了限制吧，比如ua信息</div>2022-10-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/d1/9f/d6042f62.jpg" width="30px"><span>liaozd</span> 👍（0） 💬（0）<div>数据量大的话，有没有HDFS、HBase类似的方案？</div>2023-01-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/4b/e3/31b5dc4d.jpg" width="30px"><span>马里奥</span> 👍（0） 💬（0）<div>因为我们浏览器携带的信息被服务器判定为有问题。所以服务器给我们的页面不是正常浏览者看到的。</div>2022-11-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/7f/d3/b5896293.jpg" width="30px"><span>Realm</span> 👍（0） 💬（0）<div>可能是服务器开启了反爬策略，根据ua，限制一些爬虫的行为，可以尝试把程序请求头的ua，改成普通浏览器，来绕开反爬策略.</div>2022-10-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/0d/5e/abeeda12.jpg" width="30px"><span>伏枫</span> 👍（0） 💬（0）<div>思考题可能的原因:
1. 服务器做了反爬虫策略，比如通过header中的user–agent来判断是否来自浏览器的请求
2. 网站不是服务端渲染的网站，通过URL获取到的是仅包含JS代码的网站，在浏览器可以通过运行JS渲染出我们看到的页面，而程序抓取的就只能看看JS无法运行。

另外，针对上面说的第二种情况，可以使用 headless 浏览器运行JS获取到渲染后的HTML，不过这种方法也不是一定成功，比如淘宝网站就会阻止 headless浏览器的访问</div>2022-10-22</li><br/>
</ul>