你好，我是郑建勋。

爬虫项目的一个重要的环节就是把最终的数据持久化存储起来，数据可能会被存储到MySQL、MongoDB、Kafka、Excel等多种数据库、中间件或者是文件中。

要达到这个目的，我们很容易想到使用接口来实现模块间的解耦。我们还要解决数据的缓冲区问题。最后，由于爬虫的数据可能是多种多样的，如何对最终数据进行合理的抽象也是我们需要面临的问题。

这节课，我们将书写一个存储引擎，用它来处理数据的存储问题。

## 爬取结构化数据

之前我们爬取的案例比较简单，像是租房网站的信息等。但是实际情况下，我们的爬虫任务通常需要获取结构化的数据。例如一本书的信息就包含书名、价格、出版社、简介、评分等。为了生成结构化的数据，我以[豆瓣图书](https://book.douban.com/)为例书写我们的任务规则。

**第一步，从首页中右侧获取热门标签的信息。**

![图片](https://static001.geekbang.org/resource/image/73/65/73df9e84cc9937555326b92b4e448865.png?wh=1920x1257)

```plain
const regexpStr = `<a href="([^"]+)" class="tag">([^<]+)</a>`
func ParseTag(ctx *collect.Context) (collect.ParseResult, error) {
	re := regexp.MustCompile(regexpStr)

	matches := re.FindAllSubmatch(ctx.Body, -1)
	result := collect.ParseResult{}

	for _, m := range matches {
		result.Requesrts = append(
			result.Requesrts, &collect.Request{
				Method:   "GET",
				Task:     ctx.Req.Task,
				Url:      "<https://book.douban.com>" + string(m[1]),
				Depth:    ctx.Req.Depth + 1,
				RuleName: "书籍列表",
			})
	}
	return result, nil
}
```
<div><strong>精选留言（1）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/16/8c/7d/cae6b979.jpg" width="30px"><span>出云</span> 👍（0） 💬（1）<div>按文中的写法，SqlStore.Flush() 方法不能处理同一个Batch中存在不同Task的DataCell的情况。</div>2023-03-12</li><br/>
</ul>