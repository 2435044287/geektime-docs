你好，我是徐昊，今天我们来继续学习AI时代的软件工程。

通过前面的学习，我们逐步认识了知识工程的整体框架，并且尝试用知识工程的视角重新理解软件工程，那么软件工程效率提升的问题，自然就转化成为构造知识传递效率更高的知识过程。

那么大语言模型（Large Language Model，LLM）能否让知识过程更高效呢？这就是今天我们要讨论的问题，因为这是将大语言模型（Large Language Model，LLM）应用到知识过程的前提条件。

## **LLM是革命性的迁移学习平台**

LLM是怎么帮助我们提取知识的呢？我们首先需要将**LLM看作一种特殊的迁移学习（Transfer Learning）平台**。

迁移学习（Transfer Learning）是机器学习领域的一个重要概念，意思是将从一个问题（源任务）中学到的知识应用到另一个相关的问题（目标任务）上。即使两个任务不完全相同，一个任务中学到的特征、模式和知识也可以在另一个任务中发挥作用，从而提高学习效率和性能。比如，一个可以识别猫狗的计算机视觉AI，可以通过迁移学习训练成用来识别汽车的AI。

迁移学习在实际应用中非常重要，特别是在数据稀缺的情况下。例如，在深度学习中，训练一个从头开始的模型通常需要大量的标记数据和计算资源。通过迁移学习，我们可以利用在大型数据集上预训练的模型，然后将这些模型调整（fine-tune）到特定的、数据较少的任务上。
<div><strong>精选留言（21）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/17/14/45/adf079ae.jpg" width="30px"><span>杨松</span> 👍（3） 💬（4）<div>老师，就是不知道如何去描述这个上下文，这方面是由于对所要解决的问题(任务)其中设计到的隐性知识不理解，导致无法准确描述的吧，解决的办法就是多次提出验证性的问题吗？</div>2024-03-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/87/e1/b3edcc09.jpg" width="30px"><span>范飞扬</span> 👍（2） 💬（2）<div>不知道如何去描述上下文怎么办？

老师说：多次提出验证性的问题、刻意练习。

我觉得老师的回答不够好。

我从文中总结出的方法是：“分而治之”和“筛选”循环。

比如，拿文中的例子来看看这两步是怎么发挥作用的，数字体现了上下文的演进：

上下文1.0：产品目录服务。

1、问 LLM 这个服务有什么功能。（分而治之）

（LLM回复了一大串功能。。。）

2、筛选一下功能，丢到下一个上下文，成为上下文2.0。（筛选）

上下文2.0：产品目录服务，API包含 x，y，z功能。

接下来就是重复 1 和 2 就行了。比如，继续问产品有什么信息（分而治之）。</div>2024-03-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1c/f6/27/c27599ae.jpg" width="30px"><span>术子米德</span> 👍（0） 💬（2）<div>🤔☕️🤔☕️🤔
【R】from知识工程，at软件工程：
🔼 软件工程效率 = 构造知识传递过程 🔼
迁移学习（Transfer Learning）-&gt; LLM with ctxInfo in prompt -&gt; new domain specific LLM.
【.I.】LLM里的参数，来自人类的所有知识；跟LLM聊天的过程，就是在把这些参数，还原为相应知识的过程，或者用这些参数，组合出新知识的过程。
聊法，就是让凝结为参数的知识，再次释放出知识的方法，高级点就叫做迁移学习，土法叫做会聊天。
【R】atLLM时代：做出来🔽，做正确🔼。
【Q】知识的提取与组织，跟知识的创造之间的关系是什么？提取，是否意味着知识已经存在，只是没有显式表达出来，而创造，是否意味着知识要实践过程新创造出来，才有所谓的提取知识可言？
— by 术子米德@2024年3月17日</div>2024-03-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/f5/8e/1d68db9a.jpg" width="30px"><span>Geek1591</span> 👍（0） 💬（1）<div>老师多更新一些啊，意犹未尽</div>2024-03-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/3a/ad/7f/a80b86c0.jpg" width="30px"><span>需要练习的码农</span> 👍（0） 💬（1）<div>课后题答案没思路，感觉还是和识别隐性知识一样的方式，不断prompt。背景、要求、任务中描述的更加具体。</div>2024-03-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/7a/56/29877cb9.jpg" width="30px"><span>临风</span> 👍（5） 💬（0）<div>    看到老师对留言的回复，强调了第一章内容的重要性，我又返回去看了第一节内容。答案就在题面上，“围绕不可言说知识构造知识过程”，LLM（大语言模型）就是AI时代的利器，那我们要怎么去构造知识过程呢？从第一节的内容可以知道，我们必须要通过社会化的活动，不断的训练、反思，刻意练习才能掌握。
    突然想到一个例子，不知道大家玩不玩王者荣耀，我偶尔也会玩，里面有一个绝悟AI的训练场。它可以帮助你去练习各个英雄的连招，就比如露娜的月下无限连，如果是一两年前，你想学会这个连招，你只能去看视频教程，然后自己去摆放木偶进行练习。按的快了以后，你也不知道按对了没有，因为你缺乏反馈或者反馈过慢，除了少数特别热爱或者天赋极高的人，大多数人是无法学会这个连招的。但现在，界面会提示你当下需要的操作，你每进行一次操作，界面就会给你反馈，判断你当前是否操作正确。所以有了这个训练场，对于一个资质平平的普通人，可能要过去要花几十个小时才能学会，现在花几个小时就能学会了。不可言说的游戏连招操作，在这里传递效率就提升了10多倍。
    同理，软件工程是否也是一样呢？我觉得答案也是肯定的，我们同样可以通过LLM制造一个“训练场”。比如团队中想要统一代码风格，它的好处就是能降低认知负载，每个人读自己的代码都是相对简单的，但代码风格这种东西是没办法说清楚的，但你一看到一段代码，你就能够看出来和谁的比较像，那么我给LLM喂上大量相同风格的代码，之后我再给LLM一段代码，它就能自动转换为我希望的风格，新的同事就能快速掌握团队的代码风格。</div>2024-03-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg" width="30px"><span>aoe</span> 👍（3） 💬（0）<div>在提问的时候使用敬语，和 AI 做朋友，以后就有一个强大的朋友
分离关注点，有助于学习老师提问的技能</div>2024-03-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/51/6e/efb76357.jpg" width="30px"><span>一只豆</span> 👍（2） 💬（0）<div>关于如何利用 LLM 提炼和应用“不可言说知识”，也许谜底就在谜面上。
翻阅一下“不可言说知识”在课程中提到的蛛丝马迹：1 特定场景下的 know-how 2 从应用题场景里提取隐含的数学关系，然后选择正确的公式或算法求解 3 《庄子》中轮扁询问学徒任务场景下（拿到材料和制式）的制作思路，并根据师傅的经验提供反馈 4 架构设计的不可言说知识在于 如何应对变化。
这些蛛丝马迹共同指向两个关键点： 强场景相关 ，场景解读和对策的映射具象化了不可言说知识。所以，也许“不可言说知识”的验证性问题就是：让 LLM 自编自演+内心独白。 自编自演是描述场景和解决思路；内心独白 是外化场景和解决思路之间的映射关系。
徐昊老师啊，打字打出这两段话真是费了老鼻子劲儿了～  您课程太通透了，我无以为报，只好豁出去参与一下的啦</div>2024-03-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/04/41/082e2706.jpg" width="30px"><span>keep_curiosity</span> 👍（1） 💬（0）<div>既然要让llm提取不可言说的知识，那就需要让它可以练习。那我们就要扮演老师傅，给出具体场景，让它尝试给出思路，并且告诉它有疑问可以提问，然后我们给出反馈。然后重复不同的场景，直到验证性问题的回答符合我们的预期效果。</div>2024-03-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/5d/71/4f6aad17.jpg" width="30px"><span>Sophia-百鑫</span> 👍（0） 💬（0）<div>提炼不可言说知识的 主要途径 还是要询问 对方的思维过程和对上下文背景的侧重点把握，为啥这么决定。 通过不断的提问验证提问验证，就会挖掘出不可言说的知识 ，不可言说知识通常背后有个强大的方法论支持，基石。</div>2024-07-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1c/f6/27/c27599ae.jpg" width="30px"><span>术子米德</span> 👍（0） 💬（0）<div>🤔☕️🤔☕️🤔
【R】把目标聚焦于知识，通过LLM帮助完成某些任务、实现某些功能，结果视角必然关注此，如何使用LLM更高质量完成任务和实现功能，在过程视角下更值得关注。
【.I.】原来我实现个函数，要再写这个函数的测试，难呐。如今，有LLM来结对，想必能帮我写测试吧。结果，非得我把用例的注释，写到自己都觉得完美感十足时，LLM才能帮我生成用例代码。否则，LLM顶多就是在码间随机作祟的搭子而已。
实际，原来花多少时间，现在还是花多少时间，甚至因沉浸其中，还在完美感驱动下，忘记又多花不少时间。
不过，以前，只有份函数的代码，现在，注释里写得清清楚楚，测试用例是啥、为何要这样写用例、如何实现这个用例，甚至，删除用例代码，LLM还会不厌其烦再生成一份可用的代码，还有，持续改进注释，删除代码后会生成符合新注释的测试代码。
在结果视角，没有什么变化，如果眼里只有函数代码本身的话。
在过程视角，开发要回答，如何验证才达到可交付的要求，开发能想清说清为何这么验证，在What&#47;How&#47;Why方面，同时达到真正符合交付要求。在没有代码之前，就把这些用注释表达出来，这样的过程需要开发的基本功扎实，同时，这样的过程也有助于开发训练自己的扎实基本功。
— by 术子米德@2024年5月29日</div>2024-05-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/d5/3e/7f3a9c2b.jpg" width="30px"><span>Jaising</span> 👍（0） 💬（0）<div>不能提炼出上下文就不断给答案，让 LLM 帮助我们从答案中建立知识模型，并在灌输一定上下文后让 LLM 提问我们来解答</div>2024-03-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/87/e1/b3edcc09.jpg" width="30px"><span>范飞扬</span> 👍（0） 💬（0）<div>上一讲说：“所谓知识过程，就是从知识管理的角度理解我们的工作，将我们的工作看作产生、传递、应用、消费知识的过程。”

可以得出知识工程的四个关键：产生、传递、应用、消费。

那么这一讲的“知识的提取与组织” 是不是对应与“产生”呢？

</div>2024-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/87/e1/b3edcc09.jpg" width="30px"><span>范飞扬</span> 👍（0） 💬（0）<div>知识提取流程：通过 LLM 的反馈反思并修改知识描述的方式。比如，ChatGPT 提供的信息过多（反馈），我多加点信息让 LLM 的反馈更精确。

知识传递过程：把提取出的上下文（原来是隐式知识），复制粘贴到下次与LLM的交互。比如，复制粘贴需求背景。

知识应用过程：让 LLM 做任务。比如，写 API 文档。

（最后有个问题：老师的措辞用了流程和过程这两个词，这是为啥呢？我没想出区分的理由）</div>2024-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/de/cf/ef2e0501.jpg" width="30px"><span>奇小易</span> 👍（0） 💬（0）<div>对于不可言说的知识，猜测是跟隐式知识提取过程类似，把自己对某个问题的解决方案来作为上下文信息给到 LLM 使其完成迁移学习，从而跟它开始结对解决问题。</div>2024-03-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/ad/cb/3391d24c.jpg" width="30px"><span>Halo</span> 👍（0） 💬（0）<div>获取不可言说知识的关键是分享思维的过程，而不是消费最终的结果。
因此，llm要提炼不可言说知识，就是要让llm通过上下文输出思维的步骤step，我们根据step去fine tune上下文，不断反馈。</div>2024-03-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/20/e3/44/791d0f5e.jpg" width="30px"><span>大卫</span> 👍（0） 💬（0）<div>作为可以通过零&#47;少样本学习来快速获取知识的高智商llm，对一个系统化大任务无法准确地完成的原因是对特定领域的知识并不熟悉。所以使用llm首先应该考虑如何让llm聚焦于特定领域的知识学习而不是最终的任务完成。在老鸟不断细化上下文描述的过程中完成知识的提取与传递过程！</div>2024-03-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1c/f6/27/c27599ae.jpg" width="30px"><span>术子米德</span> 👍（0） 💬（0）<div>【Q】对于不可言说知识，我们要怎提炼和应用？
【A】不可言说的知识，是长在我肌肉里的知识，你照着我做，就看你悟性够不够。可是这跟在屁股后面学，总有开小差没有跟上节奏的时候，一个不小心就要从头来过。
要是，盯住如何算完工。也就是说，哪几个方面，通过验证就算完工，是否就是不可言说知识的边界。
放在软件开发的场景，写出验证性的测试用例，无论怎么实现，总归要通过这些验证，才算符合预期，是否就是不可言说知识的边界。在这个验证边界之内去实现，去让LLM详尽办法多轮尝试实现，就是在提取出不可言说知识的过程，如此嘛？
— by 术子米德@2024年3月17日</div>2024-03-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/f9/e6/47742988.jpg" width="30px"><span>webmin</span> 👍（0） 💬（0）<div>想像你想向一位市场\管理等等方面的专家请教问题,你是需要先说明自己所处的具体领域情况的,然后再说自己的问题,在此后互动的过程逐步明晰和定位真正的问题,问题确定好,再分解逐步拆解问题,接下来就是递归此过程.</div>2024-03-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/3a/ac/b7/92ebd0a5.jpg" width="30px"><span>起个名称吧</span> 👍（0） 💬（0）<div>前面说了不可言说知识是从经验中获取的，但是我们通常很难理解对方的经验，需要实践。
所以我理解和LLM进行交流，通过反馈不断逼近该知识的最佳实践(相当于的有了他人的不可言说知识背景，虽然我没有经验，但是可以通过LLM得到了一套有效的经验)，然后根据最佳实践的内容丰富上下文，得到当前任务的最优解(应用)</div>2024-03-15</li><br/><li><img src="" width="30px"><span>Geek_97c2bb</span> 👍（0） 💬（0）<div>课后题: 让llm给出思考过程，然后我们给予反馈？</div>2024-03-15</li><br/>
</ul>