周三我们分享了“基于回归的隐变量模型”，这是在基本的矩阵分解基础上衍生出来的一类模型。这种模型把显式特性和隐变量结合起来，对解决“冷启动”问题有一定作用。

今天，我们来介绍一种叫作“**分解机**”（Factorization Machines）的推荐技术。这个模型是从基于回归的隐变量模型中衍生出来的，已成为了主流的推荐模型。

## 矩阵分解和基于回归的隐变量模型存在哪些问题？

在介绍分解机的基本原理之前，我们先来回顾一下从“矩阵分解”到“基于回归的隐变量模型”的一个发展脉络。

首先，矩阵分解主要解决了两个问题，那就是从一个大矩阵降维到两个小矩阵，并且寄希望这两个小矩阵能够抓住用户和物品的相关度。

然而，单纯的矩阵分解无法融入很多用户和物品的特性，这就引导我们开发出了基于回归的矩阵分解。所谓的回归部分，也就是从显式特性出发，建立从显式特性到隐变量之间关系的流程，从而使我们能够把更多的信号放进模型中。

在一定程度上，基于回归的隐变量模型实现了把显式变量和隐变量结合的目的，但是这类模型的学习过程非常麻烦。实际上，因为这类模型复杂的训练流程，其在实际应用中并不常见。

那么，有没有其他思路来统一显式变量和隐变量的处理方式呢？
<div><strong>精选留言（3）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/18/8f/98/7d1287d9.jpg" width="30px"><span>韩 * *</span> 👍（5） 💬（0）<div>脉络和思路才是这个专栏最大的价值，真的很棒</div>2019-08-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（3） 💬（0）<div>分解机能比传统的方法更好地解决“冷启动”的问题。分解机是基于显式变量两两配对来建模，我的理解是只要对应的2个显式变量在所有的数据集合中能计算出值即可。如果某个物品或某个用户的评分是缺失的，我们可以用显式变量的整体分布，如文中的例子的某个年龄段和某类商品的显式特性来计算。</div>2018-03-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/87/1d/e0dc3bf2.jpg" width="30px"><span>Wesley</span> 👍（1） 💬（0）<div>矩阵分解可以无需负样本就能训练. 分解机是否一定需要负样本来训练?</div>2019-02-27</li><br/>
</ul>