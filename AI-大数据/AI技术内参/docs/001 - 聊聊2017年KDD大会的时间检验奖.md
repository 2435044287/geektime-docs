国际数据挖掘与知识发现大会**ACM SIGKDD**（ACM SIGKDD Conference on Knowledge Discovery and Data Mining），简称**KDD**，是由美国计算机协会**ACM**（The Association for Computing Machinery）的数据挖掘与知识发现专委会**SIGKDD**（Special Interest Group on Knowledge Discovery and Data Mining）主办，堪称数据挖掘研究领域的顶级会议。

KDD最早是从1989年开始的KDD 研讨班（Workshop）发展而来，当时的研讨班依托于人工智能顶级会议IJCAI大会或者AAAI大会，而后在1995年升级成为会议的模式，到现在已经有20多年的历史。今年的KDD大会于8月13日至17日在加拿大哈利法克斯成功召开。

SIGKDD每年都会奖励一篇论文，这篇论文要在过去十年间对研究、方法论以及实践产生重大影响，这就是所谓的**时间检验奖**（Test of Time Award），引用次数以及对一个领域的影响力度是评选这个奖项的重要指标。

2017年的KDD时间检验奖授予了美国康奈尔大学信息科学系主任、计算机科学系教授索斯藤·乔基姆斯（Thorsten Joachims）。这次授予是为了表彰他的论文《线性时间内训练线性支持向量机》（Training Linear SVMs in Linear Time），这篇论文也是2006年的KDD最佳论文，引用数超过1600多次。

## Thorsten的学术贡献

Thorsten是一位机器学习界享有盛誉的学者，也是ACM和AAAI的双料院士，他所有论文的引用数加起来超过了4万次。2001年从德国多特蒙德大学博士毕业后，他正式加入康奈尔大学从事机器学习研究。

获得这个奖项之前，Thorsten曾多次获得重要奖项，比如2017年ACM WSDM的最佳论文奖（Best Paper Award）、2016年ACM SIGIR的时间检验奖、2015年ACM KDD的时间检验奖、2009年ECML的最佳论文奖、2009年ICML的10年最佳论文奖（Best 10-Year Paper Award）、2006年ACM KDD的最佳论文奖、2005年ICML的最佳论文奖、2005年ICML的优秀学生论文奖、2005年ACM KDD的最佳学生论文奖等。

Thorsten在机器学习领域一直有着非常特殊的贡献。首先，他在支持向量机（SVM）的应用上做出了诸多努力。比如这次的时间检验奖，**就是奖励他如何把支持向量机的训练达到线性复杂度，从而使支持向量机在大规模数据上的应用成为可能。**

Thorsten还致力于把支持向量机的基本算法，也就是仅仅支持分类问题和回归问题的算法，应用到更加复杂的有结构的输出结果上，俗称结构化的支持向量机算法。得益于这项工作，支持向量机可以对信息检索中很多复杂的、非二分的评估指标进行直接优化，如F1值（F-score）、平均精度均值（Mean Average Precision），从而让支持向量机的应用变得更加广阔。

在让支持向量机能够顺利应用到信息检索的过程中，Thorsten还发现了另外一个问题，那就是如何利用搜索引擎的间接用户反馈（Implicit Feedback）来训练排序算法（经常是一个结构化的支持向量机模型）。具体来说，传统的搜索系统和信息检索系统主要是依靠人工标注的训练数据来进行优化和评估。这里所说的人工标注训练数据，主要是指人为地评价目标查询关键字和所对应的网页是否相关。

早期大家发现，虽然搜索引擎可以利用这样的数据来优化排序算法，但是搜索引擎在使用过程中会产生很多用户数据。这些数据可以是用户点击搜索页面结果产生的信息，也可以是其他的信息（比如用户在搜索页面的驻留时间等等）。早期这些信息并没有用于优化搜索引擎。以Thorsten为主的一批学者意识到点击信息的重要性，然后开始利用这些数据来训练和评估排序算法。这是Thorsten的第二个主要学术贡献。

Thorsten第三个主要学术贡献，也是他最近几年的学术成功，那就是把**因果推论（Causal Inference）**和机器学习相结合，从而能够更加无偏差地训练模型。可以说这部分工作开创了一个新领域。

长期以来，如何有效地应用用户产生的交互数据来进行模型训练，都是大规模机器学习特别是工业界机器学习的难点。一方面，工业系统能够产生很多用户数据；另一方面，这些用户数据又受到当前部署系统的影响，一般都有一定的偏差。

因此工业级机器学习系统面临一个长期挑战，那就是，如何能够在评估模型以及训练模型的时候考虑到这样的偏差，从而去除这样的偏差。
<div><strong>精选留言（8）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/46/f4/5e878cd4.jpg" width="30px"><span>李佳</span> 👍（17） 💬（1）<div>真是开眼界了，原来大牛是这么读经典论文的，学习的榜样啊！</div>2017-09-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/89/5b/cc06e436.jpg" width="30px"><span>yaolixu</span> 👍（7） 💬（1）<div>洪老师好,您说:“Thorsten 利用因果推论中的倾向评分（Propensity Scoring）技术以及（Multi-armed Bandit）思想，把这样的方法成功地引入到机器学习中，使得无偏差地训练模型成为可能。 ” 
我对这方面的研究感兴趣,查看Thorsten教授的主页, 找到下面这篇论文: T. Joachims, A. Swaminathan, T. Schnabel, Unbiased Learning-to-Rank with Biased Feedback, International Conference on Web Search and Data Mining (WSDM), 2017. 
我的问题是, 这方面的研究(使用有偏差的数据,无偏差的训练模型)是否还有更多的参考资料?非常感谢😊</div>2018-06-18</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJOBwR7MCVqwZbPA5RQ2mjUjd571jUXUcBCE7lY5vSMibWn8D5S4PzDZMaAhRPdnRBqYbVOBTJibhJg/132" width="30px"><span>ヾ(◍°∇°◍)ﾉﾞ</span> 👍（7） 💬（0）<div>实时相关的任务，比如实时推荐，实时分类等</div>2018-01-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/46/d4/679062c0.jpg" width="30px"><span>Zolynn</span> 👍（5） 💬（0）<div>收获很多</div>2017-09-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4e/38/3faa8377.jpg" width="30px"><span>登高</span> 👍（3） 💬（1）<div>文章没怎么(ﾟoﾟ;看懂，希望随着学习的深入可以明白</div>2018-05-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/d7/37/d8c8acdf.jpg" width="30px"><span>求渔</span> 👍（1） 💬（0）<div>多因子的分类问题的训练和预测，如广告投放的预测，政府选举的预测，千人千面的推荐，舆情的分类等</div>2019-09-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/d6/6c/c3e62b69.jpg" width="30px"><span>Crystal</span> 👍（0） 💬（0）<div>请问打不开拓展阅读，怎么办呀，在电脑上显示连接到 www.cs.cornell.edu 时发生错误。</div>2020-05-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/b7/28/e8e2efec.jpg" width="30px"><span>谢贵阳Garry</span> 👍（0） 💬（0）<div>谁能解释一下什么是有序回归？</div>2019-04-08</li><br/>
</ul>