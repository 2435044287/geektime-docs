周一，我们分享了LDA（Latent Diriclet Allocation）的各种扩展模型，介绍了基于上游的和下游的两种把额外信息融入到LDA模型中的方法。同时，我们也讨论了在时间尺度上如何把LDA模型扩展到可以“感知”不同的时间段对于模型的影响。以LDA为代表的主题模型在过去的十年间发展出了一整套的扩展，为各式各样的应用场景提供了有力的工具。

尽管LDA在模型的表达力上给研究者们提供了把各种场景和模型结合的可能性，但是LDA的训练过程比较复杂，而且速度也比较慢。因此，如何能够把LDA真正应用到工业级的场景中，对于很多人来说，都是一件煞费苦心的事情。今天我们就来聊聊**LDA的算法优化问题**。

## LDA模型训练

我们首先来回顾一下LDA模型的训练过程，从高维度上为你分析一下为什么这个过程很困难。

LDA模型中最重要的未知变量就是每个单词对应的**主题下标**（Index）或者说是**主题“赋值”**（Assignment）。这个主题下标是从每个文档对应的主题分布中“采样”得来的。每个文档的主题分布本身也是一个未知的多项式分布，用来表达当前这个文档的所属主题，比如有多少百分比属于运动、有多少百分比属于金融等等。这个分布是从一个全局的狄利克雷（Diriclet）分布中产生的。狄利克雷分布在这里起到了**超参数**的作用，其参数的取值往往也是未知的。但是我们可以根据一些**经验值**对其进行设置。除了每个文档的主题分布和主题赋值以外，我们还需要对全局的主题语言模型进行估计。这些语言模型直接决定了，各类词语出现的概率是多少。

流行的LDA训练方法有两个，一个是基于\*\*吉布斯采样**（Gibbs Sampling）的随机方法，一个是基于**变分推断\*\*（Variational Inference）的确定性方法（Deterministic）。这两种方法的初始形态都无法应对大型数据。这里我们来简要介绍一下这两种方法。

**吉布斯采样**主要是针对主题赋值进行采样，最开始是完全随机的结果，但是慢慢会收敛到参数的后验概率的真值。这里面比较慢的一个原因，是这个收敛过程可能需要几百到几千个不等的迭代。同时，吉布斯采样只能一个文档一个文档进行，所有的数据结构都需要在采样的过程中进行更改。这个过程比较慢的另外一个原因，是吉布斯采样的核心是如何对一个离散分布进行采样。而离散分布采样本身，如果在分布的参数变化的情况下，最好能够达到O（KlogK），这里K是主题的数目。因此，从原理上来说，这也是阻碍吉布斯采样能够扩展到大型数据的一个原因。

**变分推断**的思路则和吉布斯采样很不一样。它是把对隐含参数的估计问题变成一个确定性的优化问题，这样我们就可以**利用种种优化算法来解决贝叶斯推断的问题**。不过和吉布斯采样相比，变分推断存在一个问题，因为这种方法并不是解决原来的优化问题，因此新的优化问题可能并不能带来原来问题的解。同时，变分推断也需要一个文档一个文档单独处理，因此推广到大规模数据上有其局限性。

## LDA的大规模优化算法

顺着我们刚才提到的问题，为了把吉布斯采样和变分推断扩大到大规模数据上，学者们有针对性地做了很多探索。我们下面就分别对这两种思路展开简要的介绍。

首先，我们来看吉布斯采样。吉布斯采样慢的一个核心就是我们刚才说的，需要从一个离散分布中采样出一个样本，在我们这个例子中也就是每个单词的主题赋值。那么，有没有什么方法让这个步骤加速呢？答案是，有的。

在KDD 2009上发表了一篇论文《应用于流文档集合的主题模型推断的高效方法》（Efficient methods for topic model inference on streaming document collections）\[1]，算是在这方面取得突出成绩的一个重要参考文献。这篇论文的主要贡献就是，对原有的采样公式进行了一个比较仔细的分析。
<div><strong>精选留言（2）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/35/df/67f91c36.jpg" width="30px"><span>帅帅</span> 👍（2） 💬（0）<div>我在spark mllib中看到了LDA的实现，应该就是并行化的实现</div>2018-10-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/7f/6d/545ab00c.jpg" width="30px"><span>vick_zh</span> 👍（0） 💬（0）<div>请问：LDA是否又被深度学习方法替代的趋势？所以在应用价值显得没那么“重要”？</div>2018-06-22</li><br/>
</ul>