今天，我们来分享一下NIPS 2017的最后一篇最佳论文《安全和嵌套子博弈解决非完美信息博弈问题》（[Safe and Nested Subgame Solving for Imperfect-Information Games](http://https://www.cs.cmu.edu/~sandholm/safeAndNested.aaa17WS.pdf)）。这篇文章讲的是什么内容呢？讲的是如何解决“非完美信息的博弈”问题。

和前两篇分享的文章类似，这篇文章也是理论性很强，并不适合初学者，我们在这里仅仅对文章的主要思想进行一个高度概括。如果你对文章内容感兴趣，还是建议要阅读原文。

另外一个值得注意的现象是，即便在深度学习如日中天的今日，我们本周分享的三篇NIPS最佳论文均和深度学习无关。这一方面展现了深度学习并不是人工智能的全部，另一方面也让我们看到机器学习和人工智能领域的宽广。

## 作者群信息介绍

本文一共两位作者。

第一作者叫诺阿·布朗（Noam Brown）。布朗是卡内基梅隆大学计算机系的博士生，目前的主要研究方向是利用强化学习和博弈论的思想来解决大规模的多机器人交互的问题。这篇文章提到的“非完美信息博弈”也是这里面的一个分支问题。布朗已经在这个方向发表了多篇论文，包括三篇AAAI论文、两篇NIPS论文、一篇ICML论文、以及一篇IJCAI论文。

和本文非常相关的一个研究内容在2017年发表于《科学》（Science）杂志上，讲述了如何利用博弈论来解决“Heads-up无限制扑克”（Heads-up No Limit Poker）的问题，并且在现实比赛中已经超过了人类的表现。这个工作也得到了不少媒体的报道。布朗2017年也在伦敦的Google DeepMind实习；在博士阶段之前，他曾经在金融领域工作。

第二作者是布朗的导师托马斯·桑德霍姆（Tuomas Sandholm）。桑德霍姆是卡内基梅隆大学计算机系的教授，其在“机制设计”（Mechanism Design）以及“拍卖理论”（Auction Theory）等领域有长期的研究，发表了450多篇学术论文，并且有超过2万多的引用数。除了他在学术上的造诣以外，桑德霍姆还有一些轶事，比如，他还有非常广泛的兴趣爱好，在他的主页就列举了他冲浪、喜好魔术以及对飞行的热爱。

## 论文的主要贡献和核心方法

我们首先来看一下这篇文章的主要贡献，弄明白这篇文章主要解决了什么场景下的问题。

对于一篇理论性很强的文章来说，我们通常需要不断地提问，这篇文章的核心主旨到底是什么，这样才能够帮助我们了解到文章的主干。

首先，文章讲的是一个“**非完美信息的博弈**”问题。这是什么意思呢？要理解“非完美信息博弈”，我们就必须要说一下“**完美信息博弈**”。

简单来说，“完美信息博弈”指的是博弈双方对目前的整个博弈状况都完全了解，对于博弈之前，以及整个博弈时候的初始状态也完全了解。在这种定义下，很多大家熟悉的游戏都是“完美信息博弈”，比如围棋、象棋等等。那么，DeepMind开发的AlphaGo以及后来的AlphaGo Zero都是典型的针对“完美信息博弈”的人工智能算法。

“非完美信息博弈”并不是说我们不知道对方的任何信息，而只是说信息不充分。什么意思呢？比如，我们可能并不知道对手在这一轮里的动作，但我们知道对手是谁，有可能有怎样的策略或者他们的策略的收益（Payoff）等。

除了在表面定义上的区别以外，在整个问题的机构上也有不同。
<div><strong>精选留言（2）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（5） 💬（0）<div>如果这个问题使用深度强化学习，感觉上这个场景是状态转移概率函数和奖赏函数都难以直接获取的免模型学习。传统的蒙特卡罗和时序差分学习都是基于采样轨迹的值来迭代更新策略。这个问题中后手能采样到的轨迹中和最优策略有可能差异会较大，这样很难生成最优策略。

不知道分成子域后这个问题是否可能有解决。</div>2018-02-02</li><br/><li><img src="" width="30px"><span>549</span> 👍（0） 💬（0）<div>打麻将属于 非完美信息博弈 吗？我只知道对方出过什么牌，但是不知道他手里还有什么牌</div>2020-10-09</li><br/>
</ul>