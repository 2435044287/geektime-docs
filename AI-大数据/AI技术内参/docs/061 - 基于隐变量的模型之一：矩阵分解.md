上周我们聊了三个简单的推荐模型，分别是基于流行度的推荐模型，基于相似信息的推荐模型和基于内容特征的推荐模型。

这周，我们来看一类非常重要的推荐模型：**基于隐变量的推荐模型**。这类模型的优势是对用户和物品信息中的隐含结构进行建模，从而能够挖掘更加深层次的用户和物品关系。

## 什么是隐变量

在解释如何用隐变量来生成推荐结果之前，我们先来说一下什么是隐变量。

**隐变量**（Latent Variable），顾名思义，就是“隐藏的变量”或者叫“隐藏的参数”，这里主要是指我们假定实际的数据是由一系列的隐含变量产生的。我们通过模型的假设，知道隐变量之间的关系，但暂时并不知道隐变量的取值。因此需要通过“推断”（Inference）过程来确定隐变量的实际取值。当我们知道了这些隐变量的取值之后，就可以根据这些取值来对未来的数据进行预测和分析。

隐变量往往还带有“统计分布”（Distribution）的假设。什么意思呢？就是隐变量之间，或者隐变量和显式变量之间的关系，我们往往认为是由某种分布产生的。

举一个最简单的隐变量模型的例子，那就是“**高斯混合模型**”（Mixture of Gaussian）。

高斯混合模型假设数据是由多个不同的高斯分布产生的，每一个高斯分布有自己的均值和方差。在最简单的两个高斯的情况下，每一个数据点，都有可能是由这两个高斯分布中的一个产生的，但是，究竟是哪一个我们并不知道。于是，对于每一个数据点，我们就有一个隐含的变量，来表达当前这个数据点究竟来自哪一个高斯分布。

很明显，这个隐含变量的取值事先并不知道。除了这个隐含变量我们不知道以外，两个高斯分布的均值和方法其实也不知道。于是，对于高斯混合模型来说，整个学习的过程就需要估计每个数据点的来源以及多个高斯分布的均值和方差。**高斯混合模型，几乎是最简单的隐变量模型，但也给我们了展示了使用隐变量模型对数据建模的灵活性以及训练的复杂性**。

## 矩阵分解作为隐变量模型

了解了隐变量模型的基本的概念以后，我们还是回到推荐的场景。
<div><strong>精选留言（4）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（11） 💬（0）<div>基于隐变量的矩阵分解有如下缺点：
推荐结果不具有很好的可解释性，分解出来的用户和物品矩阵的每个维度无法和现实生活中的概念来解释，无法用现实概念给每个维度命名，只能理解为潜在语义空间。

除了上面一点，现实的评分矩阵特别稀疏。为了使得数据更加稠密，可以加入了历史的隐式反馈数据(比如用户浏览过浏览过某个电影就可以当做一定成的喜爱的正反馈)。

我们也可以使用用户的标签（比如年龄，性别，职业）推测用户对每个因素的喜爱程度。

还可以考虑随着时间变化的动态因素以及不同因素的置信度。

类似于之前文章中减去平均打分的方法(将来可能还会讲)。我们观测到的评分数据大部分都是都是和用户或物品无关的因素产生的效果，即有很大一部分因素是和用户对物品的喜好无关而只取决于用户或物品本身特性的。例如，对于乐观的用户来说，它的评分行为普遍偏高，而对批判性用户来说，他的评分记录普遍偏低，即使他们对同一物品的评分相同，但是他们对该物品的喜好程度却并不一样。同理，对物品来说，以电影为例，受大众欢迎的电影得到的评分普遍偏高，而一些烂片的评分普遍偏低，这些因素都是独立于用户或产品的因素，而和用户对产品的的喜好无关。

我们把这些独立于用户或独立于物品的因素称为偏置(Bias)部分，将用户和物品的交互即用户对物品的喜好部分称为个性化部分。在矩阵分解模型中偏好部分对提高评分预测准确率起的作用高于个性化部分所起的作用。</div>2018-03-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/6a/a1/6270eeb7.jpg" width="30px"><span>极客星星</span> 👍（3） 💬（0）<div>矩阵分解方法应用时 经常遇到的问题是 只有正样本 缺少负样本 针对这个问题有一些策略 如BPR 等</div>2018-03-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/26/55/e72a671e.jpg" width="30px"><span>rookie</span> 👍（1） 💬（0）<div>“很明显，这个隐含变量的取值事先并不知道。除了这个隐含变量我们不知道以外，两个高斯分布的均值和方法其实也不知道。于是，对于高斯混合模型来说，整个学习的过程就需要估计每个数据点的来源以及多个高斯分布的均值和方差。”  这里的“均值和方法”应该是”均值和方差“</div>2019-12-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/2f/c5/aaacb98f.jpg" width="30px"><span>yungoo</span> 👍（0） 💬（0）<div>请问隐向量的维度是超参数吗？</div>2021-08-02</li><br/>
</ul>