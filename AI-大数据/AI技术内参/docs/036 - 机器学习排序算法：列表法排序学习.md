本周我们已经分别讨论了最基本的单点法排序学习（Pointwise Learning to Rank）和配对法排序学习（Pairwise Learning to Rank）两种思路。单点法排序学习思路简单实用，目的就是把经典的信息检索问题转化成机器学习问题。配对法排序学习则是把排序的问题转化成针对某个查询关键字每两个文档之间的相对相关性的建模问题。不过，这两种思路也都有很明显的问题，需要进一步对算法进行优化，以实现我们需要的最终目标。

今天我就来讲直接优化排序问题的“终极方法”：列表法排序学习（Listwise Learning to Rank） 。相对于尝试学习每一个样本是否相关或者两个文档的相对比较关系，列表法排序学习的基本思路是尝试直接优化像NDCG（Normalized Discounted Cumulative Gain）这样的指标，从而能够学习到最佳排序结果。

## 列表法排序学习的历史

2000年后，学术界和工业界都开始研究如何用机器学习来解决最优排序问题，五六年之后，研究者们才开始尝试直接优化整个排序列表。

这方面的研究工作很多都来自微软研究院。比如2007年左右的AdaRank，就来自微软亚洲研究院的徐君和李航。这篇论文算是较早提出列表法排序观点的研究工作。同一年在国际机器学习大会ICML 2007（International Conference on Machine Learning）上发表的ListNet算是从理论上开启了列表法的大门。这篇论文也来自微软亚洲研究院，是刘铁岩等人的重要工作。类似的研究工作在这一年里如雨后春笋般涌现。

另外一个方向，接下来我会提到，LambdaRank出现稍早，而LambdaMART则稍微晚一点。这方面的工作是在微软西雅图的研究院开发的。主导人是克里斯托弗·博格斯（Christopher J.C. Burges）。博格斯2016年退休，在微软工作了16年，可以说，他领导的团队发明了微软的搜索引擎Bing的算法。

## 列表法排序学习详解

列表法排序学习有两种基本思路。**第一种，就是直接针对NDCG这样的指标进行优化**。目的简单明了，用什么做衡量标准，就优化什么目标。**第二种，则是根据一个已经知道的最优排序，尝试重建这个顺序，然后来衡量这中间的差异**。

我先来说一下第一大思路，直接针对NDCG这样的指标进行优化。

首先，重温一下排序测试集的测试原理。总体来说，所有的基于排序的指标都要考察测试集上，对于某一个查询关键字来说，某一组文档所组成的排序是否是最优的。有两种比较通用的做法。第一个方法主要适用于二分的相关信息，对于某一个查询关键字，针对排序产生的“顶部的K”个文档进行评估，查看精度（Precision）、召回（Recall）等。第二种方法，利用五级相关信息定义，在这样的情况下，就可以利用类似于NDCG这样的评价指标。具体解读你可以回到本周前面两期我们讲解过的内容进行复习。

那么，**直接优化排序指标的难点和核心在什么地方呢？**
<div><strong>精选留言（2）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/30/1c/e160955d.jpg" width="30px"><span>sky</span> 👍（5） 💬（0）<div>列表法的假设是，已经知道了针对某个搜索关键字的完美排序，但是在并不知道完美排序或者不存在完美排序的时候就不好用了</div>2018-05-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/fe/4f/3a7b8033.jpg" width="30px"><span>幻大米</span> 👍（1） 💬（0）<div>洪老师，列表法只是在训练阶段的运算复杂度高吧，在线应用时运算复杂度不跟单点法一样吗？</div>2018-01-28</li><br/>
</ul>