在今年的EMNLP大会上，有两类研究论文得到发表，一类是8页的长研究论文，主要是比较完整的研究结果；另一类是4页的短研究论文，主要是比较新的有待进一步推敲的研究结果。大会从长研究论文中选出两篇最佳论文，从短论文中选出一篇最佳论文。

前面我们分别讨论了两篇最佳长论文，今天，我就带你认真剖析一下EMNLP 2017年的最佳短论文《多智能体对话中，自然语言并非“自然”出现》（Natural Language Does Not Merge ‘Naturally’ in Multi-Agent Dialog）。我们今天讲的论文虽然是最佳短论文，但是作者们已经在arXiv发表了较长的文章版本，因此我今天的讲解将基于arXiv的长版本。

这篇文章研究的一个主要命题就是，多个“机器人”（Agent）对话中如何才能避免产生“非自然”（Unnatural）的对话。以前很多机器人对话的研究都关注准确率的高低，但实际上机器人产生的对话是不自然的，人类交流不会用这样的方式。这篇文章希望探讨的就是这样非自然的对话是如何产生的，有没有什么方式避免这样的结果。

## 作者群信息介绍

第一作者萨特维克·库托儿（Satwik Kottur）来自卡内基梅隆大学，博士第四年，研究领域为计算机视觉、自然语言和机器学习。2016年暑假他在Snapchat的研究团队实习，研究对话系统中的个性化问题。2017年暑假在Facebook研究院实习，做视觉对话系统（Visual Dialog System）的研究。近两年，萨特维克已在多个国际顶级会议如ICML 2017、IJCAI 2017、CVPR 2017、ICCV 2017以及NIPS 2017发表了多篇高质量研究论文，包括这篇EMNLP 2017的最佳短论文，可以说是一颗冉冉升起的学术新星。

第二作者何塞·毛拉（José M. F. Moura）是萨特维克在卡内基梅隆大学的导师。何塞是NAE（美国国家工程院）院士和IEEE（电气电子工程师学会）院士，长期从事信号处理以及大数据、数据科学的研究工作。他当选2018年IEEE总裁，负责IEEE下一个阶段的发展。

第三作者斯特凡·李（Stefan Lee）是来自乔治亚理工大学的研究科学家，之前在弗吉尼亚理工大学任职，长期从事计算机视觉、自然语言处理等多方面的研究。斯特凡2016年博士毕业于印第安纳大学计算机系。

第四作者德鲁·巴塔（Dhruv Batra）目前是Facebook研究院的科学家，也是乔治亚理工大学的助理教授。德鲁2010年博士毕业于卡内基梅隆大学；2010年到2012年在位于芝加哥的丰田理工大学担任研究助理教授；2013年到2016年在弗吉尼亚大学任教。德鲁长期从事人工智能特别是视觉系统以及人机交互系统的研究工作。文章的第三作者斯特凡是德鲁长期的研究合作者，他们一起已经发表了包括本文在内的多篇高质量论文。

## 论文的主要贡献

我们先来看看这篇文章主要解决了一个什么场景下的问题。

人工智能的一个核心场景，或者说想要实现的一个目标，就是能够建立一个目标导向（Goal-Driven）的自动对话系统（Dialog System）。具体来说，在这样的系统中，机器人能够感知它们的环境（包括视觉、听觉以及其他感官），然后能和人或者其他机器人利用自然语言进行对话，从而实现某种目的。

目前对目标导向的自动对话系统的研究主要有两种思路。
<div><strong>精选留言（5）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/6c/9f/0343d633.jpg" width="30px"><span>黄德平</span> 👍（3） 💬（0）<div>理论上来讲，真实场景同样是个有限场景，有限个具象或抽象的物体，有限个属性，词汇量应该是伴随着人们能够接触到的物体数量缓慢增加的，而且增长速度慢于物体增加的速度。因为先发明的词汇通过叠加的方式可能可以描述新的物体，只有需要很长老词汇才能描述新物体时才有必要发明新词汇，而且是在新物体足够常见值得用一个新词描述的情况下。个人认为可以用一个简单公式描述，描述物体的总数是一个系数乘以词汇量的平方，比如一共一亿个物体，我只需要几万个词汇，我认为组合其中的某两个词汇足够表达新物体。</div>2018-12-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/26/53/60fe31fb.jpg" width="30px"><span>深白浅黑</span> 👍（1） 💬（0）<div>人机交互中机器人语言缺乏自然语言特征，可以使用强化学习模式来进行改进。通过降低词库数量将解决内部信息以编码形式输出的情况，通过忘记过去状态解决属性叠加的判断，使对话呈现出自然语言叠加特性特征。</div>2019-09-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/8f/98/7d1287d9.jpg" width="30px"><span>韩 * *</span> 👍（1） 💬（0）<div>个人理解:人类“自然”的对话传递信息的“速率”是有限的，限制“速率”有利于产生在人类主观看来更“自然”的信息交互过程。</div>2019-08-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/f6/30/72b1263d.jpg" width="30px"><span>小南</span> 👍（0） 💬（0）<div>这就像是学习一门语言，如何判断我有足够的语言基底把想要表达的事情讲明白呢？</div>2021-08-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/a2/04/a8b1327a.jpg" width="30px"><span>元初</span> 👍（0） 💬（0）<div>感觉在自然的语言中，越是日常的对话每句话的关键信息越少，分布越稀疏，感觉像是为了隐晦自己的目的，让自己在人际交往中说话不太突兀；而随着关键信息的密集程度上升，文字就向官方声明靠近，到达那种每一个定语的差异都带来语义的显著变化就是顶峰了（没错就是政治背书的感悟）；再往上就不自然了，是不是可以控制语句信息量来实现自然化呢</div>2021-04-16</li><br/>
</ul>