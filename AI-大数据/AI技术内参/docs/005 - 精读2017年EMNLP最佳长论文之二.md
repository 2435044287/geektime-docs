EMNLP每年都会选出两篇最佳长论文，我们已经分析过第一篇《男性也喜欢购物：使用语料库级别的约束条件减少性别偏见的放大程度》。今天我继续来讲第二篇。

EMNLP 2017年最佳长论文的第二篇是《在线论坛中抑郁与自残行为风险评估》（Depression and Self-Harm Risk Assessment in Online Forums）。这篇文章探讨了利用自然语言处理技术来解决一个社会问题。最近一段时间以来，如何利用机器学习、数据科学等技术来解决和处理社会问题，正逐渐成为很多社会科学和机器学习研究的交叉领域。

## 作者群信息介绍

第一作者安德鲁·耶特斯（Andrew Yates），计算机博士，毕业于美国华盛顿的乔治城大学（Georgetown Univeristy），目前在德国马克思普朗克信息学院（Max Planck Institute for Informatics）攻读博士后。他在博士阶段已经发表了多篇采用深度学习技术和信息检索、自然语言处理相关的论文。

第二作者阿曼·可汗（Arman Cohan），来自伊朗，是乔治城大学计算机系博士生。阿曼已在信息检索和自然语言处理相关方向发表了多篇论文。2016年，在华盛顿的Medstar Health实习并发表了两篇论文。2017年暑假，在美国加州圣何塞（San Jose）的奥多比（Adobe）研究院实习。

第三作者纳兹利·哥汗（Nazli Goharian）也来自乔治城大学计算机系，目前在系里担任计算机教授。第一作者是他之前的学生，第二作者是他当前的学生。纳兹利在长达20年的职业生涯中先后在工业界和学术圈任职，可以说有很深厚的学术和工业背景，他在信息检索和文本分析领域已发表20多篇论文。

## 论文的主要贡献

在理解这篇文章的主要贡献之前，我们还是先来弄明白，这篇文章主要解决了一个什么场景下的问题。

现代社会，人们生活工作的压力越来越大。研究表明，很多人都可能受到各式各样精神疾病（Mental Conditions）的困扰。在当下发达的互联网时代，在线场所为这些精神疾病患者寻求帮助提供了大量的资源和信息，特别是一些专业的在线支持社区，或是一些更大的在线社区比如Twitter或者Reddit。

因此，研究这些人在各种在线社区的行为，对设计更加符合他们需要的系统有很大帮助。对于很多社会研究人员来说，分析这些人的精神状态，才能更好地帮助他们长期发展。

这篇文章提出了一个比较通用的框架，来分析这些精神疾患者的在线行为。在这个框架下，可以比较准确地分析发布信息的人是否有自残（Self-Harm）行为，还可以比较容易地分析哪些用户有可能有抑郁症（Depression）的状况。

整个框架利用了近年来逐渐成熟的深度学习技术对文本进行分析。所以，这里的应用思路很值得借鉴和参考，也可以用于其他场景。

## 论文的核心方法

在介绍这篇文章提出的方法之前，作者们用不小的篇幅介绍了文章使用的数据集和如何产生数据的标签。
<div><strong>精选留言（4）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/72/3e/534db55d.jpg" width="30px"><span>huan</span> 👍（1） 💬（1）<div>我的理解是，这里的场景下，物理意义是帖子发表人表达抑郁或者自残情绪的时候，选词是比较狭窄的，负面的，和正常人比较是相对偏少的，而且抑郁或者自残的情绪波动比较少（正常人的情绪应该比较多）。不过不知道这种“物理意义“是否存在很多的偏见。
另外不知道文章中的原始输入X是怎么做向量化的，也就是“每个帖子的一个范围内单词“是怎么操作的？直接分词还是做stem，或者去掉噪音词吗？保留词的顺序吗？没有用LSTM甚至是word vector这些序列数据怎么处理的那？</div>2017-11-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/58/e3/e981f2d9.jpg" width="30px"><span>徐听听</span> 👍（14） 💬（0）<div>图像上用卷积是利用了卷积作用在图像像素的空间平移不变性，例如一只猫无论是出现在图像的哪个位置（左上还是右下角），都对分类器结果无影响。

将卷积作用在文本信息中能够有效应该也是利用了卷积的平移不变性，无论和抑郁&#47;自残相关的词句出现在文本的哪个位置，只要出现过，都可以被检测出来。</div>2017-11-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/41/a6/dcd67a78.jpg" width="30px"><span>阿卡斯</span> 👍（3） 💬（0）<div>对于那个模型我有两个技术细节不是特别清晰，，最开始输入的是文本（即帖子文章）我可以理解成是应用了word2vec向量化文章中每一个单词构成了大矩阵进入到CNN么？那这样的话每个文章字数是不同的，我们即使确定了文章最大长度的95%还是会有信息缺失，这个输入矩阵宽度如何设计？第二个问题每个用户的帖子文章数量是不同的最后我们通过CNN提取feature数量是不同的具体是怎么merge没有提到</div>2018-07-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/58/e3/e981f2d9.jpg" width="30px"><span>徐听听</span> 👍（0） 💬（0）<div>图像上用卷积是利用了卷积作用在图像像素的空间平移不变性，例如一只猫无论是出现在图像的哪个位置（左上还是右下角），都对分类器结果无影响。

将卷积作用在文本信息中能够有效应该也是利用了卷积的平移不变性，无论和抑郁&#47;自残相关的词句出现在文本的哪个位置，只要出现过，都可以被检测出来。</div>2017-11-08</li><br/>
</ul>