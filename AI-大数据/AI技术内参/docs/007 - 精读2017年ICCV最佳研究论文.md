ICCV（International Conference on Computer Vision，国际计算机视觉大会），是每两年举办一次的计算机视觉顶级会议。从1987年开始举办，已经有30年的历史。2017年的ICCV大会于10月22日至29日在意大利的水城威尼斯举行。

在每届ICCV大会上，都会从众多学术论文中挑选出两篇最有新意和价值的论文作为最佳研究论文和最佳学生论文。ICCV的最佳论文奖又叫作“马尔奖项”（Marr Prize），是为了纪念英国的心理学家和神经科学家大卫·马尔（David Marr）而设计的奖项。马尔将心理学、人工智能和神经生理学的研究成果结合起来，提出了全新的关于视觉处理的理论，他被认为是计算神经科学的创始人。

今天，我就来带你认真剖析一下ICCV 2017年的最佳研究论文“[Mask R-CNN](https://research.fb.com/wp-content/uploads/2017/08/maskrcnn.pdf)”。这篇论文是一个集大成的工作，介绍了一个新的方法可以用于同时解决图像的“**物体识别**”（Object Detection）、“**语义分割**”（Semantic Segmentation）和“**数据点分割**”（Instance Segmentation）的工作。

什么意思呢？通俗地讲，那就是给定一个输入的图像，利用这篇论文提出的模型可以分析这个图像里究竟有哪些物体，比如是一只猫，还是一条狗；同时能够定位这些物体在整个图像中的位置；并且还能针对图像中的每一个像素，知道其属于哪一个物体，也就是我们经常所说的，把物体从图像中“抠”出来。

## 作者群信息介绍

这篇论文的作者全部来自Facebook的人工智能研究院（Facebook AI Research）。

第一作者就是近几年在计算机视觉领域升起的学术之星何恺明博士（Kaiming He）。他于2016年加入Facebook人工智能研究院，之前在微软亚洲研究院进行计算机视觉的研究工作；他还是CVPR 2016年和CVPR 2009年的最佳论文得主。目前，何恺明在计算机视觉领域有三项重大贡献。

第一，他与其他合作者发明的ResNet从2016年以来成为了计算机视觉深度学习架构中的重要力量，被应用到了计算机视觉以外的一些领域，比如机器翻译和AlphaGo等，相关论文引用数超过5千次。

第二，他与其他合作者开发的Faster R-CNN技术，发表于NIPS 2015上，是图像物体识别和语义分析的重要技术手段，也是今天我们要讨论的这篇论文的基础，论文引用数超过2千次。

第三，他与其他合作者在ICCV 2015年发表论文《深入研究整流器：在ImageNet分类上超越人类水平》（[Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/He_Delving_Deep_into_ICCV_2015_paper.pdf)），研究了一种改进的ReLU（Rectified Linear Unit，线性整流函数，又称修正线性单元）结构从而达到了更好的效果，论文引用数近2千次。

第二作者乔治亚⋅吉克里奥夏里（Georgia Gkioxari）目前是Facebook人工智能研究院的博士后研究员。乔治亚可以说是师出名门，在Facebook工作之前才从加州大学伯克利毕业，师从计算机视觉泰斗吉腾德拉⋅马利克（Jitendra Malik）。乔治亚之前还分别在谷歌大脑和谷歌研究院实习过。在过去几年中，乔治亚在计算机视觉界已经发表了多篇高质量论文。

第三作者皮奥特⋅多拉（Piotr Dollár）是Facebook人工智能研究院的一名经理。2007年从加州大学圣地亚哥分校获得博士学位，2014年加入Facebook，这之前在微软研究院工作。皮奥特长期从事计算机视觉的研究工作。

最后一个作者罗斯⋅吉尔什克（Ross Girshick）是Facebook人工智能研究院的一名科学家。他于2012年毕业于芝加哥大学，获得计算机博士。罗斯之前也在微软研究院工作，也曾在计算机视觉泰斗吉腾德拉的实验室里担任博士后的研究工作。

## 论文的主要贡献

我们首先来看一下这篇文章的主要贡献。还是要先去理解，这篇文章主要解决的是一个什么场景下的问题。
<div><strong>精选留言（1）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（4） 💬（0）<div>第一步先分析一个大的矩形框，第二步进行物体检测。因为要打标签，第二步肯定是需要的。因为最终目标是物体检测，为了检测中图片中是否有物体，是什么物体。先把完整包含物体可能性最大的区域框出来，然后做里面的物体分类。第一步也是必须的。可以看成是最初CNN图片分类的升级，也更接近我们人类对于复杂图片中的物体识别方法。</div>2018-01-24</li><br/>
</ul>