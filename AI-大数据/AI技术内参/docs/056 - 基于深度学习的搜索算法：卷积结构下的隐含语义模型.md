这个星期，也是我们整个搜索领域分享的最后一周内容，来看一些搜索算法的前沿思考，特别是深度学习对搜索领域的影响。周一我们分享了一篇较早利用深度学习技术来进行搜索建模的论文，论文提出如何使用前馈神经网络来对查询关键字和文档进行信息提取，从而能够学习更有意义的语义信息。

今天我们来看一篇文章《信息检索中结合卷积池化结构的隐含语义模型》（[A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval](http://www.iro.umontreal.ca/~lisa/pointeurs/ir0895-he-2.pdf)），可以说这是我们周一分享论文的一个后续工作。这篇论文发表在第23届世界信息和知识管理大会CIKM 2014上。

## 论文背景介绍

这篇论文的主要目的是探讨深度学习中的卷积神经网络能否应用在搜索中，并取得较好的效果。

下面我们先来了解一下这篇论文作者群的信息。

第一作者Yelong Shen是微软研究院的一名资深研究员。

第二作者是何晓冬（Xiaodong He）是微软研究院深度学习组的主任研究员兼经理，发表过一百多篇学术论文，在人工智能领域，特别是近年来在深度学习领域有很突出的贡献。

第三作者高剑峰（Jianfeng Gao）是一名长期在微软研究院工作的研究员和经理。

第四作者邓力（Li Deng）是微软研究院的人工智能学者，曾担任微软的首席人工智能科学家并且领导深度学习中心。2017年5月，邓力离开微软加入Citadel，美国著名的金融机构，担任首席人工智能官的职位。

最后一位作者格雷古瓦·梅尼尔（Grégoire Mesnil）是来自蒙特利尔大学的一名博士学生。

这篇论文自2014年发表后已被引用180多次，是探讨深度学习在搜索领域中应用的主要论文之一。

## 卷积结构下的隐含语义模型详解

我们周一介绍的深度结构化语义模型，其主要思想是希望能够利用前馈神经网络来对查询关键字和文档进行信息提取。这个模型有一个很明显的问题，那就是在第一步对查询关键字或文档进行特征提取时所形成的词向量（Term Vector）是忽略了文字原本的顺序信息的，也就是依然是一个“词袋模型”（Bag of Words）假设，这显然是丢失了很多信息的。

当然，我们今天要分享的卷积结构下的隐含语义模型，也并不是第一个想要解决这个问题的模型。在经典的信息检索领域的研究中，已经有不少这方面的尝试了。那么对于深度学习来说，又有什么优势呢？