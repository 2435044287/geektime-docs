在上一篇的分享里，我们展开了文本分析这个方向，讨论了“隐语义分析”（Latent Semantic Indexing）这个模型。隐语义分析的核心是基于矩阵分解的代数方法。这种方法的好处自然是能够直接利用代数计算方法对文本进行分析，而短板则是无法很好地解释结果。而“解释性”是很多概率模型的一大优势，因此，自然就有很多研究者想到是否能够把概率的语言移植到隐语义分析上。

今天，我们就来分享“**概率隐语义分析**”（Probabilistic Latent Semantic Indexing）的一些基本内容。概率隐语义分析有时候又被简称为 **PLSA**（Probability Latent Semantic Analysis）。

## 隐语义分析核心思想

上周我们介绍过隐语义分析的核心思想，首先来简要回顾一下。

隐语义分析的核心其实就是用无监督的方法从文本中提取特性，而这些特性可能会对原来文本的深层关系有着更好的解释。

简单来说，隐语义分析就是利用了“矩阵分解”的概念，从而对“词-文档矩阵”（Term-Document Matrix）进行分解。

## 概率隐语义分析

既然概率隐语义分析是利用概率的语言，那么我们就来看看概率隐语义分析是如何对文档进行建模的。

首先，**PLSA是对文档和里面单词的联合分布进行建模**。这个文档和单词的联合分布其实就是类似隐语义分析中的那个文档和单词的矩阵。只不过，在PLSA里，我们不是直接对数据进行建模，而是认为数据是从某个分布中产生的结果。那么，对于这个联合分布该如何建模呢？
<div><strong>精选留言（1）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（0） 💬（0）<div>PLSA是从现有的数据简化的联合分布估计出来的，会不会导致对训练集的数据过拟合？</div>2018-04-27</li><br/>
</ul>