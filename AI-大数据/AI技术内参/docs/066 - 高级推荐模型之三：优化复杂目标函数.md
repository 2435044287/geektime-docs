周三我们讨论了协同矩阵分解，其主要思想就是解决多个两两关系的矩阵分解，并且希望能够建立隐变量之间的共享。

今天，我们来看一个稍微不一样的话题，那就是**如何优化更加复杂的目标函数**。

## 为什么需要复杂的目标函数

在介绍更复杂的目标函数之前，我们首先来回想一下，在之前的分享中，都接触到了哪些目标函数。

对于基于流行度或者相似度的推荐系统来说，其实并没有真正的目标函数的概念。这些推荐模型都是某种直观的“翻译”，这也导致了这些推荐系统很难直接使用在真实的应用中，往往是被当作特性用在其他模型中。

基于信息的推荐系统，本质上就是监督学习在推荐系统中的应用。因为是监督学习，那自然就需要目标函数。这里，经常是对点击率或者购买率进行建模，也就是说，经常使用**二分分类的目标函数**。

当我们使用矩阵分解的架构来对用户和物品的关系进行建模时，绝大多数情况下我们是在讨论**评分**。对于评分信息，常用的其实是**线性回归**（Linear Regression），也有学者使用**泊松回归**，因为泊松回归对于整数变量的建模要好于线性回归。当然了，矩阵分解也可以扩展到对点击率或者购买率的建模。

当年Netflix竞赛之后，Netflix公司把获奖的矩阵分解拿来进行实现，放入线上系统中，结果发现并没有本质性地提高推荐效果，这其实就和目标函数有关。虽然Netflix竞赛造就了矩阵分解等类似模型的流行，但是逐渐地，研究人员和工业界从业人员也意识到，**用户对物品的评分，并不是推荐系统需要优化的目标，也就是说目标函数“选错了”**。

那么，我们需要什么样的目标函数呢？
<div><strong>精选留言（2）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/22/69/c85fdb98.jpg" width="30px"><span>微微一笑</span> 👍（1） 💬（0）<div>推荐系统一般分为召回模块和排序模块吧，前面说的矩阵分解属于召回 学习排序属于排序模块</div>2018-03-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（0） 💬（0）<div>如果我们真地有所有用户对所有物品的喜好度的精准预测，特别是除了用户喜欢的程度，也能把用户真正不喜欢的和用户未注意到的情况区别开来，并且不考虑这么多数据量的训练性能影响，则这个point-wise模型可以用来根据评分大小作排序，可以不需要 BPR。不过实际环境中这种理想状态很难达到。

现实中我们喜欢的，商业系统推荐的是一批物品，不是单个物品。展示位置，展示时间等因素会影响用户的感受，互动和之后的评价结果。把整个系统的预测效果看成一个整体，就需要融入排序效果的学习。排序学习这个过程则依赖于物品喜好度的预测，包括一对物品之间用户更喜好那个来优化目标函数。</div>2018-03-16</li><br/>
</ul>