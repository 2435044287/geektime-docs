周一，我们分享了三个比较有代表意义的Word2Vec的扩展模型，主要有两种思路，从词的上下文入手重新定义上下文，或者对完全不同的离散数据进行建模。

今天，我们来看一看**Word2Vec在自然语言处理领域的应用**。如果我们已经通过SG模型、CBOW模型或者其他的算法获得了词向量，接下来我们可以把这些词向量用于什么样的任务中呢？

## Word2Vec的简单应用

**最直接的也是最常见的Word2Vec应用就是去计算词与词之间的相似度**。当我们的数据还是原始的“词包”（Bag of Word），这时候是没法计算词与词之间的相似度的，因为每个词都被表示为某个元素为1其余元素都为0 的离散向量。按照定义，两个离散向量之间的相似度都是0。因此，从词包出发，我们无法直接计算词与词之间的相似度，这是从定义上就被限制了的。

Word2Vec就是为了跨越这个障碍而被发明的，这一点我们在前面就已经提到过了。所以，当我们可以用Word2Vec的词向量来表示每一个单词的时候，我们就可以用“**余弦相关度**”（Cosine Similarity）来对两个词向量进行计算。**余弦相关度其实就是计算两个向量的点积，然后再归一化**。如果针对已经归一化了的向量，我们就可以直接采用**点积**来表达两个向量的相关度。不管是余弦相关度还是点积，我们都假设计算结果的值越大，两个词越相关，反之则不相关。

既然我们可以计算两个词的相关度，那么很多依赖相关度的任务就都能够轻松完成。比如，我们希望把词进行聚类，也就是说把相关的词都聚合在一起。通常的聚类算法都可以直接使用，比如我们熟悉的“K均值”算法。这些算法的核心是计算两个数据点的距离，就可以利用我们刚刚讲的余弦相关度来实现。

我们在谈Word2Vec扩展模型的时候，曾经提到了一些扩展模型，可以用于表达比词这个单位更大的文本单元，比如段落和文档向量的获取。其实，当时我们就提到了一种可以得到这些单元向量的简单方法，那就是**直接利用Word2Vec来进行加权平均**。在获得了词向量之后，我们就可以用一个文档里所有词的加权平均，甚至是简单的叠加来达到表达文档的目的。这个时候，我们也就可以利用诸如余弦相关度来计算文档之间的相关度了。

另外一个随着Word2Vec的推出而大放异彩的应用则是“**词语的类比**”。Word2Vec的原作者们用类比来表达，这种词向量能够完成一些与众不同的任务。词向量本质上就是一个连续空间的向量，因此从数学上来说，这种向量其实可以进行任何“合规”的运算，比如加、减、乘、除。于是，作者们就利用向量的加减关系，来看能否得到有意义的结果，而得到的结果令人吃惊。
<div><strong>精选留言（1）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/65/54/9cc1a2cf.jpg" width="30px"><span>Jtay-dlz</span> 👍（4） 💬（0）<div>我目前的理解更倾向于互补，主题模型提供的向量特征来自于对文档和主题的整体把握，而词向量更多的来自于上下文（特别是词序接近的）的特征提取，两者互补或可达到更好的效果</div>2020-05-05</li><br/>
</ul>