你好，我是叶伟民。

第15节课我们讲到了向量和相似度。我们以后面这五个事物为例，讲解了如何使用嵌入模型获得具体的向量值：

1. 老婆饼
2. 老婆
3. 夫妻肺片
4. 菠萝
5. 菠萝包

上一节课，我们又学习了如何使用向量数据库存储、更新、删除以上向量值。今天我们就来看看，向量值在RAG里的应用，通过计算向量值的相似度来检索知识，这也是RAG检索的核心。

## RAG检索的核心——相似度计算

我们先来看这样一个检索案例。

```plain
用户输入：我想吃一个老婆饼
系统从数据库里面检索到老婆饼数量为0
然后系统从其他四个事物中检索出一个并返回如下回答
系统回答：老婆饼没有了，我们有__，你需要吗？
```

那么问题来了。这时候，我们的应用如何从其他四个事物找出“菠萝包”来填充上面的空白之处呢？

相信细心的同学估计已经找到了答案，就是根据相似度进行查找（如果印象不深了可以回看第15节课）。换句话说，就是计算四个事物中与“老婆饼”的距离，再返回距离最近的那个。

那么这个距离应该如何计算呢？这就需要我们了解计算距离的几个方法。

1. L1距离（曼哈顿距离）
2. L2距离（欧几里得距离）
3. 负内积（Negative Inner Product）
4. 余弦距离（Cosine Distance）

## L1距离（曼哈顿距离）
<div><strong>精选留言（3）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/3b/d0/e5/0a3ee17c.jpg" width="30px"><span>kevin</span> 👍（0） 💬（1）<div>列出四种是因为他们都是面向文字处理领域的经典算法。</div>2024-10-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/a5/65/898bc6c5.jpg" width="30px"><span>wayne</span> 👍（0） 💬（0）<div>Cosine（余弦相似度）： 两个向量的余弦角度，由余弦定理可得。点积经向量长度归一化后可得，所以也叫语义搜索
IP（点积）：考虑了向量长度的 相似性，也就是未归一化前的 Cosine
L1（曼哈顿）：多维空间两个向量实际距离，几何意义就是两个向量 对坐标轴投影之后的距离
L2（欧式）: 多维空间两个向量的直线距离

点积和 Cosine 都可以通过 三角形的余弦定理推导出来
</div>2025-02-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/15/a3/e67d6039.jpg" width="30px"><span>narsil的梦</span> 👍（0） 💬（0）<div>“负内积距离在 LangChain 里面的实现如下。” 列出的是 l1 距离的计算代码，后面又说的 langchain 不支持负内积。是不是写完文档没有走查一遍😁 </div>2024-12-08</li><br/>
</ul>