你好，我是南柯。

前两讲中，我们已经学习了扩散模型的加噪去噪过程，了解了UNet模型用于预测噪声的算法原理。事实上，Stable Diffusion模型在原始的UNet模型中加入了Transformer结构（至于怎么引入的，我们等[下一讲](https://time.geekbang.org/column/article/683114)学完UNet结构便会清楚），这么做可谓一举两得，因为Transformer结构不但能提升噪声去除效果，还是实现prompt控制图像内容的关键技术。

更重要的是，Transformer结构也是GPT系列工作的核心模块之一。也就是说，我们只有真正理解了Transformer，才算是进入了当下AIGC世界的大门。这一讲，我就为你揭秘Tranformer的算法原理。

## 初识Transformer

在深度学习中，有很多需要处理时序数据的任务，比如语音识别、文本理解、机器翻译、音乐生成等。不过，经典的卷积神经网络，也就是CNN结构，主要擅长处理空间相关的任务，比如图像分类、目标检测等。

因此，[RNN](https://ieeexplore.ieee.org/document/6795228)（循环神经网络）、[LSTM](https://papers.baulab.info/Hochreiter-1997.pdf)（长短时记忆网络）以及 [Transformers](https://arxiv.org/abs/1706.03762) 这些解决时序任务的方案便应运而生。

### RNN和LSTM解决序列问题

RNN专为处理序列数据而设计，可以灵活地处理不同长度的数据。RNN的主要特点是在处理序列数据时，对前面的信息会产生某种“记忆”，通过这种记忆效果，RNN可以捕捉序列中的时间依赖关系。这种“记忆”在RNN中被称为隐藏状态（hidden state）。
<div><strong>精选留言（15）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/16/e8/c9/59bcd490.jpg" width="30px"><span>听水的湖</span> 👍（4） 💬（0）<div>虽然没有什么“跳关”秘籍，但还是有些技巧让你快速掌握一节课内容的。就像数据结构一样，每节课也有“内容结构”，想要快速消化，可以着重理一理后面这几点：这个模块 &#47; 这节课要解决什么问题（What）思路是什么 &#47; 为什么要这么解决（Why）具体如何解决的。

记各种名词没什么印象，可以试试结合例子去分析一下这个技术在里面发挥的作用。如果学习以后，能用自己的话整理一遍，也能帮助自己加深理解，查漏补缺。</div>2023-08-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg" width="30px"><span>Toni</span> 👍（6） 💬（1）<div>注意力机制给大语言模型的发展带来蓬勃动力，近期，2023年8月谷歌的一个研究团队发表了一篇文章，将AI的“领悟”机制第一次带入人们的视野，一项非常有价值的开创性工作。虽然目前还影响不到AI绘画，但还是将链接发给大家，以了解AI的重要进展。

下面是个人观点和一些感悟。

AI绘画出现后，人们就一直关注AI绘画能力的边界问题，由于AI绘画技术具有外延性属性，即它是通过数据训练学习得到的绘画能力，只能是学了什么会什么，这极大地限制了AI绘画会导致新的艺术流派出现的可能性。

我以前的想法是如果能训练AI“懂”一种流派，这个不难实现，比如今天在模型中常见到的梵高模式，然后将几种流派的特征元素提取出来，再重新结合起来，无论是随机组合还是人为干预形成的组合，就可以&quot;创建&quot;出一种新的流派。只要在AI模型所对应的参数上下下功夫，创新流派还是可以实现的。至于什么人喜欢什么人不喜欢并不重要，因它属于另一个范畴，单单艺术审美就与诸如神经元，人的阅历，喜好等众多因素有关，极其复杂，所以不在流派创新要考虑的范围内。

AI“感悟”力的出现，为AI绘画突破外延式限制打开了一扇全新的大门: 如果AI模仿艺术大师的作品，画着画着，突然有了全新的领悟，不就是新艺术流派的诞生吗？这与人类的创造过程及其相似。有趣的是这篇文章还展示了为什么有些AI没有产生“领悟”力的原因: 训练过程中的过拟合和欠拟合都会导致AI模型“领悟”力的匮乏，用大家都懂的话说&quot;过拟合&quot;就如“墨守成规”，&quot;欠拟合&quot;就如“东施效颦”。

“感悟”力机制就像本课讲到的注意力机制一样重要，非同凡响，石破惊天。

随笔记下几个“遐想”，欢迎评论。

参考文献:
&lt;&lt;谷歌发现大模型“领悟”现象！训练久了突然不再死记硬背&gt;&gt;
https:&#47;&#47;view.inews.qq.com&#47;a&#47;20230812A05OD900?devid=AD054D9E-92ED-41C6-BFC8-03C4A22E78E4&amp;qimei=f31d129575675bc1d4bebf5e000012117112#

原文:
Do Machine Learning Models Memorize or Generalize?
https:&#47;&#47;pair.withgoogle.com&#47;explorables&#47;grokking&#47;</div>2023-08-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/63/67/94d80726.jpg" width="30px"><span>vincent</span> 👍（5） 💬（3）<div>老师讲的非常好，但是对于我这个小白来说，难度还是比较高，听完后又在网上找了一些视频，结合着在看就更加理解了，在B站看到这个视频我觉得讲的比较适合小白https:&#47;&#47;www.bilibili.com&#47;video&#47;BV1MY41137AK&#47;?spm_id_from=333.337.search-card.all.click&amp;vd_source=eab8536a6dc6fd2252e60d2ccb546be1</div>2023-08-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/51/6e/efb76357.jpg" width="30px"><span>一只豆</span> 👍（3） 💬（2）<div>不知道大家是否和我有同样的感触啊，上节课内容能听懂，这节课好像也凑活。但是，开篇那一句“事实上，Stable Diffusion 模型在原始的 UNet 模型中加入了 Transformer 结构，”这句桥梁一样的话，好像有点跳。所以看课程的总体过程中，脑子里一直在想，是怎么加进去的。。。总觉得有一种缺半句话 or 一句话的感觉～～～见笑了</div>2023-07-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/f1/16/9eda1d16.jpg" width="30px"><span>五木老祖</span> 👍（1） 💬（1）<div>平时写前端和后端，想了解一下ai，但是太专业了，估计知识点缺失听不懂了。</div>2023-08-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1a/9d/4f/4c12de43.jpg" width="30px"><span>syp</span> 👍（0） 💬（1）<div>是我肤浅了，开始前几讲还觉得老师讲的不够深入，现在发现深不见底变成看不懂的天书了😨</div>2023-08-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/08/1f/b24a561d.jpg" width="30px"><span>～风铃～</span> 👍（0） 💬（3）<div>好深奥，身为程序员的我，一点也没看懂。可能没学过人工智能的都弄不懂吧</div>2023-08-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/38/42/59/bedf7932.jpg" width="30px"><span>留点空白</span> 👍（0） 💬（1）<div>确实听不懂这几讲，就过一遍了解一下吧</div>2023-08-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/f6/d6c1a0c2.jpg" width="30px"><span>海杰</span> 👍（0） 💬（1）<div>记得好像在输入层对token进行编码的时候，还会掺入用三角函数算出来的位置信息，所以同一个token 出现在序列中的不同位置，得到的K,Q,V值是不一样的。所以跟距离远的token 和距离近的token 算出来的注意力权重值也不一样。这样理解对吧？</div>2023-08-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/63/67/94d80726.jpg" width="30px"><span>vincent</span> 👍（0） 💬（1）<div>哈哈，听不懂</div>2023-08-02</li><br/><li><img src="" width="30px"><span>Geek_053403</span> 👍（0） 💬（1）<div>感觉基础篇专业性太强了</div>2023-07-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg" width="30px"><span>peter</span> 👍（0） 💬（2）<div>请教老师两个问题：
Q1：以SD为例，研发SD，需要多少人？需要多少机器？
Q2：AI绘画能制作表情包吗？</div>2023-07-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/a0/c3/c5db35df.jpg" width="30px"><span>石云升</span> 👍（1） 💬（0）<div>这节课比较难理解，所以我让AI帮我举例个例子。想象我们在做一个巨大的拼图，这个拼图是一张巨大的森林图片，而每一块拼图代表森林中的一个小部分，比如一只小鸟、一棵树、一朵花等。我们的目标是把这些拼图块正确地拼在一起，重现整个森林的图案。

Transformer模型
如果把这个拼图比作是Transformer模型要完成的任务，那么Transformer模型就像是一个超级聪明的机器人，它可以同时看到手中的所有拼图块，并且知道怎样快速准确地把它们拼在一起。这个机器人不需要像我们一样，一块一块地试着去拼，它可以利用它的超级大脑（自注意力机制），一眼就看出哪些拼图块应该放在一起。

自注意力机制
现在，我们来聊聊这个机器人的超级大脑，也就是自注意力机制。这个大脑能让机器人在看每一块拼图时，同时记住其他所有拼图块的样子。这样，当它看到一块拼图时，就能立即知道这块拼图周围应该是什么样的其他拼图块。比如，如果它手里有一块拼图是一只小鸟的一部分，它的大脑会立刻告诉它，这块拼图旁边应该是包含树枝的拼图块，因为小鸟通常会停在树枝上。

用一个简单的例子来说，假如你正在玩一个游戏，需要你描述你的朋友给你看过的一张很酷的贴纸。如果你只能记住贴纸的一小部分，比如上面有一只猫，但忘记了猫旁边有什么，这会让描述变得很难。但如果你记得猫旁边有一棵树，猫下面有一条鱼，这样的所有细节，你就能更好地描述整张贴纸。Transformer模型里的自注意力机制，就像是帮助机器人记住贴纸上每一个细节的超级能力，让它可以更好地完成任务。

结论
所以，想象一下你有一个超级机器人朋友，它有一个特别厉害的大脑，可以帮助它记住和理解每一块拼图是如何与其他拼图块一起工作的。这就是Transformer模型和自注意力机制的魔力——它们帮助机器理解和处理信息，就像是把一个巨大的、复杂的拼图拼在一起一样容易和有趣！</div>2024-03-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/e8/c9/59bcd490.jpg" width="30px"><span>听水的湖</span> 👍（1） 💬（0）<div>接下来的分享就是“用自己的话做整理，加深学习理解”的小案例。

我们让机器具备人的信息理解能力，有两个要解决的关键问题。

【问题一，看了后面忘前面】：当一个字一个字喂给计算机时，它很快就会忽略了前面的字。
【问题二，机器无法评估一段内容里，啥信息重要】：句子里有的词重要有的不重要，句子和句子之间也是，段落和段落之间也是这样。

为了解决这些问题，我们要把人类“不言自明”的一些天赋，换成机器能理解的描述方法教给他。类似于三角形加辅助线，或者我们通过多个维度的信息得出“唯一确定解”的思路，我们把机器本来不理解的输入信息，抽象成它能理解的数字。

结合Transformer里encoder的decoder，大概可以分成四步。

第一步，输入信息，但这个信息人类能懂。

第二步，encoder把它转化成机器可以计算的数据。

第三步，算法专家设计好的计算方法帮助机器“画辅助线”，提示机器注意信息的重点是啥，每个信息有多重要（重要程度一样也可以用数字表示）。做复杂计算，计算的目的是让机器用它能理解的方式，给出规定任务（比如让它把输入序列翻译成另一个语言）的“输出”。

第四步，机器给的输出还是“机器语言”，一堆数，我们人直接看不友好，再通过decoder把“答案”，转换成人类语言输出出来，大功告成。

有描述不准确的地方，欢迎批评指正。感谢热心群友Toni同学的讲解和提出Transformer不好理解的和某欢同学。

另外，关于Transformer，也推荐极客时间李沐老师的公开课最后一章（121～123讲）的内容，适合学有余力想深入代码跟技术细节的同学。https:&#47;&#47;time.geekbang.org&#47;course&#47;detail&#47;100077201-428460</div>2023-08-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/60/a1/45ffdca3.jpg" width="30px"><span>静心</span> 👍（0） 💬（0）<div>因为是初学，有一个初级的问题请教一下老师：
Q = X * W_Q
K = X * W_K
V = X * W_V

我想知道其中的X表示什么？权重矩阵 WQ​、WK​、WV​ 又是怎么来的？</div>2023-10-25</li><br/>
</ul>