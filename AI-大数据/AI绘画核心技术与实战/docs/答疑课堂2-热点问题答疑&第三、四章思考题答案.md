你好，我是南柯。

现在，我们已经完成了进阶篇和综合演练篇的学习。在更新过程中，我也看到了很多同学的留言评论。这次加餐，我精选了评论区中的高频问题做个回复，希望能帮你答疑解惑。

另外，第13讲到第25讲的思考题答案，我也放在了这篇加餐中。我希望你可以独立思考之后再查看答案，把答案和自己的想法做个对比。有一些没提供参考答案的是实操练习题，希望你课后多动手尝试，也欢迎你把你的实验成果用Colab链接等方式，在留言区分享出来。

## 热点问题答疑

**Q1：在AI绘画中，如何缓解手部生成的瑕疵问题？**

我们使用SD1.4、SD1.5等模型时确实很容易生成畸形手指，即使如今最新的 [SDXL模型](https://clipdrop.co/stable-diffusion?output=true)、Google的 [ideogram模型](https://ideogram.ai/)，生成的手部仍旧容易出现瑕疵。

对于手部生成的瑕疵问题，我提供两个解决的思路。

第一，在negative prompt中指定“bad hands, bad fingers”，引导模型关注手部区域的生成。

第二，使用针对手部的修复插件 [Depth Library](https://github.com/jexom/sd-webui-depth-lib)，这个插件中提供了各种不同的手势深度图，用于配合ControlNet的Depth控制条件。你可以通过 [这个视频](https://www.youtube.com/watch?v=mldTYb34X2E) 了解WebUI中如何使用Depth Library插件。
<div><strong>精选留言（2）</strong></div><ul>
<li><img src="" width="30px"><span>Geek_7ce725</span> 👍（1） 💬（1）<div>针对25讲中 如何生成文字，我有一个想法
通过chat抽无用户prompt中想要显示的文本内容，然后随机选择一款字体，生成对应的mask，基于controlnet技术对mask渲染，然后再去除result image 中 mask之外的内容 获得一张艺术字png</div>2023-09-15</li><br/><li><img src="" width="30px"><span>Geek_7ce725</span> 👍（0） 💬（0）<div>diffusers即将支持blipdiffusion和control_lora，风格临摹的效果将会得到改善</div>2023-09-15</li><br/>
</ul>