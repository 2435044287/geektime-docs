你好，我是独行。

前面我们[从0～1构建大模型](http://https://time.geekbang.org/column/article/787626?utm_campaign=geektime_search&utm_content=geektime_search&utm_medium=geektime_search&utm_source=geektime_search&utm_term=geektime_search)的那节课里，最后我通过5MB数据训练出的模型，占用了大概500M的存储空间，参数量约1.2亿，当时为了节省时间，只简单跑了一下，这比较极端，可以说大量的参数是浪费的，这里我简单举个例子说明一下，比如公式：

$$f(x)=k\_{1}x\_{1}+k\_{2}x\_{2}+k\_{3}x\_{3}+…+k\_{1000}x\_{1000}$$

经过少量数据训练后，我们只确定了 $k\_{1}$、$k\_{2}$…$k\_{100}$，后面的参数都未经过训练，所以其实是没用的。这种情况下，这个公式就有了可优化的空间，比如把 $k\_{100}$ 之后的全部砍掉，或者保留 $k\_{300}$ 之前的，之后的全部砍掉。

放在模型中，我们知道虽然参数量和训练数据量有很大关系，但是参数量还和模型网络的设计息息相关，当模型设计的层数比较深，那么也是很有可能产生浪费的情况。这种情况下，就可以对模型进行优化，优化的目标是**降低模型的复杂度，包括参数量、占用空间**。模型复杂度降低了，那么就可以降低资源的消耗，模型就可以运行在更低配置的设备上。
<div><strong>精选留言（2）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/a0/c3/c5db35df.jpg" width="30px"><span>石云升</span> 👍（3） 💬（0）<div>基于梯度的剪枝：
  计算每个参数对损失函数的梯度。
  梯度小的参数被认为不那么重要,可以被剪掉。
  这种方法考虑了参数对模型性能的实际影响。

基于激活的剪枝：
分析神经元的激活情况。
很少被激活或激活值很小的神经元可能不那么重要。


基于重构误差的剪枝：
  评估删除某个参数后对网络输出的影响。
  影响小的参数可以被剪掉。
  这种方法更准确但计算成本较高。

基于敏感度的剪枝：
  分析每个参数对模型性能的敏感度。
  敏感度低的参数可以被剪掉。</div>2024-09-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/3a/78/b0/13b19797.jpg" width="30px"><span>潇洒哥66</span> 👍（0） 💬（0）<div>除了参数对于模型输出重要性的考虑，有其它标准作为剪枝的依据吗？类似于参数对于模型稳定性，甚至是泛化能力的影响。</div>2024-10-16</li><br/>
</ul>