你好，我是独行。

铺垫了这么多，终于到重头戏了，如果把前面讲的基础知识都当作开胃小菜的话，那么这节课我们讲的Transformer妥妥的算主菜、大菜了。

回想一下上节课讲的Seq2Seq，我们的案例中底层使用的是GRU（门控循环单元），我们在讲RNN的时候提过但没有深入介绍。不论是GRU还是LSTM都面临一系列问题，比如梯度消失和梯度爆炸，还有RNN必须按照顺序处理序列中的每个元素，没法并行处理，当然还有长依赖问题，虽然RNN可以处理长序列，但是实战中效果并不是很好，等等。

这些问题一直困扰学术界多年，直到有一天，Google的研究员发表了一篇论文——[Attention Is All You Need](https://arxiv.org/pdf/1706.03762.pdf)，提出了Transformer模型，名字就霸气侧漏，瞬间这些问题貌似迎刃而解！我们今天这节课就来扒一扒细节，学习下为什么Transformer能解决这些问题。

## Transformer

Transformer是一种基于自注意力机制的深度学习模型，诞生于2017年。目前大部分大语言模型，像GPT系列和BERT系列都是基于Transformer架构。Transformer摒弃了之前序列处理任务中广泛使用的循环神经网络（RNN），转而使用自注意力层来直接计算序列内各元素之间的关系，从而有效捕获长距离依赖。这一创新设计不仅明显提高了处理速度，由于其并行计算的特性，也大幅度提升了模型在处理长序列数据时的效率。
<div><strong>精选留言（5）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/3b/5b/41/ac4cced1.jpg" width="30px"><span>_jordan</span> 👍（12） 💬（4）<div>结合线形代数来理解就好理解了，大模型在数学上的原理其实很简单。
1. 向量的分解（投影到子空间）
在多头注意力机制中，查询（Query）、键（Key）、值（Value）向量首先被分割成多个子向量。在线性代数中，这可以看作是将一个高维向量投影到多个低维子空间。2. 线性变换的应用
在每个头中，都会对这些子向量应用注意力机制。这些操作本质上是对向量在低维空间中的一种线性变换。在每个子空间中，查询、键和值向量分别进行如下操作：这实际上是一种通过线性代数中的矩阵运算，计算向量之间的相似性并应用到值向量上的过程。尽管这里用到了 softmax 函数来归一化注意力权重，但本质上，每个注意力头中的操作都是在一个低维子空间中进行的矩阵乘法，这仍然属于线性代数范畴。

在这个阶段，向量在每个头中进行的变换都依赖于相应的投影矩阵和后续的点积相似度计算。每个子空间中的结果是独立的，但仍然保持线性的变换结构。3. 重新组合的线性变换
在每个头独立地完成注意力计算后，所有这些低维空间中的向量被拼接在一起，形成一个新的高维向量。这可以用拼接操作来表示，形式上相当于将多个线性变换的结果组合成一个更大的向量：这一步并不是矩阵乘法，而是通过简单的拼接将每个子向量连接成一个完整的高维向量。

最后，为了确保拼接后的向量维度与原始输入的维度一致，应用了一个线性变换：这个步骤的目的在于将不同子空间中捕获的特征重新映射回原始空间中。4. 能否恢复原来的向量？
从线性代数的角度来看，能否恢复原始向量取决于两个关键因素：

投影是否为可逆的。
是否丢失了信息。
投影的可逆性：
投影到低维子空间后，理论上来说，单独的投影操作是不可逆的，因为在投影到较低维度时，一部分信息被压缩或丢失了。例如，从 512 维向量投影到 64 维，意味着我们丢失了一部分维度上的信息。因此，单个头的投影操作无法恢复出完整的原始向量。

信息重构：
虽然单个头的投影无法完全保留原始信息，但由于我们有多个头（每个头是独立的线性投影），模型通过多个子空间的组合能够捕捉到输入的不同特征。因此，多个头的组合实际上可以帮助模型在不同方向上恢复原始向量的不同成分，并在重新组合时保留大部分信息。

因此，虽然单个头的投影是不可逆的，但是通过多个头的组合和最后的线性变换，可以很好地近似恢复原始的高维向量。换句话说，最终的输出保留了大部分输入信息，同时还引入了模型从多个不同子空间中学习到的特征。
</div>2024-09-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/05/7f/a7df049a.jpg" width="30px"><span>Standly</span> 👍（6） 💬（1）<div>完了，上一节还能骗自己看懂了，这一节彻底看不懂了</div>2024-07-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/0a/a4/828a431f.jpg" width="30px"><span>张申傲</span> 👍（6） 💬（0）<div>第14讲打卡~
思考题：Transformer模型可能会先通过自注意力机制，识别出“不坏”和“不算特别好”这两个形容词，它们都是表达情感，但是在偏向性上有所不同，所以需要分析它们共同作用下的整体倾向。之后，Transformer可能会基于位置编码，判断出“不算特别好”是出现在“不坏”之后，并且使用“但”表达了情感转折，因此可能更倾向于后面的表达。最终整体的情感可能是轻微偏向负面的。
当然这只是理论上的推测，实际上这种比较模糊的情感表达，即使人类也未必能完全理解正确。
</div>2024-06-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/3b/5b/41/ac4cced1.jpg" width="30px"><span>_jordan</span> 👍（5） 💬（0）<div>
5. 小结
从线性代数角度，多头注意力中的向量分割可以理解为将原始向量投影到多个低维子空间。
每个头在独立的子空间中执行线性变换，捕捉不同的特征。
最终通过拼接和线性变换，模型重新组合子空间中的特征，将它们映射回原始的高维空间。
单个子空间中的线性变换不可逆，但多个头的组合能够重建输入的丰富特征，并通过线性变换确保输出维度和输入一致。
因此，虽然经过分解和线性变换的向量并不完全等同于原始向量，但通过多头的组合，它们能够捕捉到原始向量的多个方面，使得模型能够从不同的视角理解输入数据，并最终生成富有意义的输出。</div>2024-09-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/a0/c3/c5db35df.jpg" width="30px"><span>石云升</span> 👍（5） 💬（0）<div>1. 词嵌入和位置编码

首先，句子中的每个词都会被转换为向量表示（词嵌入），并添加位置信息：
&quot;这部 电影 不坏，但 也 不算 特别 好。&quot;

2. 自注意力机制

在自注意力层，模型会计算句子中每个词与其他词的关系：

&quot;不坏&quot;会与&quot;电影&quot;建立强联系
&quot;不算&quot;会与&quot;特别好&quot;建立强联系
&quot;但&quot;作为转折词，会得到特别的关注

3. 多头注意力

不同的注意力头可能关注句子的不同方面：

一个头可能专注于否定词（&quot;不坏&quot;、&quot;不算&quot;）
另一个头可能关注情感词（&quot;坏&quot;、&quot;好&quot;）
第三个头可能注意句子结构，特别是转折词&quot;但&quot;

4. 语义理解

通过多层编码器的处理，模型逐步构建对句子的深层理解：

理解&quot;不坏&quot;是一个轻微的正面评价
理解&quot;不算特别好&quot;是一个轻微的负面评价
捕捉到&quot;但&quot;表示前后两部分存在对比

5. 情感分析

在最后的处理阶段，模型会综合所有信息来判断整体情感倾向：

&quot;不坏&quot;略偏正面
&quot;不算特别好&quot;略偏负面
&quot;但&quot;表示后半句更重要

最终，模型可能会得出这是一个略微偏向负面，但基本中性的评价。

6. 上下文理解

如果这句话在更大的上下文中，Transformer还会考虑周围的句子来进一步调整理解。</div>2024-09-03</li><br/>
</ul>