你好，我是独行。

上一节课，我们通过一个企业内部小助手的案例，学习了6B的微调过程。其中，除了微调，还有一种模式就是知识库，用来增强大模型信息检索的能力，我们称之为检索增强生成（RAG），这是目前非常流行的一种做法，知识库模式相比于微调有2个好处。

1. 知识准确：先把知识进行向量化，存储到向量数据库里，使用的时候通过向量检索从向量库把知识检索出来，这样可以确保知识的准确性。
2. 更新频率快：当你发现知识库里的知识不全的时候，可以随时补充，不需要像微调一样，重新跑微调任务、验证结果、重新部署等。

这节课我们就通过外挂向量库的方式，继续完善法律小助手案例。除了大模型6B外，你还需要了解LangChain、向量化、向量库等组件及概念。ChatGLM3官方提供了一个和LangChain结合的demo：Langchain-Chatchat，还带有UI界面，我们可以直接拿过来使用。如果你理解了这个演示项目，那么智能体的原理也就学得差不多了，剩下的就是工程化的事情了。

## Langchain-Chatchat架构

Langchain-Chatchat主要包含几个模块：大语言模型、Embedding模型、分词器、向量数据库、Agent Tools、API、WebUI。
<div><strong>精选留言（19）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/21/82/e8/3c0c767a.jpg" width="30px"><span>LJT</span> 👍（8） 💬（1）<div>文中的langchain-chat需要是0.2.x版本，如果是直接从github上拉下来是0.3.x，文件夹中没有requirement.txt那些文件。所以，应该使用git clone https:&#47;&#47;github.com&#47;chatchat-space&#47;Langchain-Chatchat.git --branch v0.2.10 --depth=1</div>2024-06-21</li><br/><li><img src="" width="30px"><span>Geek_27bf62</span> 👍（4） 💬（2）<div>其实，实际项目中，我得出的经验是：能RAG，就不微调。有时候微调花了很多心血，可效果却一般</div>2024-06-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/0a/a4/828a431f.jpg" width="30px"><span>张申傲</span> 👍（4） 💬（1）<div>第6讲打卡~
思考题：现在大部分知识库的产品设计都是：优先展示大模型的输出结果，并且在最下方以参考资料的形式给出知识库中的匹配结果，用户可以点击展开匹配详情，查看具体检索到的资料和所在段落。</div>2024-06-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/71/4f/bce0d5bc.jpg" width="30px"><span>哈哈</span> 👍（2） 💬（1）<div>老师，对于RAG是否可以这样理解，它是增加了大模型的知识储备，可以基于这些知识做出更准确和全面的回答。而要提高大模型的能力，例如逻辑推理能力，还是需要训练和微调来解决。</div>2024-06-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/32/c2/ffa6c819.jpg" width="30px"><span>冰冻柠檬</span> 👍（1） 💬（1）<div>快快更新</div>2024-06-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4c/aa/37705e4e.jpg" width="30px"><span>影明</span> 👍（0） 💬（1）<div>课程有配套源码的吗</div>2024-09-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/62/81/ad80f427.jpg" width="30px"><span>Lane</span> 👍（0） 💬（1）<div>python这个包管理真拉胯，pip装的同时只能有一个版本。
比如A要求request&gt;= 3.2       B要求&lt;3.2      这时候怎么办？</div>2024-08-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/31/1b/9b75b80d.jpg" width="30px"><span>h</span> 👍（0） 💬（2）<div>老师好呀，苹果电脑M3芯片，在部署chatGLM3的时候，发现需要的依赖包vLLM没有，请问有什么办法可以解决嘛，望答复，感恩</div>2024-07-07</li><br/><li><img src="" width="30px"><span>Geek_336019</span> 👍（0） 💬（1）<div>文本中的左侧的知识库管理，可以进行知识库的上传。想问下，如果自己实现，需要先将文件用中文分词（比如jieba等），然后再传给向量库吗？自己分词有个好处是 可以自定义分词。还是说向量库的模型，已经很好的处理了中文分词呢？</div>2024-07-05</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erG6I79WlHDjs51JOff9GBibD4Fh2PhITQMvmh2aTUVzH2BKia1tFLLoQr7VFeZddywwRoZlVUyhDDQ/132" width="30px"><span>Geek_frank</span> 👍（0） 💬（1）<div>打卡第6课：在安装langchain-chatchat的时候遇到挺多问题，目前停留在知识库初始化中，继续研究下</div>2024-07-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/3b/8e/bf/f3dcc7ed.jpg" width="30px"><span>yp</span> 👍（0） 💬（1）<div>上传的知识库文件，在内容和形式上面有没有具体要求呢？比如是文本段落就行，还是需要整理成一问一答的形式？又或者是需要处理成某种格式？</div>2024-06-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/25/36/cc/f3bc7bbf.jpg" width="30px"><span>newCheng</span> 👍（0） 💬（1）<div>可不可以讲讲通过ollama来对大模型进行下载、管理和使用的方法呢？</div>2024-06-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/8b/4b/15ab499a.jpg" width="30px"><span>风轻扬</span> 👍（0） 💬（1）<div>老师。安装faiss的时候。pip install faiss-gpu，报了一个错误。
Error: Could not find a version that satisfies the requirement faiss-gpu(from version none)
Error: No matching distribution found for faiss-gpu。
当前的python是3.11版本
查了查，说是faiss-gpu不支持python的3.11版本，这是需要降低python的版本吗？</div>2024-06-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/90/19/b3403815.jpg" width="30px"><span>Juha</span> 👍（0） 💬（1）<div>老师，1-15步那里的第11步，从向量数据库里拿出来的相似数据给到LLM的时候，这里的数据是之前通过输入到知识库里的某条具体数据吗，还是说基于另一个LLM根据向量生成的文本呀</div>2024-06-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/90/19/b3403815.jpg" width="30px"><span>Juha</span> 👍（0） 💬（2）<div>1-15的流程那里，11步检索出来的结果，是提问的问题向量化之后的最相似的内容，是啥内容呢，是知识库的某个提问吗，这里涉及到LLM嘛</div>2024-06-17</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEKSVuNarJuDhBSvHY0giaq6yriceEBKiaKuc04wCYWOuso50noqDexaPJJibJN7PHwvcQppnzsDia1icZkw/132" width="30px"><span>Matthew</span> 👍（0） 💬（1）<div>能否补充下容器化部署的过程</div>2024-06-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/ec/89/681d9b13.jpg" width="30px"><span>小一</span> 👍（0） 💬（0）<div>思考题我的想法：知识库检索的内容，作为prompts输入给大模型，然后获取大模型的回答</div>2025-02-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/a0/c3/c5db35df.jpg" width="30px"><span>石云升</span> 👍（0） 💬（0）<div>一般我们只会在调试端看到知识库的命中，用户看到的只会是大模型的输出。</div>2024-08-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/a0/a4/b060c723.jpg" width="30px"><span>阿斯蒂芬</span> 👍（0） 💬（0）<div>向量为什么要存储？因为如果每次都是实时将query与知识计算向量算相似度，资源耗费大，且效率低，所以衍生了存储和高效检索的需求，所以有了专用的向量数据（Faiss和Milvus）。从使用经验来看，这类向量数据库大多以分簇的概念对向量进行聚类检索，大大提升了检索性能，不过也存在检索精度缺失的可能，就是直观上和数值上你认为最相似的，并不在其检索结果中，这是使用时特别需要注意和权衡的。当然，向量数据库也很成熟了，提供了多种参数让你根据实际需求选取合适的存储引擎和检索策略。</div>2024-06-22</li><br/>
</ul>