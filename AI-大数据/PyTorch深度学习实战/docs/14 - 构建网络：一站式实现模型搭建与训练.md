你好，我是方远。

前面我们花了不少时间，既学习了数据部分的知识，还研究了模型的优化方法、损失函数以及卷积计算。你可能感觉这些知识还有些零零散散，但其实我们不知不觉中，已经拿下了模型训练的必学内容。

今天这节课，也是一个中期小练习，是我们检验自己学习效果的好时机。我会带你使用PyTorch构建和训练一个自己的模型。

具体我是这么安排的，首先讲解搭建网络必备的基础模块——nn.Module模块，也就是如何自己构建一个网络，并且训练它，换句话说，就是搞清楚VGG、Inception那些网络是怎么训练出来的。然后我们再看看如何借助Torchvision的模型作为预训练模型，来训练我们自己的模型。

## 构建自己的模型

让我们直接切入主题，使用PyTorch，自己构建并训练一个线性回归模型，来拟合出训练集中的走势分布。

我们先随机生成训练集X与对应的标签Y，具体代码如下：

```python
import numpy as np
import random
from matplotlib import pyplot as plt

w = 2
b = 3
xlim = [-10, 10]
x_train = np.random.randint(low=xlim[0], high=xlim[1], size=30)

y_train = [w * x + b + random.randint(0,2) for x in x_train]

plt.plot(x_train, y_train, 'bo')
```
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/j24oyxHcpB5AMR9pMO6fITqnOFVOncnk2T1vdu1rYLfq1cN6Sj7xVrBVbCvHXUad2MpfyBcE4neBguxmjIxyiaQ/132" width="30px"><span>vcjmhg</span> 👍（15） 💬（2）<div>class MyCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)
        # conv1输出的特征图为222x222大小
        self.fc = nn.Linear(16 * 222 * 222, 10)

    def forward(self, input):
        x = self.conv1(input)
        # 进去全连接层之前，先将特征图铺平
        x = x.view(x.shape[0], -1)
        x = self.fc(x)
        return x
# 尽量使用gpu进行训练,如果没有cpu则使用gpu来训练
device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
cnn = MyCNN().to(device)
transform = transforms.Compose([
    # 修改裁剪图片的尺寸
    transforms.RandomResizedCrop((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,
                                               train=False,
                                               transform=transform,
                                               target_transform=None,
                                               download=True)
dataloader = DataLoader(dataset=cifar10_dataset,  # 传入的数据集, 必须参数
                        batch_size=32,  # 输出的batch大小
                        shuffle=True,  # 数据是否打乱
                        num_workers=2)  # 进程数, 0表示只有主进程
# 定义优化器
optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)
steps = 0
for epoch in range(16):
    for item in dataloader:
        steps += 1
        output = cnn(item[0].to(device))
        target = item[1].to(device)
        # 使用交叉熵损失函数
        loss = nn.CrossEntropyLoss()(output, target)
        # 每100步打印一次loss
        if steps % 100 == 0:
            print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1, loss))
        cnn.zero_grad()
        loss.backward()
        optimizer.step()
# 测试分类结果
im = Image.open(&#39;data&#47;img.png&#39;)
input_tensor = transform(im).unsqueeze(0)
result = cnn(input_tensor.to(device)).argmax()
print(result)
# tensor(3, device=&#39;cuda:0&#39;)</div>2021-11-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/e5/76/5d0b66aa.jpg" width="30px"><span>Mr_李冲</span> 👍（2） 💬（8）<div>我在使用预训练好的alexnet-owt-7be5be79.pth模型，反复执行下面这段代码的时候
alexnet(input_tensor).argmax()
得到的结果并不总是263，而有时候会得到151和264或者其他的数值，请问我最终应该相信哪一个预测结果呢，是进行多次预测取预测次数最多的那个吗？还是有别的科学的方法呢？</div>2022-03-15</li><br/><li><img src="" width="30px"><span>clee</span> 👍（2） 💬（1）<div>调整之后，可以正常训练了，但是测试数据的时候我发现有些图片分类会有问题，比如狗和猫，鹿和马就容易分类错误，这是因为欠拟合吗？应该如何优化？</div>2021-11-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/92/7b/8c7e3e61.jpg" width="30px"><span>Monroe  He</span> 👍（1） 💬（1）<div>老师请教一个问题，在梯度清零代码中

13 节课用的是优化器
optimizer.zero_grad()

这节课用的是模型
alexnet.zero_grad()

这两行代码有什么区别吗？
</div>2023-03-19</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/ajNVdqHZLLDm5eHbw1fuicJiaXercgBI48O0Idt2mHUElmZyBM4o119NkndU1SNpsv8rZzKFibj8z1FibFAdNEO3zw/132" width="30px"><span>zhangting</span> 👍（1） 💬（3）<div>老师请教个问题，为什么改全连接后，训练出来的模型，总是输出的是5。而未做改动前，预测出来的是263.源码如下：

alexnet = models.alexnet()
alexnet.load_state_dict(torch.load(&#39;.&#47;model&#47;alexnet-owt-7be5be79.pth&#39;)) 

fc_in_features = alexnet.classifier[6].in_features

alexnet.classifier[6] = torch.nn.Linear(fc_in_features, 10)
print(alexnet)

transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,                                       
                                               train=False,                                       
                                               transform=transform,                                       
                                               target_transform=None,                                       
                                               download=False)
dataloader = DataLoader(dataset=cifar10_dataset, batch_size=32, shuffle=True, num_workers=4)

optimizer = torch.optim.SGD(alexnet.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

for epoch in range(3):
    for item in dataloader: 
        output = alexnet(item[0])
        target = item[1]
        loss = nn.CrossEntropyLoss()(output, target)
        print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss))
        alexnet.zero_grad()
        loss.backward()
        optimizer.step()
       
im = Image.open(&#39;dog.jpg&#39;)
transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
input_tensor = transform(im).unsqueeze(0)

alexnet.eval()

print(alexnet(input_tensor).argmax())</div>2022-05-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/f2/23/bb13b3ed.jpg" width="30px"><span>刘利</span> 👍（1） 💬（5）<div>hi，老师，微调的时候，如果这样写，参数都不更新了，那还有哪部分参数会被训练呢？是需要再接一层全连接层么？
alexnet = models.alexnet()
alexnet.load_state_dict(torch.load(&#39;.&#47;model&#47;alexnet-owt-4df8aa71.pth&#39;))
for param in alexnet.parameters(): 
    param.requires_grad = False</div>2022-05-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/8d/8a/ec29ca4a.jpg" width="30px"><span>马克图布</span> 👍（1） 💬（1）<div>思考：

使用 `nn.CrossEntropyLoss` 作为 loss function 时，会自动在网络最后添加 `nn.LogSoftmax` 和 `nn.nLLLos`，因此不用再在 fc 层后面手动添加 Softmax 层；

问题：

transform 中，标准化的 mean 和 std 是如何确定的（我们需要使用均值为[0.485, 0.456, 0.406]，标准差为[0.229, 0.224, 0.225]对数据进行正规化）？</div>2021-11-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/45/2f/b0b0dd74.jpg" width="30px"><span>杨杰</span> 👍（0） 💬（1）<div>import torchvision.models as models
from PIL import Image
import torchvision
import torchvision.transforms as transforms

alexnet = models.alexnet(pretrained=True)

im = Image.open(&#39;.&#47;data&#47;dog.jpg&#39;)

transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

input_tensor = transform(im).unsqueeze(0)
print(alexnet(input_tensor).argmax())

以上代码输出的不一定是264，这个是啥情况？</div>2022-10-04</li><br/><li><img src="" width="30px"><span>Geek_827444</span> 👍（0） 💬（2）<div>老师您好：我一步一步按照咱们那个步骤来的，为什么代码运行不了那？谢谢您！

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.models as models

import torchvision.models as models
alexnet = models.alexnet(pretrained=True)


import torchvision.transforms as transforms

transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])
])

import torchvision

cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,#注：这里是存在													pycharm文件当中的data文件夹里
                                              train=False,
                                              transform=transform,
                                              target_transform=None,
                                              download=True)

from torch.utils.data import DataLoader

dataloader = DataLoader(dataset=cifar10_dataset,
                       batch_size=32,
                       shuffle=True,
                       num_workers=2)



fc_in_features = alexnet.classifier[6].in_features
alexnet.classifier[6] = torch.nn.Linear(fc_in_features,10)

optimizer = torch.optim.SGD(alexnet.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

for epoch in range(3):
    # ↓定义比对的元素
    for item in dataloader:
        output = alexnet(item[0])
        target = item[1]

        # ↓使用损失函数
        loss = nn.CrossEntropyLoss()(output, target)
        print(&#39;Epoch{},Loss{}&#39;.format(epoch + 1, loss))

        # ↓更新损失函数和优化函数
        alexnet.zero_grad()
        loss.backward()
        optimizer.step()

</div>2022-08-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/02/2a/90e38b94.jpg" width="30px"><span>John(易筋)</span> 👍（0） 💬（1）<div>巨人肩膀@马克图库
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from PIL import Image
transform = transforms.Compose([
    transforms.RandomResizedCrop((224, 224)), 
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

cifar10_train_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,train=True,transform=transform,target_transform=None)
train_loader = torch.utils.data.DataLoader(dataset=cifar10_train_dataset,batch_size=32,shuffle=True,num_workers=2) 
classes = (&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;)
n_total_steps = len(train_loader)

class MyCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)
        self.fc = nn.Linear(16 * 222 * 222, 10)
        
    def forward(self, input):
        x = self.conv1(input)
        x = x.view(x.shape[0], -1)
        x = self.fc(x)
        return x
    
device = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
model = MyCNN().to(device)

criterion = nn.CrossEntropyLoss() 
optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

print(&#39;Start training...&#39;)
for epoch in range(4):
    for i, (images, labels) in enumerate(train_loader):
        images = images.to(device)
        labels = labels.to(device)
        labels_pred = model(images)
        loss = criterion(labels_pred, labels)
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step
        
        if (i+1) % 100 == 0:
            print(f&#39;Epoch [{epoch+1}&#47;{4}], Step [{i+1:5d}&#47;{n_total_steps}], Loss={loss.item():.4f}&#39;)

print(&#39;Training complete!&#39;)

with torch.no_grad():
    im = Image.open(&#39;.&#47;images&#47;dog.jpg&#39;)
    input_tensor = transform(im).unsqueeze(0).to(device)
    label_pred = model(input_tensor).argmax()
    print(f&#39;Your label predicted: {classes[label_pred]}&#39;)</div>2022-08-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2c/8d/70/b0047299.jpg" width="30px"><span>Zeurd</span> 👍（0） 💬（1）<div>老师，想请问一下，我在换了一个模型InceptionV3，做损失函数的时候，会提示我argument &#39;input&#39; (position 1) must be Tensor, not InceptionOutputs这是什么原因呢？我用output预测完输出的是一个InceptionOutPuts的量，而不是Tensor形式的，当我想用torch.tensor又会提示我不是一维的，不能转化</div>2022-07-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/3f/4a/b1c9e5e3.jpg" width="30px"><span>万化8af10b</span> 👍（0） 💬（1）<div>老师，请教一下，上面的例子

# 训练3个Epoch
for epoch in range(3): 
for item in dataloader: 
output = alexnet(item[0]) target = item[1] 
# 使用交叉熵损失函数 loss = nn.CrossEntropyLoss()(output, target) 
print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss)) #以下代码的含义，我们在之前的文章中已经介绍过了 alexnet.zero_grad() 
loss.backward()
 optimizer.step()


每epoch里面作的次数我做了计数是313次backwards，为什么会是这个数字，我计算了以下50000张训练集，50000&#47;32&#47;2=781.25次才对阿。请老师点明我算错在哪里？</div>2022-06-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/8c/5c/3f164f66.jpg" width="30px"><span>亚林</span> 👍（0） 💬（1）<div>照抄抄出来了，但是对损失函数选取，优化器参数设置，还是一脸懵</div>2022-05-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/25/89/23/e71f180b.jpg" width="30px"><span>Geek_fc975d</span> 👍（0） 💬（1）<div>or epoch in range(3): for item in dataloader: output = alexnet(item[0]) target = item[1] # 使用交叉熵损失函数 loss = nn.CrossEntropyLoss()(output, target) print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss)) #以下代码的含义，我们在之前的文章中已经介绍过了 alexnet.zero_grad() loss.backward() optimizer.step()

想请教老师和各位同学，这个item是多少， 是cifar10的总数据数&#47;batch_size吗？原先我以为这个值等于batch-size，看起来这个结果不对呢。

还想请教下epoch这个参数是指什么， 是说按照这个batch_size将整个数据集训练几次吗？

我在Jupyter中训练，训练的速度超级慢，有什么提升的方法吗？</div>2022-04-10</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIW9p3Q9OuX2kGgroDacib99YvjkichWdl54YBVicno8wNPW9gKibUNb0QPtYvTljSWFdjgXdrGPr7Q5g/132" width="30px"><span>璐璐棒</span> 👍（0） 💬（1）<div>你好，老师，请教下，想用预训练的effientnet b0来训练自己的数据，自己的数据是png的图片，这个行的通吗，是需要修改下输入通道数就可以吗，还是说不能使用预训练的模型，可以重新训练一个新的模型？</div>2021-12-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/d2/d7/7f00bea1.jpg" width="30px"><span>Hit黎明分明🎩</span> 👍（0） 💬（3）<div>
#数据加载

transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,
                                       train=False,
                                       transform=transform,
                                       target_transform=None,
                                       download=True)
dataloader = DataLoader(dataset=cifar10_dataset, # 传入的数据集, 必须参数
                               batch_size=32,       # 输出的batch大小
                               shuffle=True,       # 数据是否打乱
                               num_workers=0)      # 进程数, 0表示只有主进程


#定义模型
class myCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3,16,kernel_size=3)
        self.fc = nn.Linear(16 * 222 *222 ,10)
        
    def forward(self,input):
        x = self.conv1(input)
        # 进去全连接层之前，先将特征图铺平
        x = x.view(x.shape[0],-1)
        x = self.fc(x)
        return x

# 尽量使用gpu进行训练,如果没有cpu则使用gpu来训练
device = torch.device(&quot;cuda:0&quot;if torch.cuda.is_available()else &quot;cpu&quot;)

cnn = myCNN().to(device)


optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)
steps = 0

for epoch in range(30):
    for item in dataloader:
        steps += 1
        output = cnn(item[0])
        target = item[1].to(device)
        loss = nn.CrossEntropyLoss()(output,target)
        print(&#39;Epoch{},Loss{}&#39;.format(epoch + 1 ,loss))
        cnn.zero_grad()
        loss.backward()
        optimizer.step()
im = Image.open(&#39;data&#47;img.png&#39;)
input_tensor = transform(im).unsqueeze(0)
result = cnn(input_tensor.to(device)).argmax()
print(result)
老师您好，我运行以后出现报错：
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor</div>2021-12-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/fc/de/6e2cb960.jpg" width="30px"><span>autiplex</span> 👍（0） 💬（2）<div>from PIL import Image
from torch.utils.data import DataLoader
import torch
from torch import nn
import torchvision.transforms as transforms
import torchvision


#  读取数据
transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,
                                       train=False,
                                       transform=transform,
                                       target_transform=None,
                                       download=True)
dataloader = DataLoader(dataset=cifar10_dataset, # 传入的数据集, 必须参数
                               batch_size=32,       # 输出的batch大小
                               shuffle=True,       # 数据是否打乱
                               num_workers=2)      # 进程数, 0表示只有主进程


#  网络结构
class MyCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)
        # conv1输出的特征图为222x222大小
        self.fc = nn.Linear(16 * 222 * 222, 10)

    def forward(self, input):
        x = self.conv1(input)
        # 进去全连接层之前，先将特征图铺平
        x = x.view(x.shape[0], -1)
        x = self.fc(x)
        return x

cnn = MyCNN()
#  损失函数
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

#  训练10个Epoch
for epoch in range(10):
    for item in dataloader: 
        output = cnn(item[0])
        target = item[1]
        loss = criterion(output, target)
        print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss))
        #以下代码的含义，我们在之前的文章中已经介绍过了
        cnn.zero_grad()
        loss.backward()
        optimizer.step()

#  测试结果
pass

老师上面的代码运行会发生下面的报错，我查了一下说是要放在__name__==&#39;__main__&#39;里运行，我没太明白

The &quot;freeze_support()&quot; line can be omitted if the program
        is not going to be frozen to produce an executable.
</div>2021-11-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/b5/4c/6b9528f8.jpg" width="30px"><span>zhaobk</span> 👍（0） 💬（1）<div>#图像分类
class MyCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)
        # conv1输出的特征图为222x222大小
        self.fc = nn.Linear(16 * 222 * 222, 10)

    def forward(self, input):
        x = self.conv1(input)
        # 进去全连接层之前，先将特征图铺平
        x = x.view(x.shape[0], -1)
        x = self.fc(x)
        return x


#定义读取数据格式 mean和std是ImageNet的均值与标准差。torchvision中的模型都是在ImageNet上训练的。
transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0.224, 0.225])
])
#获取数据

cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,
                                       train=False,
                                       transform=transform,
                                       target_transform=None,
                                       download=True)


#加载数据
dataloader = DataLoader(
    dataset=cifar10_dataset, # 传入的数据集, 必须参数
    batch_size=32,       # 输出的batch大小
    shuffle=True,       # 数据是否打乱
    num_workers=0)      # 进程数, 0表示只有主进程

cnn = MyCNN()
#定义优化器
optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

for epoch in range(10):
    for item in dataloader:
        cnt+=1
        output = cnn(item[0])
        target = item[1]
        # 使用交叉熵损失函数
        loss = nn.CrossEntropyLoss()(output, target)
        print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss))
        #首先要通过zero_grad()函数把梯度清零

        cnn.zero_grad()
        # 算完loss之后进行反向传播，这个过程之后梯度会记录在变量中
        loss.backward()
        # 用计算的梯度去做优化
        optimizer.step()

im = Image.open(&#39;dog.jpg&#39;)
input_tensor = transform(im).unsqueeze(0)
print(cnn(input_tensor).argmax())

我训练完loss总是在1.8~~2.0之间震荡，最后用dog.jpg测试出来的分类是3，cat。请问老师，我的代码有问题么？还是训练的少？</div>2021-11-15</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ0F94uoYZQicSOIfEfSr9gH7CTKibNBsS6d9PRDd8cy7bdTCF9jibXYtf0esGqsQAItHnElejIFovxg/132" width="30px"><span>cab</span> 👍（0） 💬（1）<div>请问一下为什么PyTorch中的AlexNet网络结构与论文中的不一样呢？
</div>2021-11-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/8d/8a/ec29ca4a.jpg" width="30px"><span>马克图布</span> 👍（0） 💬（1）<div>代码：

import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
from PIL import Image


transform = transforms.Compose([
    transforms.RandomResizedCrop((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

cifar10_train_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;, train=True, transform=transform, target_transform=None, download=True)
train_loader = torch.utils.data.DataLoader(dataset=cifar10_train_dataset, batch_size=32, shuffle=True, num_workers=2)
classes = (&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;)
n_total_steps = len(train_loader)


class MyCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3)
        self.fc = nn.Linear(16 * 222 * 222, 10)

    def forward(self, input):
        x = self.conv1(input)
        x = x.view(x.shape[0], -1)
        x = self.fc(x)
        return x


device = torch.device(&#39;cuda:0&#39; if torch.cuda.is_available() else &#39;cpu&#39;)
model = MyCNN().to(device)

criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

print(&#39;Start training...&#39;)
for epoch in range(4):
    for i, (images, labels) in enumerate(train_loader):
        images = images.to(device)
        labels = labels.to(device)
        labels_pred = model(images)
        loss = criterion(labels_pred, labels)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        if (i+1) % 100 == 0:
            print(f&#39;Epoch [{epoch+1}&#47;{4}], Step [{i+1:5d}&#47;{n_total_steps}], Loss = {loss.item():.4f}&#39;)
print(&#39;Training complete!&#39;)

print(&#39;Start testing...&#39;)
with torch.no_grad():
    im = Image.open(&#39;dog.jpg&#39;)
    input_tensor = my_transform(im).unsqueeze(0).to(device)
    label_pred = model(input_tensor).argmax()
    print(f&#39;Your label predicted：{classes[label_pred]}&#39;)
</div>2021-11-12</li><br/><li><img src="" width="30px"><span>clee</span> 👍（0） 💬（2）<div>import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import transforms
import torchvision

transform = transforms.Compose([transforms.RandomResizedCrop((224,224)), 
                                transforms.ToTensor(), 
                                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) ])
cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;, 
                                               train=False, 
                                               transform=transform, 
                                               target_transform=None, 
                                               download=True)
dataloader = DataLoader(dataset=cifar10_dataset, batch_size=32)
class MyCNN(nn.Module): 
  def __init__(self): 
    super().__init__()
    self.conv1 = nn.Conv2d(3, 16, kernel_size=3)
    self.fc = nn.Linear(16 * 222 * 222, 10)
  def forward(self, input):
    x = self.conv1(input)
    # 进去全连接层之前，先将特征图铺平
    x = x.view(x.shape[0], -1)
    x = self.fc(x)
    return x

class MyCNN_Model():
  def __init__(self):
    self.learning_rate = 0.001
    self.epoches = 100
    self.model = MyCNN()
    self.optimizer = torch.optim.SGD(self.model.parameters(), lr=self.learning_rate, momentum=0.9)
    self.loss_function = nn.CrossEntropyLoss()

  def train(self):
    for epoch in range(self.epoches):
      for item in dataloader:
        prediction = self.model(item[0])
        loss = self.loss_function(prediction, item[1])
        self.optimizer.zero_grad()
        loss.backward()
        self.optimizer.step()
      print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss))
    torch.save(self.model.state_dict(), &#39;mycnn.pth&#39;)

疑问一：Loss输出特别大，是哪个参数没有配置正确吗?
Epoch 1, Loss 44.85285568237305
Epoch 2, Loss 6869.75048828125，
疑问二：
loss.backward()，optimizer.step() 两行代码都是执行了方法而已，没有传递任何参数，那么损失函数和优化器内部和模型是怎么关联起来的。
</div>2021-11-12</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q3auHgzwzM7uYZvwhrLHsJICstGXaOvUNZnyq0aO7gF0OLicMyZAZFnRiaDyvM1lGxnEDP2VUMV3m6UjiazMmSNGQ/132" width="30px"><span>Geek_8cfc4c</span> 👍（0） 💬（1）<div>有个神奇问题，我在mac上跑模型训练loss感觉没有收敛的迹象
用linux机器跑就收敛了……
版本号都是一样的……
这可能是什么问题呢？</div>2021-11-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2b/13/3e/d028cddd.jpg" width="30px"><span>王珎</span> 👍（0） 💬（2）<div>from PIL import Image
import torchvision
import torchvision.transforms as transforms
import torch
from torch.utils.data import DataLoader

# 数据读取
transform = transforms.Compose([
    transforms.RandomResizedCrop((224,224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#39;,
                                       train=False, #下载测试集
                                       transform=transform,
                                       target_transform=None,
                                       download=True)
dataloader = DataLoader(dataset=cifar10_dataset, # 传入的数据集, 必须参数
                               batch_size=32,       # 输出的batch大小
                               shuffle=True,       # 数据是否打乱
                               num_workers=2)   # 进程数, 0表示只有主进程

# 定义计算设备
device = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;) 

# 实例化模型
cnn = MyCNN().to(device)
# 定义优化器
optimizer = torch.optim.SGD(cnn.parameters(), lr=1e-4, weight_decay=1e-2, momentum=0.9)

steps = 0
for epoch in range(10):
    for item in dataloader: 
        steps += 1
        output = cnn(item[0].to(device))
        target = item[1].to(device)
        # 使用交叉熵损失函数
        loss = nn.CrossEntropyLoss()(output, target)
        
        if steps % 50 == 0:
            print(&#39;Epoch {}, Loss {}&#39;.format(epoch + 1 , loss))
        cnn.zero_grad()
        loss.backward()
        optimizer.step()


# 用训练好的模型预测
im = Image.open(&#39;dog.jpg&#39;)
input_tensor = transform(im).unsqueeze(0)
cnn(input_tensor.to(device)).argmax()

输出：tensor(5, device=&#39;cuda:0&#39;)

预测类别是“狗”。

是运气好吗？只训练了10 epochs，最后显示的loss 1.8左右
</div>2021-11-12</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q3auHgzwzM7uYZvwhrLHsJICstGXaOvUNZnyq0aO7gF0OLicMyZAZFnRiaDyvM1lGxnEDP2VUMV3m6UjiazMmSNGQ/132" width="30px"><span>Geek_8cfc4c</span> 👍（0） 💬（3）<div>对于本节课有几个问题不太明白还望赐教 （pytorch版本&#39;1.10.0&#39;）

1. 模型训练那 部分
`y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(0)`
unsqueeze的意义是啥呢？ (y_train本来size是Size([30])正好和x_train匹配)
这样做反而得到了一个warning
`
UserWarning: Using a target size (torch.Size([1, 30])) that is different to the input size (torch.Size([30])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
`

2. 再说微调 部分
一开始直接下载的AlexNet模型(alexnet-owt-7be5be79.pth), 预测结果是151
后来使用于文中一样的版本才变成263

因为torchvision的版本不同，预训练的模型结果就有了差异么？
如果是的话我看到的标签列表中151是吉娃娃（Chihuahua）……

谢谢
</div>2021-11-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/b8/6e/0aae08d6.jpg" width="30px"><span>VincentQ</span> 👍（0） 💬（0）<div>pretrained = True不能用了

from torchvision.models import AlexNet_Weights

alexnet = models.alexnet(weights=AlexNet_Weights.IMAGENET1K_V1)</div>2024-06-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/81/e9/d131dd81.jpg" width="30px"><span>Mamba</span> 👍（0） 💬（0）<div>固定整个网络的参数，只训练最后的全连接层, 在读取完预训练模型之后，将参数全部锁死,然后新增一个全连接层

### 修改网络结构
# 导入预训练的AlexNet模型
alexnet = models.alexnet(pretrained=True)
# 冻结所有层
for param in alexnet.features.parameters():
    param.requires_grad = False
# 获取AlexNet最后一个全连接层的输出特征数
input_features = alexnet.classifier[-1].out_features

# 添加一个新的全连接层，用于10分类任务
alexnet.classifier.add_module(&#39;fc&#39;, nn.Linear(input_features, 10))

# 打印模型结构，确认更改
print(alexnet)</div>2024-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg" width="30px"><span>ifelse</span> 👍（0） 💬（0）<div>学习打卡</div>2023-12-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/5d/24/ccecf795.jpg" width="30px"><span>benny</span> 👍（0） 💬（0）<div>这个课程有github地址吗？</div>2023-08-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/02/2a/90e38b94.jpg" width="30px"><span>John(易筋)</span> 👍（0） 💬（2）<div>&#47;&#47; 这里需要 import DataLoader
from torch.utils.data import Dataset, DataLoader

cifar10_dataset = torchvision.datasets.CIFAR10(root=&#39;.&#47;data&#47;&#39;,
                                              train=False,
                                              transform=transforms.ToTensor(),
                                              target_transform=None,
                                              download=True)
tensor_dataloader = DataLoader(dataset=cifar10_dataset,                               
                               batch_size=32)
data_iter = iter(tensor_dataloader)
img_tensor, label_tensor = data_iter.next()
print(img_tensor.shape)
grid_tensor = torchvision.utils.make_grid(img_tensor, nrow=16, padding=2)
grid_img = transforms.ToPILImage()(grid_tensor)
display(grid_img)
</div>2022-08-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/f2/23/bb13b3ed.jpg" width="30px"><span>刘利</span> 👍（0） 💬（0）<div>hi，老师，微调的时候，</div>2022-05-03</li><br/>
</ul>