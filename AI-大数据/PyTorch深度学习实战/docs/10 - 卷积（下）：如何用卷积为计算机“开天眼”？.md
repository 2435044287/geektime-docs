你好，我是方远。

经过上一节课的学习，相信你已经对标准的卷积计算有所了解。虽然标准卷积基本上可以作为主力Carry全场，但是人们还是基于标准卷积，提出了一些其它的卷积方式，这些卷积方式在应对不同问题时能够发挥不同的作用，这里我为你列举了一些。

![图片](https://static001.geekbang.org/resource/image/8a/4b/8a3f6bba138f36c1b31e52aeb3e2604b.jpg?wh=1920x977)

在上一节课中，我们学习了conv2d的in\_channels、out\_channels、kernel\_size、stride、padding与bias参数。

其中，PyTorch中conv2d中剩余的两个参数，它们分别对应着两种不同的卷积，分别是深度可分离卷积和空洞卷积，让我们一起来看看。

## 深度可分离卷积（Depthwise Separable Convolution）

我们首先看看依托groups参数实现的深度可分离卷积。

随着深度学习技术的不断发展，许多很深、很宽的网络模型被提出，例如，VGG、ResNet、SENet、DenseNet等，这些网络利用其复杂的结构，可以更加精确地提取出有用的信息。同时也伴随着硬件算力的不断增强，可以将这些复杂的模型直接部署在服务器端，在工业中可以落地的项目中都取得了非常优秀的效果。

但这些模型具有一个通病，就是速度较慢、参数量大，这两个问题使得这些模型无法被直接部署到移动终端上。而移动端的各种应用无疑是当今最火热的一个市场，这种情况下这些深而宽的复杂网络模型就不适用了。
<div><strong>精选留言（21）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/27/fc/ca/c1b8d9ca.jpg" width="30px"><span>IUniverse</span> 👍（5） 💬（2）<div>x=torch.rand((3,128,128)).unsqueeze(0)
print(x.shape)

in_channel_DW=x.shape[1]
out_channel_DW=x.shape[1]
kernel_size=3
DW=nn.Conv2d(in_channel_DW,out_channel_DW,kernel_size,groups=in_channel_DW)

in_channels_PW=out_channel_DW
out_channels_PW=10
PW=nn.Conv2d(in_channels_PW,out_channels_PW,1)
output=PW(DW(x))
print(output.shape)</div>2021-11-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/af/fa/5714677b.jpg" width="30px"><span>sonald</span> 👍（3） 💬（2）<div>我觉得没有解释清楚“它最大的优点就是不需要缩小特征图，也可以获得更大的感受野。”，感受野是增大了，特征图没缩小吗？</div>2022-02-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/5d/3f/ad1fed4a.jpg" width="30px"><span>黑暗骑士</span> 👍（2） 💬（2）<div>老师好，请问为什么in_channel_DW=x.shape[1]，x.shape[0]才是通道啊？</div>2022-02-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2e/e3/c4/68bf7e23.jpg" width="30px"><span>醒狮</span> 👍（1） 💬（1）<div>老师，我另外有一个问题没想明白，就是这个“groups”到底是怎么一回事？groups的定义是需要out和in_channels都能整除groups吗？我的理解是把输入和输出的通道除groups之后进行配对，各自组成小的基本卷积（比如除完之后又2组in，就将这两组in当做两个通道，让后out处完之后有3组，就当做一个卷积核的3个通道，再进行基本卷积）让后再把这groups这么多组得出的结果加和在一起组成新的单独的一个输出特征图，大概是这个意思吗？谢谢老师，您辛苦了！</div>2022-08-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/c2/df/e619d023.jpg" width="30px"><span>硕掌柜</span> 👍（0） 💬（1）<div>老师您好，当我从原理上知道一个Conv2d的计算量是m * n * k * k * h&#39; * w&#39; 后，pytorch是否提供了函数可以查看，当给定一个batch数据时 &#47; batchsize = 1时的计算量（理解为运算的次数）呢</div>2022-11-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/02/2a/90e38b94.jpg" width="30px"><span>John(易筋)</span> 👍（0） 💬（1）<div>import torch
import torch.nn as nn
# 生成一个三通道的128x128特征图
x = torch.rand((3,128,128)).unsqueeze(0)
print(x.shape)

# 请注意DW中，输入特征通道数与输出通道数是一样的
in_channels_dw = x.shape[1]
out_channels_dw = x.shape[1]

# 一般来讲DW卷积的kernel size为3
kernel_size = 3
stride = 1

# DW卷积groups参数与输入通道数一样
dw = nn.Conv2d(in_channels_dw, out_channels_dw, kernel_size, stride, groups=in_channels_dw)

in_channels_pw = out_channels_dw
out_channels_pw = 10

pw = nn.Conv2d(in_channels_pw, out_channels_pw, kernel_size_pw, stride)
output = pw(dw(x))
print(output.shape)

# Output
torch.Size([1, 3, 128, 128])
torch.Size([1, 10, 126, 126])</div>2022-08-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2e/e3/c4/68bf7e23.jpg" width="30px"><span>醒狮</span> 👍（0） 💬（1）<div>import torch
import torch.nn as nn
a = torch.rand(3,128,128)       # 注：torch.tensor的分类是（batch_size,channels，w，h）
a = torch.unsqueeze(a,0)
print(a.shape)

dw = nn.Conv2d(3,3,(3,3),stride=(3,3),groups=3)
dw = dw(a)
pw = nn.Conv2d(3,10,(1,1))
b = pw(dw)
print(b)

老师好，请您检查一下，谢谢您！</div>2022-08-04</li><br/><li><img src="" width="30px"><span>Geek_622508</span> 👍（0） 💬（2）<div>请问，您这种动态图是用什么画的呢？</div>2022-06-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/8c/5c/3f164f66.jpg" width="30px"><span>亚林</span> 👍（0） 💬（1）<div>import torch
import torch.nn as nn
# 生成一个三通道的128x128特征图
x = torch.rand((3, 128, 128)).unsqueeze(0)
print(x.shape)

# 请注意DW中，输入特征通道数与输出通道数是一样的
in_channels_dw = x.shape[1]
out_channels_dw = x.shape[1]
# 一般来讲DW卷积的kernel size为3
kernel_size = 3
stride = 1
# DW卷积groups参数与输入通道数一样
dw = nn.Conv2d(in_channels_dw, out_channels_dw, kernel_size, stride, groups=in_channels_dw)

in_channels_pw = out_channels_dw
out_channels_pw = 10
kernel_size_pw = 1
pw = nn.Conv2d(in_channels_pw, out_channels_pw, kernel_size_pw, stride)
out = pw(dw(x))
print(out.shape)</div>2022-05-17</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/ajNVdqHZLLDm5eHbw1fuicJiaXercgBI48O0Idt2mHUElmZyBM4o119NkndU1SNpsv8rZzKFibj8z1FibFAdNEO3zw/132" width="30px"><span>zhangting</span> 👍（0） 💬（1）<div>请问下，感受野=输入特征图中蓝色加橘黄色部分，但是为啥不计算原图中右边和下边的白色格子？然后就是原图是6X6不是5X5</div>2022-05-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2d/0c/1f/fcc777e1.jpg" width="30px"><span>乐呵的hehe</span> 👍（0） 💬（1）<div>import torch
import torch.nn


in_feature = torch.randn([8,3,128,128])
print(in_feature.shape)
model = torch.nn.Sequential(torch.nn.Conv2d(3, 3, (3,3), stride=1, padding=1, bias=True, groups=3), torch.nn.Conv2d(3, 10, (1,1), stride=1, padding=0, bias=True))
out_feature = model(in_feature)
print(out_feature.shape)</div>2022-04-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2d/0c/1f/fcc777e1.jpg" width="30px"><span>乐呵的hehe</span> 👍（0） 💬（1）<div>import torch
import torch.nn


in_feature = torch.randn([10,3,128,128])
print(in_feature.shape)
conv2d = torch.nn.Conv2d(3, 3, (3,3), stride=1, padding=1, bias=True, groups=3)
out_feature = conv2d(in_feature)
print(out_feature.shape)</div>2022-04-28</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/8MZhBkm8kAJGVbhOr64n0Dd2Q6wDpjKwDcQyibN91qlWQRGDeeIuAGe7FzaBrcPB58uibJaF04bHyvIiadWHgG6Ig/132" width="30px"><span>时光不负有心人</span> 👍（0） 💬（2）<div>感受野的概念还不是太明白，为啥说原图是 5x5 的图像？不是6x6吗？</div>2022-02-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/27/12/55/f8d607c6.jpg" width="30px"><span>薛定谔的喵~</span> 👍（0） 💬（2）<div>请问下老师，为啥要对x进行unsqueeze(0)呢？</div>2021-12-23</li><br/><li><img src="" width="30px"><span>clee</span> 👍（0） 💬（1）<div>x = torch.rand((3, 128, 128)).unsqueeze(0)
in_channels_dw = x.shape[1]
out_channels_dw = x.shape[1]
kernel_size = 3
stride = 1
dw = nn.Conv2d(in_channels_dw, out_channels_dw, kernel_size, stride, groups=in_channels_dw)
in_channels_pw = out_channels_dw
out_channels_pw = 10
kernel_size_pw = 3
pw = nn.Conv2d(in_channels_pw, out_channels_pw, kernel_size_pw, stride)
out = pw(dw(x))
print(out.shape)</div>2021-11-08</li><br/><li><img src="" width="30px"><span>Geek_a95f0e</span> 👍（0） 💬（1）<div>import torch
input_feat=torch.randint(0,100,(1,3,128,128),dtype=torch.float32)
dw=torch.nn.Conv2d(3,3,3,groups=3)
pw=torch.nn.Conv2d(3,10,1)
result=pw(dw(input_feat))
print(result)</div>2021-11-04</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/j24oyxHcpB5AMR9pMO6fITqnOFVOncnk2T1vdu1rYLfq1cN6Sj7xVrBVbCvHXUad2MpfyBcE4neBguxmjIxyiaQ/132" width="30px"><span>vcjmhg</span> 👍（0） 💬（1）<div>import torch
import torch.nn as nn

# 生成一个三通道的128x128特征图
x = torch.rand((3, 128, 128)).unsqueeze(0)
print(x.shape)
# 输出：
torch.Size([1, 3, 5, 5])
# 请注意DW中，输入特征通道数与输出通道数是一样的
in_channels_dw = x.shape[1]

out_channels_dw = x.shape[1]
# 设置size为3
kernel_size = 3
stride = 1
# DW卷积groups参数与输入通道数一样
dw = nn.Conv2d(in_channels_dw, out_channels_dw, kernel_size, stride, groups=in_channels_dw)

in_channels_pw = out_channels_dw
# 卷积和个数为10
out_channels_pw = 10
kernel_size_pw = 1
pw = nn.Conv2d(in_channels_pw, out_channels_pw, kernel_size_pw, stride)
out = pw(dw(x))
print(out.shape)</div>2021-11-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2b/e0/ca/adfaa551.jpg" width="30px"><span>孙新</span> 👍（10） 💬（0）<div>感受野那个地方我直接看懵了，去其他地方查了才明白。如果不知道概念直接看那个图片示例的文字说明稍微有点不好理解。个人觉得那块的表达可以优化一下。我想了一下问题出在哪，因为前面没有明确说感受野是啥。
个人感觉前边可以加一句通俗解释：
感受野指的是，卷积输出时一个单元在输入特征图中代表的单元数。
第一层卷积输出的一个单元就是原始特征图的3*3单元信息，感受野为3，
第二层卷积输出的一个单元就是原始特征图的5*5单元信息，感受野为5。

</div>2022-09-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/b8/6e/0aae08d6.jpg" width="30px"><span>VincentQ</span> 👍（0） 💬（0）<div>dilation 扩张率？ </div>2024-06-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg" width="30px"><span>ifelse</span> 👍（0） 💬（0）<div>学习打卡</div>2023-11-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/cd/4d/b0cd5bca.jpg" width="30px"><span>没有十万伏特的皮卡丘👿</span> 👍（0） 💬（0）<div>import torch
import torch.nn as nn
input_features = torch.randn(3,128,128),unsqueeze(0)
kernel_size_dw = 3
in_channels_dw = input_features.shape[1]
out_channels_dw = input_features.shape[1]l
dw = nn.Conv2d(in_channels_dw,out_channels_dw,kernel_size_dw,stride, groups=in_channels_dw)
in_channels_pw = in_channels_dw
out_channels_pw = 10
kernel_size_pw = 1
stride = 1
pw = nn.Conv2d(in_channels_pw,out_channels_pw,kernel_size_pw,stride)
out_features = pw(dw(input_feaures))
print(out_features.shape)</div>2021-12-05</li><br/>
</ul>