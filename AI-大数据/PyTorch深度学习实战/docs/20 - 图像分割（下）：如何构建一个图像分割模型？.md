你好，我是方远。

在上一节课中，我们掌握了图像分割的理论知识，你是不是已经迫不及待要上手体验一下，找找手感了呢？

今天我们就从头开始，来完成一个图像分割项目。项目的内容是，对图片中的小猫进行语义分割。为了实现这个项目，我会引入一个简单但实用的网络结构：UNet。通过这节课的学习，你不但能再次体验一下完整机器学习的模型实现过程，还能实际训练一个语义分割模型。

课程代码你可以从[这里](https://github.com/syuu1987/geekTime-semantic-segmentation/tree/main)下载。

## 数据部分

我们还是从机器学习开发三件套：数据、训练、评估说起。首先是数据准备部分，我们先对训练数据进行标记，然后完成数据读取工作。

### 分割图像的标记

之前也提到过，图像分割的准备相比图像分类的准备更加复杂。那我们如何标记语义分割所需要的图片呢？在图像分割中，我们使用的每张图片都要有一张与之对应的Mask，如下所示：

![图片](https://static001.geekbang.org/resource/image/c2/db/c258c4f2ffd1f819c662aa1e9f6a8cdb.jpg?wh=1024x640)  
![图片](https://static001.geekbang.org/resource/image/1a/a0/1a35623ceccb0750cd8058568d847fa0.png?wh=1024x640)

上节课我们说过，Mask就是含有像素类别的特征图。结合这里的示例图片，我们可以看到，Mask就是原图所对应的一张图片，它的每个位置都记录着原图每个位置对应的像素类别。对于Mask的标记，我们需要使用到Labelme工具。

标记的方法一共包括七步，我们挨个看一下。

第一步，下载安装[Labelme](https://github.com/wkentaro/labelme)。我们按照Github中的安装方式进行安装即可。如果安装比较慢的话，你可以使用国内的镜像（例如清华的）进行安装。
<div><strong>精选留言（23）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/2b/a5/82/183bc76c.jpg" width="30px"><span>克bug体质</span> 👍（5） 💬（4）<div>老师你好，Loss也要放到放到gpu后也会报和之前一样的错误：【
Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument weight in method wrapper__cudnn_batch_norm)
  File &quot;D:\U-Net\unet.py&quot;, line 25, in forward
    x = nn.BatchNorm2d(num_features=self.features)(x)
  File &quot;D:\U-Net\unet.py&quot;, line 67, in forward
    conv_encoder_1_1 = self.conv_encoder_1(x)
  File &quot;D:\U-Net\train.py&quot;, line 50, in main
    y_pred = unet(x)
  File &quot;D:\U-Net\train.py&quot;, line 136, in &lt;module&gt;
    main(args)
】
我尝试在unet.py文件中的创建class UNet中self.conv_encoder_1 = Block(in_channels, features)改为：self.conv_encoder_1 = Block(in_channels, features).to(device)后也没解决这个问题，会报一样的错。</div>2022-02-14</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/j24oyxHcpB5AMR9pMO6fITqnOFVOncnk2T1vdu1rYLfq1cN6Sj7xVrBVbCvHXUad2MpfyBcE4neBguxmjIxyiaQ/132" width="30px"><span>vcjmhg</span> 👍（3） 💬（2）<div>老师您好，我自己有尝试复现deeplab v3+这个比较主流的语义分割网络，然后发现针对一些尺寸较大的目标其分割效果还是比较不错的，但是对小的目标分割效果很差，甚至好多时候都分割不到，请问针对这种小目标，除了在数据集上做处理外，还有哪些好的处理或者优化方法呢？</div>2021-11-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2d/7b/1e/8bb7c7fe.jpg" width="30px"><span>..................</span> 👍（2） 💬（1）<div>真的很棒，我要亲手操作一遍</div>2022-05-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/53/db/244953c6.jpg" width="30px"><span>蓝色天空  好萌啊</span> 👍（1） 💬（1）<div>老师你好，请问有这节课的完整代码地址吗？</div>2022-01-21</li><br/><li><img src="" width="30px"><span>Geek_a95f0e</span> 👍（1） 💬（2）<div>方老师，可不可以解释一下自定义类中 super().__init__() 和super(class_name,self).__init__() 有什么区别？</div>2021-12-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/35/f3/aa70c17a.jpg" width="30px"><span>Geek_niu</span> 👍（0） 💬（1）<div>老师你好，请问数据准备中，标记好的图片有什么作用呢，谢谢</div>2024-03-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/d7/45/d1621188.jpg" width="30px"><span>学渣汪在央企打怪升级</span> 👍（0） 💬（2）<div>老师你好，非常感谢老师的耐心，我成功的跑通了自己的一个实例。但目前遇到如下问题，麻烦老师有空的时候能提点一下。
使用unet训练，还是老师的代码，差不多是40 epoch之后，预测出来的图像分割，预测对的点的概率非常集中，大概都在[1,...,0.99999535 0.9999949  0.9999943 0.9999933  0.999992   0.9999907  0.9999889  0.99998796 0.99998724 0.9999856  0.99998343 0.99998116 0.99997723 0.99997675 0.9999764 0.9999703  0.9999577  0.9999535  0.9999486  0.9999453  0.999944 0.99992955 0.99992025 0.9999181  0.9999089  0.9999058  0.9998952 0.99984705 0.9998202  0.9996326  0.9996008  0.9995078  0.99922884 0.9967386  0.99539775 0.995391   0.991197   0.9906724  0.9892915 0.9892553  0.9782649  0.96968466 0.95937544 0.9416338  0.93462884
 0.91682875 0.8949944  0.87671226 0.75603426 0.7475551  0.7284518 0.6420492  0.62891126 0.5325708  0.52544403, ... ]
请教一下，这样是不是过拟合了。有没有什么好的方法可以使得预测概率有阈值可选？丰富样本吗？麻烦老师了。</div>2022-11-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/d7/45/d1621188.jpg" width="30px"><span>学渣汪在央企打怪升级</span> 👍（0） 💬（1）<div>方老师，请教一下：
如果我不是对图片进行语义分割，而是对类似视频，比如（400,384,288）的数据立方体进行语义分割，还可以使用unet吗？如果使用的话，这个示例里的通道数是从3-&gt;512-&gt;32-&gt;1，那么这种400通道的该怎么处理？
谢谢。</div>2022-10-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/c5/86/1134c2f1.jpg" width="30px"><span>gavin</span> 👍（0） 💬（1）<div>方老师，请问一下如果是多分类，特征图输出要怎么弄？</div>2022-09-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/02/2a/90e38b94.jpg" width="30px"><span>John(易筋)</span> 👍（0） 💬（1）<div>predict_single.py 代码改了一下文件的相对路径可以跑通，发现output.jpg 大小为256x256. 原图微1024x640. 请教方老师，为啥语义分割出来的图片不是原始图片的等比缩小呢？ 谢谢
```
import torch
import numpy as np

from PIL import Image

img_size = (256, 256)
unet = torch.load(&#39;.&#47;ckpts&#47;unet_epoch_51.pth&#39;)

unet.eval()


im = np.asarray(Image.open(&#39;.&#47;data&#47;JPEGImages&#47;6.jpg&#39;).resize(img_size))

im = im &#47; 255.
im = im.transpose(2, 0, 1)
im = im[np.newaxis, :, :]
im = im.astype(&#39;float32&#39;)
output = unet(torch.from_numpy(im)).detach().numpy()

output = np.squeeze(output)
output = np.where(output&gt;0.5, 150, 0).astype(np.uint8)
print(output.shape, type(output))
im = Image.fromarray(output)
im.save(&#39;.&#47;output.jpg&#39;)
```</div>2022-08-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/3f/4a/b1c9e5e3.jpg" width="30px"><span>万化8af10b</span> 👍（0） 💬（2）<div>请问&#47;weights&#47;unet_epoch_51.Pth找不到，谢谢</div>2022-07-03</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/ajNVdqHZLLDm5eHbw1fuicJiaXercgBI48O0Idt2mHUElmZyBM4o119NkndU1SNpsv8rZzKFibj8z1FibFAdNEO3zw/132" width="30px"><span>zhangting</span> 👍（0） 💬（1）<div>老师，这个猫的数据集可以分享一下么？</div>2022-05-30</li><br/><li><img src="" width="30px"><span>Geek_709f77</span> 👍（0） 💬（1）<div>lebelme那个github上的zip包下载后怎么解压的时候报文件已损坏啊？</div>2022-04-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2d/0b/e3/4b9cac41.jpg" width="30px"><span>Cougar</span> 👍（0） 💬（1）<div>self.image_slices.append(im &#47; 255.)
请问这里为什么要除以一个255呢</div>2022-03-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/56/f4/6c57f148.jpg" width="30px"><span>dndidoflbup</span> 👍（0） 💬（1）<div>老师好，对于输入图片的尺寸有要求么，我自己用900*900的学习，报错如下：

conv_decoder_3_2 = torch.cat((conv_decoder_3_1, conv_encoder_3_1), dim=1)
RuntimeError: Sizes of tensors must match except in dimension 1. Expected size 224 but got size 225 for tensor number 1 in the list.</div>2022-01-10</li><br/><li><img src="" width="30px"><span>Geek_a95f0e</span> 👍（0） 💬（2）<div>方老师，经过试验，本课自定义类的dataset，在实例化时，transform参数是不起作用的，请问这是什么原因呢？如果要让自定义类的dataset也能对transform参数起作用，该怎么操作呢？</div>2021-12-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/cd/b7/6efa2c68.jpg" width="30px"><span>李雄</span> 👍（0） 💬（1）<div>老师您好，首先感谢老师的简洁讲述，但我仍有几个问题想请教：
（1）关于使用Unet能否使用预训练模型？或者说是否有预训练模型？
（2）Unet的训练数据量最少大致为多少呢？能否给个具体的参考？
（3）老师能否推荐一个目标检测数据标注工具呢？我最近要标注一个自己的目标检测数据集？
感谢老师！！！</div>2021-12-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/b5/4c/6b9528f8.jpg" width="30px"><span>zhaobk</span> 👍（0） 💬（2）<div>老师您好。关于class Block(nn.Module): class UNet(nn.Module):这两个类，我有点不明白，为什么要这么实现？是根据论文来搭建的吗？如果需要实现其他算法，也是要根据相关论文来自己搭建这种结构吗？</div>2021-11-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/e3/d7/d7b3505f.jpg" width="30px"><span>官</span> 👍（0） 💬（1）<div>感觉mIoU也可以用在语义分割模型里，不知道有没有这种可能</div>2021-11-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/ea/1d/1954451e.jpg" width="30px"><span>十里秋波不起雨</span> 👍（0） 💬（1）<div>收获颇丰</div>2021-11-26</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epJHlrZ1pcs2sxHpxW6EaDmUq8sMD85vm3hskWVn2LmlcUI84tARViam4vAuS0uVibpFq1uRAABff6g/132" width="30px"><span>hbuelgr</span> 👍（0） 💬（1）<div>收获很多，每天听听。</div>2021-11-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/8c/5c/3f164f66.jpg" width="30px"><span>亚林</span> 👍（1） 💬（0）<div>照着抄，抄出来了</div>2022-05-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/4c/b4/1b079b47.jpg" width="30px"><span>文子</span> 👍（0） 💬（0）<div>您好，从unet结构图中看一个块内特征图的尺寸在变小，如第一块，572-570-568逐层变小，但是代码中padding确设置为same，没明白什么意识，请您解惑。</div>2024-06-22</li><br/>
</ul>