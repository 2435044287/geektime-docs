> 本门课程为精品小课，不标配音频

你好，我是王吕。

在之前的课程中，我们讨论了极客时间小助手这类聊天机器人的实现，用户可以和 LLM 对话互动，通过一问一答，获取想要的知识。不过在真实使用场景中，我们的对话都是连续的，我们也期望 LLM 能知道我们刚才说了什么。今天这节课，我就来帮你实现 AI 多轮对话的功能，并且讨论一下如何实现给每个用户增加记忆的功能。

## 什么是 LLM 的记忆？

记忆简单来说就是存储，把相关数据存储下来供之后使用，这就是 LLM 的记忆。可是，随着时间的增加，记忆数据越来越大，远远超过 LLM 对话的 token 长度了，这该怎么办？

我们首先想到的就是裁剪，只保留最近的数据，但是这样就会丢失很多的重要信息。最好的解决办法是把记忆抽象为两种类型：**短期记忆和长期记忆**，短期记忆是精确的数据，长期记忆是模糊的数据，只记录关键信息。

在这个方法的指导下，针对对话场景，我们可以设计下边这个结构体，作为传递给 LLM 的消息。

![图片](https://static001.geekbang.org/resource/image/31/05/317f23bdb71264bbaa8de6a07d64c905.jpeg?wh=1920x1080)

短期记忆很简单，我们直接把对话记录的最近 N 条作为短期记忆，也就是对话上下文，这保证了用户在对话过程中聊天内容的连续性。长期记忆是把之前的历史消息进行总结提炼，只记录关键信息，类似于背景信息，再加上用户最新的对话，这三部分就组成了一个拥有记忆的 LLM，可以实现多轮对话的能力。
<div><strong>精选留言（1）</strong></div><ul>
<li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/MpKow66ExJ0y3G471ql99hxqcdQ7RF0M7XBnN38uIvhK3bIxadn3W8KPnlbExTBgmAMhAsRnfkC0TsqKrNicnGg/132" width="30px"><span>乔克哥哥</span> 👍（0） 💬（0）<div>可以实现一个银翼杀手2049里的电子女友</div>2025-01-18</li><br/>
</ul>