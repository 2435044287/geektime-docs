今天来讲一个非常轻松的话题，这个话题看似和推荐系统没什么关系，但肯定有用，只是在别的推荐系统相关话题里都没人会提。

## 一些场景

还记得前面讲到的用户画像吗？想象一个场景：你经过辛辛苦苦抓数据，清洗数据，收集用户行为，目的就是给用户计算兴趣标签。

这时候你可能会遇到一个两难的问题：如果给用户计算出兴趣标签的权重了，那应该保留多少标签呢？

保留太多的话，每次召回候选集时，计算复杂度可不低，只保留少部分吧，那真是手心手背都是肉，生怕丢弃的标签才是用户的真爱。

怎么办？这时候，你需要的一个简单的加权采样算法，每次召回时并不使用全部用户标签，而是按照权重采样一部分标签来使用，这样做的好处当然很明显：

1. 大大减少召回时的计算复杂度；
2. 可以保留更多的用户标签；
3. 每次召回计算时还能有所变化；
4. 虽然有变化，但是依然受标签的权重相对大小约束。

加权采样的应用不只这一个地方，比如在热门排行榜展示时，也可以用加权采样，而不仅仅按照排行榜分数顺序展示，采用加权采样的展示方法，会让排行榜每次刷新都略有变化，人民群众也会更加喜闻乐见。

下面介绍几种常用的加权采样算法及其原理，供你日常随手拿来使用。

## 加权采样

加权采样有两种情况，一种是能够已知全部样本的个数。这需要遍历整个样本，比如说用户标签采样输出，那么每次采样时仍然需要遍历所有的标签，来依次决定每一个标签输出的概率。

另一种是不知道总量样本是多大，或者总量很大，以至于你不愿意全部遍历之后再输出采样结果，这样的数据就是数据流，对应的就是流采样。
<div><strong>精选留言（11）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/8c/54/deb19880.jpg" width="30px"><span>slvher</span> 👍（4） 💬（0）<div>加权采样算法 Weighted Random Sampling Without Replacement，可简写为WRS

本文给出的算法出自 Pavlos S. Efraimidis 论文：
https:&#47;&#47;utopia.duth.gr&#47;~pefraimi&#47;research&#47;data&#47;2007EncOfAlg.pdf

也可通过蓄水池采样算法的wikipedia条目了解：
https:&#47;&#47;en.wikipedia.org&#47;wiki&#47;Reservoir_sampling
</div>2018-10-02</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKmErICiaf9SDOYSWxg5I9cahYWIniaxQ5rqC9m2Ee4gxF75DNh1MbD5XOGhICnv9jeNjhQiboXRjiaFA/132" width="30px"><span>felixdae</span> 👍（1） 💬（0）<div>第一个例子中k其实是1对吧，如果k是2或者3模拟出来的结果还会保持与权重一样的比例关系吗？</div>2018-07-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（1） 💬（0）<div>负权重的例子我其实还是不太理解的。原始的WRS算法就是要求权重是非负数。我能想到的是按权重的绝对值算采样分数，然后负的得出一个最差排名，正的得出一个最好排名。</div>2018-04-25</li><br/><li><img src="" width="30px"><span>行行行</span> 👍（1） 💬（0）<div>s=r^1&#47;w的原理是什么呢老师，或者有什么参考资料，或者这个算法叫什么名字。谢谢老师</div>2018-04-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/39/0d/80ae66d7.jpg" width="30px"><span>zzz</span> 👍（0） 💬（0）<div>蓄水池采样中大于k的替换概率应该为1&#47;i（表示第几个样本），不是k&#47;n</div>2021-12-29</li><br/><li><img src="" width="30px"><span>Geek_de6c32</span> 👍（0） 💬（0）<div>理解采样方法一中w和R正相关，但是经过非线性变形后，采样结果和w很相近，这点上有点不理解</div>2021-08-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/5c/fe/43cdc2c3.jpg" width="30px"><span>光彩照人</span> 👍（0） 💬（0）<div>指数分布这个，是不是应该取出随机数最小的k个进行采样呢，因为越小，说明时间间隔越短，说明权重越大呢。</div>2019-07-23</li><br/><li><img src="" width="30px"><span>miaomiaomiao</span> 👍（0） 💬（0）<div>请问，在推荐算法召回阶段，蓄水池采样权重是什么？是本身推荐物品与该用户的匹配概率吗？ 
模型融合阶段的权重又是什么？这个时候各个召回模块的推荐的物品的评价标准并不一致</div>2019-06-12</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/qRjoqWIGC6tpmKZBGTxjQKC9cbz9XLhw2nF1c74R4icFOYOdVO4iaeQEQDqEvmbicxn6HEc4SU8kpkwVaO5nABMug/132" width="30px"><span>shangqiu86</span> 👍（0） 💬（0）<div>指数分布采样的时候，随机数选取应该在（1 - 5）之间，当大于5之后，lambd = 0.1得到的值将远远大于lambd = 0.4和0.5 ，这样若随机数选取在（1-10）之间得到的数据并不满足权重的关系，我的实验结果是这样的，老师您说对吗？</div>2019-05-06</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKmErICiaf9SDOYSWxg5I9cahYWIniaxQ5rqC9m2Ee4gxF75DNh1MbD5XOGhICnv9jeNjhQiboXRjiaFA/132" width="30px"><span>felixdae</span> 👍（0） 💬（0）<div>把权重除以权重之和得到标签上的离散分布，不是就可以直接用来采样了么，采样频率也跟权重成正比</div>2018-06-04</li><br/><li><img src="" width="30px"><span>cjalchange</span> 👍（0） 💬（1）<div>无刀老师，请问指数分布采样公式中的x是取的啥值呀</div>2018-05-24</li><br/>
</ul>