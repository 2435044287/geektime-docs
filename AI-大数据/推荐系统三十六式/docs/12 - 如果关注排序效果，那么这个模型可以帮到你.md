矩阵分解在推荐系统中的地位非常崇高，恐怕本专栏介绍的其他算法模型都不能轻易地撼动它。

它既有协同过滤的血统，又有机器学习的基因，可以说是非常优秀了；但即便如此，传统的矩阵分解无论是在处理显式反馈，还是处理隐式反馈都让人颇有微词，这一点是为什么呢？

## 矩阵分解的不足

前面我讲过的两种矩阵分解，本质上都是在预测用户对一个物品的偏好程度，哪怕不是预测评分， 只是预测隐式反馈，也难逃这个事实，因为算法展现出来的目标函数就出卖了这一切。

得到这样的矩阵分解结果后，常常在实际使用时，又是用这个预测结果来排序。所以，从业者们口口声声宣称想要模型的预测误差最小化，结果绕了一大圈最后还是只想要一个好点的排序，让人不禁感叹：人心总是难测。

这种针对单个用户对单个物品的偏好程度进行预测，得到结果后再排序的问题，在排序学习中的行话叫做point-wise，其中point意思就是：只单独考虑每个物品，每个物品像是空间中孤立的点一样。

与之相对的，还有直接预测物品两两之间相对顺序的问题，就叫做pair-wise，pair，顾名思义就是成对成双，也许恐怕这类模型对单身的人士不是很友好。

前面讲的矩阵分解都属于point-wise模型。这类模型的尴尬是：只能收集到正样本，没有负样本，于是认为缺失值就是负样本，再以预测误差为评判标准去使劲逼近这些样本。逼近正样本没问题，但是同时逼近的负样本只是缺失值而已，还不知道真正呈现在用户面前，到底是不喜欢还是喜欢呢？

虽然这些模型采取了一些措施来规避这个问题，比如负样本采样，但是尴尬还是存在的，为了排序而绕路也是事实。

既然如此，能不能直面问题，采用pair-wise来看待矩阵分解呢？当然能，不然我也不会写出这一篇专栏文章了。

其实人在面对选择时，总是倾向矮子中选高个子，而不是真的在意身高到底是不是180，因此，更直接的推荐模型应该是：能够较好地为用户排列出更好的物品相对顺序，而非更精确的评分。

这个问题已经有可爱的从业者们提出了方法，就是本文的主角：贝叶斯个性化排序，简称BPR模型。下面，我就带你一探这个模型的究竟。

## 贝叶斯个性化排序

在前面的专栏文章中，有一个词叫做均方根误差，被我提过多次，用于评价模型预测精准程度的。那么现在要关注的是相对排序，用什么指标比较好呢？答案是AUC，AUC全称是Area Under Curve，意思是曲线下的面积，这里的曲线就是 ROC 曲线。

### AUC

但是，我不打算继续解释什么是 ROC 曲线了，那是它的原始定义，而我想跟你悄悄说的是另一件事，AUC这个值在数学上等价于：模型把关心的那一类样本排在其他样本前面的概率。最大是1，完美结果，而0.5就是随机排列，0就是完美地全部排错。

听到这个等价的AUC解释，你是不是眼前一亮？这个非常适合用来评价模型的排序效果，比如说，得到一个推荐模型后，按照它计算的分数，能不能把用户真正想消费的物品排在前面？这在模型上线前是可以用日志完全计算出来的。

AUC怎么计算呢？一般步骤如下。

1. 用模型给样本计算推荐分数，比如样本都是用户和物品这样一对一对的，同时还包含了有无反馈的标识；
2. 得到打过分的样本，每条样本保留两个信息，第一个是分数，第二个是0或者1，1表示用户消费过，是正样本，0表示没有，是负样本；
3. 按照分数对样本重新排序，降序排列；
4. 给每一个样本赋一个排序值，第一位 r1 = n，第二位 r2 = n-1，以此类推；其中要注意，如果几个样本分数一样，需要将其排序值调整为他们的平均值；
5. 最终按照下面这个公式计算就可以得到AUC值。

我在文稿中放了这个公式，你可以点击查看。

$$AUC = \\frac{\\sum\_{i\\in(样本)}{r\_{i}} - \\frac{M\\times{(M+1)}}{2}}{M\\times{N}}$$

这个公式看上去复杂，其实很简单，由两部分构成：

第一部分： 分母是所有我们关心的那类样本，也就是正样本，有M个，以及其他样本有N个，这两类样本相对排序总共的组合可能性，是M x N；

第二部分： 分子也不复杂，原本是这样算的：第一名的排序值是r1，它在排序上不但比过了所有的负样本，而且比过了自己以外的正样本。

但后者是自己人，所以组合数要排除，于是就有n - M种组合，以此类推，排序值为rM的就贡献了rM - 1，把这些加起来就是分子。

关于AUC，越接近1越好是肯定的，但是并不是越接近0就越差，最差的是接近0.5，如果AUC很接近0的话，只需要把模型预测的结果加个负号就能让AUC接近1，具体的原因自行体会。

好了，已经介绍完排序的评价指标了，该主角出场了，BPR模型，它提出了一个优化准则和学习框架，使得原来传统的矩阵分解放进来能够焕发第二春。

那到底BPR做了什么事情呢？主要有三点：

1. 一个样本构造方法；
2. 一个模型目标函数；
3. 一个模型学习框架。

通过这套三板斧，便可以脱离评分预测，来做专门优化排序的矩阵分解。下面详细说说这三板斧。
<div><strong>精选留言（16）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（5） 💬（2）<div>我看了好一会的Adaptive k-Nearest-Neighbor的英文公式，总算有点理解。也就是先用一个传统的距离算法计算每个用户曾经有过交互的物品中的相似度值或距离值，然后对于任意上述物品集合中的一对物品，仿照矩阵分解中sigmoid 函数的计算方法由相似度值或距离值的差值来推导Θ，在由Θ优化目标函数。

如果理解有误盼望老师能指出。

上次的问题我现在明白了。文稿查看是针对录音。目标函数是先验概率与似然概率的乘积，它与AUC值有相似性。似然概率值是用sigmoid函数计算出来，原文中相当于sigmoid函数值的连乘。</div>2018-04-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/43/19/20d3bb26.jpg" width="30px"><span>陈松林</span> 👍（0） 💬（1）<div>auc计算的时候只选正样本？</div>2018-10-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/03/7c/39ea8a23.jpg" width="30px"><span>曾阿牛</span> 👍（36） 💬（0）<div>算法通过短文的方式理解较费劲，有参考书籍&#47;开源代码推荐吗？</div>2018-03-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/aa/21/6c3ba9af.jpg" width="30px"><span>lfn</span> 👍（25） 💬（0）<div>看完之后不太明白，私下里找了两个讲解的比较清楚的博客，分享给看不明白的小伙伴：
https:&#47;&#47;www.cnblogs.com&#47;gatherstars&#47;p&#47;6084696.html ROC曲线和AUC值
https:&#47;&#47;www.cnblogs.com&#47;pinard&#47;p&#47;9128682.html   贝叶斯个性化排序</div>2018-09-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/b4/36/8e3e4d4e.jpg" width="30px"><span>greekzf</span> 👍（10） 💬（1）<div>这句话 和公式不匹配。。。    但后者是自己人，所以组合数要排除，于是就有 n - M 种组合，以此类推，排序值为 rM 的就贡献了 rM - 1，把这些加起来就是分子。   </div>2018-06-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/23/b0/baba4968.jpg" width="30px"><span>麦子</span> 👍（7） 💬（0）<div>AUC公式分子讲解的不太清楚，看不懂文字跟公式间的联系。</div>2018-09-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/3c/e7/eb5aea59.jpg" width="30px"><span>山药</span> 👍（3） 💬（1）<div>关于AUC不错的一种解释https:&#47;&#47;tracholar.github.io&#47;machine-learning&#47;2018&#47;01&#47;26&#47;auc.html</div>2019-07-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（3） 💬（0）<div>谢谢陈老师的分享。我在手机端查看。请问AUC公式的“可以点击文稿查看”是指在电脑端可以点击，会打开参考文献的链接吗？

文中BPR pair wise在真实场景应用中优化的目标函数是(1)AUC值还是(2)先验概率与似然概率的乘积值？

似然概率值是在矩阵参数上一步的估计值&#47;初始值确认后用文中提到的sigmoid函数计算出来的吗？

最后文中的延伸问题是指BPR算法如何应用于计算KNN的场景吗？手机端搜索和查阅自己不熟悉领域的文献慢些，之后有时间用电脑检索。</div>2018-03-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/5c/3d/372c93d6.jpg" width="30px"><span>对白</span> 👍（2） 💬（0）<div>有一个问题是BPR的优化算法为什么需要结合重复采样呢，文章中写道后面还是使用随机梯度下降法，也就是随机采样一个样本，那前面做的从全量样本中做有放回的采样不就多此一举吗，请老师指点谢谢！</div>2019-07-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/ec/13/49e98289.jpg" width="30px"><span>neohope</span> 👍（1） 💬（0）<div>老师，近邻模型做排序的话，可不可以直接通过相似度排序，然后排除买过的物品就可以呢？
感觉每一部分都能勉强看懂，但还是前后串不起来。
希望能多提供一些例子，或者能提供一些代码。</div>2019-12-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/2a/66/96df31f9.jpg" width="30px"><span>zgl</span> 👍（1） 💬（0）<div>老师，请问对于音频推荐来说，排序负样本如何构建？只有点击日志没有曝光日志</div>2018-04-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/ae/5b/4bd42286.jpg" width="30px"><span>宋计洋</span> 👍（0） 💬（0）<div>步骤讲的太粗糙了，对于入门的人完全看不懂</div>2021-09-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/ad/8f/ef7d1baa.jpg" width="30px"><span>Kyogre</span> 👍（0） 💬（0）<div>auc计算公式里，i应该属于正样本</div>2021-07-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/22/3d/50cab519.jpg" width="30px"><span>张飞</span> 👍（0） 💬（0）<div>老师想问下数据少的话，到底能做推荐系统不？</div>2018-04-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/4e/8e/f4297447.jpg" width="30px"><span>吴文敏</span> 👍（0） 💬（0）<div>如果仅是top 1推荐，而且既有点击数据又有曝光未点击数据，是否还有必要用pair-wise算法？</div>2018-04-10</li><br/><li><img src="" width="30px"><span>刘大猫</span> 👍（0） 💬（0）<div>学到的是相对排序 跟全局排序还是有些不太一样</div>2018-03-30</li><br/>
</ul>