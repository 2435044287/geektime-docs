今天依然要讲到两个问题，它们看似和推荐系统没有必然关系，但实际上，在你构建自己的推荐系统的时候，不可避免地会遇到这两个问题。

## 去重是刚需

在推荐系统中，有一个刚需就是去重，那么说在哪些地方有去重的需求呢？

主要是在两个地方：一个是内容源去重，另一个是不重复给用户推荐。

先说说内容源的去重，这部分以前几年的图文信息流推荐为典型的例子。

如果一个平台自己不生产内容，只是做内容搬运和聚合分发，那么从大量第三方的内容生产处抓取内容，就难免遇到相似甚至重复的内容。这就需要对内容做一个重复检测了。

对内容做重复检测，直观的思路是分词，然后提取关键词，再两两计算词向量之间的距离，距离小于一定阈值后就判定为重复。然而，这对于海量内容，比如几千万以上的内容来说简直就是灾难。

其实，内容源去重并不是仅在推荐系统中才首次出现，这早在搜索引擎时代就是一个刚需了，搜索引擎把整个互联网的网页都下载到自己的服务器上，这时，重复冗余的内容就需要被检测出来。

另一个需求是在内容阅读类推荐场景下，给用户推荐的内容不要重复，推荐过的内容就不再出现在推荐候选集中。

在你刷一个信息流产品时，不断看到重复的内容，想必不是使用感很好的一件事。因为以抓取作为主要内容来源的信息流产品，不同于社交网站上用户自发产生内容，除非遇到用户恶意发送，否则后者是不容易重复的。

以上两个场景，需要在你打造自己的推荐系统时予以考虑和应对。今天就介绍两种最常见的去重算法，两者有相通之处也有不同的之处，听我慢慢说来。
<div><strong>精选留言（15）</strong></div><ul>
<li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eogXpJz4QXkrIamNmh2DiahxHguM4o9eluFMK2Cic2PcCH03VhSUibBKhEECkFic3ZMJGW1x6El5zNBqg/132" width="30px"><span>yyy</span> 👍（1） 💬（2）<div>信息流页面，调用api接口获取到推荐的数据，一般情况下会在页面进行瀑布流加载更多。那么每次请求数据和整个瀑布流批次数据如何统一？防止重复推荐？如何处理整个批次的推荐和单次的存储、缓存、以及统一呢？ 作者回复: 关于这个问题，在我的图书中有详细介绍。
我：哪本书呢</div>2019-05-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4f/7d/dd852b04.jpg" width="30px"><span>chon</span> 👍（0） 💬（1）<div>老师，simhash算法有啥好用的来源项目吗？谢谢</div>2019-03-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/59/34/2df52bae.jpg" width="30px"><span>Da.du.Ma</span> 👍（0） 💬（1）<div>信息流页面，调用api接口获取到推荐的数据，一般情况下会在页面进行瀑布流加载更多。那么每次请求数据和整个瀑布流批次数据如何统一？防止重复推荐？如何处理整个批次的推荐和单次的存储、缓存、以及统一呢？
</div>2019-01-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（10） 💬（0）<div>Counting Bloom Filter支持删除操作，除了已有的二进制向量，向量的每一位对应一个整数计数器。每当增加一个元素时，哈希函数映射到的二进制向量对应的整数计数器加一，删除时减一。有了这个操作可以增加，查找和删除集合里的元素。</div>2018-04-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/5d/0b/9d4da40a.jpg" width="30px"><span>chy2048</span> 👍（6） 💬（1）<div>买了这个专栏只想请教下关于去重的问题，不知道还会不会有人回复😂
用布隆过滤器防止内容重复推荐，具体是怎么实现的？
1.是一个用户一个布隆过滤器吗？
2.如果是一人一个布隆过滤器的话，如何设置布隆过滤器的大小呢？貌似不能动态伸缩吧？
3.布隆过滤器持久化是依赖redis吗？
4.如果需要对过去24小时的内容去重，如果每隔24小时创建一个布隆过滤器，那两个过滤器如何平滑过度？
看到有空麻烦回复下，谢谢🙏买这个专栏只为这一篇，本来想看下面的评论，结果评论只有10条，我晕</div>2019-07-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/3f/a4/acbd2eb4.jpg" width="30px"><span>EAsY</span> 👍（4） 💬（1）<div>用布隆过滤来过滤用户推荐记录的话 是否需要为每个用户存一个向量 之前考虑过用bitmap 内容池经常变动 感觉比较麻烦 </div>2018-04-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/dd/11/b93ae644.jpg" width="30px"><span>vicviz</span> 👍（2） 💬（3）<div>Bloomfilter非常大的时候，用什么存储呢？用户数过亿，保存上千条内容不重，还得持久化</div>2018-05-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/03/7c/39ea8a23.jpg" width="30px"><span>曾阿牛</span> 👍（2） 💬（1）<div>对于分页展示的推荐列表，有更快速的方法保证前后几页不重复吗？</div>2018-04-26</li><br/><li><img src="" width="30px"><span>随心而至</span> 👍（1） 💬（0）<div>如果每一节能把参考的资料给出来就好了，虽然有的通过Google可以找到类似的。</div>2019-08-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/03/7c/39ea8a23.jpg" width="30px"><span>曾阿牛</span> 👍（1） 💬（0）<div>业界一般是不对布隆过滤器剔除元素，原因是剔除已有元素有可能导致整体数据错误。想到一种方法：使用一个同样长度的向量，记录对于位置1的个数，剔除是先hash6映射，对于1的位置，个数大于的话不变，等于1的话设为0；不过，缺点是这个向量占空间，存储成稀疏向量吧</div>2018-04-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/b9/70/c454312c.jpg" width="30px"><span>早早凡</span> 👍（0） 💬（0）<div>布隆过滤器是先查询推荐的分页内容，再使用布隆过滤器过滤。

如果分页查询是基于mysql或者es，会不会查询出来被去重完了，做很多无效分页查询？</div>2021-10-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/a2/76/bdea7aa1.jpg" width="30px"><span>晨晓</span> 👍（0） 💬（0）<div>少说了一个simhash抽屉原理，这个在大量pairwise计算中是很有用的</div>2020-03-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/6a/f6/e1ad3e30.jpg" width="30px"><span>luis</span> 👍（0） 💬（1）<div>如bloomfilter要存储的过滤数据很大 每个用户至少需要20mb 全放在内存 100万用户就要2000g的内存 这要怎么解决</div>2019-09-03</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/qRjoqWIGC6tpmKZBGTxjQKC9cbz9XLhw2nF1c74R4icFOYOdVO4iaeQEQDqEvmbicxn6HEc4SU8kpkwVaO5nABMug/132" width="30px"><span>shangqiu86</span> 👍（0） 💬（0）<div>感觉布隆过滤不错，可以考虑把我们这目前的累计用户的点击sku串改成布隆过滤这种方式，来增加保存的用户历史行为数据量</div>2019-05-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/e5/02/ea609428.jpg" width="30px"><span>wzm1990</span> 👍（0） 💬（0）<div>请教个问题，我们在用 simhash 做文本去重，用一个 simhash 值跟几十万个值比对。目前是把几十万的值放到 redis，比对时加载到程序里，这样做特别耗cpu，有没有其他更好的实现</div>2018-05-11</li><br/>
</ul>