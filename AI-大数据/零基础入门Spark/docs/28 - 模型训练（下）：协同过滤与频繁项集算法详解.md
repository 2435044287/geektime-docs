你好，我是吴磊。

如果你平时爱刷抖音，或者热衷看电影，不知道有没有过这样的体验：这类影视App你用得越久，它就好像会读心术一样，总能给你推荐对胃口的内容。其实这种迎合用户喜好的推荐，离不开机器学习中的推荐算法。

今天是咱们模型训练的最后一讲，在今天这一讲，我们就结合两个有趣的电影推荐场景，为你讲解Spark MLlib支持的协同过滤与频繁项集算法。与上一讲一样，咱们还是先来贴出下面这张“全景图”，方便你对学过和即将要学的知识做到心中有数。

![图片](https://static001.geekbang.org/resource/image/f1/54/f1d0ce11953030d6a9eb4475c7827d54.jpg?wh=1920x2035 "Spark MLlib支持的模型算法")

## 电影推荐场景

今天这一讲，咱们结合Kaggle竞赛中的[MovieLens数据集](https://www.kaggle.com/jneupane12/movielens)，使用不同算法来构建简易的电影推荐引擎。尽管MovieLens数据集包含了多个文件，但课程中主要用到的，是ratings.csv这个文件。文件中的每条数据条目，记录的都是用户对于电影的打分，如下表所示。

![图片](https://static001.geekbang.org/resource/image/dd/9f/ddb19aa4974092047yyc287929953b9f.jpg?wh=1648x710 "ratings.csv样本示例")

其中第一列userId为用户ID，movieId表示电影ID，而rating就是用户对于电影的评分。像这样，同时存有用户与物品（电影）信息的二维表，我们把它们统称为“交互矩阵”，或是“共现矩阵”。你可能会疑惑，通过这么一份简单的二维表，我们能干些什么呢？

可别小瞧这份数据，与合适的模型算法搭配在一起，我就能根据它们构建初具模样的推荐引擎。在Spark MLlib框架下，至少有两种模型算法可以做到这一点，一个是协同过滤（Collaborative Filtering），另一个是频繁项集（Frequency Patterns）。其中，前者天生就是用来做推荐用的，而后者是一种常规的非监督学习算法，你可以结合数据特点，把这个算法灵活运用于推荐场景。
<div><strong>精选留言（1）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/27/bd/95/882bd4e0.jpg" width="30px"><span>Abigail</span> 👍（3） 💬（1）<div>协同过滤算法本身其实对于推荐什么物品是一点都不关心的，所有的推荐机制都是基于用户对物品的行为来制定的, 优点基于用户行为，因此对推荐内容无需先验知识；只需要用户和商品的关联矩阵即可，结构简单；在用户行为丰富的情况下，效果好。 当然如此一来，缺点也非常明显：需要大量的显性&#47;隐形的用户行为数据，有冷启动问题；需要通过完全相同的商品关联，相似的不行 aka 同义词问题；在数据稀疏的情况下易受影响。
频繁项集它暗示了某些事物之间总是结伴或成对出现。本质上来说，不管是因果关系还是相关关系，都是共现关系。理论上所有机器学习算法都可以暴力搜索，也就不需要承担启发式搜索带来的局部优化损失问题，估计现在很少有人这么做了。FP-growth算法只需要对数据库进行两次扫描，同Aprion相比压缩度更高，不过对内存开销大，而且只能用于挖掘单维的布尔关联规则。理论上一般建议使用Apriori算法进行关联分析，用FP-growth算法来高效发现频繁项集。当然实际工程还是要根据数据的质量和目标需求以及运营成本来调整。</div>2021-11-17</li><br/>
</ul>