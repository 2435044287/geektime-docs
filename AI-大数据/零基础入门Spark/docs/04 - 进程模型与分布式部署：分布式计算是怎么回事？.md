你好，我是吴磊。

在[第2讲](https://time.geekbang.org/column/article/417164)的最后，我们留了一道思考题。Word Count的计算流图与土豆工坊的流水线工艺，二者之间有哪些区别和联系？如果你有点记不清了，可以看下后面的图回忆一下。

![图片](https://static001.geekbang.org/resource/image/af/6d/af93e6f10b85df80a7d56a6c1965a36d.jpg?wh=1920x512 "Word Count计算流图")

![图片](https://static001.geekbang.org/resource/image/4f/da/4fc5769e03f68eae79ea92fbb4756bda.jpg?wh=1920x586 "土豆工坊的流水线工艺")

我们先来说区别。首先，Word Count计算流图是一种抽象的流程图，而土豆工坊的流水线是可操作、可运行而又具体的执行步骤。然后，计算流图中的每一个元素，如lineRDD、wordRDD，都是“虚”的数据集抽象，而流水线上各个环节不同形态的食材，比如一颗颗脏兮兮的土豆，都是“实实在在”的实物。

厘清了二者之间的区别之后，它们之间的联系自然也就显而易见了。如果把计算流图看作是“设计图纸”，那么流水线工艺其实就是“施工过程”。前者是设计层面、高屋建瓴的指导意见，而后者是执行层面、按部就班的实施过程。前者是后者的基石，而后者是前者的具化。

你可能会好奇：“我们为什么非要弄清这二者之间的区别和联系呢？”原因其实很简单，**分布式计算的精髓，在于如何把抽象的计算流图，转化为实实在在的分布式计算任务，然后以并行计算的方式交付执行。**

今天这一讲，我们就来聊一聊，Spark是如何实现分布式计算的。分布式计算的实现，离不开两个关键要素，一个是进程模型，另一个是分布式的环境部署。接下来，我们先去探讨Spark的进程模型，然后再来介绍Spark都有哪些分布式部署方式。
<div><strong>精选留言（20）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/19/08/1d/30b32c93.jpg" width="30px"><span>路人丁</span> 👍（23） 💬（4）<div>老师好！讲解很精彩！
为了帮助大家理解，还是要说说 standalone 模式下的 主从选举过程，三个节点怎么互相找到并选出主从。另外，standalone 模式下的 master 和 worker，与前面进程模型里说的 Driver 和 executor，二组之间的对应关系，也要讲讲。只要能简单串起来就可以了。让大家获得一个即便简单、但却完成的理解模型。
</div>2021-11-08</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epGTSTvn7r4ibk1PuaUrSvvLdviaLcne50jbvvfiaxKkM5SLibeP6jibA2bCCQBqETibvIvcsOhAZlwS8kQ/132" width="30px"><span>Geek_2dfa9a</span> 👍（35） 💬（3）<div>  1.
  collect，触发action返回全部组分区里的数据，results是个数组类型的数组，最后在把这些数组合并。
  因为所有数据都会被加载到driver，所以建议只在数据量少的时候使用。源码如下：
  &#47;**
   * Return an array that contains all of the elements in this RDD.
   *
   * @note This method should only be used if the resulting array is expected to be small, as
   * all the data is loaded into the driver&#39;s memory.
   *&#47;
  def collect(): Array[T] = withScope {
    val results = sc.runJob(this, (iter: Iterator[T]) =&gt; iter.toArray)
    Array.concat(results: _*)
  }
  take代码太长就不发了，注释上说是先取一个分区，然后根据取到的数量预估出还需要取多少个分区。
  和collect一样，建议只在数据量少的时候使用。如果rdd里有Nothing和Null的话，会抛出异常。
  具体实现：
  先尝试从第一个分区0开始collet数据，
    如果返回数量为0的话，每次都拉已扫描分区数4倍的分区数（可以通过spark.rdd.limit.scaleUpFactor参数设置，默认值为4），
    如果返回数量大于0但是还不够需要take的数量的话，从已扫描分区数4倍的分区数和已扫描分区数预估一个需要扫描分区数（1.5*剩余需要take的数据数*已扫描分区数&#47;已取到的数据数，然后向上取整）选一个最小值
  一直到拿到take数据数&#47;全部分区都取完。
  &#47;**
   * Take the first num elements of the RDD. It works by first scanning one partition, and use the
   * results from that partition to estimate the number of additional partitions needed to satisfy
   * the limit.
   *
   * @note This method should only be used if the resulting array is expected to be small, as
   * all the data is loaded into the driver&#39;s memory.
   *
   * @note Due to complications in the internal implementation, this method will raise
   * an exception if called on an RDD of `Nothing` or `Null`.
   *&#47;

   2.使用了yarn，没有使用standalone所以也没啥生产经验，简单看了下官方部署文档：
   首先需要关注安全问题，SparkRpc的身份验证和加密，本地文件（shuffle）的加密，SparkUI的安全（身份验证，https，其他web安全）
   Event Logging和访问，客户端模式下的持久化日志的权限
   然后是高可用，spark的worker是支持高可用的，master是通过zk实现的</div>2021-09-17</li><br/><li><img src="https://wx.qlogo.cn/mmopen/vi_32/wgMMrp1hvSB3E30KqZvMsj3KQdAI3T1uQM77LT7hZ65nVSjPGRg3AbUOyiahnssA6AIT5PAkyHFmlTBzUH9gdyQ/132" width="30px"><span>pythonbug</span> 👍（10） 💬（1）<div>老师好，有一个地方一直不懂，textFile算子是在excutor端执行的吗？那岂不是每个excutor都会先读取整个文件</div>2021-10-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/23/bb/a1a61f7c.jpg" width="30px"><span>GAC·DU</span> 👍（10） 💬（4）<div>1、collect()方法回把RDD所有的元素返还给Driver端，并在Driver端把数据序列成数组，如果数据量过大，会导致Driver端内存溢出，也会导致Driver进程奔溃。但是有个问题，既然collect方法有弊端，spark开发者为什么还要对用户提供它？难道还有别的什么特殊用户场景吗？请老师指点。
2、目前使用的是YARN进行任务调度，提交任务需要指定--master yarn 和 --deploy-mode [cluster | client]。
有个问题咨询老师，比如说wordCount的top5，take(5)是如何知道要从哪个executor提取想要的数据的？</div>2021-09-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/28/9e/8801bfd6.jpg" width="30px"><span>coderzjh</span> 👍（7） 💬（2）<div>讲的真好懂，老师能不能更快点哈，从来没有像现在这样爱好学习</div>2021-09-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/57/61/369a609c.jpg" width="30px"><span>A</span> 👍（5） 💬（1）<div>数据交换之后，所有相同的单词都分发到了相同的 Executors 上去；
老师这里我有个问题在任务执行的时候executor之间还会进行通信嘛？
任务分发完成之后每一个executor不就是按部就班的执行自己的任务嘛？我不需要去拉取别的executor中的数据我只需要计算我自己的就好，聚合 的时候由driver来完成就好（不过这点也说不过去因为driver不负责计算）
疑惑点就是executor怎么通过dag来让每个executor去不同的executor上拉取数据？每个executor是如何感知之前的stage生成的数据都存在哪里？（相同的单词）难不成处理完前一个stage后executor会像driver报道我本次处理完的数据放在哪里
麻烦老师给解答一下，或是提供个引子我去追一下spark源码
感谢老师！</div>2022-01-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/27/bd/95/882bd4e0.jpg" width="30px"><span>Abigail</span> 👍（4） 💬（2）<div>分享的经验：工作后一开始接触分布式计算时，直接上手的就是在 Azure&#47;AWS&#47;GCP 利用 DataBricks 进行数据分析处理和建模，感觉自己直接跳过了很多关于 Spark 基础的东西，关于如何部署Spark系统更是没有动手经验，平时就是 Create Cluster 然后一路点下去，或启动之前配置好的 Cluster，遇到门槛直接找 IT 或 DataBricks 的技术服务就解决了。不知道会不会影响自己未来技术积累和事业发展……心里小小慌张一下，不过目前大概是知道怎么个流程了，不是那么慌了。
在我看来这个“零基础”入门Spark其实不是很零基础～还是有一定的门槛的。
吴老师能否考虑稍后出一个基于Spark项目实战技术的教程，配上辅助的代码和教程，这样和这个基础入门结合起来会更受欢迎的！</div>2021-11-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/ed/44/2267a5a7.jpg" width="30px"><span>一期一会</span> 👍（3） 💬（1）<div>有个问题麻烦老师回答：在咱们的word count示例中的take(5)前面运行了sortByKey(false)， 那是不是各分区在分区内部做了排序，而不是所有分区进行了归并排序呢？然后take(5)就是返回各分区中取排序前几个的，最后凑出来5个结果呢？也就是说，如果各分区自己排序然后给出结果并汇总，那take(5)的结果，并不一定是全局中出现频率最高的5个单词？</div>2022-01-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/27/bd/95/882bd4e0.jpg" width="30px"><span>Abigail</span> 👍（1） 💬（1）<div>吴老师能否出一个更为详细一点的spark在AWS EC2上部署的note，我在AWS上尝试了一遍, 选的也是centOS7，最好好不容易把环境设置好了，在运行最后一个例子时， 又出现了一个bug如下。本人非IT需要手把手的带一遍。

[centos@ip-172-31-40-xxxx spark_latest]$ MASTER=spark:&#47;&#47;node0:7077 $SPARK_HOME&#47;bin&#47;run-example org.apache.spark.examples.SparkPi
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:&#47;opt&#47;spark&#47;spark-3.1.2-bin-hadoop3.2&#47;jars&#47;spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)
WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
Exception in thread &quot;main&quot; org.apache.spark.SparkException: Master must either be yarn or start with spark, mesos, k8s, or local
</div>2021-11-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/6f/4f/3cf1e9c4.jpg" width="30px"><span>钱鹏 Allen</span> 👍（1） 💬（1）<div>吴老师的进程模型讲得易于理解，
各种RDD的算子计算，我们带入到日常的生活场景里去理解。Driver和Executor，包工头和工人的比喻。  
期待老师的后续课程~</div>2021-09-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/76/51/96291466.jpg" width="30px"><span>猫太太</span> 👍（0） 💬（1）<div>请问在自己机器上装了一个Ubunto的虚拟机，如何完成spark的分布式部署</div>2021-11-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/65/4c/f7f86496.jpg" width="30px"><span>welldo</span> 👍（0） 💬（1）<div>老师，
图片“Driver与Executors：Spark进程模型”里，
一个节点里有两个executor，这是啥意思呢？
我一直以为“节点=executor”</div>2021-10-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/39/68/56dfc8c0.jpg" width="30px"><span>子兮</span> 👍（0） 💬（1）<div>老师，请问每个数据分片也就是partition的执行单元不是core嘛？为什么说是excutor呢？</div>2021-09-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/75/ec/c60b29f5.jpg" width="30px"><span>Alvin-L</span> 👍（0） 💬（1）<div>多谢老师，希望以后都能有类似薯片这样的形象例子，帮助新手理解里面各种听不懂的抽象概念</div>2021-09-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/23/a2/1e/7a75c121.jpg" width="30px"><span>我叫王子小白</span> 👍（0） 💬（0）<div>分布式环境部署好之后，如何使用呢？spark-shell --master spark:&#47;&#47;node0:7077 直接连接master节点跑spark任务吗？</div>2023-03-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/22/bf/43/05571148.jpg" width="30px"><span>DeanWinchester</span> 👍（0） 💬（0）<div>老师您好，您提到每个Executor只负责一个数据分片，那如果数据分片总数大于Executor个数时，每个Executor会怎么执行呀？
我猜可能是每个Executor ‘负责’多个数据分片，然后自己切换不同的分片执行吗？
辛苦老师解答啦</div>2022-07-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/3e/be/f7bc225d.jpg" width="30px"><span>Ty</span> 👍（0） 💬（0）<div>老师您好，想请问下reduceByKey不是应该先在各个分区内部先进行一次聚合再进行shuffle操作吗？为什么本文中的图解是在转成pairRDD value为1的时候就开始和driver通信了呢？</div>2022-07-06</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIw0Nnvrrt9fV1wHVfBlPzrZmxNCRTbWPfNEbCEMtuoj6gw0LlMbbS3gtRLgLMfCoAV3TXsk5giavw/132" width="30px"><span>Geek_b2839b</span> 👍（0） 💬（1）<div>老师，对于统计次数，如果先使用groupby这个算子，然后再使用聚合算子统计次数，这个过程中如果group by算子shuffle后某一个单词的个数超过了一个executor内存的数量，那么后面怎么去统计次数呢</div>2022-05-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2c/cb/97/5bbf4d08.jpg" width="30px"><span>康</span> 👍（0） 💬（0）<div>老师好，请教如下几个问题，麻烦您得空解答下，谢谢！
1. Driver分发任务是以什么形式进行的，是把用户写的JAVA程序编译后，每个stage都对应一段编译后的代码，每次分发任务就是把这一段编译后的代码分发给Executor？

2. 遇到有Shuffle的算子比如reduceBy，底层是会拆分给两个函数吗，这两个函数分别对应两个Stage中 ,前一个函数用于在同一个Executor做聚合，后一个函数进行跨Executor数据聚合？

3. 在整个job执行中，Executor的数量会发生变化吗，比如在Word Count例子中，一开始分配了3个Executor，最后执行统计的时候，可能只有两个单词，理论上来说，只需要两个Executor就够了</div>2022-03-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/58/52/f35f5265.jpg" width="30px"><span>空de</span> 👍（0） 💬（0）<div>请问在实际应用中， 数据分片数量是和Executors数量一致吗，还是可以自由分配分片数量？</div>2022-03-10</li><br/>
</ul>