你好，我是吴磊。

国庆假期即将结束，我们的基础模块也即将收尾。到目前为止，我们一起学习了RDD编程模型、Spark分布式部署、Spark工作原理，以及RDD常用算子。恭喜你，到这里，可以说你已经完全跨入了Spark分布式应用开发的大门。有了现在的知识储备，对于大多数的业务需求，我相信你都能很快地实现。

不过，快速用代码实现各式各样的业务需求，这还只是第一步。我们不光要让代码跑起来，还需要让代码跑得又快又稳。

要想做到这些，我们还需要配置项来帮忙。如果把Spark看作是一部F1赛车的话，那么配置项就是赛车车身的各项配置参数，如发动机缸数、最大转矩、车身轴距、悬挂方式、整车装备质量，等等。只有合理地配置车身参数，才能让车子本身的稳定性和性能得到保障，为选手的出色发挥奠定基础。

今天这一讲，我们就来说一说Spark都有哪些配置项，以及这些配置项的含义与作用。

## 配置项

打开Spark官网的[Configuration页面](http://spark.apache.org/docs/latest/configuration.html)，在这里你能找到全部的Spark配置项。

不过，让人沮丧的是，配置项数目过于庞大，种类繁多，有的需要设置true/false，有的则需要我们给出明确的数值，让人看上去眼花缭乱、无所适从。

![图片](https://static001.geekbang.org/resource/image/b2/4c/b28bd6e736f3634yy5ee74bd3027624c.png?wh=793x646 "配置项示意图")

那么问题来了，面对这么多的配置项，我们应该从哪里入手呢？别着急，既然我们的目的是让车子“跑得稳”、“跑得快”，那咱们不妨从这两个角度出发，来整理那些我们必须要掌握的配置项。
<div><strong>精选留言（11）</strong></div><ul>
<li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epGTSTvn7r4ibk1PuaUrSvvLdviaLcne50jbvvfiaxKkM5SLibeP6jibA2bCCQBqETibvIvcsOhAZlwS8kQ/132" width="30px"><span>Geek_2dfa9a</span> 👍（11） 💬（2）<div>关于何时何处配置Property这一块，官网文档有提及，属性主要分为两块：deploy相关和Spark Runtime Control（个人理解是任务运行相关，
即Driver，任务及其相关资源）相关。前面的比如“spark.driver.memory”, “spark.executor.instances”，适合放在spark-defaults.conf
后面的比如“spark.task.maxFailures”，适合在SparkConf（Driver）&#47;spark-submit命令中指定。关于两处属性的覆盖问题：
通常情况优先级最高的是SparkConf，其次是spark-submit，最后是spark-defaults.conf，当然也有例外，“spark.driver.memory”, 
“spark.executor.instances”这两个属性在SparkConf设置也不会生效。
属性是也是细分的，按照官方文档分类：
Application Properties 这块主要是任务相关的，应该对应开发自己设置，从生产角度来看，我觉得每个任务必须设置，甚至不应该有默认值。
Runtime Environment 任务运行相关，比如依赖存放的位置，这块可以统一设置，按需在任务里覆盖
Shuffle Behavior shuffle行为，大部分偏spark-defaults.conf统一设置，“spark.shuffle.service.enabled”配置值得一提，
开启后可以由统一服务维护shuffle的数据文件，避免Executor shuffle时意外终止导致的找不到shuffle文件。
Spark UI
Compression and Serialization 压缩和序列化，在任务里按需设置，主要降低网络IO负载，但是肯定会带来CPU额外开销
Memory Management 内存，统一设置，按需在任务里覆盖
Execution Behavior 执行相关，统一设置，按需在任务里覆盖
Executor Metrics 执行指标，统一设置，按需在任务里覆盖，这块是不是用来分析性能瓶颈的？
Networking和Scheduling都是偏spark-defaults.conf统一设置，感觉没啥可以在任务里设置的
Barrier Execution Mode这块我分析应该是面向MPI模型（模型训练）和BSP模型（图计算）的，应该也是和任务相关的，说实话后面都不怎么看得懂了，都是猜的
Dynamic Allocation，Thread Configurations 这两个搞不太清楚
Security 安全，偏集群部署方向的配置多，可以统一配置</div>2021-10-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/cd/04/e27b7803.jpg" width="30px"><span>小新</span> 👍（4） 💬（1）<div>相反，如果你的应用场景是机器学习、或是图计算，这些计算任务往往需要反复消耗、迭代同一份数据，处理方式就不一样了。在这种情况下，咱们要充分利用 RDD Cache 提供的性能优势，自然就要把 sf 这个参数设置得稍大一些，从而让 Storage Memory 有足够的内存空间，来容纳需要频繁访问的分布式数据集。

就这个问题，想问一下，如果整个应用前期是ETL， 后期使用MLlib进行机器学习，那个参数可以代码里手动调整吗？</div>2021-12-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1a/49/fe/48846a6d.jpg" width="30px"><span>Ebdaoli</span> 👍（1） 💬（1）<div>关于 1 core 1 task , 集群中总core 为 executors * cores 这一块，在SparkSQL 中设置 spark.shuffle.partitions 时，遵照总的并行度 设置为 总core 数的 2~3 倍, 避免在某些执行过快的task在执行完本次任务后，还有其他的任务可以执行，充分利用集群的资源，这里如果设置成4~5倍或者更大的倍数会对性能造成什么影响，是好的还是坏的？理论来说如果 并行度更多了，集群资源也是能充分利用，每个task 处理的数据量还会更少，这里有些困惑对于 2~3 倍的并行度设置的理解，所以能请老师帮忙分析下吗？</div>2022-02-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/d6/ad/850992a5.jpg" width="30px"><span>William</span> 👍（1） 💬（1）<div>
D&#47;P ~ m&#47;c
老师，公式中的P与是 spark.default.parallelism 和 spark.sql.shuffle.partitions有关，这里的P与这两者的关系具体是怎样的呢？具体是以那个为准呢？</div>2021-12-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/cd/04/e27b7803.jpg" width="30px"><span>小新</span> 👍（1） 💬（1）<div>D&#47;P ~m&#47;c与前面讲的一般把并发数设置为集群cores的2~3倍，有何关联。一个是讲局部Executor, 一个是整体优化概念是吗？</div>2021-12-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1c/60/89/1f424b14.jpg" width="30px"><span>Zhenng</span> 👍（0） 💬（1）<div>spark.executor.instances参数是在Yarn的Spark集群中使用的，在Standalone集群中executor的个数是由spark.cores.max&#47;spark.executor.cores 这两个参数决定的。我在Standalone集群中修改spark.executor.instances参数并不起作用</div>2022-03-03</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/iaQgtbE98VGIVIyribdo6dgLOnaNoe7ZdUuPr60ibsduibscrzQCTzdW2AfL9nxwe8YlSK75gOnK3YbAJKTaFPxibdg/132" width="30px"><span>小李</span> 👍（0） 💬（1）<div>对于D&#47;P ~ m&#47;c，其中对于p和c比较好量化，存储尺寸D（若是压缩存储）势必加载到内存会有膨胀的情况，这对于Execution Memory（m）的设置是否会不好把握（需要加载一下数据看一下实际占用的内存大小）？</div>2022-01-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/f2/f5/b82f410d.jpg" width="30px"><span>Unknown element</span> 👍（0） 💬（4）<div>老师 问下spark.local.dir是spark安装目录下的文件夹吗</div>2021-10-08</li><br/><li><img src="" width="30px"><span>Geek_6ec9b9</span> 👍（0） 💬（0）<div>优先级顺序不对吧？</div>2024-11-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/d3/be/f51eac52.jpg" width="30px"><span>细嗅蔷薇</span> 👍（0） 💬（0）<div>spark.sql.shuffle.partitions 参数中的sql 代表只能此参数只能应用于spark sql作业吗？</div>2024-08-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/97/83/a9559709.jpg" width="30px"><span>LHJ_Stan</span> 👍（0） 💬（0）<div>老师，spark涉及的概念比较多，经常出现同一概念多个名词解释，譬如，数据分区、分片、partitions，这三者的区别，可以麻烦老师稍微再详细讲一讲吗？</div>2023-03-01</li><br/>
</ul>