你好，我是吴磊。

感谢你在国庆假期仍然坚持学习，今天这一讲，我们来学习存储系统，与调度系统一样，它也是Spark重要的基础设施之一。不过，你可能会好奇：“掌握Spark应用开发，需要去了解这么底层的知识吗？”坦白地说，还真需要，为什么这么说呢？

我们前面学了Shuffle管理、RDD Cache和广播变量，这些功能与特性，对Spark作业的执行性能有着至关重要的影响。而想要实现这些功能，底层的支撑系统正是Spark存储系统。

学习和熟悉存储系统，不单单是为了完善我们的知识体系，它还能直接帮你更好地利用RDD Cache和广播变量这些特性。在未来，这些知识也能为你做Shuffle的调优奠定良好的基础。

既然存储系统这么重要，那要怎样高效快速地掌握它呢？本着学以致用的原则，我们需要先了解系统的服务对象，说白了就是存储系统是用来存什么东西的。

## 服务对象

笼统地说，**Spark存储系统负责维护所有暂存在内存与磁盘中的数据，这些数据包括Shuffle中间文件、RDD Cache以及广播变量**。

对于上述三类数据，我们并不陌生。我们先回顾一下什么是Shuffle中间文件，在Shuffle的计算过程中，Map Task在Shuffle Write阶段生产data与index文件。接下来，根据index文件提供的分区索引，Shuffle Read阶段的Reduce Task从不同节点拉取属于自己的分区数据。而Shuffle中间文件，指的正是两个阶段为了完成数据交换所仰仗的data与index文件。
<div><strong>精选留言（10）</strong></div><ul>
<li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epGTSTvn7r4ibk1PuaUrSvvLdviaLcne50jbvvfiaxKkM5SLibeP6jibA2bCCQBqETibvIvcsOhAZlwS8kQ/132" width="30px"><span>Geek_2dfa9a</span> 👍（9） 💬（2）<div>今天的题好像面试啊，LinkedHashMap是HashMap的增强版，直接继承了HashMap类，多提供了一个可以按插入顺序的遍历，这个遍历是通过
两方面实现的：
1.直接扩展HashMap的Map.Entry，增加了before,after的指针，这样就在不改变本身数组的结构下
（哈希表本身通过数组实现常数级查询的时间复杂度，因此会打乱插入顺序），又变成了一个双链表，双链表的顺序就是插入顺序。
2.记录链头，链尾，这样就可以从头&#47;尾按顺序遍历了。
这里LinkedHashMap是怎么组织链表的值得提一下，LinkedHashMap没有覆盖HashMap的put方法，HashMap使用了模版设计模式，
很好的实现了扩展和解耦，通过提供空方法扩展点afterNodeAccess，afterNodeInsertion，afterNodeRemoval，
LinkedHashMap是通过重写这些扩展点实现了链表的插入和删除。
最后回一下上节课和老师交流的打开视野，目前来说，Spark对我来说有点像盲人摸象，现在只摸到了象腿，所以说大象像根柱子，
但是Spark可能还有很多精彩的地方我没摸到，期待老师带我们从多角度深入了解Spark这头大象。</div>2021-10-11</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epGTSTvn7r4ibk1PuaUrSvvLdviaLcne50jbvvfiaxKkM5SLibeP6jibA2bCCQBqETibvIvcsOhAZlwS8kQ/132" width="30px"><span>Geek_2dfa9a</span> 👍（10） 💬（1）<div>MemoryStore这块涉及大量的nio，看得我头皮发麻。简单点讲，里面有个核心的常量LinkedHashMap，作为LRU缓存，存储所有Block。
putBytes()这个方法主要用来写数据，方法入参分别是blockId（数据块的标识），size（数据块长度），memoryMode（存放在堆上还是堆外），
_bytes（具体内存分配的闭包），具体实现逻辑是，先检查blockId对应的数据块是否已缓存，然后通过memoryManager（1.6以前是StaticMemoryManager，
不能支持堆外内存，1.6以后默认UnifiedMemoryManager，可以通过spark.memory.useLegacyMode指定）确认内存是否够缓存，在后通过
_bytes把数据拷贝到DirectByteBuffer，如果数据本来就在堆外的话就省略这个逻辑，最后把blockId作为key，ChunkedByteBuffer
（就是一个DirectByteBuffer数组，里面是要缓存的数据）作为SerializedMemoryEntry存到LinkedHashMap里，这里注意，
为了保证线程安全，LinkedHashMap需要加锁，这里是一个细粒度锁加到少部分代码上减少开销。
上面的是缓存序列化块的逻辑，putIterator既可以缓存序列化的值（堆内&#47;堆外），也可以直接缓存对象（只能存放在堆内），具体逻辑和LinkedHashMap
不太相关了，篇幅有限就不分析了。
作为一个LRU缓存，Spark肯定还要有一个容量满后的清除操作，触发点在put时校验空间是否足够，具体逻辑在evictBlocksToFreeSpace，
入参有三个blockId（失效后需要缓存的block），space（需要缓存的block的长度），memoryMode。缓存失效这块影响比较大，需要加两个锁，
在外层给memoryManager加锁，之后再给LinkedHashMap加锁，因为put的时候memoryManager没加锁，如果正在put的时候清理缓存会发生数据竞争，
因此LinkedHashMap也需要加锁，保证同一时间LinkedHashMap只能有一个操作，之后的操作就简单了，拿到LinkedHashMap的迭代器，
从第一个Entry开始判断，如果可以失效（）的话就记录下blockId并在blockInfoManager针对blockId加锁，
一直到释放的内存达到space。接下来判断如果清理这些失效的block能否拿到需要的space，不能的话就返回0，表示不能清理出所需空间，如果能拿到的话，
就开始dropBlock（），有些block可能同时在磁盘和内存缓存，如果只清除一处的话blockInfo无需删除解锁即可，如果磁盘和内存都没有了则需删除blockInfo，
如果清理过程中发生异常，则把还没清理的blockInfo解锁（这块逻辑放在finally里，并且作为一个编程技巧注释出来）。
另外有一点值得注意，Spark为了避免MaxDirectMemorySize的限制，使用了反射拿到了DirectByteBuffer的私有构造方法
private DirectByteBuffer(long addr, int cap)，这样就避开了allocateDirect方法里面Bits.reserveMemory的限制。</div>2021-10-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/75/ec/c60b29f5.jpg" width="30px"><span>Alvin-L</span> 👍（1） 💬（2）<div>原本存储在mysql里的数据如何转存储到spark里？老师可否加餐讲一讲mysql转存spark的相关内容</div>2021-10-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/5e/b2/aceb3e41.jpg" width="30px"><span>Neo-dqy</span> 👍（1） 💬（1）<div>【BlockManagerMaster 与众多 BlockManager 之间通过**心跳**来完成信息交换】，可以问一下老师这个心跳机制是什么呀？具体是怎么实现的呢？</div>2021-10-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/70/67/0c1359c2.jpg" width="30px"><span>qinsi</span> 👍（1） 💬（1）<div>LinkedHashMap 可用来实现 LRU Cache</div>2021-10-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/97/c4/6c92c78a.jpg" width="30px"><span>小强</span> 👍（0） 💬（1）<div>请问老师，RDD Cache 以及广播变量是存储在storage memory, 那shuffle中间文件是否是存储在execution memory里啊？</div>2021-10-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/6f/4f/3cf1e9c4.jpg" width="30px"><span>钱鹏 Allen</span> 👍（0） 💬（2）<div>LinkedHashMap可以类比HashMap前者有序，后者无序</div>2021-10-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/f2/f5/b82f410d.jpg" width="30px"><span>Unknown element</span> 👍（0） 💬（3）<div>老师在文章倒数第二张图片里shuffle中间文件的blockid里有个属性叫 是否为shuffle block ，这里的shuffle block是什么呢？为什么shuffle中间文件不属于shuffle block?</div>2021-10-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/f8/2b/339660f1.jpg" width="30px"><span>Wangyf</span> 👍（1） 💬（0）<div>插个眼。
为嘛内存的那个 MemoryStore 是自己干活，但磁盘的 DiskStore 却要维护另一个对象来干活？那它自己又去干嘛了？</div>2022-07-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4f/f2/6ac3bdcf.jpg" width="30px"><span>qingtama</span> 👍（0） 💬（0）<div>老师有个问题想请教下，如果使用LinkedHashMap是为了LRU的话就是说数据会有被淘汰的情况，但是我理解不过是内存的数据还是磁盘的数据都不能因为达到了LinkedHashMap存储上限而被清理掉吧，尤其数据都在被使用着的时候。</div>2022-04-03</li><br/>
</ul>