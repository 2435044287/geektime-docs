你好，我是Tyler。

又到了答疑课堂的时间了。之前我们讲过的内容你都学会了吗？建议已经忘记前面知识的同学在课前再回顾一下。这节课整理的题目会加大难度，直接和目前最前沿的大模型技术相关。

你做好准备了吗？让我们现在正式开始。具体的问题和答案你可以直接看文稿，每节课我也加入了超链接，方便你复习回顾。（这里我单独提一下第19节课的思考题，因为想清楚这节课的问题，对你理解提示语工程相当关键，我们在前面的课程中说过，我们是通过苏格拉底的产婆术来教会大模型思考的，而提示语工程就是大模型技术的产婆。）

# 第三章 技术原理篇

## [第11节课](https://time.geekbang.org/column/article/692796)

**思考题**

预训练模型和大模型之间的关系是什么？

**参考答案**

预训练模型（pre-training model）首先通过一批语料进行训练，然后在这个初步训练好的模型基础上，再继续训练或者另作他用。为了最大化模型复用的效果，往往使用参数量较大的模型作为预训练模型的网络结构。

## [第12节课](https://time.geekbang.org/column/article/696734)

**思考题**

1.这节课我们学习了如何给 LSTM 增加 Attention 机制，你可以思考一下，如果要给上节课学到的 CNN 增加这个机制，该如何做呢？

2.沿着课程中传声筒游戏可以“作弊”的思路想下去，你还能想出哪些作弊方法？越离谱越好！
<div><strong>精选留言（1）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg" width="30px"><span>peter</span> 👍（1） 💬（1）<div>请教老师几个问题：
Q1：chatGPT是用什么语言开发的？Python吗？
Q2：有能操作的例子吗？
 平时工作忙，都是地铁上阅读专栏的。专栏很不错，想深入学习一下，能想到的方法是实际跑几个例子。本专栏哪几个例子有详细说明？就是照着文档能跑下来的那种。两三个就可以。</div>2023-11-07</li><br/>
</ul>