你好，我是Tyler。从今天起，我们正式开始学习“AI大模型架构”。

最近，各大媒体热搜上都在讨论AI大模型，国内外的各个大厂也都在相关领域开疆拓土。“AI大模型将成为新一代应用平台”的观点，似乎已经成为各大公司的共识。

![图片](https://static001.geekbang.org/resource/image/b0/9f/b031006f5f880356af9cee14ff37b99f.png?wh=2560x485)

相信你学习这门课程的目的，也是为了在AI大模型的技术浪潮下，尽早熟悉甚至驾驭这个新的基础设施，走在技术的前沿。不过在开始之前，我想先问你一个问题：学习一个全新领域的时候，你一般第一件事会做什么？

我的习惯是follow数学上的方法，先搞清楚这个领域的“公理”有哪些，因为它是该领域的**共识**，如果不能在一开始，就和领域中的大多数人建立共识，后续所有的认识都会出现偏差。所以在正式开始学习之前，我们有必要花点时间了解这些“公理”以及它们背后的历史，让自己的认知更接近该领域的专家，这样后面的学习才能事半功倍。

今天这节课里，我们主要会讨论后面这几个问题。

- AI大模型是什么？
- AI大模型能做什么？
- 为什么说AI大模型是新一代应用平台？

理解了这几个问题，你才能真正进入到属于技术人的AI大模型世界。

## AI大模型是什么？

我相信在过去的一年里，你经常听到各种名词，比如大模型、AI模型、生成式AI、AIGC、生成式AI大模型等等。好像机器突然被魔法棒点中，瞬间觉醒了智能，现在已经学会了诗歌和绘画，接下来就要开始统治和奴役人类。
<div><strong>精选留言（11）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/f1/d7/3d129aa2.jpg" width="30px"><span>润泽</span> 👍（0） 💬（1）<div>请问学习本课程、以及从事大模型工作，需要具备较强的数学基础吗？</div>2024-03-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/c4/51/5bca1604.jpg" width="30px"><span>aLong</span> 👍（2） 💬（1）<div>结合最近OpenAI出现的反转剧情来看。 “以担心人工智能系统将达到不可控程度” 这方面的内容确实存在的问题。 尤其是在 IILYA 的一些课看法中感觉到IILYA对OpenAI安全政策的批评是具有建设性的。OpenAI应该认真考虑IILYA的建议，并采取措施加强AI安全。
 
具体来说，两者有以下相似之处：
1. 都认为AI技术存在一定的风险。
2. 都认为需要采取措施加强AI安全。
3. 都建议建立独立的机构来监督AI技术的开发和使用。

而马斯克旗下的Grok。又是联名信后的另一个产物，我不知道他内心是怎么想的。挺半年这个措施，如果是为了商量讨论怎么来制定安全有关的会议，我想那可能还是单纯的考虑安全问题。但是Grok的出现，以及他平时宣传风格。马斯克的安全意识还是要加引号的。</div>2023-11-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/22/ae/8a2945c8.jpg" width="30px"><span>_MISSYOURLOVE</span> 👍（6） 💬（1）<div>目前的工作就是调用openAI的接口，为其包装一层供公司各部门的业务人员使用，提高效率。希望能在老师得带领下，踏上这趟不一样的列车</div>2023-08-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/c4/9d/0f4ea119.jpg" width="30px"><span>周晓英</span> 👍（3） 💬（1）<div>个人感觉马斯克的担心有一定的道理，由于大模型已经学习了海量人类知识和经验，且具备学习和推理能力，按照这个发展趋势，出现接近或超越人类的智商是有可能的，且这一点如果被坏人利用，很容易对人类产生伤害。AI技术是双刃剑，必要的监管是需要的。但马斯克的公开信或许也有自己的目的，用于拖延一下对手的发展速度，为自己企业推出业界最具竞争力的大模型之一争取时间。
但从另外一个角度思考，出现强人工智能、超人工智能需要大量的计算资源、数据和时间进行训练和优化，目前可能不会很快出现这一情况？</div>2023-09-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/90/19/b3403815.jpg" width="30px"><span>Juha</span> 👍（3） 💬（2）<div>7月13日，「网信中国」官方发布了：「生成式人工智能服务管理暂行办法」，将于8月15日正式施行。
对于这个，老师是啥看法呢～</div>2023-08-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/60/a1/45ffdca3.jpg" width="30px"><span>静心</span> 👍（2） 💬（1）<div>马同志是在表示：你们跑得太快了，我已经追赶不上你们了，等等我，咱一起跑！</div>2023-10-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/85/49/101d4ba3.jpg" width="30px"><span>Lucky+</span> 👍（2） 💬（1）<div>马斯克的担忧是基于人工智能的快速发展和潜在的滥用。他担心的“不可控的程度”可能是指强人工智能或超级智能，这种智能可能超过人类智能，有自我意识和自我改进的能力。如果没有适当的控制和道德框架，这样的系统可能会做出对人类不利的决策。

通向这种情况的技术路径可能包括深度学习、机器学习、神经网络和其他人工智能技术的进一步发展和完善。这些技术的发展需要大量的研究和开发，以及大量的计算资源和数据。因此，成本可能会非常高。

然而，这并不意味着我们应该停止发展人工智能。相反，我们应该制定更严格的法规和道德框架，以确保人工智能的安全和有益的使用。同时，我们也需要对人工智能的潜在风险有更深入的了解和研究。</div>2023-09-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/9e/50/21e0beca.jpg" width="30px"><span>kylin</span> 👍（2） 💬（1）<div>老师，请问：重要的 AI 应用，如 AlphaZero 和无人驾驶，能够以较低成本自动生成训练数据，能不能举个具体的例子说明如何自动生成训练数据呢</div>2023-08-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/23/bb/a1a61f7c.jpg" width="30px"><span>GAC·DU</span> 👍（1） 💬（1）<div>现在这个“大胖孩子”已经在风口上顺势起飞，不禁要问为啥停训六个月，而不是停训六年，六个月能有什么意义，暂缓一两个大版本的跨越？估计是成老马节奏带不动了吧</div>2023-08-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/db/95/daad899f.jpg" width="30px"><span>Seachal</span> 👍（0） 💬（0）<div>AI大模型是热门话题，本文探讨其定义、应用和技术发展。基础模型是大型机器学习模型，经大量数据训练以适应下游任务。AIGC应用展现大模型技术追求“大”的趋势。数据规模和计算能力增加推动模型参数扩大。文章以“一切皆为训练数据”时代作结，强调大模型发展持续。大模型兴起源于多因素，如语言模型能力涌现、跨模态建模发展及生成式模型交互提升。存储和计算能力是其前提，大模型在翻译、创意、创作和代码编写上表现出色，但面临时效性和因果推断局限。工业级系统需应对这些局限，大模型平台将提升生产效率。马斯克呼吁暂停训练更强大AI，担忧不可控风险。本文深入探讨AI大模型技术特点和发展趋势，引发深刻思考</div>2024-11-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/e7/b6/c9b56731.jpg" width="30px"><span>St.Peter</span> 👍（0） 💬（0）<div>没有CCF这一类的论文，是不是很难从事大模型的算法方面的工作啊</div>2024-11-11</li><br/>
</ul>