你好，我是Tyler！

最近，大家对大模型技术的关注越来越高，也不断有人询问我对最新发展的看法。这让我深刻感受到，**生成式 AI 已经从一个前沿技术话题，逐渐成为许多人学习、研究甚至实际应用的重点。**

随着行业的快速演进，很多新趋势、新突破值得我们深入探讨。因此，我决定做一次课程的加餐迭代，和大家统一交流一下最近的观察与思考。

回顾此前的课程，在《[31｜发展趋势：生成式AI系统的未来发展趋势是什么？](https://time.geekbang.org/column/article/720951)》里，我曾经提到几个关键趋势：  
混合专家模型（MoE）是大模型参数进一步优化的重要方向。  
大模型技术正在加速平民化，越来越多的开发者和企业可以直接获取和应用这些能力。

如今，随着 DeepSeek V3 和 DeepSeek R1 等开源模型的发布，这些趋势正在逐步成为现实。

混合专家模型的价值已经得到验证，它能够通过智能调度计算资源，提升大模型进一步享受 Scaling Law 红利的可行性，帮助开源公司构建出可以和 OpenAI 分庭抗礼的开源模型。

而 DeepSeek R1 的开源，则让更多人有机会深入研究和优化大模型，使 AI 生态更加开放、多元。

在这次的课程迭代中，我会围绕这两个趋势展开，深入剖析它们对未来的影响。

首先，我们会重点探讨以 DeepSeek V3 为代表的混合专家模型，它是如何优化推理效率，并可能成为未来主流架构之一的。