你好，我是Tyler。

上节课我们学习了模型工程相关的知识，你掌握得如何？今天，我们来进一步学习更多的数据算法。

其实数据算法的本质是对人类智能的仿生，作为人类，我们进化出了神经反馈系统、大脑和各种感官。我们与生俱来的眼耳鼻舌身意这些高配传感器，还有大脑这个深度神经网络，让我们成为万物灵长，稍加学习就能适应外部世界。

不过作为AI系统造物主的你，就没那么轻松了。你需要先发挥自己的聪明才智，替AI系统去选择合适的输入数据，才能让你的AI系统足够智能。

你可能会问，为什么非得我们代劳，来完成选择数据的工作呢？我举个例子你就明白了。

假设，我们希望让一个智能体快速察觉到班主任的凝视，这个智能体很难自己判断哪些“数据”是重要的，它需要问遍身体的每一个传感器，才有可能找到传感信号和探测目标之间的关系。而我们只需要根据生活经验稍作思考，就知道最有价值的是听觉和视觉信号，只要将摄像头和麦克风信号供给模型，它就能判断是否有“危险”了。

在AI系统里也是同样的道理，我们利用人类的经验把数据分成了主体数据、客体数据和环境数据这三类数据。比如在无人驾驶和车联网系统中，这三类数据对应的是车辆数据、交通流数据和环境数据。

再比如我们熟悉的AIRC系统，它利用数据包括用户特征、物品特征和场景特征。这些数据都遵循了主体、客体和环境这种划分方式。
<div><strong>精选留言（4）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/15/23/bb/a1a61f7c.jpg" width="30px"><span>GAC·DU</span> 👍（18） 💬（1）<div>主体在对话中，主体通常指的是模型或参与对话的用户。
客体指的是主体在对话中讨论的主题、事物或概念。在对话中，主体通常会涉及一个或多个客体，以其问题、回答或讨论内容来定义对话的方向和主题。
环境数据是在对话过程中提供背景信息和上下文的数据。这些数据可能包括对话历史、之前的提问、回答，以及在对话中引入的其他文本。环境数据有助于理解对话的脉络，确保主体对当前对话情境有准确的理解。
用户特征
提供明确的指导，例如要求ChatGPT以特定的语气、风格或格式回答问题。这有助于模型生成更符合用户预期的内容。在对话中提供反馈，指出哪些回答是有用的，哪些回答需要改进。这有助于模型逐步调整生成内容。参考之前的对话历史，以便模型可以更好地理解用户的偏好、兴趣和问题，有助于生成更连贯和相关的内容。
内容特征
提供准确详细的信息，以便模型可以从中获取更具信息价值的内容。在问题中提供清晰的背景和上下文，以确保模型理解问题的背景，从而生成更恰当的回答。避免使用模棱两可的语句，特别是当涉及到多个可能的含义时，这可以减少模型误解意图的可能性。
场景特征
如果对话涉及特定领域的知识，提供相关的专业术语和背景信息，以确保模型在生成内容时具有正确的专业性。考虑到文化差异和语境，以便模型可以生成适合特定文化和背景的内容，避免可能的误解或冒犯。如果需要特定风格的回答，可以明确指示模型使用哪种语气、语言风格或情感色彩。

场景特征更关注于对话的背景和环境，而用户特征更关注于对话中的用户需求和个性化，场景特征通常包括对话主题、领域和文化等，而用户特征包括用户指令、历史记录和风格偏好等。而“用户最近 30 分钟内，观看的运动类视频数量”属于和时间相关的用户行为特征。

三种算法包括拿知识的实体识别算法，合知识的实体关系抽取算法，学知识的图数据学习算法。

</div>2023-08-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/c4/9d/0f4ea119.jpg" width="30px"><span>周晓英</span> 👍（3） 💬（0）<div>在 ChatGPT 的设计中，可以将 &quot;主体&quot; 理解为模型自身，&quot;客体&quot; 理解为与模型交互的用户，而 &quot;环境&quot; 则是交互的上下文环境，包括但不限于用户的输入、对话的历史记录以及外部信息等。

1. 基于用户、内容和场景的特征优化内容生成:
用户特征: 用户的行为、偏好、历史交互记录等。例如，用户的年龄、性别、喜好、之前的查询等。
内容特征: 输入的内容、模型的回复、外部知识源等。例如，文本的复杂度、情感、主题等。
场景特征: 对话的场景、时间、地点等。例如，对话的目的（如咨询、购物、娱乐等）、时间、地点等。
优化步骤：
特征工程：首先需要进行特征工程，提取和构建与用户、内容和场景相关的特征。
模型定制：根据这些特征定制模型结构，例如，通过添加特征嵌入层或特征条件层来整合这些特征。
训练和调优：使用带有这些特征的数据进行模型训练和调优，以改善内容生成的质量。
2. 特征分类:
“用户最近30分钟内，观看的运动类视频数量”这个特征应该是一个用户特征，因为它反映了用户的实时行为。
3. 知识图谱构建三个步骤中的算法选择:
构建知识图谱通常包括三个基本步骤：实体识别、关系抽取和知识融合。

实体识别: 可以选择条件随机场 (CRF) 算法，它是一种有效的序列标注算法，常用于实体识别任务。
关系抽取: 卷积神经网络 (CNN) 或 循环神经网络 (RNN) 可以被用于关系抽取，通过学习文本中的模式来识别实体间的关系。
知识融合: 同源性检测算法 (如 SimRank) 可以用于知识融合，以识别和合并来自不同源的重复或相似的知识。</div>2023-10-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/ff/7b/cbe07b5c.jpg" width="30px"><span>顾琪瑶</span> 👍（1） 💬（0）<div>1. 数据:
1.1 主体: GPT本身, 或者说是模型自身
1.2 客体: 不同的用户
1.3 环境: 不同用户的上下问数据
2. 质量:
2.1 用户: 
2.1.1 时区或位置(IP): 由于不同地区的发展程度不一致, 相同的问题更合适的答案应该也是不同的
2.2.2 特征: 根据提问内容检索提出相似问题的人群, 如更倾向于科普类, 或专业类
2.2 内容: 可以考虑在响应用户回答后, 再选择几个相似度高的答案, 作为备选, 拓展用户的提问思路引导用户
2.3 场景: 如果是非通用型大语言模型, 可以在应用层就提示模型, 当前是属于什么场景下的提问, 如购物, 检测等, 提高模型的准确度
3. 区分: 更偏向于用户特征
3.1 场景特征: 可适用于观看视频的场景太多, 几乎任何和平地区且有网络的地区都可以</div>2023-08-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/db/95/daad899f.jpg" width="30px"><span>Seachal</span> 👍（0） 💬（0）<div>学完这课，对数据在AI系统里的应用有了点新体会。用户画像、物品特征和场景特征，这三块都得搞明白。用户画像嘛，就是得挖掘用户数据，用Look-alike算法找找相似人群。物品特征，得靠知识图谱，把物品都连起来。场景特征，就是得结合对话的上下文，理解用户的真实需求。

还有啊，别忘了多观察生活，多和数据打交道，这样才能真正理解用户习惯，找到关键特征。图神经网络、知识图谱、跨模态预训练模型这些技术，都是AI大模型的基石，得好好学。

另外，特征优化这块也挺有意思。用户特征、内容特征、场景特征，都得考虑进去，这样才能生成更符合用户预期的内容。特征工程、模型定制、训练和调优，这些步骤都不能少。

说到算法，实体识别可以用CRF，关系抽取CNN或RNN都行，知识融合可以试试SimRank。这些都是构建知识图谱的好帮手。</div>2024-11-23</li><br/>
</ul>