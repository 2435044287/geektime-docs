你好，我是 Tyler。

前面我们一起学习了提示语工程方法，你掌握得如何了？从今天开始，我们即将踏入一个新的篇章——模型工程。

正式开始之前，我想先从顶层帮你理解一下两者之间的异同。其实这两个领域的工作，本质上都是进行知识注入。不同的是，提示语工程采用了上下文学习的方法，通过提供少量示例代码向模型注入新知识。而模型工程则是通过参数学习的方法（更新模型参数）学习新知。

在模型工程部分，我们的学习重点就是理解参数学习的体系和方法。今天我们要解决的关键的问题是参数学习的数据从何而来。

## 模型发展

为了学习模型工程，我们先来学习一下 OpenAI 大火之后，陆续出现的一些大模型工作。我相信你在很多地方都已经见过各种各样的大型语言模型，比如那些经典的“羊驼系列”，包括LLAMA（美洲驼）、ALPACA（羊驼）、VICUNA（小羊驼）、GUANACO（骆马），甚至是华佗（不过因为大家开的玩笑多了，现在已经改名为“本草”）。

![](https://static001.geekbang.org/resource/image/5d/d1/5dca3968f8bc94214b2b91a62975bdd1.jpg?wh=4000x2250)

在阅读这些论文后，你会发现，在这些研究中，他们都在努力回答两个关键问题——**第一个问题是如何获取训练数据，第二个问题是如何获得足够的计算资源。**

这两个核心问题，也是每个涉及大型模型训练的技术团队都不可避免的现实挑战。幸运的是，由于这两个问题足够重要，目前已经有许多的公开研究工作在致力于解决这些难题。
<div><strong>精选留言（2）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/11/ff/7b/cbe07b5c.jpg" width="30px"><span>顾琪瑶</span> 👍（5） 💬（1）<div>上限:
* 就目前使用GPT来生成样本数据集的话, 那么上限应该是GPT模型本身的知识范围, 在多次对特定领域进行样本数据生成时, 次数越多, 重复的样本也会相应增多</div>2023-10-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/bc/d0/7a595383.jpg" width="30px"><span>l_j_dota_1111</span> 👍（1） 💬（1）<div>如果相对垂直领域进行模型微调，但是现在的垂直领域的数据都是文本（就是一个一个word文档），如何生成可以使用的样本数据呢（任务就是正常的对话）</div>2024-01-09</li><br/>
</ul>