你好，我是Tyler。

前几节课，我们学习了提示语工程和模型工程。你掌握得如何？今天，我将带你整体回顾架构实战篇所学内容，并且为你揭开AI大模型系统的面纱。除了回顾总结，我还会带你从真实应用的角度了解如何构建一个AIGC系统。在这节课中，我将更多地结合我的亲身经验，为你提供一些在其他地方无法获得的具体例子。

我们首先来探讨离线系统，因为通常在开发一个系统时，都会按照先离线，后在线的顺序进行。

## 模型工程

设计离线系统的第一步，就是清晰梳理我们系统的数据流程。下面我将带你一步步梳理AIGC系统中模型训练的数据链路。

![](https://static001.geekbang.org/resource/image/e2/aa/e2a0076eeb72d029b9a55a26cfef81aa.jpg?wh=4000x1532 "全量模型训练流程")

首先是模型训练的数据流程。

在大语言模型对话应用中，我们可以收集到丰富的对话信息，这是宝贵的指令微调语料，AI系统会将这些对话内容，上报并存储到服务端，来获取足够多的对话数据，供给模型训练使用。

这里需要注意的是，你要重点甄别对抗样本，避免它成为攻击你大语言模型的武器，我们不能假设所有的日志反馈都是安全的，必须进行后续的风控处理，使用专门的分类模型，来识别对抗样本，并将它们从训练数据中剔除。当然这主要是离线风控策略的流程，在线的风控策略关注的主要还是模型越狱和内容安全的风险。

具体而言，你可以用OpenAI的母公司微软开源的 [PromptBench](https://github.com/microsoft/promptbench.git) 来实现你的风控策略，虽然现在各大厂使用的方法更健全，但是这个项目已经是一个很好的开源替代选择，麻雀虽小，五脏俱全。
<div><strong>精选留言（1）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/14/c4/9d/0f4ea119.jpg" width="30px"><span>周晓英</span> 👍（5） 💬（0）<div>个人浅见：在我工作的领域，工业级 AI 大模型系统与原型验证工具（如 Langchain 和 AutoGPT）之间的区别，主要是工业级AI要通过严密的测试，确保系统提供的内容百分之百准确、合规、没有法律风险，能支撑大量用户并发，在用户体验、响应速度、系统成本中间找到平衡。如果受合规制约，调用的是国产大模型，没有像OpenAI那么完善的生态支持，还要做很多的胶水组件，探索很多细节。by the way 国产大模型的能力正在追上来，比如10月27日发布的智谱Chatglm3</div>2023-10-29</li><br/>
</ul>