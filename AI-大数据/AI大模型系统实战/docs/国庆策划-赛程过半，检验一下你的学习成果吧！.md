你好，我是Tyler。

国庆即将到来，为了让你过节期间能够轻松一些，同时也能巩固之前所学，从10月2日到10月8日，我们会暂停三次更新。已经跟上学习进度到同学，不妨复习一下前面所学，查漏补缺。还没有跟上大部队的同学，也可以利用这个时间继续学习。

另外，为了帮助你检验学习效果，我从之前的课程里精选了一些知识点，定制了后面这套测试题。客观题的答案和解析，你在测试后就能直接看到。

至于主观题，我选择了一些你在学习中很可能会忽视，或者误以为自己已经理解的一些信息。同样，因为这些常见误区往往也会出现在行内人的身上，所以这也是面试中常常出现的题目。

首先是选择题的环节。你点击文稿下方按钮，就可以进入测试。

[![](https://static001.geekbang.org/resource/image/28/a4/28d1be62669b4f3cc01c36466bf811a4.png?wh=1142%2A201)](http://time.geekbang.org/quiz/intro?act_id=6360&exam_id=13744)

接下来是三道主观题。这三道题目**既跟课程内容密切相关，也是我们招聘AIGC技术人才时，从校招生到技术专家的面试中都会经常会考察的内容**。期待在留言区看到你的分析和思考。

1.现在各类 AIGC 应用产品逐渐深入人心，人们越来越熟悉通过自然语言与模型对话的方式。然而，因为AI大模型系统对提示语的层层优化封装，大多数人已经混淆了用户提供给 AIGC产品的提示词和大语言模型中所说的上下文学习中的提示词的含义。所以，这里希望你做一个辨析，你觉得上下文学习的本质是什么，提示词的两个主要作用是什么？
<div><strong>精选留言（3）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/1f/3b/42/73cdf913.jpg" width="30px"><span>蚂蚁压路</span> 👍（0） 💬（2）<div>上下文学习的本质是模型具有的少样本学习few shot learning特性，对吗？提示词的作用，第一是给模型提供任务的样本，第二是让模型理解如何完成任务。</div>2024-02-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/ff/7b/cbe07b5c.jpg" width="30px"><span>顾琪瑶</span> 👍（1） 💬（0）<div>1.1 ICL的本质: 我认为是让模型明确自己对当前任务的定位或者说是&quot;角色&quot;, 以及这个&quot;角色&quot;应该有哪些行为特征, 最终以什么样的形式来完成任务
1.2 prompt的作用: 
* 1: 与模型沟通的技巧, 掌握此技巧能够更清晰的向模型表达自己的需求和意图
* 2: 没想到

2. 反zuobi特征:
* 针对国家及地区的政策对模型进行微调, 防止出现敏感相关的内容
* 使用多种模型, 对垂直领域的回答进行校验, 让模型与模型对抗

3. 反思&amp;规划:
* 每当current agent与another agent交互时, 都让current agent以当前的自身的角色定位与another agent输出的内容进行思考, 如: &quot;你作为一名[优秀的&#47;专业的&#47;负责的&#47;xxx的]医生, [热爱&#47;专注]家庭的[丈夫&#47;妻子&#47;儿子&#47;女儿]来思考一下[another agent name]所说的内容是否符合你自身[价值观&#47;行为准则&#47;目标方向], 如认为自身的信息量不足, 则可以通过联网的功能查询对应角色的定位信息再来进行思考, 如果你认为[another agent name]说的有理, 则记录在某个记忆区, 回去再和自身的家庭成员讨论, 如果大多数都认为是有理的, 则更新你自身的价值观信息&quot;</div>2023-09-28</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erms9qcIFYZ4npgLYPu1QgxQyaXcj64ZBicNVeBRWcYUpCZ9p0BGsrEcX8heibMLCV4Gde4P9pf7PjA/132" width="30px"><span>yanger2004</span> 👍（0） 💬（0）<div>又🐮又勤奋👍</div>2023-09-28</li><br/>
</ul>