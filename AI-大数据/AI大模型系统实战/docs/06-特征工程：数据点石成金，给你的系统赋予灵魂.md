你好，我是Tyler。

上节课我们学习了AI系统的建模策略，你掌握得如何？希望你已经对AI系统有了初步的了解。从今天开始，你将学习与AI系统特征工程相关的内容。

特征工程其实是数据工程的一部分，我们把它单独拿出来讲是因为特征工程是数据工程的灵魂，而且它与模型工程也密切相关。从这节课开始，我们的课程也逐渐进入深水区，请你带好泳镜泳帽，我们要开始学游泳了。

其实特征工程和模型工程没有特别明显的边界，许多特征工程的动作，在足够复杂的模型中已经被自动化掉了，所以你要清楚，特征工程主要是为了帮助模型减轻压力。

我先用一句话概括一下特征工程的核心工作：特征处理的过程**是对数据进行微观和宏观投影的过程**，所以虽然叫特征处理，但特征本身其实没有变化，变的只是你观察的维度。接下来，我会循序渐进，带你从不同的维度观察特征。

## 从特征到特征

我先举个例子，让你直观理解一下从不同观察角度提取的特征，它们的差异有多大。

如果将光作为一个特征，你只能告诉模型这里有一条光线。但是如果加上一个三棱镜，你便可以告诉模型，这里有七种颜色的光。

是不是找到一些感觉了？其实这是在从不同角度刻画你的特征，其实是在寻找**特征的特征**。

![](https://static001.geekbang.org/resource/image/56/61/56bdd37895b3c246ef2151311edb0261.jpg?wh=3900x2194)

通常情况下，合理的数据变换能帮助现有模型更好地理解样本中的信息。一个常见的例子是年龄特征，因为往往各年龄段用户的数据量往往参差不齐，所以如果你给模型的特征是年龄，它学起来可能会很吃力。
<div><strong>精选留言（16）</strong></div><ul>
<li><img src="" width="30px"><span>Paul Shan</span> 👍（24） 💬（2）<div>独热编码是如何处理分类特征的？
独热编码是把每个类型分配一个维度，这样不同的维度可以做到独立和正交
为什么需要进行正交的空间投影？
正交投影是确保了维度不缩小，并且不同的维度不相关，在这个基础上可以压缩维度和寻找关系，如果不正交的话，必然预设了不同维度之间的关系，这些预设值很可能和现实不符，会增加了模型走弯路的可能，如果丢失了维度，再让模型回到原来的维度就不可能了，高维映射到低维是可能的，反之就不可能了。
解释一下在高维空间刻画特征距离的意义和作用。
特征在高维空间中的距离反应了事物的相似程度，可以用来聚类和分类</div>2023-08-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/4f/81/3c228f3a.jpg" width="30px"><span>张金磊</span> 👍（4） 💬（3）<div>老师，明明都是数字的向量，为什么在NLP这里就叫嵌入（虽然是中文的翻译，但英文原文也不是 vector)，非常想知道这个答案，有什么历史“渊源”吗？或者去哪里查资料可以知道这个问题的答案，谢谢老师</div>2024-02-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg" width="30px"><span>piboye</span> 👍（2） 💬（1）<div>老师， 现在词的embedding 还是用 cbow, skip-gram 来训练的吗？</div>2023-10-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/23/bb/a1a61f7c.jpg" width="30px"><span>GAC·DU</span> 👍（2） 💬（1）<div>独热编码将每个分类值转换为一个二进制向量，其中只有一个元素为1，其余元素为0。优点是独立，缺点是可能会引入大量维度，导致维度灾难。
进行正交空间投影是为了数据降维，减少数据的维度，解决独热编码的缺点。
高维空间中刻画特征距离的意义在于帮助理解数据的结构、相似性和关联性，从而支持各种数据分析和机器学习任务。选择适当的距离度量方法，在特征工程中，通过分析特征距离，可以帮助选择最具信息量的特征，从而提高模型的性能和效率。</div>2023-08-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/bf/52/59304c42.jpg" width="30px"><span>默默且听风</span> 👍（0） 💬（1）<div>从空间到世界:这部分基本上能懂
从低维到高维:这部分结合one-hot encoding和代码能get到
从特征到特征:这个还有什么例子吗？脑子里基本没有想象空间啊，我现在的大脑就像那个三菱的光一样什么一没存住</div>2023-11-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/bc/d0/7a595383.jpg" width="30px"><span>l_j_dota_1111</span> 👍（0） 💬（1）<div>三个类型可以相互正交，但是超过三个如何相互正交呢，还有就是为何要保证每个类型相互正交</div>2023-09-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/c2/cf/f64d6c9d.jpg" width="30px"><span>`¿`</span> 👍（0） 💬（1）<div>为啥听了之后，后面的问题还是不太能回答。是需要补充更多概念知识嘛</div>2023-09-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg" width="30px"><span>peter</span> 👍（0） 💬（1）<div>第5讲中的PID是自动控制中的PID吗？</div>2023-08-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/1a/f3/41d5ba7d.jpg" width="30px"><span>iLeGeND</span> 👍（0） 💬（1）<div>怎么感觉特征是离散的呢，怎么组成语言句子呢</div>2023-08-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/c4/9d/0f4ea119.jpg" width="30px"><span>周晓英</span> 👍（6） 💬（3）<div>独热编码 (One-Hot Encoding):
想象一下你有一盒彩色的蜡笔，有红色、蓝色和绿色。我们想把这些颜色告诉计算机，但计算机只能理解数字。独热编码就是一种解决办法。我们为每种颜色分配一个特殊的数字序列。例如，红色可以是[1, 0, 0]，蓝色是[0, 1, 0]，绿色是[0, 0, 1]。这样，每种颜色都有一个独一无二的数字序列，计算机就能区分它们了。

正交空间投影 (Orthogonal Projection):
正交空间投影有点像是影子。想象一下，当阳光直射到你身上时，你的影子会掉到地上。在这个过程中，三维空间（你的身体）被简化为二维空间（影子）。正交投影是一种特殊的投影，它保留了一些重要的信息，使得原始的数据（你的身体）和投影后的数据（影子）之间的关系更清晰。

高维空间中的特征距离 (Feature Distance in High-Dimensional Space):
在高维空间中，我们可以通过测量点之间的距离来了解它们的相似度。比如说，如果我们在一个大商店里，每个商品都放在不同的位置，我们可以通过测量两个商品之间的距离来了解它们是否相似或相关。在高维空间里，每个维度代表了一个特征，比如颜色、大小或品牌。通过测量这些特征的距离，我们可以更好地理解和比较不同的商品。

高维空间的特征距离对于机器学习和数据分析非常重要，它帮助我们理解数据的结构，找到相似的点，甚至可以帮助我们预测新数据点可能属于哪个类别。</div>2023-10-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/6d/87/0b8bddb5.jpg" width="30px"><span>Ghostown</span> 👍（1） 💬（0）<div>有个疑惑的地方，male，female，unknow分别被one-hot编码之后表示成[1,0,0] [0,1,0] [0,0,1]之后，这三个特征的距离（三维空间欧氏距离）也就是关系被固定了，那么如何再在后面学习并更新三者之间的关系呢。还是说[1,0,0] [0,1,0] [0,0,1]只是代表向量空间的正交基，具体的male，female，unknow特征会在后面学到，可能学到的值是male:[0.9, 0.1, 0] female:[0.8, 0.2, 0] unknow:[0.5, 0.5, 0]，望老师解惑！</div>2023-12-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/db/95/daad899f.jpg" width="30px"><span>Seachal</span> 👍（0） 💬（0）<div>特征工程，AI里的重头戏，给数据做个“变身”，让模型看得更清。年龄离散化、数值变换，都是为了让模型吃得懂；特征交叉、低维到高维，看得更全面。独热编码，更是数据高维旅行的必备“护照”，特征间互不干扰。说到底，特征工程就是给模型送“大餐”，让它吃得准、吃得香，提升准确性和泛化力。这篇文章，就像是个开胃菜，让人对特征工程有了个初步了解。还有预训练模型、空间关系那些，对比学习，让模型在高维空间里找关系，更懂特征的真实含义。学完之后，感觉特征工程挺有意思的，还得继续深入探索。</div>2024-11-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/db/95/daad899f.jpg" width="30px"><span>Seachal</span> 👍（0） 💬（0）<div>特征工程，AI里挺关键的一环，给数据做“美容”，让模型看得更清。文章里，比喻、实例一堆，把特征工程那点事儿说得挺透。年龄离散化、数值特征变换，都是为了模型好消化。特征交叉、低维到高维，也是常用手法。独热编码，更是把数据送上高维高速路，特征间互不干扰。说白了，特征工程就是让模型吃得准、吃得饱，提高准确性和泛化力。这篇文章，算是入门级的“菜谱”，让人对特征工程有了个大概认识。还有预训练模型、空间关系那些，对比学习，让模型在高维空间里找捷径，理解特征的真实关系。</div>2024-11-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/39/0d/d1/045d5726.jpg" width="30px"><span>Clying Deng</span> 👍（0） 💬（0）<div>Skip-gram 和 CBOW是通过草料中单词和单词同时出现的概率来推出词与词的空间距离吗？如果是这样的话 经书 预处理效果就很差了</div>2024-10-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/bc/d0/7a595383.jpg" width="30px"><span>l_j_dota_1111</span> 👍（0） 💬（0）<div>针对这句话“羽毛球与高尔夫、钓鱼之间一定关系更近，而羽毛球与绘画、插花之间一定关系更远。可是在独热编码之后，它们在空间中的距离可是一模一样的，这时候只能让模型不断地总结学习，才可能得到它们之间的关系”，独热编码后，这些词在高维空间中都是正交的，那么经过让模型不断学习，这些词经过相似度表达后，会调整他们在空间中的位置吗，在高维空间中从正交变成不正交吗</div>2023-12-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/9a/ab/fd201314.jpg" width="30px"><span>小耿</span> 👍（0） 💬（0）<div>1.热独立编码将每一个分类特征映射到空间中一个独立的维度，确保特征之间数值上是正交关系，以此保证每一个特征都能被模型很好的区分出来。
2.正交的空间投影应该是为了保证模型训练的时候，不会把不同特征混合起来无法辨认，而是每一个特征都能被独立识别，这样才能分类相对准确。
3.特征距离可以表达两个特征之间的亲密度。他可以作为预训练模型的一个参数，以此给正式的模型训练一些提示。</div>2023-11-14</li><br/>
</ul>