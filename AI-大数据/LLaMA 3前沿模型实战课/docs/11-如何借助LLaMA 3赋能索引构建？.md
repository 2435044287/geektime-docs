你好，我是Tyler！

上节课我们讨论了检索增强生成（RAG，Retrieval-Augmented Generation）方法中 LLaMA 3 所能带来的提升。今天，我们将深入学习LLaMA 3在实际应用中的作用。计算机科学领域有一句常用的话：“垃圾进，垃圾出。” 这句话强调了输入数据的质量对系统输出结果的决定性作用。

在基于RAG的模型中，输入数据的质量至关重要，它直接决定了生成内容的优劣。RAG 模型主要由两个环节组成：检索（Retrieval）和生成（Generation）。简而言之，R 负责从知识库中检索相关信息，G 基于检索到的内容生成自然语言回答。由此可见，检索阶段的输入质量直接影响生成阶段的表现。如果想提高生成结果的准确性与上下文相关性，首先需要专注于优化检索阶段的表现，例如提高知识库的覆盖面、检索算法的准确度，以及过滤无关信息的能力。

## 基于文章片段向量检索的问题

当前许多 RAG 实现采用基于文章片段的向量检索技术，这种方法虽然在某些应用场景下提升了效率，但也存在一些明显的局限性。

1. **语义信息碎片化**：为了适应向量检索的机制，长篇文章通常会被切割成多个独立的小片段。然而，这种片段化处理会割裂文章的语义联系，无法完整保留原文中的上下文关联。在生成阶段，系统由于缺乏跨片段的语义信息，可能输出不连贯或前后矛盾的回答。
2. **歧义性问题**：向量检索在处理多义词时容易受限于局部片段的信息，无法理解词语的上下文语境。例如，“cloud”既可能指“云计算”，也可能指“气象云”，甚至日常生活中的“云”。如果模型无法正确消解歧义，检索内容可能偏离用户预期。
3. **缺乏全局知识**：向量检索基于片段化的文档信息，通常缺乏对整体语境或跨领域知识的综合理解。这使得系统在应对需要全局视角或跨领域信息的任务时表现较差，生成的回答难以深入挖掘信息之间的复杂关系。