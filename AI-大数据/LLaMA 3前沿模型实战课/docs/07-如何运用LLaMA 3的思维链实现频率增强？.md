你好，我是 Tyler。

在上一节课中，我们学习了如何构建一个简易的ChatGPT模型，这为我们后续的学习奠定了基础。你们已经掌握了生成式预训练模型的基本原理，并了解了如何应用这些原理来实现类似ChatGPT的对话系统。这节课，我们将继续深入，讨论LLaMA 3模型在进行多轮推理时的局限性，并探讨如何有效应对这些挑战。

在第四节课中，我们详细了解了基于思维链（Chain of Thought, CoT）的多步推理方法。这种方法通过将复杂问题分解成多个易于处理的子问题，逐步推进推理过程，从而帮助我们更有效地解决复杂的推理任务。尽管思维链在提升推理准确性方面有其优势，但在处理多轮推理任务时也暴露出了一些局限性。

## LLaMA 3在多轮推理中的局限性

LLaMA 3模型基于自回归的生成方式进行文本生成，即通过预测下一个字符或单词来逐步构建完整的句子或段落。这种方式在大多数情况下表现良好，能够生成流畅且连贯的文本。然而，在处理复杂的、多步骤推理任务时，模型可能会出现**不一致**的表现——在多次尝试中，模型可能会给出不同的答案，有时是正确的，但其他时候可能出现错误。这种不一致性主要源于以下几个方面：

- **上下文依赖性**：自回归模型在生成文本时依赖于先前生成的内容。如果前文的推理或上下文信息存在误差，后续的生成也可能受到影响，导致不一致的输出。
- **推理路径的随机性**：自回归生成的过程包含一定的随机性，尤其是在温度采样较高时，这可能导致模型在相同问题上产生不同的回答。
<div><strong>精选留言（1）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/83/7f/7b1f3f68.jpg" width="30px"><span>willmyc</span> 👍（1） 💬（0）<div>老师，您好，这段代码 # 统计推理结果并寻找最常见的答案def extract_answer(text):    # 尝试从文本中提取数字    match = re.search(r&#39;\d+&#39;, text)    if match:        return int(match.group(0))    return None，准确的做法是否应该是匹配最后一个数字，因为模型的生成结果中第一个数字一般会是推理过程的输出的数字，并不是最终的答案，所以我把代码改成了下面这样，# 统计推理结果并寻找最常见的答案
def extract_answer(text):
    # 尝试从文本中提取数字
    match = re.findall(r&#39;\d+&#39;, text)
    if match:
        return int(match[-1])
    return None</div>2024-12-05</li><br/>
</ul>