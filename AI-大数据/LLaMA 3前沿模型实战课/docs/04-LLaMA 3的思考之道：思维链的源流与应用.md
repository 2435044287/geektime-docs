你好，我是Tyler。

在上节课中，我们讨论了如何将大模型从传统的“对话框”应用场景中解放出来，通过指令和工具的使用，扩展其在实际应用中的能力。然而，即便如此，大模型在处理复杂任务时，仍然会出现力不从心的情况。面对长篇复杂的任务描述，模型往往会抓不住重点，甚至可能产生一些奇怪的错误，这在实际应用中显然是不可接受的。

那么，如何让大模型在处理复杂问题时更加得心应手？研究人员通过不断的探索，提出了一种名为**思维链**（Chain of Thought, CoT）的技术。它不仅能帮助模型更好地理解复杂问题，还能逐步推理出准确的答案。今天我将带你深入探讨思维链的概念、应用场景、技术实现及其在未来智能体应用中的潜力。

## 什么是思维链？

思维链，顾名思义，就是引导模型进行逐步推理的链条。通过分步骤思考，模型能够在复杂的任务中逐渐接近正确答案，避免因直接跳到结论而产生的错误。这种方法最初是由一句简单的提示语“Let’s think step by step”衍生出来的。这句提示语告诉模型：“我们一步一步来，别急。”这句话可以显著提高模型在处理复杂问题时的准确性。

![图片](https://static001.geekbang.org/resource/image/14/52/14955c841ace33370ebfa0bc9241eb52.png?wh=940x473 "图片来源于 https://arxiv.org/abs/2201.11903")

在探讨思维链的过程中，我们需要思考一个重要的问题：所有的思维链是否都是链？实际上，思维链的灵活性和复杂性远不止于此。尽管“链”暗示了一个线性结构，但实际上，思维链可以表现为更加复杂的多步骤推理路径。这些路径有时可能是树状结构，有时则可能需要在多个平行的推理分支中进行选择和组合。因此，思维链的设计并非总是线性的，而是根据具体任务的复杂性和需求进行灵活调整。
<div><strong>精选留言（2）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/2b/63/57/b8eef585.jpg" width="30px"><span>小虎子11🐯</span> 👍（0） 💬（0）<div>课程代码地址：https:&#47;&#47;github.com&#47;tylerelyt&#47;LLaMa-in-Action</div>2024-11-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/86/fb/4add1a52.jpg" width="30px"><span>兵戈</span> 👍（3） 💬（1）<div>Tyler老师，学完了您《LLaMA 3 前沿模型实战课》的第4课，并跑通了其中的相关案例代码。

但我看当前工程中还一直没有第4课的工程代码，于是我提交PR：https:&#47;&#47;github.com&#47;tylerelyt&#47;llama&#47;pull&#47;2

您看看是否需要，可以Merge进来，或者直接上传您那边的工程代码：

对应课程代码，有些地方稍作修改，使得能运行成功或者更顺畅：

# 1、修改所有example中 response 的获取方式
response[&#39;content&#39;] -&gt; response[&#39;message&#39;][&#39;content&#39;]

# 2、example4 中添加step判断，减少循环次数
if step == &#39;&#39;:
    continue</div>2024-10-23</li><br/>
</ul>