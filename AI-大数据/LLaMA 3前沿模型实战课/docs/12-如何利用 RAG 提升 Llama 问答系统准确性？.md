你好，我是Tyler！

在上一讲中，我们学习了如何通过 LLaMa 3 来高效构建索引，提升 RAG 系统的输入质量。在这一讲中，我们将探讨如何优化 RAG 系统的在线检索效果，以确保生成内容的准确性和时效性。

## 知识冲突时的默认行为

在预训练过程中，LLaMA 3 积累了大量知识，主要分为两类。第一类是来自原始语料的历史实时信息，反映特定时间点的事实、事件或观点，但这些信息随着时间推移可能失去时效性。第二类则是模型通过学习原始数据模式所总结出的知识，这类知识通常不是直接的事实，而是对语言或概念的统计关联和推断。这两类知识都有一个共同的问题：随着时间的推移，原始数据中的事实信息可能失效，导致模型生成的内容不再准确反映当前情况。

在前面的课程中我们学到过，为了解决时效性的问题，使用上下文学习是一种有效策略。上下文学习通常通过提供提示词来引导模型，使其能够获取与当前任务或目标场景相关的事实信息。这些提示词为模型提供了最新的语境，从而确保生成的内容更加准确且紧贴现实需求。例如，在应对最新的新闻事件或动态变化时，提示词可以为模型提供最新的数据和信息，增强生成结果的时效性和相关性。

因此，在上下文学习的设计背景下，当模型在预训练过程中学到的历史知识与RAG提供的实时信息发生冲突时，模型默认会优先参考提示词中的事实信息。这种默认优先机制的初衷是为了让提示词引入当前的上下文，使得模型能够生成与实际情况更吻合的回答。