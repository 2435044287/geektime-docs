今天我们学习AdaBoost算法。在数据挖掘中，分类算法可以说是核心算法，其中AdaBoost算法与随机森林算法一样都属于分类算法中的集成算法。

集成的含义就是集思广益，博取众长，当我们做决定的时候，我们先听取多个专家的意见，再做决定。集成算法通常有两种方式，分别是投票选举（bagging）和再学习（boosting）。投票选举的场景类似把专家召集到一个会议桌前，当做一个决定的时候，让K个专家（K个模型）分别进行分类，然后选择出现次数最多的那个类作为最终的分类结果。再学习相当于把K个专家（K个分类器）进行加权融合，形成一个新的超级专家（强分类器），让这个超级专家做判断。

所以你能看出来，投票选举和再学习还是有区别的。Boosting的含义是提升，它的作用是每一次训练的时候都对上一次的训练进行改进提升，在训练的过程中这K个“专家”之间是有依赖性的，当引入第K个“专家”（第K个分类器）的时候，实际上是对前K-1个专家的优化。而bagging在做投票选举的时候可以并行计算，也就是K个“专家”在做判断的时候是相互独立的，不存在依赖性。

## AdaBoost的工作原理

了解了集成算法的两种模式之后，我们来看下今天要讲的AdaBoost算法。
<div><strong>精选留言（23）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/a4/5a/e708e423.jpg" width="30px"><span>third</span> 👍（22） 💬（2）<div>
作业
1.假设分类正确就是吃鸡成功。

1）训练多个弱分类器，并不断迭代弱分类器，选择最优弱分类器
枪法，一个弱分类器，你可以通过玩的越来越多，练习越来越好
身法，一个弱分类器，同理
意识，一个弱分类器。同理
···


2）将弱分类器组合起来，形成一个强分类器

枪法，身法，眼神，你只有一个的话，实际上，你的吃鸡概率并不高。但是三个都好的人，吃鸡概率就是高。这就是强分类器。

2.把分类正确理解成功的的话，

1）训练多个弱分类器，并不断迭代弱分类器，选择最优弱分类器
努力获取了一个领域的知识和道理，就是一个弱分类器，不断地学习和精进，在一个知识领域变得更强

3）将弱分类器组合起来，形成一个强分类器
合理跨界，将两个领域的知识组合起来，产生新收益。比如软硬件结合的苹果，仅一家公司就占据了整个手机市场利润的50%以上。

两个领域的组合，就是一个强分类器。


理解
1.通过修改样本的数据分布来实现算法的。
正确分类的，就少分点
错误分类的，就多分点。

像做题，
做正确的题，下次就少做点，反正会了。
做错的题，下次多做点，集中在错题上
每次这个题都在变化，随着你学习的深入，你做错的题会越来越少。


2.样本的权重时根据之前的k论权重以及k个分类器的准确率而定的。

你决定做什么样题。
1.取决于你上次做对了什么题，做错了什么题
2.做正确了，你就少做点。
3.做错了，你就多做点。

提问：Zk是啥意思？，yi是啥意思？

流程
1.获取基础权重
2.获取基础分类器
3.计算错误率，选择错误率最低的为最优分类器
4.通过计算分类器权重公式，达到减少正确样本数据分布，增加错误样本数据分布
5.代入W k+1,i和D k+1 的公式，得到新的权重矩阵
7.在新的权重矩阵上，计算错误率，选择错误最低的为最优分类器
剩下的就是迭代，重复
直到迭代完成，获得强分类器
</div>2019-03-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/a4/77/12913b94.jpg" width="30px"><span>清夜</span> 👍（12） 💬（1）<div>多个弱分类器训练成为一个强分类器。
类比为：
全班同学都做一张正常的高中试卷，但是每道题无论大小都是一样的分数。
1.  给得分最高的同学赋予一个比他人更高的权重，并且他做错的题目分数都提高一些。
2. 重新计分，选择此时分数最高的人赋予一定权重，提高他做错题目的分数。
3. 不断重复以上步骤。
4. 每个同学都重新有了权重之后，一个强分类器就诞生了。</div>2019-10-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/6a/21/e252b092.jpg" width="30px"><span>Ehh1ouyz</span> 👍（8） 💬（3）<div>补充：这里的Zk是归一化因子。</div>2019-03-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg" width="30px"><span>Geek_hve78z</span> 👍（8） 💬（1）<div>如何理解 AdaBoost 中弱分类器，强分类器概念的？另外，AdaBoost 算法是如何训练弱分类器从而得到一个强分类器的？

1、弱分类器，是指基础分类器，正确率略高于50%的那种。
强分类器是通过训练出多个弱分类器，并赋值权重，最后形成弱分类器+权重的模型。

2、得到强分类器的方法：
参考链接：https:&#47;&#47;www.cnblogs.com&#47;hlongch&#47;p&#47;5734293.html
adaboost算法的核心思想是针对同一个训练集训练不同的分类器(弱分类器)，然后把这些弱分类器集合起来，构成一个更强的最终分类器(强分类器)。

1.一开始，给训练数据中的每一个样本，赋予其一个权重，权重都初始化成相等值。如（1&#47;样本数量）
2.首先在训练数据中训练出一个弱分类器并计算改分类器的错误率，选取错误率最小的分类器，并基于分类器错误率计算其权重值alpha。
3.在分类器的第二次训练当中，将会重新调整每个样本的权重，其中第一次分对的样本的权重将会降低，而第一次分错的样本权重将会提高。然后在同一数据集上再次训练弱分类器。得出第二个错误率小的分类器，并基于错误率计算权重。
4.重复“重新分配样本权重——计算分类器错误率——选取分类器——计算分类器权重”

5.最后将每次训练得到的分类器最后融合起来，作为最后的决策分类器。</div>2019-03-01</li><br/><li><img src="" width="30px"><span>三硝基甲苯</span> 👍（4） 💬（1）<div>根据我的反推，首先这里的所有涉及到对数和指数的都是以e为底的，然后就是Dk+1这一步，需要先计算Zk，这个就是把 wk*e^(-ak*y*Gk(x))把全部的加起来就是了，然后再去算Wk+1，然后就进一步可以算出Dk+1。
个人理解就是AdaBoost就是先把数据通过权重的方式分割成不同的部分，然后每个部分再去交给在这些里较为专业的分类器去分类，通过迭代，再把计算的结果带上权重后，就是结果了。</div>2019-03-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/b5/98/ffaf2aca.jpg" width="30px"><span>Ronnyz</span> 👍（3） 💬（1）<div>弱分类器：分类准确率比较低，可能在(50%~70%)之间
强分类器：在AdaBoost算法中，将一系列的弱分类器以不同的权重比组合作为最终分类选择
在筛选每一轮的最优分类器后，调整样本的权重，以获得一个更优的弱分类器。</div>2019-11-24</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/ziaN7rOONp15HJm6A9JoAYicJL8VA59x10DX4JZyvcfqmmpCnumXgAkNn37aFoALftyTaQNlUF7te54LibvVm20TQ/132" width="30px"><span>Geek_c9fa4e</span> 👍（2） 💬（1）<div>1、假设AdaBoost算法是球队
弱分类器：在众多球队里，踢得不好的队伍
强分类器：通过在弱分类不断地寻找出弱分类里面踢得好的，最后组成一个强的球队
2、如何训练成强分类器：
  1、首先初始化一个相同权重。
  2、然后在训练数据中计算弱分类·的错误率，选择错误率最低的去计算该权重
  3、接着再次训练，重新调整每个样本的权重，其中第一次分对的样本的权重将会降低，而第一次分错的样本权重将会提高。然后在同一数据集上再次训练弱分类器。得出第二个错误率小的分类器，并基于错误率计算权重。
  4、重复此步骤
  5、最后将每次训练得到的分类器最后融合起来，作为最后的决策分类器。</div>2020-04-30</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/1rd5KVxbBWO1Jnq3syrfRQg0NGerVl4Dt7uHTMcy9A7KTqxmy7iaoomoWsjuHM4n7fBr0ESG8OqfJKCDHExzjvQ/132" width="30px"><span>juixv3937</span> 👍（0） 💬（3）<div>log没有底数怎么计算啊</div>2019-08-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/5d/27/74e152d3.jpg" width="30px"><span>滨滨</span> 👍（0） 💬（1）<div>弱分类器分类正确率比随机稍微高一点，每次选择相对最优的分类器，然后对分类错误的部分加强训练，最后得到一个强分类器。

1.一开始，给训练数据中的每一个样本，赋予其一个权重，权重都初始化成相等值。如（1&#47;样本数量）
2.首先在训练数据中训练出一个弱分类器并计算改分类器的错误率，选取错误率最小的分类器，并基于分类器错误率计算其权重值alpha。
3.在分类器的第二次训练当中，将会重新调整每个样本的权重，其中第一次分对的样本的权重将会降低，而第一次分错的样本权重将会提高。然后在同一数据集上再次训练弱分类器。得出第二个错误率小的分类器，并基于错误率计算权重。
4.重复“重新分配样本权重——计算分类器错误率——选取分类器——计算分类器权重”

5.最后将每次训练得到的分类器最后融合起来，作为最后的决策分类器。</div>2019-04-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/cb/07/e34220d6.jpg" width="30px"><span>李沛欣</span> 👍（0） 💬（1）<div>通过训练多个弱分类器，集成一个强分类器。</div>2019-03-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/79/9a/4f907ad6.jpg" width="30px"><span>Python</span> 👍（0） 💬（1）<div>弱分类器是决策层，强分类器是决策汇总后的结果</div>2019-03-02</li><br/><li><img src="" width="30px"><span>Geek_3e33b6</span> 👍（1） 💬（0）<div>1&#47;2 * log((1-0.3)&#47;0.3) = 0.184   为啥文章里是0.4236</div>2022-12-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/dc/68/006ba72c.jpg" width="30px"><span>Untitled</span> 👍（1） 💬（0）<div>整个算法流程我自己理解为把上一次分类错误的缺点放大，优点缩小，然后等另一个分类器来把放到的缺点进行优化。</div>2020-03-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（1） 💬（0）<div>老师，你好。请问样本权重的计算公式是个指数函数exp，为啥是指数函数？不用指数的话，有啥不同么？</div>2019-03-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/22/58/63/5c98ef22.jpg" width="30px"><span>教育兴国，科技强国</span> 👍（0） 💬（0）<div>这个样本权重的公式是咋样来的啊？
第 k+1 轮中的样本权重，是根据该样本在第 k 轮的权重以及第 k 个分类器的准确率而定，具体的公式就是那个：w(k+i,i)=.....</div>2022-04-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/23/77/81/9bc87164.jpg" width="30px"><span>佳成_Cahen</span> 👍（0） 💬（0）<div>W_k+1_i的公式里那个Z_k是什么含义没有说明</div>2021-08-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/53/3c/c86e3052.jpg" width="30px"><span>猛仔</span> 👍（0） 💬（0）<div>老师想问一下在构建好强分类器后，在用强分类器进行分类时，每个样本还会按照在构造强分类器时的权重在弱分类器中进行运算么？</div>2020-04-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg" width="30px"><span>Simon</span> 👍（0） 💬（0）<div>一个好问题：为什么每次迭代后，错误样本的权重变大了，而正确样本的权重变小了？怎么看出来的？</div>2020-04-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/4d/62/0fe9cbb3.jpg" width="30px"><span>William～Zhang</span> 👍（0） 💬（2）<div>请问老师，在计算错误率的时候，为什么是用样本权重 直接乘以错误个数，而不是，再除以10？</div>2020-03-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/dc/68/006ba72c.jpg" width="30px"><span>Untitled</span> 👍（0） 💬（1）<div>老师，上面第2次算的样本权重，我花了一个早上，怎么都算不出来跟您同样的结果，可以详细给下计算过程吗？或者加个微信，看看我究竟错了哪里，拜托</div>2020-03-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/ce/55/00846acb.jpg" width="30px"><span>忠超</span> 👍（0） 💬（0）<div>您好。我有两个地方不明白，请老师答疑。为什么每次迭代的权重的计算方式是那么设置？另外，每次迭代得到的分类器前面的权重之和也不为1？还有，错误率等于权重乘以分类错误的个数，这个也不太理解。</div>2019-03-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/1d/3a/cdf9c55f.jpg" width="30px"><span>未来已来</span> 👍（0） 💬（1）<div>请问每次迭代之后，错误率是如何进行计算的呢？</div>2019-03-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/1d/3a/cdf9c55f.jpg" width="30px"><span>未来已来</span> 👍（0） 💬（0）<div>我的显示界面中，很多数学符号变成了[Math Processing Error]</div>2019-03-01</li><br/>
</ul>