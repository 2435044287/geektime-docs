算法篇更新到现在就算结束了，因为这一模块比较难，所以大家提出了形形色色的问题。我总结了同学们经常遇到的问题，精选了几个有代表性的来作为答疑。没有列出的问题，我也会在评论区陆续解答。

## 17-19篇：决策树

### 答疑1：在探索数据的代码中，print(boston.feature\_names)有什么作用？

boston是sklearn自带的数据集，里面有5个keys，分别是data、target、feature\_names、DESCR和filename。其中data代表特征矩阵，target代表目标结果，feature\_names代表data对应的特征名称，DESCR是对数据集的描述，filename对应的是boston这个数据在本地的存放文件路径。

针对sklearn中自带的数据集，你可以查看下加载之后，都有哪些字段。调用方法如下：

```
boston=load_boston()
print(boston.keys())
```

通过boston.keys()你可以看到，boston数据集的字段包括了\[‘data’, ‘target’, ‘feature\_names’, ‘DESCR’, ‘filename’]。

### 答疑2：决策树的剪枝在sklearn中是如何实现的？

实际上决策树分类器，以及决策树回归器（对应DecisionTreeRegressor类）都没有集成剪枝步骤。一般对决策树进行缩减，常用的方法是在构造DecisionTreeClassifier类时，对参数进行设置，比如max\_depth表示树的最大深度，max\_leaf\_nodes表示最大的叶子节点数。
<div><strong>精选留言（16）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/13/f5/12/a5383fff.jpg" width="30px"><span>志</span> 👍（24） 💬（1）<div>Kaggle的Python数据分析入门教程：https:&#47;&#47;www.kaggle.com&#47;kanncaa1&#47;data-sciencetutorial-for-beginners

另外入门级别的kernels就是Titanic和房价预测：
1、https:&#47;&#47;www.kaggle.com&#47;c&#47;titanic
2、https:&#47;&#47;www.kaggle.com&#47;c&#47;house-prices-advanced-regression-techniques</div>2019-03-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/2f/e2/3640e491.jpg" width="30px"><span>小熊猫</span> 👍（13） 💬（2）<div>老师可以总结一下，这十个算法的应用场景、优缺点吗</div>2019-03-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg" width="30px"><span>Geek_hve78z</span> 👍（8） 💬（1）<div>一、sklearn自带的小数据集（packageddataset）：sklearn.datasets.load_&lt;name&gt;

1)鸢尾花数据集：load_iris（）：用于分类任务的数据集
2)手写数字数据集：load_digits（）:用于分类任务或者降维任务的数据集
3)乳腺癌数据集load_breast_cancer（）：简单经典的用于二分类任务的数据集
4)糖尿病数据集：load_diabetes（）：经典的用于回归认为的数据集，值得注意的是，这10个特征中的每个特征都已经被处理成0均值，方差归一化的特征值。
5)波士顿房价数据集：load_boston（）：经典的用于回归任务的数据集
6)体能训练数据集：load_linnerud（）：经典的用于多变量回归任务的数据集。

体能训练数据集中的特征名称linnerud.feature_names为[&#39;Chins&#39;, &#39;Situps&#39;, &#39;Jumps&#39;]
鸢尾花数据集的特征名称iris.feature_names为[&#39;sepal length (cm)&#39;,&#39;sepal width (cm)&#39;,&#39;petal length (cm)&#39;,&#39;petal width (cm)&#39;]</div>2019-03-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/50/91/0dd2b8ce.jpg" width="30px"><span>听妈妈的话</span> 👍（4） 💬（1）<div>https:&#47;&#47;www.kaggle.com&#47;learn&#47;overview 页面里有分类好的比较简单的kernel，可以fork kernel在kaggle上运行，也可以下载ipynb或者rmd文件在自己的电脑上运行。比较经典的kaggle竞赛有泰坦尼克预测，房价预测，数字识别等，刚起步时可以参考这些竞赛里的kernel.
另外，有一个开源组织ApacheCN有一些kaggle的培训，有很多相关的活动，也可以找同伴组队参加比赛。</div>2019-03-23</li><br/><li><img src="" width="30px"><span>Merlin</span> 👍（3） 💬（1）<div>尝试过kaggle上预测房价的项目，适合入门</div>2020-01-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/a4/5a/e708e423.jpg" width="30px"><span>third</span> 👍（3） 💬（1）<div>import sklearn.datasets as db
# help(db)#可以查看文档，有很多的数据集
# 准备数据集
iris=db.load_iris()
print(iris.feature_names)
结果
[&#39;sepal length (cm)&#39;, &#39;sepal width (cm)&#39;, &#39;petal length (cm)&#39;, &#39;petal width (cm)&#39;]

说来惭愧，到现在为止，都还没有注意到Kaggle的重要性。刚去看看了入门，发现这篇文章介绍的不错
http:&#47;&#47;www.360doc.com&#47;content&#47;18&#47;0106&#47;16&#47;44422250_719580875.shtml#

一些摘要
Kaggle成立于2010年，是一个进行数据发掘和预测竞赛的在线平台。从公司的角度来讲，可以提供一些数据，进而提出一个实际需要解决的问题；从参赛者的角度来讲，他们将组队参与项目，针对其中一个问题提出解决方案，最终由公司选出的最佳方案可以获得5K-10K美金的奖金。

除此之外，Kaggle官方每年还会举办一次大规模的竞赛，奖金高达一百万美金，吸引了广大的数据科学爱好者参与其中。从某种角度来讲，大家可以把它理解为一个众包平台，类似国内的猪八戒。但是不同于传统的低层次劳动力需求，Kaggle一直致力于解决业界难题，因此也创造了一种全新的劳动力市场——不再以学历和工作经验作为唯一的人才评判标准，而是着眼于个人技能，为顶尖人才和公司之间搭建了一座桥梁。</div>2019-03-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg" width="30px"><span>建强</span> 👍（2） 💬（1）<div>有一个问题想请教一下老师，每次做算法模型训练，用训练集数据拟合一个模型后，如何把它保存下来，如果不保存拟合后的模型，每次要做新的预测时，难道都要用样本训练集重新拟合模型？</div>2019-12-28</li><br/><li><img src="" width="30px"><span>吃饭睡觉打窦窦</span> 👍（2） 💬（1）<div>学校学了一遍，这里又学一遍，这才把东西学透点，但是我好奇为啥课堂上学不会呀?[滑稽]（老师是个海归）</div>2019-03-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/2f/e2/3640e491.jpg" width="30px"><span>小熊猫</span> 👍（2） 💬（2）<div>老师 为什么三个相关性大的特征只选一个呢？原理是什么？</div>2019-03-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg" width="30px"><span>Geek_hve78z</span> 👍（2） 💬（1）<div>在第21课朴素贝叶斯分类（下），对中文文档进行分类，老师可以提供完整代码吗？一直遇到对中文词组不支持的问题？</div>2019-03-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/86/d7/46842f90.jpg" width="30px"><span>小晨</span> 👍（1） 💬（1）<div>答疑3：carbin是卡宾枪 &#47;偷笑&#47;偷笑</div>2021-03-11</li><br/><li><img src="" width="30px"><span>周志翔</span> 👍（1） 💬（1）<div>我觉得在kaggle可以学到很多数据处理的方法，看厉害的人怎么做的，是个很不错的网站</div>2019-07-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/10/dc/96476998.jpg" width="30px"><span>Hulk</span> 👍（1） 💬（2）<div>K-Means的例子还是看不懂</div>2019-07-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/5d/27/74e152d3.jpg" width="30px"><span>滨滨</span> 👍（3） 💬（0）<div>预减枝就是在划分子树的时候不能带来准确度的提升，就不划分。后减枝就是试着减掉每一个叶子节点，看准确度是否有提升。</div>2019-04-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg" width="30px"><span>Geek_hve78z</span> 👍（2） 💬（0）<div>在第21课朴素贝叶斯分类（下）：
在模块4:生成朴素贝叶斯分类器，特征训练集的特征空间 train_features，以及训练集对应的分类 train_labels 是如何获取的。老师并没有讲清楚。</div>2019-03-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/30/94/12c20983.jpg" width="30px"><span>宏伟</span> 👍（1） 💬（0）<div>陈老师，微软的PowerBI里已经集成了Python，可以安装anaconda，那么您课程里的十大算法是不是都可以在powerbi里的Python操作建模、拆分数据集、训练、验证、测试，乃至部署模型、进入实战呢？
之前看您讲Python的IDE时，没有提到anaconda的jupyter notebook。但黄佳老师（我就是从他的机器学习课程链接到您的课程的）讲，传统机器学习用notebook就可以了。
期盼回复。</div>2021-09-28</li><br/>
</ul>