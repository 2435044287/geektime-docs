我们采集的数据经常会有冗余重复的情况。举个简单的例子，假设你是一个网络综艺节目的制片人，一共有12期节目，你一共打算邀请30位明星作为节目的嘉宾。你知道这些明星影响力都很大，具体在微博上的粉丝数都有标记。于是你想统计下，这些明星一共能直接影响到微博上的多少粉丝，能产生多大的影响力。

然后你突然发现，这些明星的粉丝数总和超过了20亿。那么他们一共会影响到中国20亿人口么？显然不是的，我们都知道中国人口一共是14亿，这30位明星的影响力总和不会覆盖中国所有人口。

那么如何统计这30位明星真实的影响力总和呢？这里就需要用到数据集成的概念了。

数据集成就是将多个数据源合并存放在一个数据存储中（如数据仓库），从而方便后续的数据挖掘工作。

据统计，大数据项目中80%的工作都和数据集成有关，这里的数据集成有更广泛的意义，包括了数据清洗、数据抽取、数据集成和数据变换等操作。这是因为数据挖掘前，我们需要的数据往往分布在不同的数据源中，需要考虑字段表达是否一样，以及属性是否冗余。

## 数据集成的两种架构：ELT和ETL

数据集成是数据工程师要做的工作之一。一般来说，数据工程师的工作包括了数据的ETL和数据挖掘算法的实现。算法实现可以理解，就是通过数据挖掘算法，从数据仓库中找到“金子“。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/fa/79/4ffa6b0b.jpg" width="30px"><span>Monica</span> 👍（22） 💬（3）<div>在“数据分析实战交流群”，老师分享了额外干货资料：“Kettle的操作视频”，有入群需求的，可加我的微信：imonica1010，和老师及同学们交流数据分析的学习心得。

由于申请人数太多，进群免费但设置了一道小门槛，欢迎加我，了解入群规则。</div>2019-01-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/02/ce/57c871e0.jpg" width="30px"><span>云深不知处</span> 👍（27） 💬（1）<div>大约三年大数据工程师工作，从最开始的数据集成（sqoop、代码、商用软件ETL工具等），将数据汇聚到数据仓库，理解业务，清洗应用需要的数据。数据集成是将多源（多系统）、多样（结构化、非结构化、半结构化）、多维度数据整合进数据仓库，形成数据海洋，更好的提供业务分析系统的数据服务，通过数仓的数据集成，达到数据共享的效果，降低对原始业务系统的影响，同时加快数据分析工作者的数据准备周期。数据集成最开始就是原始系统的数据，照样搬到数据仓库，这种类型工作长期实施，容易疲劳失去兴趣，理解业务需求，通过自己的数据集成、清洗、数据分析，提供有意思的数据，就是挖金子过程，应该也是一件有趣的事情。</div>2019-06-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/d3/fd/41eb3ecc.jpg" width="30px"><span>奔跑的徐胖子</span> 👍（14） 💬（2）<div>希望有如我一般的使用Mac的屌丝注意，安装完了Kettle之后，要去mysql官网下载驱动，这个驱动不能用最新版本的，要用老版本的才能连接数据库，我用的是5.1.46</div>2019-03-22</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/wJphZ3HcvhjVUyTWCIsCugzfQY5NAy6VJ0XoPLibDlcHWMswFmFe678zd0lUjFETia80NQhyQcVnGDlKgKPcRGyw/132" width="30px"><span>JingZ</span> 👍（14） 💬（1）<div>#2019&#47;1&#47;9 Kettle数据集成

1、安装jdk：官网http:&#47;&#47;www.oracle.com&#47;technetwork&#47;java&#47;javase&#47;downloads&#47;jdk8-downloads-2133151.html，下载mac版的JDK，下载后，直接安装。终端验证java-version~

2、安装Kettle：https:&#47;&#47;sourceforge.net&#47;projects&#47;pentaho&#47;files&#47;Data%20Integration&#47;
下载最新pdi-ce-8.2.0.0-342.zip压缩包，直接生成data integration文件夹

3、下载数据库驱动：https:&#47;&#47;dev.mysql.com&#47;downloads&#47;connector&#47;j&#47;
mysql-connector-java-5.1.41.tar.gz解压，但是出现了query-cache-size问题，重新下载最新mysql-connector-java-8.0.13.tar.gz，又出现找不到jar文件。重启也不行～最后两个文件都放在了data integration&#47;lib里面，貌似就可以了，这块还需再探索

4、打开终端，启动Kettle：sh spoon.sh打开Spoon，开始文本输入和表输出了

5、安装MySQL，同时安装了MySQL WorkBench建立数据库wucai和表score，目前出现表输出Unexpected batch update error committing the database connection和org.pentaho.di.core.exception.KettleDatabaseBatchException问题，可能是对SQL设置问题，还需debug

接触新工具，还需多实践</div>2019-01-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/9c/b5/3d96280e.jpg" width="30px"><span>veical</span> 👍（6） 💬（1）<div>加载就是把转换后的数据从中间层(stage层，通常是一个数据库或数据库集群)导入数据分析层，然后才能在模型中用这些干净的数据进行数据分析</div>2019-01-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/18/d0/49b06424.jpg" width="30px"><span>qinggeouye</span> 👍（3） 💬（1）<div>1、搭环境(open jdk , mysql 8.0 , mysql-connector for java, kettle)
2、启动 kettle , 实操 ...</div>2019-11-12</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJYEdMwBDUC6gYrUoI7092ocWJPyw1aP8xNOFXxOv7LEw1xj5a4icDibV7pd9vN45lXicXYjB7oYXVqg/132" width="30px"><span>羊小看</span> 👍（2） 💬（1）<div>目前我们做的业务需求比较多，一个需求有时会关联五六张表，所以我们特别希望可以先做转换，做成大宽表，入仓，可以直接用。
老师说的先加载再转换，是适用于做数据挖掘时吗？</div>2019-08-27</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKkpApOjdIb81ZHxeAup1IGH97eaD8oiawlCtUJdvct1AP6UfmmpYlE6r25tNM5cgOCgM3oAzpic5Aw/132" width="30px"><span>Sandy</span> 👍（1） 💬（2）<div>我现在每天的工作就是写kettle job</div>2019-04-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/43/d8/92604ed5.jpg" width="30px"><span>旭霁</span> 👍（1） 💬（1）<div>数据库 MySQL 操作
本地登录
mysql -u root -p

创建数据库 wucai
CREATE DATABASE wucai;

查询数据库
show databases;

切换&#47;进入数据库 wucai
use wucai;

创建数据库表 score。包含 create_time、name、Chinese、English、Math 五个字段。
CREATE TABLE score (create_time VARCHAR(255) NULL, name VARCHAR(255) NULL, Chinese VARCHAR(255) NULL, English VARCHAR(255) NULL, Math VARCHAR(255) NULL);

查询数据库表
show tables;</div>2019-03-19</li><br/><li><img src="" width="30px"><span>lemonlxn</span> 👍（0） 💬（1）<div>通过pandas预处理数据，然后用 pd.to_sql 的方式直接写到 数据库里面，这个方式感觉会更快。
或者通过 Koalas 的 to_spark 后的overwrite模式，可以直接 将数据写入到 DBFS里面的</div>2020-09-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/cf/4d/a10bdb9f.jpg" width="30px"><span>hegw</span> 👍（0） 💬（1）<div>数据集成：数据抽取、数据转换、数据加载
工具：DataX、Sqoop</div>2020-05-08</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJAl7V1ibk8gX62W5I4SER2zbQAj3gy5icJlavGhnAmxENCia7QFm8lE3YBc5HOHvlyNVFz7rQKFQ7dA/132" width="30px"><span>timeng27</span> 👍（0） 💬（1）<div>直接用pandas进行数据转换应该也可以。</div>2020-03-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/4d/dc/6c0a311e.jpg" width="30px"><span>Geek_樗</span> 👍（0） 💬（1）<div>今天学习收获良多，以前没有ETL和ELT的概念，现在清楚多了。</div>2020-03-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/7a/ac/ee7067e9.jpg" width="30px"><span>北房有佳人</span> 👍（0） 💬（2）<div>老师,kettle的教程不太详细，github的数据集也没办法下载啊</div>2019-11-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg" width="30px"><span>建强</span> 👍（0） 💬（1）<div>数据集成理解：数据集成是对各种业务数据进行清洗、按数据仓库模型转换后形成一套跨业务的集成数据，这套集成数据可以从各个维度、全方位地展示业务数据，为BI分析和数据挖掘提供可靠、丰富的数据来源。
我曾经用过的ETL工具是IBM的DataStage，DataStage的数据抽取效率还是挺高的，它是在抽取过程中对数据进行分区，各个分区并行抽取和转换，最后再对各个分区进行收集和合并，这种机制极大提高了ETL的效率。
DataStage采用图形化界面进行流程设计，不需要编程，上手比较容易，但各个组件需要进行大量配置，配置比较繁琐，另外，调试起来也不是很直观方便，但总体来说还是一款不错的ETL工具。</div>2019-08-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/11/19/6e0c5c9e.jpg" width="30px"><span>冯德章</span> 👍（0） 💬（1）<div>1.  ETL ELT 区别与联系
2. 占据80工作量
3.  开源工具.kettle datax sqoop</div>2019-04-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/df/f0/9a6a40a5.jpg" width="30px"><span>丸子</span> 👍（0） 💬（1）<div>kettle下不下来啊，有没有别的下载渠道啊</div>2019-02-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/cb/07/e34220d6.jpg" width="30px"><span>李沛欣</span> 👍（0） 💬（1）<div>今天的看完了。
数据集成的目标是把不同数据源的数据放到同一个库里统一进行分析。
这真的就像把大象塞进冰箱的步骤。
ETL：提取，转换，加载。
或者是ELT，即先提取加载，再通过外部软件进行转换。

课程里重点介绍了kettle水壶的使用方式，以及把文本文档数据转换为MySQL数据。

其实最近我一直在困惑于流程设计，很多标准化的东西能否实用，关键就在于流程。而数据集成这道工序，亦然。</div>2019-01-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/1d/3a/cdf9c55f.jpg" width="30px"><span>未来已来</span> 👍（0） 💬（1）<div>我经常用 kettle 从外部文件导数据</div>2019-01-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/d3/02/ff2e1881.jpg" width="30px"><span>闫伟</span> 👍（0） 💬（1）<div>工作中kettle用的比较多，通过kettle可以快速处理许多数据问题。</div>2019-01-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/99/23/3c3272bd.jpg" width="30px"><span>林</span> 👍（16） 💬（1）<div>实际操作完成，说下操作过程中注意事项：
1、下载安装jdk1.8+，注意配置系统JAVA_HOME环境变量
2、下载Kettle
3、如果你用的是MySQL,导入数据时会报Driver class &#39;org.gjt.mm.mysql.Driver&#39; could not be found, make sure the &#39;MySQL&#39; driver (jar file) is installed. org.gjt.mm.mysql.Driver错误。此时需要到https:&#47;&#47;dev.mysql.com&#47;downloads&#47;file&#47;?id=468318%20下载后，解压出mysql-connector-java-5.1.41-bin.jar 包，放到pdi-ce-8.2.0.0-342\data-integration\lib目录即可。</div>2019-01-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/2f/e2/3640e491.jpg" width="30px"><span>小熊猫</span> 👍（12） 💬（2）<div>老师前面讲了ELT比ETL更方便，结果后面介绍的是ETL。。。</div>2019-01-21</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKerOHGs8VAMWj0ysxZpTPcARHEITiaH8YDJR7aoDNYhRpbLsZ0pJdJXIfzvR7u06iaKPBUoWfic5Zww/132" width="30px"><span>Geek_qsftko</span> 👍（9） 💬（0）<div>做了三四年的大数据工程师，数据清洗工作是长期存在的，做了这么多的ETL的工作，看了这个课程后，才知道，针对大数据工程师而言，几乎所有场景下做的数据清洗都是ELT，基本流程都是抽取原始数据，加载到更强大的分布式计算框架中，eg: Spark  来进行数据的转换，最终输出结果数据。 </div>2020-02-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/48/d2/c510e9b4.jpg" width="30px"><span>GGYY</span> 👍（7） 💬（0）<div>“we were unable to find any new incoming fields”

这里试试在“内容”一栏，吧编码方式改一下。默认为 DOS</div>2019-01-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/a5/99/db2f6325.jpg" width="30px"><span>lingmacker</span> 👍（5） 💬（1）<div>为什么我获取字段会出现 we were unable to find any new incoming fields! 错误啊？</div>2019-01-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/d3/40/39d41615.jpg" width="30px"><span>Yafei</span> 👍（4） 💬（0）<div>Deepin linux 
1. 安装 openjdk
2. 0. 下载kettle zip包，解压即可。
2. 下载 mysql jdbc driver(https:&#47;&#47;dev.mysql.com&#47;downloads&#47;connector&#47;j&#47;),解压將 mysql-connector-java-8.0.15 (我用的这个版本) 放入 ‘data-integration&#47;lib&#47;’ 目录下。
3. sudo apt-get install mysql ，安装完后如果使用 root 用户，注意是否能以localhost登录，创建一个数据库用来测试，并创建一个table，表名随意，字段能对应到你的数据即可。
4. 运行脚本 spoon.sh 打开 kettle, 添加 text input ，双击 -- 添加数据文件 -- 切换到‘内容’ -- 修改分隔符为tab -- 修改格式为 Unix（如不修改会找不到字段） -- 切换到‘字段’ --获取字段</div>2019-03-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/3b/bd/ad19952d.jpg" width="30px"><span>夏天</span> 👍（4） 💬（0）<div>使用postgresql的朋友, 记得再spoon中给表字段加引号</div>2019-01-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/9f/9d/67a33381.jpg" width="30px"><span>Lin_嘉杰</span> 👍（3） 💬（1）<div>对数据集成的理解仅限于对多个来源的数据源，比如csv，mysql，nosql，excel等，尽可能完整集合成一个全面的数据库，方便后续数据挖掘。</div>2019-01-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/7d/d9/36b52e23.jpg" width="30px"><span>叫我源仔</span> 👍（2） 💬（1）<div>老是http:&#47;&#47;t.cn&#47;E4SzvOf打不开了。求数据</div>2022-05-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/8e/6d/c68e07ef.jpg" width="30px"><span>Chino</span> 👍（2） 💬（1）<div>文本文件输入那里获取字段出错误了 出错原因拿去搜了下 还什么都搜不出来 求教啊
we were unable to find any new incoming fields</div>2019-01-21</li><br/>
</ul>