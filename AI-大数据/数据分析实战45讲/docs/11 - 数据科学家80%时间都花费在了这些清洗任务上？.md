我们在上一节中讲了数据采集，以及相关的工具使用，但做完数据采集就可以直接进行挖掘了吗？肯定不是的。

就拿做饭打个比方吧，对于很多人来说，热油下锅、掌勺翻炒一定是做饭中最过瘾的环节，但实际上炒菜这个过程只占做饭时间的20%，剩下80%的时间都是在做准备，比如买菜、择菜、洗菜等等。

在数据挖掘中，数据清洗就是这样的前期准备工作。对于数据科学家来说，我们会遇到各种各样的数据，在分析前，要投入大量的时间和精力把数据“**整理裁剪**”成自己想要或需要的样子。

为什么呢？因为我们采集到的数据往往有很多问题。

我们先看一个例子，假设老板给你以下的数据，让你做数据分析，你看到这个数据后有什么感觉呢？

![](https://static001.geekbang.org/resource/image/5e/23/5e69b73b96c0d824240ac8035fe69723.png?wh=522%2A334)

你刚看到这些数据可能会比较懵，因为这些数据缺少标注。

我们在收集整理数据的时候，一定要对数据做标注，数据表头很重要。比如这份数据表，就缺少列名的标注，这样一来我们就不知道每列数据所代表的含义，无法从业务中理解这些数值的作用，以及这些数值是否正确。但在实际工作中，也可能像这个案例一样，数据是缺少标注的。

我简单解释下这些数据代表的含义。

这是一家服装店统计的会员数据。最上面的一行是列坐标，最左侧一列是行坐标。

列坐标中，第0列代表的是序号，第1列代表的会员的姓名，第2列代表年龄，第3列代表体重，第4~6列代表男性会员的三围尺寸，第7~9列代表女性会员的三围尺寸。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/a4/5a/e708e423.jpg" width="30px"><span>third</span> 👍（47） 💬（3）<div>自己不知道有没有什么好的工具，所以就把图片上一个一个敲进去了。
数据.csv格式
链接：https:&#47;&#47;pan.baidu.com&#47;s&#47;1jNnUpntrlxFSubmna3HtXw 
提取码：e9hc</div>2019-02-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/ca/98/a75e400b.jpg" width="30px"><span>wonderland</span> 👍（46） 💬（5）<div>一、首先按照所讲的数据质量准则，数据存在的问题有：
1.&quot;完整性&quot;问题：数据有缺失，在ounces列的第三行存在缺失值
处理办法：可以用该列的平均值来填充此缺失值
2.“全面性”问题：food列的值大小写不统一
处理办法：统一改为小写
3.“合理性”问题：某一行的ounces值出现负值
处理办法：将该条数据记录删除
4.“唯一性”问题：food列大小写统一后会出现同名现象，
处理办法：需要将food列和animal列值均相同的数据记录进行合并到同一天记录中国</div>2019-01-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/a3/87/c415e370.jpg" width="30px"><span>滢</span> 👍（38） 💬（6）<div>原始数据链接：https:&#47;&#47;github.com&#47;onlyAngelia&#47;Read-Mark&#47;blob&#47;master&#47;数据分析&#47;geekTime&#47;data&#47;accountMessage.xlsx    （课程中讲解原始数据-点击view Raw即可下载）
课后练习原始数据: https:&#47;&#47;github.com&#47;onlyAngelia&#47;Read-Mark&#47;blob&#47;master&#47;数据分析&#47;geekTime&#47;data&#47;foodInformation.xlsx （点击View Raw下载）</div>2019-04-11</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eonMJazpAb9sj7ialYVsumyv9wC1F8RTHpmBPMgj7yNDmof7cpuONtultJc8NRlLyQ34uHjmxByfPg/132" width="30px"><span>Geek_5hxn61</span> 👍（27） 💬（2）<div>import pandas as pd
&quot;&quot;&quot;利用Pandas清洗美食数据&quot;&quot;&quot;

# 读取csv文件
df = pd.read_csv(&quot;c.csv&quot;)

df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()  # 统一为小写字母
df.dropna(inplace=True)  # 删除数据缺失的记录
df[&#39;ounces&#39;] = df[&#39;ounces&#39;].apply(lambda a: abs(a))  # 负值不合法，取绝对值

# 查找food重复的记录，分组求其平均值
d_rows = df[df[&#39;food&#39;].duplicated(keep=False)]
g_items = d_rows.groupby(&#39;food&#39;).mean()
g_items[&#39;food&#39;] = g_items.index
print(g_items)

# 遍历将重复food的平均值赋值给df
for i, row in g_items.iterrows():
    df.loc[df.food == row.food, &#39;ounces&#39;] = row.ounces
df.drop_duplicates(inplace=True)  # 删除重复记录

df.index = range(len(df))  # 重设索引值
print(df)</div>2019-02-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg" width="30px"><span>西南偏北</span> 👍（16） 💬（1）<div>这些东西，大家都一定要上手去实现一遍。最简单的就是，搞一个文本，把这些数据放进去，用Python读这个文本，转成dataframe，把老师讲的那些清洗相关的API都一个一个试一下，才会有体会，光看一遍真的没啥用的！
现在只是很少的几十条数据，等你真正去搞那些上亿的数据的时候，就知道核对数据是个多么复杂的事情了……</div>2019-01-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/a3/87/c415e370.jpg" width="30px"><span>滢</span> 👍（9） 💬（2）<div>觉得完全合一原则挺好，不过有些操作顺序是不是得更改一下，比如数值补全要在删除全空行之后，否则在补全的时候全空行也会补全。接下来总结在清洗过程中的问题：（1） 不知道Python2 执行情况如何，在用Python3进行数据清理的时候，对于女性三围数据补全的时候因为列中有空字符的存在，会提示‘must str not int’,需要自己过滤含有数值的有效数据进行mean()计算。  (2)生成的新列一般会自动补到后面，但first_name,last_name需要在第一列和第二列，所以要进行列移动或列交换。(3)在删除数据之后默认加载的索引会出现问题，需要自己更新索引</div>2019-04-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/60/de/5c67895a.jpg" width="30px"><span>周飞</span> 👍（6） 💬（1）<div>完整性：ounces 列数据中存在NAN
全面性：food列数据中存在大小写不一致问题
合法性：ounces列数据存在负值
唯一性：food列数据存在重复
# -*- coding: utf-8 -*
import pandas as pd
import numpy as np
from pandas import Series, DataFrame
df = pd.read_csv(&#39;.&#47;fooddata.csv&#39;)
# 把ounces 列中的NaN替换为平均值
df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].mean(), inplace=True)
# 把food列中的大写字母全部转换为小写
df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()
# 把ounces 列中的负数转化为正数
df[&#39;ounces&#39;]= df[&#39;ounces&#39;].apply(lambda x: abs(x))
#删除food列中的重复值
df.drop_duplicates(&#39;food&#39;,inplace=True)
print (df)
</div>2019-01-12</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJAeZ2VCia2y3bW9N7EMfgBqX8WClXUydwaXDPcK7Bm3XaMnMKx7q5ffA0UuTeJmEusxtQAibf8djCA/132" width="30px"><span>上官</span> 👍（6） 💬（1）<div>weight = int(float((lbs_row[&#39;weight&#39;][:-3])&#47;2.2)
老师好，这行代码中[：-3]的作用是什么啊？


</div>2019-01-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/02/82/abed70a0.jpg" width="30px"><span>北方</span> 👍（3） 💬（1）<div>#!&#47;usr&#47;bin&#47;env python
# -*- coding:utf8 -*-
# __author__ = &#39;北方姆Q&#39;
# __datetime__ = 2019&#47;1&#47;11 15:53


import pandas as pd

# 导入
df = pd.read_csv(&quot;.&#47;s11.csv&quot;)
# 去除完全的空行
df.dropna(how=&#39;all&#39;, inplace=True)
# 食物名切分并去掉原本列
df[[&quot;first_name&quot;, &quot;last_name&quot;]] = df[&quot;food&quot;].str.split(expand=True)
df.drop(&quot;food&quot;, axis=1, inplace=True)
# 名称首字母大写
df[&quot;first_name&quot;] = df[&quot;first_name&quot;].str.capitalize()
df[&quot;last_name&quot;] = df[&quot;last_name&quot;].str.capitalize()
# 以食物名为标准去重
df.drop_duplicates([&quot;first_name&quot;, &quot;last_name&quot;], inplace=True)

print(df)</div>2019-01-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/18/d0/49b06424.jpg" width="30px"><span>qinggeouye</span> 👍（2） 💬（2）<div>https:&#47;&#47;github.com&#47;qinggeouye&#47;GeekTime&#47;blob&#47;master&#47;DataAnalysis&#47;11_data_clean.py

import pandas as pd

# 读取数据
data_init = pd.read_csv(&quot;.&#47;11_clothingStoreMembers.csv&quot;)

# 清洗数据

# 删除 &#39;\t&#39; 列, 读取 csv 文件多了一列
data_init.drop(columns=&#39;\t&#39;, inplace=True)
# 重命名列名
data_init.rename(
    columns={&quot;0&quot;: &quot;SEQ&quot;, &quot;1&quot;: &quot;NAME&quot;, &quot;2&quot;: &quot;AGE&quot;, &quot;3&quot;: &quot;WEIGHT&quot;, &quot;4&quot;: &quot;BUST_M&quot;, &quot;5&quot;: &quot;WAIST_M&quot;, &quot;6&quot;: &quot;HIP_M&quot;,
             &quot;7&quot;: &quot;BUST_F&quot;, &quot;8&quot;: &quot;WAIST_F&quot;, &quot;9&quot;: &quot;HIP_F&quot;}, inplace=True)
print(data_init)

# 1、完整性
# 删除空行
data_init.dropna(how=&#39;all&#39;, inplace=True)

# 4、唯一性
# 一列多个参数切分
data_init[[&quot;FIRST_NAME&quot;, &quot;LAST_NAME&quot;]] = data_init[&quot;NAME&quot;].str.split(expand=True)
data_init.drop(&quot;NAME&quot;, axis=1, inplace=True)
# 删除重复数据
data_init.drop_duplicates([&quot;FIRST_NAME&quot;, &quot;LAST_NAME&quot;], inplace=True)

# 2、全面性
# 列数据单位统一, 体重 WEIGHT 单位统一（lbs 英镑， kg 千克）
rows_with_lbs = data_init[&quot;WEIGHT&quot;].str.contains(&quot;lbs&quot;).fillna(False)
print(rows_with_lbs)
# lbs 转为 kg
for i, lbs_row in data_init[rows_with_lbs].iterrows():
    weight = int(float(lbs_row[&quot;WEIGHT&quot;][:-3]) &#47; 2.2)
    data_init.at[i, &quot;WEIGHT&quot;] = &quot;{}kgs&quot;.format(weight)
print(data_init)

# 3、合理性
# 非 ASCII 字符转换，这里删除处理
data_init[&quot;FIRST_NAME&quot;].replace({r&#39;[^\x00-\x7F]+&#39;: &#39;&#39;}, regex=True, inplace=True)
data_init[&quot;LAST_NAME&quot;].replace({r&#39;[^\x00-\x7F]+&#39;: &#39;&#39;}, regex=True, inplace=True)

# 1、完整性
# 补充缺失值-均值补充
data_init[&quot;AGE&quot;].fillna(data_init[&quot;AGE&quot;].mean(), inplace=True)
# 体重先去掉 kgs 的单位符号
data_init[&quot;WEIGHT&quot;].replace(&#39;kgs$&#39;, &#39;&#39;, regex=True, inplace=True)  # 不带单位符号 kgs
data_init[&quot;WEIGHT&quot;] = data_init[&quot;WEIGHT&quot;].astype(&#39;float&#39;)
data_init[&quot;WEIGHT&quot;].fillna(data_init[&quot;WEIGHT&quot;].mean(), inplace=True)

data_init.replace(&#39;-&#39;, 0, regex=True, inplace=True)  # 读取的 csv 数据多了&#39;-&#39;
data_init[&quot;WAIST_F&quot;] = data_init[&quot;WAIST_F&quot;].astype(&#39;float&#39;)
data_init[&quot;WAIST_F&quot;].fillna(data_init[&quot;WAIST_F&quot;].mean(), inplace=True)

# 用最高频的数据填充
age_max_freq = data_init[&quot;AGE&quot;].value_counts().index[0]
print(age_max_freq)
data_init[&quot;AGE&quot;].fillna(age_max_freq, inplace=True)
print(data_init)</div>2019-11-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/8e/6d/c68e07ef.jpg" width="30px"><span>Chino</span> 👍（2） 💬（1）<div>有一个问题 就是代码最后那里to_excel 如果参数的路径是指定的那种 就会报错显示filenotfound 搜了很久都没找到是什么原因 求解
另外感觉这一讲有好多点都没讲深入呀 下面代码是对课程中的样例进行清洗 感觉只能做到几小点了. 特别是在填充nan值的时候 一开始想着遍历每一个nan值 然后再特判列的类型进行填充的. 但是发现三围那里有个大问题 按理说三围应该是int类型 但是因为有- 这个东西的存在 搞的三围是object类型 一开始赋值的时候报错提示需要str 后来想把列的类型转换成int也失败了 还有好多地方都卡着了...
import pandas as pd
import numpy as np
from pandas import Series, DataFrame

data = DataFrame(pd.read_excel(&#39;~&#47;Desktop&#47;data.xlsx&#39;))

print(data)

# 更改列名
data.rename(columns={0:&#39;序号&#39;,1:&#39;姓名&#39;,2:&#39;年龄&#39;,3:&#39;体重&#39;,4:&#39;男三围1&#39;,5:&#39;男三围2&#39;,6:&#39;男三围3&#39;,7:&#39;女三围1&#39;,8:&#39;女三围2&#39;,9:&#39;女三围3&#39;},inplace = True)

# 去掉重复行
data = data.drop_duplicates()

# 1.完整性
# 填充缺失值
col = data.columns.values.tolist()
row = data._stat_axis.values.tolist()

# 先把姓名的数据类型改成字符串
data[&#39;姓名&#39;] = data[&#39;姓名&#39;].astype(&#39;str&#39;) 

# 1.1 先清除空行
data.dropna(how = &#39;all&#39;, inplace = True)

# 1.2 填充缺失值
age_maxf = data[&#39;年龄&#39;].value_counts().index[0]

# 以年龄频率最大值来填充
data[&#39;年龄&#39;].fillna(age_maxf, inplace=True)

# 2.全面性
# 把体重单位为lbs的转化为kgs 2.2lbs = 1kgs
# 把所有体重单位为lbs的记录存放在一起 (如果体重是nan则不要)
rows_with_lbs = data[&#39;体重&#39;].str.contains(&#39;lbs&#39;).fillna(False)

for i,lbs_row in data[rows_with_lbs].iterrows():
    weight = int(float(lbs_row[&#39;体重&#39;][:-3]) &#47; 2.2)
    # 第一个参数是y坐标(竖) 第二个参数是x坐标(横) 
    data.at[i,&#39;体重&#39;] = &#39;{}kgs&#39;.format(weight)

print(data)

# 把清洗后的数据输出
data.to_excel(&#39;CleanData.xlsx&#39;)
# 会报错
# data.to_excel(&#39;~&#47;Desktop&#47;CleanData.xlsx&#39;)</div>2019-01-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/24/b0/a6e0b03a.jpg" width="30px"><span>一语中的</span> 👍（1） 💬（1）<div>#pd读取数据
df = pd.read_excel(&#39;testdata11.xlsx&#39;)
#1.完整性，ounces列NA值用平均值填充
df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].mean(), inplace=True)
#2.全面性，统一food列大小写
df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()
#3.合法性，ounces列负值取绝对值
df[&#39;ounces&#39;] = df[&#39;ounces&#39;].apply(lambda x: abs(x))
#4.唯一性.animal列有重复值
df.drop_duplicates(&#39;food&#39;, inplace=True)
#5.重新排序显示
df.reset_index(drop=True, inplace=True)
print(df)

</div>2019-02-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/f9/81/54b1a5a8.jpg" width="30px"><span>littlePerfect</span> 👍（1） 💬（1）<div>import pandas as pd

df = pd.read_excel(&quot;E:\data_analys_work&#47;food_data.xlsx&quot;)

# 1. 完整性问题: 缺失值
# df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].mean(),inplace=True) # 平均值
ounces_maxf = df[&#39;ounces&#39;].value_counts().index[0] # 出现频率最高的值
df[&#39;ounces&#39;].fillna(ounces_maxf, inplace=True)

# 2. 全面性问题: 列首字母不统一
df[&#39;food&#39;] = df[&#39;food&#39;].str.title()

# 3. 合理性问题: 列数据的单位不统一
df[&#39;ounces&#39;] = df[&#39;ounces&#39;].apply(lambda x: abs(x))

# 4. 唯一性问题: 食物重复出现,求和合并,并删除多余行
# 没想出来.....
</div>2019-02-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg" width="30px"><span>Geek_hve78z</span> 👍（1） 💬（1）<div>1、完整性：
在ounces一列，存在缺失值。处理步骤：删除，因为有重复值
2、全面性：
food列首字母大小写不统一。处理步骤：利用DataFrame.columns.str.lower()全部换成小写
3、合法性：
在重量一列，存在负数。处理步骤，删除
4、唯一性：
在食品名称一列，统一大小写后，存在重复值。处理：求和合并</div>2019-02-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/8e/6d/c68e07ef.jpg" width="30px"><span>Chino</span> 👍（1） 💬（1）<div>作业
import pandas as pd
import numpy as py
from pandas import Series, DataFrame

data = DataFrame(pd.read_excel(&#39;~&#47;Desktop&#47;HomeworkData.xlsx&#39;))

# 把食物的名字统一大小写
data[&#39;food&#39;] = data[&#39;food&#39;].str.title()

# 完整性
# 填充空值
data[&#39;ounces&#39;].fillna(data[&#39;ounces&#39;].mean(), inplace = True)

# 全面性
# 没有发现问题

# 合理性
# ounces值应大于等于0 负值取绝对值
data[&#39;ounces&#39;][data[&#39;ounces&#39;] &lt; 0] = data[&#39;ounces&#39;][data[&#39;ounces&#39;] &lt; 0] * -1

# 唯一性
# 清除食物名重复的数据
data.drop_duplicates(&#39;food&#39;,inplace = True)

data.to_excel(&#39;HomeworkCleanData.xlsx&#39;)
</div>2019-01-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/5e/cb/ad85b408.jpg" width="30px"><span>黃喻榆</span> 👍（0） 💬（1）<div>1. 完整性: 有一格缺失值
2. 全面性: 單位不統一，food欄位值有大小寫，不一致
3. 合理性: 若這是物料控管清單，負值可能是出貨，所以減少庫存。需要跟業主確認。
4. 唯一性: 若是出貨紀錄，就沒必要要求food欄位是唯一。</div>2021-02-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/17/01/1c5309a3.jpg" width="30px"><span>McKee Chen</span> 👍（0） 💬（1）<div>#练习
我的思考：从excel中打开数据，对其空白值进行填充，然后对food列的值全部小写，再按food和animal对数据进行分类，计算ounces均值，最后数据输出成新的excel
import pandas as pd
import numpy as np
from pandas import Series,DataFrame
#建立数据表
df1 = pd.read_excel(r&#39;C:\Users\XXX\Desktop\0928.xlsx&#39;)
#用ounces.mean()填充空白值
df1[&#39;ounces&#39;].fillna(df1[&#39;ounces&#39;].mean(), inplace=True)
#将food列全部小写
for i in range(9):
    df1.at[i,&#39;food&#39;] = df1[&#39;food&#39;][i].lower()
#通过groupby对相同的food和animal求ounces均值
df1 = df1.groupby([df1[&#39;food&#39;],df1[&#39;animal&#39;]]).mean()
df1.to_excel(r&#39;C:\Users\XXX\Desktop\0928_1.xlsx&#39;)

老师讲的数据清洗非常易懂，得多加练习，才能熟能生巧，并要做到温故知新</div>2020-09-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/da/9d/1f825568.jpg" width="30px"><span>拾光</span> 👍（0） 💬（1）<div>这是ocr识别的源数据，供实验用
[[&quot;bacon&quot;, 4.0, &quot;pig&quot;],
[&quot;pulled pork&quot;, 3.0, &quot;pig&quot;],
[&quot;bacon&quot;, NaN , &quot;pig&quot;],
[&quot;Pastrami&quot;, 6.0, &quot;cow&quot;],
[&quot;corned beef&quot;, 7.5, &quot;cow&quot;],
[&quot;Bacon&quot;, 8.0, &quot;pig&quot;],
[&quot;pastrami&quot;, 3.0, &quot;cow&quot;],
[&quot;honey ham&quot;, 5.0, &quot;pig&quot;],
[&quot;nova lox&quot;, 6.0, &quot;salmon&quot;]]</div>2020-08-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/3c/b8/cd7dc389.jpg" width="30px"><span>热河</span> 👍（0） 💬（1）<div>import pandas as pd

file_path = &quot;.&#47;foodInformation.csv&quot;
df = pd.read_csv(file_path)
#数据清洗四项基本原则
#1、完整性：缺失、空行
#删除空行,how不写含有nan的行全部删除
df.dropna(how=&quot;all&quot;, inplace=True)

#均值替换
#df[&quot;ounces&quot;].fillna(df[&quot;ounces&quot;].mean(), inplace=True)
#高频替换
ou_maxf = df[&quot;ounces&quot;].value_counts().index[0]
df[&quot;ounces&quot;].fillna(ou_maxf, inplace=True)

#2、合法性：负数转为正数
# for i in df[&quot;ounces&quot;]:
#     if i&lt;0:
#         i = abs(i)
df[&quot;ounces&quot;] = df[&quot;ounces&quot;].apply(lambda a: abs(a))

#合法性：统一大小写
df[&quot;food&quot;] = df[&quot;food&quot;].str.lower()

#唯一性：删除重复
df.drop_duplicates(&quot;food&quot;, inplace=True)

#排序
df_sort = df.sort_values(by=[&quot;ounces&quot;], axis=0, ascending=True)

print(df_sort)
</div>2020-07-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/3c/b8/cd7dc389.jpg" width="30px"><span>热河</span> 👍（0） 💬（1）<div>import pandas as pd

file_path = &quot;.&#47;foodInformation.csv&quot;
df = pd.read_csv(file_path)
#数据清洗四项基本原则
#1、完整性：缺失、空行
#删除空行,how不写含有nan的行全部删除
df.dropna(how=&quot;all&quot;, inplace=True)

#均值替换
#df[&quot;ounces&quot;].fillna(df[&quot;ounces&quot;].mean(), inplace=True)
#高频替换
ou_maxf = df[&quot;ounces&quot;].value_counts().index[0]
df[&quot;ounces&quot;].fillna(ou_maxf, inplace=True)

#2、合法性：负数转为正数
# for i in df[&quot;ounces&quot;]:
#     if i&lt;0:
#         i = abs(i)
df[&quot;ounces&quot;] = df[&quot;ounces&quot;].apply(lambda a: abs(a))

#合法性：统一大小写
df[&quot;food&quot;] = df[&quot;food&quot;].str.lower()

#唯一性：删除重复
df.drop_duplicates(&quot;food&quot;, inplace=True)

#排序
df_sort = df.sort_values(by=[&quot;ounces&quot;], axis=0, ascending=True)

print(df_sort)
</div>2020-07-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/0e/3d/ded8bc06.jpg" width="30px"><span>As1m0v</span> 👍（0） 💬（1）<div>Python3 
Jupyter Notebook
练习题回答
# 根据ounces列删除含有缺失值数据项
file2.dropna(subset = [&#39;ounces&#39;], inplace = True)

# 将food列中每一行数据统一大小写
file2[&#39;food&#39;] = file2[&#39;food&#39;].str.lower()

# 将ounces列中数据统一为正数(方法一)
file2[&#39;ounces&#39;] = file2[&#39;ounces&#39;].abs()

# 将ounces列中异常数据删除(方法二)
# 这种情况下，这一方法可以和第一条合并
#file2 = file2[file2[&#39;ounces&#39;]&gt;0]

# 将具有相同food列值和animal列值的数据（可选）
file3 = file2.groupby([&#39;food&#39;,&#39;animal&#39;]).sum()</div>2020-06-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/54/d9/76a53118.jpg" width="30px"><span>清风</span> 👍（0） 💬（1）<div>import pandas as pd
import numpy as np
df = pd.DataFrame({&#39;food&#39;:[&#39;bacon&#39;, &#39;pulled pork&#39;, &#39;bacon&#39;, &#39;Pastrami&#39;, &#39;corned beef&#39;, &#39;Bacon&#39;, &#39;pastrami&#39;, &#39;honey ham&#39;, &#39;nova lox&#39;],
                  &#39;ounces&#39;:[4.0, 3.0, None, 6.0, 7.5, 8.0, -3.0, 5.0, 6.0],
                  &#39;animal&#39;:[&#39;pig&#39;, &#39;pig&#39;, &#39;pig&#39;, &#39;cow&#39;, &#39;cow&#39;, &#39;pig&#39;, &#39;cow&#39;, &#39;pig&#39;, &#39;salmon&#39;]},
                 columns=[&#39;food&#39;, &#39;ounces&#39;, &#39;animal&#39;])
df
df.isnull().any()
# 处理None值 赋值为高频词
# 这里初始处理时按赋值 后来发现删除可能更好一点
# df[&#39;ounces&#39;].fillna(df[&#39;ounces&#39;].value_counts().index[0], inplace=True)
df.dropna(inplace=True)
# 把负值赋值为6.0
# df[&#39;ounces&#39;].where(df[&#39;ounces&#39;] &gt; 0, df[&#39;ounces&#39;].value_counts().index[0])
# 绝对值处理
df[&#39;ounces&#39;] = df[&#39;ounces&#39;].apply(lambda x:abs(x))
df
df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()
items = df.groupby(&#39;food&#39;).mean()
items[&#39;food&#39;] = items.index
for i, row in items.iterrows():
    df.loc[df[&#39;food&#39;] == row[&#39;food&#39;],&#39;ounces&#39;] = row[&#39;ounces&#39;]
df.drop_duplicates(inplace=True)
df.reset_index(inplace=True, drop=True)
df</div>2020-06-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/3c/a2/09a2215c.jpg" width="30px"><span>夕子</span> 👍（0） 💬（1）<div>（1）完整性：ounces列存在空值NaN
清洗方式：用均值填充
（2）全面性：food列大小写不统一
清洗方式：统一为小写
（3）合理性：ounces列存在负值
清洗方式：判断是否合理，若不合理，删除或者均值填充
（4）唯一性：food列有重复
清洗方式：去重</div>2020-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/b5/0d/df1f17b5.jpg" width="30px"><span>哎哟哟</span> 👍（0） 💬（1）<div>1，第四行第二列缺失数据，需删除。
2，倒数第3行第2列数据不合法，需删除。
3，重复数据，bacon有3条数据、pastrami有2行数据，如果数据有效需合并，否则删除。
4，food列有大小写，需统一替换。

操作步骤：先删除空值、不合法数据。替换大小写，合并有效数据、删除重复数据。

环境就整了几天结果还是没搞定，pyCharm装第三方库顺利的时候真简单，一旦有问题各种复杂，最后用Spyder跑了【晨星】同学的代码终于跑通了，差点又死在环境上。。。</div>2020-04-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/4d/dc/6c0a311e.jpg" width="30px"><span>Geek_樗</span> 👍（0） 💬（1）<div>刚开始接触这个工作时，就因为不注意数据的整洁，犯了不少笑话。跑出来的报表数据吓死个人。</div>2020-03-30</li><br/><li><img src="" width="30px"><span>十六。</span> 👍（0） 💬（1）<div>import pandas as pd
from pandas import Series,DataFrame

df = pd.read_csv(&#39;dws&#47;foodInfo.csv&#39;)
# 首先 通过学习的数据分析的‘完全合一’简单清洗定理来分析数据
# 数据存在空值（空值可以删除或是使用均值填入，此处我们删除）、大小写不一、单位不合理存在负数
# 首先去除导入进来时多出和行
df = df.dropna()
df = df.drop(df[df[&#39;ounces&#39;] &lt; 0].index)
df[&#39;food&#39;] = df[&#39;food&#39;].str.lower()
# 对数据进行重新行索引
df.index = range(len(df))
# df.reindex(index=list(range(len(df))))
df

	food	ounces	animal
0	bacon	4.0	pig
1	pulled port	3.0	pig
2	pastrami	6.0	cow
3	corned beef	7.5	cow
4	bacon	8.0	pig
5	honey ham	5.0	pig
6	nova lox	6.0	salmon


</div>2020-03-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/6d/ff/d5d14e2c.jpg" width="30px"><span>pyall</span> 👍（0） 💬（1）<div>整理思路：
1、删掉无效数据（整行），并填充缺失值
2、添加性别列，填充性别值
3、合并三维（三列）数据
4、重命名表头字段名称
5、第3列统一标准单位，且数字化

&quot;&quot;&quot;
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

path = r&quot;E:\accountMessage.xlsx&quot;

df = pd.read_excel(path)
df.columns #Index([&#39;\t&#39;, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=&#39;object&#39;)
#df.drop([&#39;&#39;])
df = df[[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]]
#1、删掉空值（整行）
df.dropna(axis=0,how=&#39;all&#39;,inplace = True)

#重命名表头字段名称
df = df.rename(columns = {0:&#39;id&#39;,1:&#39;Name&#39;,2:&#39;Age&#39;,3:&#39;Weight&#39;})
df[&#39;Age&#39;] = df[&#39;Age&#39;].fillna(round(df[&#39;Age&#39;].mean(),0)) #使用平均数填充
df[&#39;Age&#39;].value_counts().index[0]#使用频数最高的数填充


#2、添加性别列，填充性别值
df[&#39;sex&#39;]=&#39;&#39;
df[&#39;sex&#39;][df[4]==&quot;-&quot;]=&#39;female&#39;
df[&#39;sex&#39;][df[4]!=&quot;-&quot;]=&#39;male&#39;

#3、合并三维（三列）数据
df[df==&#39;-&#39;]=0
df2 = df.replace(&#39;-&#39;,0)
df2[&#39;d1&#39;] =df2[4] +df2[7]
df2[&#39;d2&#39;] =df2[5] +df2[8]
df2[&#39;d3&#39;] =df2[6] +df2[9]

df3 = df2.drop([4,5,6,7,8,9],axis=1)
df3 = df2.drop([4]) #默认删除行数据

#5、第3列统一标准单位，且数字化
#1磅(lb)=0.4535924公斤(kg)

df3.isnull().sum()

#数字与字母分开,分成两列
df3[&#39;Weight&#39;].str.replace(&#39;s&#39;,&quot;z&quot;)
df3[&#39;w_unit&#39;] = df3[&#39;Weight&#39;].str[-3:]
df3[&#39;w_new&#39;] = df3[&#39;Weight&#39;].str[:-3].astype(float)

#转化单位数值
df3[&#39;w_kg&#39;] = 0
#不执行
df3[df3[&#39;w_unit&#39;]==&#39;lbs&#39;].loc[:,&#39;w_kg&#39;] = df3[&#39;w_new&#39;]*0.4535924
#执行成功
df3.loc[:,&#39;w_kg&#39;][df3[&#39;w_unit&#39;]==&#39;lbs&#39;] = df3[&#39;w_new&#39;]*0.4535924
df3.loc[:,&#39;w_kg&#39;][df3[&#39;w_unit&#39;]==&#39;kgs&#39;] = df3[&#39;w_new&#39;]</div>2020-03-26</li><br/><li><img src="" width="30px"><span>周铭宇</span> 👍（0） 💬（1）<div>data = {&#39;food&#39;:[&#39;bacon&#39;,&#39;pulled pork&#39;,&#39;bacon&#39;,&#39;Pastrami&#39;,&#39;couned beef&#39;,&#39;bacon&#39;,&#39;pastrami&#39;,&#39;honey ham&#39;,&#39;nova lox&#39;],
        &#39;ounces&#39;:[4.0,3.0,None,6.0,7.5,8.0,-3.0,5.0,6.0],
        &#39;animal&#39;:[&#39;pig&#39;,&#39;pig&#39;,&#39;pig&#39;,&#39;cow&#39;,&#39;cow&#39;,&#39;pig&#39;,&#39;cow&#39;,&#39;pig&#39;,&#39;salmon&#39;,]}

df1 = DataFrame(data)
df1.columns = df1.columns.str.title() # 大写开头
df1[&#39;Food&#39;] = df1[&#39;Food&#39;].str.title()
df1[&#39;Ounces&#39;].fillna(df1[&#39;Ounces&#39;].mean(),inplace=True) # 填充空值
df1[&#39;Ounces&#39;] = df1[&#39;Ounces&#39;].apply(lambda a:abs(a)) # 替换负值
df1.sort_values([&#39;Food&#39;],ascending=[False],inplace=True) # 重新排序
df1.index = range(len(df1)) 
indexArray = [0]
for i in range(1,df1[&#39;Food&#39;].count()): 
    indexArray.append(i)
df1[&#39;Id&#39;] = indexArray
pysqldf = lambda sql: sqldf(sql, globals())
data1 = {&#39;Food&#39;:[&#39;0&#39;]}
lastResult = DataFrame(data1) # 创建一个新的数据 用来判断是否为重复数据
repeatArray = []
for i in range(0,df1[&#39;Food&#39;].count()): # 找出列值均相同行
    sql = &quot;select * from df1 where Animal = &#39;{}&#39; AND Food = &#39;{}&#39;&quot;.format(df1[&#39;Animal&#39;][i],df1[&#39;Food&#39;][i])
    result = DataFrame(pysqldf(sql))
    if len(result) != 1:
        if result[&#39;Food&#39;][0] != lastResult[&#39;Food&#39;][0]: # 判断是否数据
            lastResult = result
            repeatArray.append(result)



def calculate(result): # 计算平均数
    mean = 0.0;
    for i in range(0,result[&#39;Food&#39;].count()):
        mean = result[&#39;Ounces&#39;][i] + mean

    mean = mean &#47; result[&#39;Food&#39;].count()
    return mean

def replaceOunces(result,mean): # 将平均数改为Ounces的值

    for i in range(0,result[&#39;Food&#39;].count()):
        resultId = result[&#39;Id&#39;][i]
        df1.Ounces[df1[&#39;Id&#39;]==resultId]=mean


for i in range(0,len(repeatArray)): # 初次清洗
    mean = calculate(repeatArray[i])
    replaceOunces(repeatArray[i],mean)

df1.drop([&#39;Id&#39;],axis=1,inplace=True) #删除
df1.drop_duplicates(inplace=True) # 去重
print(df1)

&#39;&#39;&#39;
输出结果
          Food    Ounces  Animal
0  Pulled Pork  3.000000     pig
1     Pastrami  4.500000     cow
3     Nova Lox  6.000000  salmon
4    Honey Ham  5.000000     pig
5  Couned Beef  7.500000     cow
6        Bacon  5.520833     pig

&#39;&#39;&#39;</div>2020-03-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/bd/66/bf0cfd22.jpg" width="30px"><span>卢嘉敏</span> 👍（0） 💬（1）<div>文字的缺失该如何实现数据清洗</div>2019-09-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/e9/e9/1f95e422.jpg" width="30px"><span>杨陆伟</span> 👍（0） 💬（1）<div>微服务架构提供数据的微服务中也可以吸纳数据清洗的思想</div>2019-08-21</li><br/>
</ul>