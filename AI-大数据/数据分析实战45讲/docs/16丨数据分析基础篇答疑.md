截止到今天，我们已经将数据分析基础篇的内容都学习完了。在这个过程中，感谢大家积极踊跃地进行留言，既给其他同学提供了不少帮助，也让专栏增色了不少。在这些留言中，有很多同学对某个知识点有所疑惑，我总结了NumPy、Pandas、爬虫以及数据变换中同学们遇到的问题，精选了几个具有代表性的来作为答疑。

## NumPy相关

**答疑1：如何理解NumPy中axis的使用？**

这里我引用文稿中的一段代码：

```
a = np.array([[4,3,2],[2,4,1]])
print np.sort(a)
print np.sort(a, axis=None)
print np.sort(a, axis=0)  
print np.sort(a, axis=1)  
```

同学们最容易混淆的是axis=0 和 axis=1的顺序。你可以记住：axis=0代表跨行（实际上就是按列），axis=1 代表跨列（实际上就是按行）。

如果排序的时候，没有指定axis，默认axis=-1，代表就是按照数组最后一个轴来排序。如果axis=None，代表以扁平化的方式作为一个向量进行排序。

所以上面的运行结果为：

```
[[2 3 4]
 [1 2 4]]
[1 2 2 3 4 4]
[[2 3 1]
 [4 4 2]]
[[2 3 4]
 [1 2 4]]
```

我解释下axis=0的排序结果，axis=0代表的是跨行（跨行就是按照列），所以实际上是对\[4, 2] \[3, 4] \[2, 1]来进行排序，排序结果是\[2, 4] \[3, 4] \[1, 2]，对应的是每一列的排序结果。还原到矩阵中也就是 \[\[2 3 1], \[4, 4, 2]]。

**答疑2：定义结构数组中的S32代表什么意思**？
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/11/cb/81/57024c59.jpg" width="30px"><span>河蟹hxscript</span> 👍（69） 💬（1）<div>这个答疑课是真的良心了。。。。。。</div>2019-01-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/24/b0/a6e0b03a.jpg" width="30px"><span>一语中的</span> 👍（9） 💬（1）<div>import numpy as np
a = np.array([[4,3,2],[2,4,1]])
print (np.sort(a, axis=0) )

关于爬虫：
1.selenium+chrome&#47;chromeless&#47;phatomJS， 可以处理页面加载后，需要运行javaScript，元素才会显示的情况；
2.Scrapy 爬虫框架，针对数据量大，层级嵌套较多的网页，框架中用到yield生成器，是关键
3.解析，lxml,bs4包，正则表达式等  </div>2019-02-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/ee/b8/da245945.jpg" width="30px"><span>几何</span> 👍（8） 💬（1）<div>pyquery解析网页挺好用的</div>2019-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/29/2c/746d0d5d.jpg" width="30px"><span>🦍小梓桐🌙</span> 👍（5） 💬（1）<div>关于numpy中的axis，可以理解成旋转轴或者映射，尤其是高维数组，不应该死记硬背。0是第一维度，也就是行，在行上的映射也就是每一列。以此类推。</div>2019-07-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/f8/99/8e760987.jpg" width="30px"><span>許敲敲</span> 👍（5） 💬（2）<div>np.sort(a,axis=0)
第二题 就会最简单的request 加beautifulsoup. 
加re表达式，爬过 地铁网站 机械专业论坛</div>2019-01-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/bf/e3/2aa8ec84.jpg" width="30px"><span>鱼非子</span> 👍（2） 💬（1）<div>import numpy as np

a = np.array([[4,3,2],[2,4,1]])
b = np.sort(a,axis= 0)
print(b)

爬虫还是新手一枚，目前只会一点request和八爪鱼爬虫
</div>2020-02-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/d5/d6/fe04f976.jpg" width="30px"><span>路过蜻蜓</span> 👍（2） 💬（1）<div>第一题：
import numpy as np
a = np.array([[4,3,2],[2,4,1]])
print (np.sort(a, axis=0) )
第二题
爬虫用的是requests，分析用的比较多的是xpath，有时会用re，re有些优势是xpath不能替代的。beautiful soup 会用，但不用，因为抓取速度是比xpath和re慢。用过senlenium 和headless chromedriver 抓取过一些只用javascript生成数据的网页，xhr都抓不出什么数据的，加密的太严格了。senlenium的确可以无脑抓取网页，但很容易崩溃，不稳定，Puppeteer没有用过，之后会尝试去替代senlenium来抓取。
</div>2019-02-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/a9/32/eb71b457.jpg" width="30px"><span>Grandia_Z</span> 👍（1） 💬（1）<div>报个到，已经上了18讲了，打算利用周末的时间回顾下做个期中复习(^_^)a</div>2019-01-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/b5/0d/df1f17b5.jpg" width="30px"><span>哎哟哟</span> 👍（0） 💬（1）<div>import numpy as np
a = np.array([[4,3,2],[1,2,3]])
print(np.sort(a,axis = 0))

老师教的八爪鱼、requests</div>2020-04-21</li><br/><li><img src="" width="30px"><span>十六。</span> 👍（0） 💬（1）<div>np.sort(a,axis=0)

经常用的是requests，解析库lxml感觉比较容易上手，而且scrapy也有lxml
爬过：51job，安居客，58同城，知乎，哔哩哔哩，豆瓣。。。
scrapy看了一点没看完呢，就跑过来学数据分析了
追求速度还是scrapy，requests学习生活中爬取速度够了，要注意反爬封ip</div>2020-03-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/43/56/3572a20c.jpg" width="30px"><span>xqs42b</span> 👍（0） 💬（1）<div>import numpy as np
a = np.array([[4, 3, 2], [2, 4, 1]])
for i range(len(a)):
   sorted(list(a[i], reverse=False))

老师我想做一个编程的数据分析师，可以往那个方向走！</div>2019-07-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/63/5e/b413dee1.jpg" width="30px"><span>薛定谔的猫</span> 👍（0） 💬（1）<div>无界面浏览器最厉害，fiddler三方工具配合手机模拟器适合抓难抓的数据，比如说淘宝，re的正则是最万能的</div>2019-07-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c5/21/4b1cafe4.jpg" width="30px"><span>泄矢的呼啦圈</span> 👍（0） 💬（1）<div># 评论没啥有用内容，纯夸，加热度
虽然看到这里的时候前面遇到的疑惑已经自行搜索解决了，还是要为老师的处理方式点赞啊（之前看老师回复相对较少，还以为已经不对评论区内容跟进了）</div>2019-04-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/7f/e6/c8a69b20.jpg" width="30px"><span>随便讲两句</span> 👍（0） 💬（1）<div>ChromeDriver要留意版本问题，老师上面留的地址是对应Chrome 72的。
应该到 https:&#47;&#47;npm.taobao.org&#47;mirrors&#47;chromedriver&#47; 下载对应版本（暂时最新是74）。</div>2019-04-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/ee/b8/da245945.jpg" width="30px"><span>几何</span> 👍（0） 💬（1）<div>chromedriver那个需要下载和自己电脑chrome版本相对应的chromedriver</div>2019-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg" width="30px"><span>Geek_hve78z</span> 👍（0） 💬（1）<div>第一道题：假设矩阵 a = np.array([[4,3,2],[2,4,1]])，请你编写代码将矩阵中的每一列按照从小到大的方式进行排序。
import numpy as np
a = np.array([[4,3,2],[2,4,1]])
print (np.sort(a, axis=0) )
第二道题：你都用过哪些 Python 爬虫工具，抓取过哪些数据，觉得哪个工具好用？
1、爬虫工具用过八爪鱼采集器，原因是简单可视化操作。
2、也是用过python的requests库，另外加beautiful解析</div>2019-02-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/2f/e2/3640e491.jpg" width="30px"><span>小熊猫</span> 👍（0） 💬（1）<div>1. 按列，axis=0
a = np.array([[4,3,2], [2, 4, 1]])
np.sort(a, axis=0)

2.目前就用了跟老师一样的。requests，selenium，</div>2019-02-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/21/57/ee02ef41.jpg" width="30px"><span>大龄小学生</span> 👍（0） 💬（1）<div>用过requests+re,但是python的re不完整。
</div>2019-01-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/37/5d/bf3b09f5.jpg" width="30px"><span>任欣</span> 👍（10） 💬（0）<div>使用过Python中的beautiful soup挖掘招聘网站中的人员信息。解析网页比较快，但是遇到验证码的问题比较难搞，如果遇见比较难搞的验证码，比如火车票的验证码，怎么办</div>2019-01-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/b3/d5/1ac75658.jpg" width="30px"><span>Mingjie</span> 👍（4） 💬（0）<div>我简单学过scrapy，很容易上手的爬虫框架，用cookie解决登录问题，</div>2019-01-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/be/76/55e5e326.jpg" width="30px"><span>Chen</span> 👍（1） 💬（0）<div>需要和陈老师讨论一个问题，在网上看到有前辈讲关于“逻辑回归是否需要进行标准化？”，答案是取决于逻辑回归是不是用正则。讲的原因是不用正则时，仅仅是度量预测与真实值的差距，加上正则后，损失函数除了要度量差距外还要度量参数值是否足够小。。而参数值的大小程度或者说大小的级别是与特征的数值范围相关的。您是否同意呢？您讲是当用到梯度下降作为优化器，提高寻找最优解的效率而做标准化。这个前辈讲的是否有道理呢？我比较迷糊了。</div>2019-02-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/31/55/ec/08d0a03f.jpg" width="30px"><span>嫒宝粑粑</span> 👍（0） 💬（0）<div>使用过playwright，pyppeteer，selenium，undetected_chromedriver，playwright使用起来更为方便，可以自动生成自动化代码</div>2023-01-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/62/2c/1145ba50.jpg" width="30px"><span>🍃Edward</span> 👍（0） 💬（0）<div>老师、两份数据、根据经纬度怎么找到相同的一个点？需要使用哪个算法？</div>2022-01-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/f9/4f/66576892.jpg" width="30px"><span>里白💯</span> 👍（0） 💬（0）<div>先按公式计算出百分等级。百分等级（年级）=100-(100x 年级名次 -50)&#47; 有效参加考试人数。这里百分等级是每个学生在该批学生中的相对位置，其中百分等级是按照正态分布图的所占面积比例求得的；按照百分等级数去标准正态分布表中查询得出 Z-Score 值，这样最终得出的 Z 分便是标准的正态分布，能够将偏态转化成标准正态。

这个算法看不懂</div>2021-11-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/25/33/7b/9e012181.jpg" width="30px"><span>Soul of the Dragon</span> 👍（0） 💬（0）<div>思考题：np.sort(a, axis=0)。说实话，平时最常用的爬虫工具还是lxml+Xpath。</div>2021-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/ea/65/f0c93137.jpg" width="30px"><span>Dragon#</span> 👍（0） 💬（1）<div>爬虫工具使用过八爪鱼，爬虫框架使用过scrapy。但是对异步加载的网站不是很会处理，请问老师有什么方法可以处理异步加载的网站？有些网站需要模拟浏览器进行数据采集才行，但是数据采集速度较慢。</div>2020-08-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/7e/a6/4e331ef4.jpg" width="30px"><span>骑行的掌柜J</span> 👍（0） 💬（0）<div>一直以为我已经把这个课程基本都学完了，结果发现还遗漏了几个，这个答疑篇才是精华啊！！！</div>2020-03-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/64/9b/d1ab239e.jpg" width="30px"><span>J.Smile</span> 👍（0） 💬（0）<div>selenium+chrome这种方式遇到问题：
当我爬取某个网站的时候出现了输入验证码的操作，于是我通过selenium+chrome将验证码自动填写进输入框中（验证码使用的是外部api返回的数字），但是发现即便验证码正确。依然是没有权限，我猜应该是别人有反selenium爬虫的机制。看来爬虫也不是万能的！</div>2020-02-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/19/99/e1017dfd.jpg" width="30px"><span>Shawn</span> 👍（0） 💬（0）<div>import numpy as np
a = np.array([[4,3,2],[2,4,1]])
print(a)
a.sort(axis=0,kind=&#39;quicksort&#39;,order = None)
print(a)</div>2019-06-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/c6/fe/cf8b21ab.jpg" width="30px"><span>尚科</span> 👍（0） 💬（0）<div>在一些教材中，数据预处理环节，有一致性检验，具体含义、作用是什么？有没有什么场景举例</div>2019-03-20</li><br/>
</ul>