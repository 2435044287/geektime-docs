上一篇文章中，我们用随机森林以及之前讲过的SVM、决策树和KNN分类器对信用卡违约数据进行了分析，这节课我们来研究下信用卡欺诈。

相比于信用卡违约的比例，信用卡欺诈的比例更小，但是危害极大。如何通过以往的交易数据分析出每笔交易是否正常，是否存在盗刷风险是我们这次项目的目标。

通过今天的学习，你需要掌握以下几个方面：

1. 了解逻辑回归分类，以及如何在sklearn中使用它；
2. 信用卡欺诈属于二分类问题，欺诈交易在所有交易中的比例很小，对于这种数据不平衡的情况，到底采用什么样的模型评估标准会更准确；
3. 完成信用卡欺诈分析的实战项目，并通过数据可视化对数据探索和模型结果评估进一步加强了解。

## 构建逻辑回归分类器

逻辑回归虽然不在我们讲解的十大经典数据挖掘算法里面，但也是常用的数据挖掘算法。

逻辑回归，也叫作logistic回归。虽然名字中带有“回归”，但它实际上是分类方法，主要解决的是二分类问题，当然它也可以解决多分类问题，只是二分类更常见一些。

在逻辑回归中使用了Logistic函数，也称为Sigmoid函数。Sigmoid函数是在深度学习中经常用到的函数之一，函数公式为：

![](https://static001.geekbang.org/resource/image/3e/18/3e7c7cb4d26d1a71f958610f26d20818.png?wh=444%2A204)  
函数的图形如下所示，类似S状：

![](https://static001.geekbang.org/resource/image/b7/3b/b7a5d39d91fda02b21669137a489743b.png?wh=477%2A206)  
你能看出g(z)的结果在0-1之间，当z越大的时候，g(z)越大，当z趋近于无穷大的时候，g(z)趋近于1。同样当z趋近于无穷小的时候，g(z)趋近于0。同时，函数值以0.5为中心。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/18/24/ad/54571ab3.jpg" width="30px"><span>西湖晨曦</span> 👍（22） 💬（7）<div>继续上面的问题。就是，我就是银行信用卡部的工作人员。假设我通过fit()方法得到了信用卡诈骗分析的逻辑回归。假设特征是：性别、收入、是否有房子、是否有车子、是否有助学贷款、是否有公积金这几个特征。我通过fit()方法得到了这个有这些特征的逻辑回归曲线。我如何找到每一个特征前面的系数呢？-----说得直白点，我作为银行信用控制部门工作人员，希望知道上面的特征，哪一个是最重要的，哪一个次重要？哪一个不重要？这样我才能对我的信控工作作出调整。比如我假如知道了是否有助学贷款这个特征不重要，那么我就可以在未来工作中，在银行客户是否允许开信用卡的条件中，取消这个是否有助学贷款的条件，从而给银行信用卡开卡工作带来业务效益。</div>2019-09-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/0c/e5/d8ba6ba0.jpg" width="30px"><span>泷泱汰</span> 👍（11） 💬（1）<div>X = np.array(data.as_matrix()) 这个方法现在在pandas里面移除了，改成X = np.array(data.values)</div>2020-07-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/aa/d1/076482f3.jpg" width="30px"><span>白夜</span> 👍（7） 💬（1）<div>试了下SVM
精确率: 0.843
召回率: 0.717
F1值: 0.775

可以通过人的行为（反动言论，购物情况，日常行为）分析预测人群的标签，比如反社会人格，小众爱好者
也可以，反过来通过人的标签（爱喝酒程度，注意力集中度，运动量等）分析人的行为（车祸，罕见疾病的发生）</div>2019-03-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg" width="30px"><span>Geek_hve78z</span> 👍（6） 💬（1）<div>1、使用LinearSVC输出的结果：
精确率:0.846
召回率:0.733
F1值:0.786
2、结果代码，把

# 逻辑回归分类
clf=LogisticRegression()
clf.fit(train_x,train_y)
predict_y=clf.predict(test_x)

更换为：
#线性SVM分类
from sklearn import svm
model=svm.LinearSVC()
model.fit(train_x,train_y)
predict_y=model.predict(test_x)</div>2019-03-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/24/b0/a6e0b03a.jpg" width="30px"><span>一语中的</span> 👍（4） 💬（1）<div>用SVM的LinearSVC算法进行分类
精确率:0.846
召回率:0.733
F1  值:0.786
如果F1值越大，代表的模型的结果越好，那么SVM应该是优于逻辑回归，但是，从计算时间上来看，用逻辑回归算法比用SVM要节约50多秒（在我本地环境，其他条件不变的情况下）</div>2019-03-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/24/ad/54571ab3.jpg" width="30px"><span>西湖晨曦</span> 👍（2） 💬（4）<div>对本期的信用卡诈骗分析中，涉及逻辑回归（LogisticRegression）有几点问题，我在网上找了大量资料都找不到答案。特地求助~ 
1. 逻辑回归数学公式中，求出的值，是介于（0,1）之间。LogisticRegreesion的predict()方法，会设定一个阈值，比如是0.5，把大于0.5的逻辑回归值，设为1，相反小于0.5的，设置为0。那么我的问题是，为什么要设置0.5？是固定的吗？如果我希望把阈值(threshold)提高到0.6，如何设置？---我看了无数遍API，就是找不到如何设置这个阈值。
 2. 如何看逻辑回归的各个参数。假设我通过fit()这个方法对训练集进行训练，得到了逻辑回归的各个target的值，即我已经得到了这个逻辑回归的各个参数了。假设有10个特征。我如何知道每一个特征前面的变量呢？
</div>2019-09-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/a4/f6/f2b74c42.jpg" width="30px"><span>陈锦榕</span> 👍（2） 💬（1）<div>
***********The evaluation of split test data.*************
Accuracy-Test data: 0.9601
************************************************************************************************************************
Kappa: 0.07924493469331251
************************************************************************************************************************
Confusion matrix,↓real laebl, →predict label”
      0    1
0  9583  397
1     2   18
************************************************************************************************************************
              precision    recall  f1-score   support

           0       1.00      0.96      0.98      9980
           1       0.04      0.90      0.08        20

    accuracy                           0.96     10000
   macro avg       0.52      0.93      0.53     10000
weighted avg       1.00      0.96      0.98     10000</div>2019-07-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/a4/5a/e708e423.jpg" width="30px"><span>third</span> 👍（2） 💬（1）<div>0、所有的小概率事件都属于不平衡数集，比如得某种病，出现车祸或者意外

1、LinearSVC结果：
精确率:0.845
召回率:0.732
F1值:0.778
2、结果代码，把

# 逻辑回归分类
clf=LogisticRegression()
clf.fit(train_x,train_y)
predict_y=clf.predict(test_x)

更换为：
#线性SVM分类
from sklearn import svm
model=svm.LinearSVC()
model.fit(train_x,train_y)
predict_y=model.predict(test_x)</div>2019-03-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg" width="30px"><span>Geek_hve78z</span> 👍（2） 💬（1）<div>逻辑回归混淆矩阵对应的TP、FP、TN、FN的位置，以输出的混淆矩阵图为例，
1）首先这四个概念的定义
1. TP：预测为正，判断正确；
2. FP：预测为正，判断错误；
3. TN：预测为负，判断正确；
4. FN：预测为负，判断错误。
2）回归原图
1、predicted=1，True=1，代表预测为正，判断正确，所以TP=37
2、predicted=1，true=0，代表预测为正，判断错误，所以FP=7
3、predicted=0，true=1，代表预测为负，判断错误，所以FN=23

</div>2019-03-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/da/9d/1f825568.jpg" width="30px"><span>拾光</span> 👍（1） 💬（1）<div>F1值表示什么呢，没搞明白，模型判断出一笔交易有可能涉嫌欺诈，准确率只有84.1%，不是也很低吗？</div>2020-12-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg" width="30px"><span>Simon</span> 👍（1） 💬（1）<div>正负样本极不均衡，为什么在train_test_split时，没有分层采样：stratify=y？</div>2020-04-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg" width="30px"><span>建强</span> 👍（1） 💬（1）<div>思考题：
1.不平衡的数据：历年飞机空难和正常飞行的数据，历年发生重大事故的企业和正常生产的企业
2.使用SVM模型对信用卡数据集分类，计算效率比逻辑回归模型低很多，精确率要低于逻辑回归、但召回率和F1都要高于逻辑回归模型，这三个指标分别为
精确率: 0.793
召回率: 0.767
F1值: 0.780</div>2020-04-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/36/88/20b6a6ee.jpg" width="30px"><span>Simon</span> 👍（0） 💬（1）<div>为什么v1~v28没有做归一化？只是&quot;Amount&quot;做了。因为v1~v28量纲差不多？</div>2020-04-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/94/6d/5cd6e8c7.jpg" width="30px"><span>张贺</span> 👍（0） 💬（1）<div>精确率: 0.846
召回率: 0.733
F1值: 0.786</div>2020-03-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/ff/98/6e17646a.jpg" width="30px"><span>桔子</span> 👍（0） 💬（1）<div>前提是进行了pca处理，不然还要考虑多重共线性</div>2020-03-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/5b/fa/b796d9f0.jpg" width="30px"><span>Since一九八三</span> 👍（0） 💬（2）<div>老师您好，我想请问一下V1，V2，……V28这28个特征是如何判定他是有序的数值特征还是无序的类别特征呢？如果这是无序类别特征是不是需要做独热编码处理呢？但是这类别数量太大要怎么做独热？</div>2020-03-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/47/a0/f12115b7.jpg" width="30px"><span>Sam.张朝</span> 👍（0） 💬（1）<div>我以为程序是判断一笔交易，是否是不正常的。</div>2019-08-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/47/4c/65404d1e.jpg" width="30px"><span>东东哥</span> 👍（0） 💬（1）<div>(0, 0)格子真实值和预测值都为0，称为预测Negative正确，记作True Negative，简写为TN。
(0, 1)格子真实值为0，但预测值为1，称为预测Positive错误，记作False Positive，简写为FP。
(1, 0)格子真实值为1， 但预测值为0，称为预测Negative错误，记作False Negative，简写为FN。
(1, 1)格子真实值和预测值都为1，称为预测Positive正确，记作True Positive，简写为TP。</div>2019-07-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c3/24/4731d31d.jpg" width="30px"><span>digitarts</span> 👍（0） 💬（1）<div>老师，我看到，在预测比特币走势的最后一张图表上，实际值与预测值尽管趋势类似，但是在发生的时间上，测试值比实际值晚了一段时间，请问有什么方法尽量缩短这个时间序列的间隙么？多谢🙏</div>2019-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/62/a5/43aa0c27.jpg" width="30px"><span>TKbook</span> 👍（0） 💬（1）<div>model = svm.SVC()
model.fit(train_x, train_y)
predict_y = model.predict(test_x)
cm = confusion_matrix(test_y, predict_y)
show_metrics()

精确率：0.953
召回率：0.683
F1值：0.796</div>2019-03-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/24/b0/a6e0b03a.jpg" width="30px"><span>一语中的</span> 👍（0） 💬（0）<div>不平衡数据：
1.欺诈预测（欺诈的数量远远小于真实交易的数量）
比如，本节内容的信用卡欺诈交易
2.自然灾害预测（不好的事情远远小于好的事情）
3.买彩票中奖（小概率）
4.在图像分类中识别恶性肿瘤（训练样本中含有肿瘤的图像远比没有肿瘤的图像少）</div>2019-03-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/7d/05/4bad0c7c.jpg" width="30px"><span>Geek_hve78z</span> 👍（0） 💬（1）<div>不均衡数据集是指，数据集中每个类别下的样本数目相差很大。
比如，在客户流失的数据集中，绝大部分的客户是会继续享受其服务的（非流失对象），只有极少数部分的客户不会再继续享受其服务（流失对象）
又如，检查出厂冰箱的合格率，本来合格率就高达了96%。如果对样本进行检测，准确率也是很高的，那么将会无法判断次品。
再如，检查邮件中的垃圾邮件，因为垃圾邮件占全部邮件极少的部分，所以也是属于不平衡数据集
</div>2019-03-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/8b/dc/925e0f8a.jpg" width="30px"><span>换个调调</span> 👍（2） 💬（1）<div>1.置信分数是一个什么概念呢？
2.为什么计算PR值取 score_y 而不是 pred_y?
3.像SVC、LogisticRegression没有 feature_importances 如何判断各个特征的重要性呢？</div>2020-03-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/32/52/c843fc53.jpg" width="30px"><span>feng</span> 👍（1） 💬（0）<div>逻辑回归模型的求解这里不做介绍，我们来看下如何使用 sklearn 中的逻辑回归工具。在 sklearn 中，我们使用 LogisticRegression() 函数构建逻辑回归分类器，函数里有一些常用的构造参数：penalty：惩罚项，取值为 l1 或 l2，默认为 l2。当模型参数满足高斯分布的时候，使用 l2，当模型参数满足拉普拉斯分布的时候，使用 l1；
请问老师这个模型的参数是满足高斯分布还是拉普拉斯分布，为什么？</div>2022-08-25</li><br/><li><img src="" width="30px"><span>杨博</span> 👍（1） 💬（0）<div>问题一：本文中PCA如何判断降维到28是较适合？维度不同对结果的影响很大。
问题二：在其他的场景进行回归预测，1954条数据，20个特征变量，但是在sklearn中的几个典型的回归模型中R2分值差别很大，集成类的模型打分0.93+，有的0.7+，有的0.8+，请教是数据存在一定问题？还是模型不合适的问题？</div>2022-02-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/86/79/066a062a.jpg" width="30px"><span>非同凡想</span> 👍（0） 💬（0）<div>reg = LinearSVC()
reg.fit(train_x, train_y)
pred_y = reg.predict(test_x)
cm = confusion_matrix(test_y, pred_y)
class_names = [0,1]
plot_confusion_matrix(cm, classes=class_names, title=&#39;混淆矩阵&#39; )
show_metrics(cm)

precision:0.830
recall:0.650
f1:0.729</div>2020-11-30</li><br/><li><img src="" width="30px"><span>Geek_00acb1</span> 👍（0） 💬（0）<div>请问：1、如果现实中不能等到正常交易和异常交易样本的数据都收集完后，才进行模型训练。比如目前只收集了正常样本的数据。是否可以利用正常数据的进行学习，得到正常样本的模型。然后每次交易都和这个模型进行比较。比如利用，高斯混合模型求出正常交易的样本分布情况，每次交易都和正常模型分布进行比较，这种模型训练的方式是否可行？2、文中提到用linearsvm进行模型训练，是否可以用oneclasssvm进行模型训练，oneclasssvm是否适用该数据不均衡的分类问题？</div>2020-11-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg" width="30px"><span>JustDoDT</span> 👍（0） 💬（0）<div>交作业：
https:&#47;&#47;github.com&#47;LearningChanging&#47;Data-analysis-in-action&#47;tree&#47;master&#47;40-%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E6%88%98%EF%BC%882%EF%BC%89%EF%BC%9A%E4%BF%A1%E7%94%A8%E5%8D%A1%E8%AF%88%E9%AA%97%E5%88%86%E6%9E%90</div>2020-04-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/3e/97/b5da2693.jpg" width="30px"><span>李翔</span> 👍（0） 💬（0）<div>特征选择中为什么要drop掉amount这个特征呀？上一步amount不是刚标准化嘛？</div>2020-01-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8e/0a/31ec5392.jpg" width="30px"><span>挠头侠</span> 👍（0） 💬（0）<div>老师 为什么只依靠查准率无法判断模型的好坏呢？我试过很多情况，让我感觉是基本上都可以通过查准率判断模型好坏</div>2019-06-05</li><br/>
</ul>