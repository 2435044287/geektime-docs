你好，我是金伟。

回想一下前几节课和电商客服项目里的具体例子，为什么我们要开发电商客服专用模型呢？其实，总体的目的还是提升模型处理特定复杂问题的能力，具体事实上，我们采用的是微调训练JSON原子能力的方法。

之所以要训练JSON原子能力，是因为大模型需要和智能体配合才能达到较高的可靠性，而JSON是最适合跟现有编程体系对接的数据格式。

本节课将进一步探讨整个项目中JSON等数据协议的提升方法，包括基础数据格式化、专有模型构建，以及后续的各类优化。它们的灵魂还是数据工程，这些补充经验对你将来做其他项目也同样适用。

## 基础数据格式化

经过之前的课程，你可能会觉得只有当大模型遇到处理不了的问题时候，才会做数据工程，实际上则不然，我们回顾一下Dify的Agent智能体流程图。

![图片](https://static001.geekbang.org/resource/image/4c/4a/4c08c2d85e2eac965e87758ea4bc5a4a.png?wh=1920x1063)

需要注意，不管客服问题有多少分类，Agent智能体在意图识别阶段，最重要的能力就是把用户的问题转化为JSON的数据格式，用作参数传递给后续的工作流。

```plain
顾客:我的订单12345到哪了？
智能客服：
```

比如这个订单物流查询的例子，Agent智能体需要抽取出如下格式的信息。

```plain
{
  "order_id": "12345"
}
```

我们在真实项目中的经验是，可以**对每一个基础的问题分类都做数据抽取格式的训练**。这样能极大提高大模型的意图识别能力。
<div><strong>精选留言（1）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/16/c8/79/0e91a8bd.jpg" width="30px"><span>Aoinatsume</span> 👍（1） 💬（0）<div>《Does Prompt Formatting Have Any Impact on LLM Performance?》（https:&#47;&#47;arxiv.org&#47;html&#47;2411.10541v1）这篇论文里有提到提示格式化方式会显著影响基于GPT的模型性能，例如，在GPT-4模型上使用Markdown的表现更好一些，而GPT-3.5-turbo模型中使用JSON进行翻译任务时性能会比其他提示格式高40%。老师您觉得以后不同的提示格式、不同的大模型和不同的任务类型进行适配会是一项常规工作吗，还是最终会统一出一种格式。</div>2024-11-28</li><br/>
</ul>