你好，我是金伟。

对于咱们开发者来说，在本地体验大模型，相当于写一个 `hello world` 程序，没什么难度。那这节课，我们就讨论讨论大模型AI智能体开发过程里更多的一些挑战。

接触过一些大模型知识的朋友都听过一个词，大模型幻觉，指的是大模型有一定概率会胡编乱造。比如你问它桃园三兄弟“刘备、关羽、赵云”是怎么先后战死的啊？很明显，这问题就是错误的。但是大模型还会沿着错误一本正经地发挥。

![图片](https://static001.geekbang.org/resource/image/5c/3d/5c7dee4c6ff4d01e17be9b29ff9cd23d.png?wh=1920x1138)

我们介绍过，Transformer架构是基于概率输出内容，这是大模型产生幻觉的原因。然而幻觉并不一定就意味着是坏事，没有幻觉的大模型不可能具有创造性，对吧？**做大模型AI智能体开发，本质上就是如何尽量提高大模型的创造性，同时避免大模型出现偏差错误的过程。**

我把大模型AI智能体开发由浅入深分为三个层次，**应用开发、微调开发和专有模型开发**。这节课，我们就把这三个层次分别都是什么，需要做什么给讲清楚。

## 应用开发

想要了解清楚大模型在应用开发中的角色，我们需要先从传统的互联网开发架构谈起。如下图所示，传统的互联网开发架构分为数据库层、应用层和用户终端层。

![图片](https://static001.geekbang.org/resource/image/36/d9/36441abf8e21029a7c7b462b8d4911d9.png?wh=1920x848)

加入大模型之后的应用架构应该是什么样的呢？我们需要进一步分析。上图中的LLM表示大模型，在真实应用开发中，指的就是一个公开提供服务的大模型平台。
<div><strong>精选留言（5）</strong></div><ul>
<li><img src="https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJkwbyTYtSCx6Qc7cQPnnRWv38Jybh3etziaPmuP8gHcgS6FMxcdftrKgWiamH6fc2iciaicDKDVEwcEibQ/132" width="30px"><span>sami</span> 👍（8） 💬（1）<div>思考题：
在大模型AI智能体开发中,功能实现的选择通常如下:

1. 使用LLM(大语言模型)实现的功能:
   - 自然语言理解和生成
   - 复杂问题的推理和解答
   - 创意内容生成(如写作、故事创作)
   - 多轮对话管理
   - 上下文相关的任务处理

2. 使用传统程序接口实现的功能:
   - 精确的数学计算
   - 数据库操作和管理
   - 系统级操作(如文件处理、网络通信)
   - 特定领域的专业算法(如金融模型、物理模拟)
   - 用户界面和交互

选择标准主要考虑以下几点:

1. 任务的性质:是否需要语言理解或生成?是否涉及复杂推理?
2. 精确度要求:任务是否需要高度精确的结果?
3. 计算效率:哪种方法能更快地完成任务?
4. 可解释性:是否需要清晰解释决策过程?
5. 数据隐私:任务是否涉及敏感信息处理?
6. 资源消耗:考虑计算资源和成本。
7. 可维护性:哪种方法更容易更新和维护?

评判标准可以包括:

1. 性能:任务完成的速度和质量。
2. 准确性:结果的精确度。
3. 可靠性:系统的稳定性和一致性。
4. 可扩展性:能否轻松处理更大规模的任务。
5. 用户体验:最终用户使用的流畅度和满意度。
6. 开发和维护成本:包括时间和资金投入。

实际应用中,往往需要LLM和传统程序接口的结合使用,以达到最佳效果。例如,可以使用LLM处理自然语言输入,然后调用传统接口执行具体操作,最后再用LLM生成人性化的输出。

选择时需要权衡各种因素,并根据具体项目需求做出最适合的决定。随着技术的发展,这种选择的界限可能会越来越模糊,未来可能会出现更智能的混合系统。</div>2024-08-16</li><br/><li><img src="https://wx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJkwbyTYtSCx6Qc7cQPnnRWv38Jybh3etziaPmuP8gHcgS6FMxcdftrKgWiamH6fc2iciaicDKDVEwcEibQ/132" width="30px"><span>sami</span> 👍（2） 💬（1）<div> 金字塔
1. 大模型AI智能体开发
   1.1 应用开发
      1.1.1 传统互联网架构
      1.1.2 大模型接口
      1.1.3 提示词工程
      1.1.4 逻辑控制
   1.2 微调开发
      1.2.1 微调概念
      1.2.2 数据整理
      1.2.3 效果对比
      1.2.4 向量数据库vs微调
   1.3 专有模型开发

## 核心概念解释

 1. 大模型幻觉

 专业解释
大模型幻觉是指大型语言模型(如GPT)有时会产生看似合理但实际上不正确或虚构的信息。这是由于模型基于概率生成内容,而不是严格的事实检索。

 5W2H分析
- What(是什么): 大模型生成不准确或虚构信息的现象
- Why(为什么): 基于概率的生成机制导致
- Where(在哪里): 在大模型的输出结果中
- When(何时): 在模型回答问题或生成内容时
- Who(谁): 影响使用大模型的开发者和用户
- How(如何发生): 模型基于训练数据和概率分布生成内容

 生活类比
想象一个博学多才但偶尔会&quot;胡说八道&quot;的朋友。他知识渊博,能侃侃而谈,但有时会不经意间混淆事实或编造故事。

 2. 提示词工程

 专业解释
提示词工程是指设计和优化输入到大语言模型的文本提示,以获得期望的输出结果。它是让大模型执行特定任务的关键技术。

 生活类比
提示词工程就像是与一位聪明但需要精确指令的助手沟通。想象你在指导一位厨师烹饪一道特殊菜肴。你需要清晰、准确地描述每个步骤,考虑到所有细节,这样才能得到理想的菜品。
提示词工程就是这样,通过精心设计的&quot;菜谱&quot;(提示词),引导大模型&quot;烹饪&quot;出我们想要的&quot;菜肴&quot;(输出结果)。

## 技术原理简述

 1. 大模型接口

 专业解释
大模型接口是访问和使用大语言模型能力的入口。

 生活类比
想象大模型是一个超级智能的图书馆管理员。这个图书馆管理员知识渊博,可以回答各种问题。大模型接口就像是图书馆的咨询台,你可以在这里提出问题(输入),然后得到管理员的回答(输出)。
不同的是,你还可以通过调整一些参数(如温度),来影响管理员回答的风格和创造性。

 2. 模型微调

 专业解释
模型微调是一种技术,通过使用特定领域的数据集对预训练的大模型进行进一步训练,使其适应特定任务或领域的过程。

 生活类比
想象你有一位通晓多国语言的朋友。这位朋友已经掌握了基本的语言能力(预训练模型)。现在,你想让他专门学习医学术语(特定领域)。通过集中学习医学教材和论文(微调数据集),你的朋友不仅保持了原有的语言能力,还获得了专业的医学知识。这就是模型微调的过程,让原本&quot;全能&quot;的模型在特定领域更加精通。
</div>2024-08-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/f1/d7/3d129aa2.jpg" width="30px"><span>润泽</span> 👍（0） 💬（1）<div>请问学完整个专栏之后，个人开发者能具备足够的能力去开发一些产品进行创业么？是否另需要学习pytorch或者TensorFlow？</div>2024-09-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/3b/0a/c5/c1d13a44.jpg" width="30px"><span>Tristan</span> 👍（0） 💬（1）<div>目前来看ai first的接口开发模式还很难替代传统模式，响应时间，算力消耗，幻觉问题</div>2024-08-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/23/c2/5c/791d0f5e.jpg" width="30px"><span>易企秀-郭彦超</span> 👍（0） 💬（2）<div>你好，当询问明天天气 ，直接转成向量去查询 能理解明天是哪一天吗</div>2024-08-14</li><br/>
</ul>