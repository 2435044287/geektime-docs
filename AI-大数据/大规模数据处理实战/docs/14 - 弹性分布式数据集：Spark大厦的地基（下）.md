你好，我是蔡元楠。

上一讲我们介绍了弹性分布式数据集（RDD）的定义、特性以及结构，并且深入讨论了依赖关系（Dependencies）。

今天让我们一起来继续学习RDD的其他特性。

## RDD的结构

首先，我来介绍一下RDD结构中其他的几个知识点：检查点（Checkpoint）、存储级别（ Storage Level）和迭代函数（Iterator）。

![](https://static001.geekbang.org/resource/image/8c/1c/8cae25f4d16a34be77fd3e84133d6a1c.png?wh=1776%2A2263)

通过上一讲，你应该已经知道了，基于RDD的依赖关系，如果任意一个RDD在相应的节点丢失，你只需要从上一步的RDD出发再次计算，便可恢复该RDD。

但是，如果一个RDD的依赖链比较长，而且中间又有多个RDD出现故障的话，进行恢复可能会非常耗费时间和计算资源。

而检查点（Checkpoint）的引入，就是为了优化这些情况下的数据恢复。

很多数据库系统都有检查点机制，在连续的transaction列表中记录某几个transaction后数据的内容，从而加快错误恢复。

RDD中的检查点的思想与之类似。

在计算过程中，对于一些计算过程比较耗时的RDD，我们可以将它缓存至硬盘或HDFS中，标记这个RDD有被检查点处理过，并且清空它的所有依赖关系。同时，给它新建一个依赖于CheckpointRDD的依赖关系，CheckpointRDD可以用来从硬盘中读取RDD和生成新的分区信息。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/16/67/8a/babd74dc.jpg" width="30px"><span>锦</span> 👍（63） 💬（4）<div>区别在于Checkpoint会清空该RDD的依赖关系，并新建一个CheckpointRDD依赖关系，让该RDD依赖，并保存在磁盘或HDFS文件系统中，当数据恢复时，可通过CheckpointRDD读取RDD进行数据计算；持久化RDD会保存依赖关系和计算结果至内存中，可用于后续计算。</div>2019-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/9a/18/3596069c.jpg" width="30px"><span>RocWay</span> 👍（32） 💬（1）<div>主要区别应该是对依赖链的处理：
checkpoint在action之后执行，相当于事务完成后备份结果。既然结果有了，之前的计算过程，也就是RDD的依赖链，也就不需要了，所以不必保存。
但是cache和persist只是保存当前RDD，并不要求是在action之后调用。相当于事务的计算过程，还没有结果。既然没有结果，当需要恢复、重新计算时就要重放计算过程，自然之前的依赖链不能放弃，也需要保存下来。需要恢复时就要从最初的或最近的checkpoint开始重新计算。</div>2019-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/41/27/3ff1a1d6.jpg" width="30px"><span>hua168</span> 👍（7） 💬（2）<div>老师，我想问下，如果是linux 命令分析单机300G log日志，内存只有16G，怎搞？
如果用spark思想，，从io读很卡，直接内存爆了。
如果先分割日志为100份，再用shell，一下10个并发执行，最后结果合并。感觉还是有点慢。</div>2019-05-17</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLdWHFCr66TzHS2CpCkiaRaDIk3tU5sKPry16Q7ic0mZZdy8LOCYc38wOmyv5RZico7icBVeaPX8X2jcw/132" width="30px"><span>JohnT3e</span> 👍（5） 💬（2）<div>两者区别在于依赖关系是否保留吧。checkpoint的话，检查点之前的关系应该丢失了，但其数据已经持久化了；而persist或者cache保留了这个依赖关系，如果缓存结果有丢失，可以通过这个关系进行rebuild。</div>2019-05-17</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/9chAb6SjxFiapSeicsAsGqzziaNlhX9d5aEt8Z0gUNsZJ9dICaDHqAypGvjv4Bx3PryHnj7OFnOXFOp7Ik21CVXEA/132" width="30px"><span>挖矿的小戈</span> 👍（4） 💬（1）<div>1. 前者：persist或者cache除了除了持久化该RDD外，还会保留该RDD前面的依赖关系
2. 后者：将该RDD保存到磁盘上，并清除前面的依赖关系
感觉后者的开销会大很多</div>2019-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/3d/5d/ac666969.jpg" width="30px"><span>miwucc</span> 👍（3） 💬（1）<div>手动调用缓存函数和checkpoint本质上是一样的吧。就是一个手动控制落盘时间，一个自动控制。</div>2019-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/aa/fa/3ad0a689.jpg" width="30px"><span>廖师虎</span> 👍（3） 💬（1）<div>记不太清除了，checkpoint清除血缘关系，一般保存在类hdfs文件系统，目的是容错，缓存是保留血缘关系，并保存在本机，的目的是提高效率，High performance Spark书讲得很详细。

第一次遇到把driver翻译成驱动程序的，个人感觉还是保留Driver，Action为佳。</div>2019-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/48/f3/65c7e3ef.jpg" width="30px"><span>cricket1981</span> 👍（3） 💬（1）<div>终于明白spark惰性求值的原理了。我理解对 RDD 进行持久化操作和记录 Checkpoint的区别是：前者是开发人员为了避免重复计算、减少长链路计算时间而主动去缓存中间结果，而后者是spark框架为了容错而提供的保存中间结果机制，它对开发人员是透明的，无感知的。</div>2019-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/6a/86/f1876812.jpg" width="30px"><span>Steven</span> 👍（2） 💬（3）<div>缓存了之后，第一个action还是需要从头计算的吧？ &quot;所以无论是 count 还是 first，Spark 都无需从头计算&quot;， 这句话是不是有误？</div>2019-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/1f/a7/d379ca4f.jpg" width="30px"><span>jon</span> 👍（2） 💬（1）<div>checkpoint不会存储该rdd前面的依赖关系，它后面的rdd都依赖于它。
persist、 cache操作会存储依赖关系，当一个分区丢失后可以根据依赖重新计算。</div>2019-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/fe/45/c353f3da.jpg" width="30px"><span>Peter</span> 👍（1） 💬（1）<div>在缓存 RDD 的时候，它所有的依赖关系也会被一并存下来。所以持久化的 RDD 有自动的容错机制。如果 RDD 的任一分区丢失了，通过使用原先创建它的转换操作，它将会被自动重算</div>2019-05-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/93/b8/6510592e.jpg" width="30px"><span>渡码</span> 👍（0） 💬（1）<div>设计上，应用场景不同，checkpoint用来做故障恢复，cache为了避免重复计算。实现技术上我没做深入了解不清楚，猜测存储技术类似，可能checkpoint会额外增加用于故障恢复的信息</div>2019-05-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/ee/16/742956ac.jpg" width="30px"><span>涵</span> 👍（14） 💬（0）<div>从目的上来说，checkpoint用于数据恢复，RDD持久化用于RDD的多次计算操作的性能优化，避免重复计算。从存储位置上看checkpoint储存在外存中，RDD可以根据存储级别存储在内存或&#47;和外存中。</div>2019-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/f3/dc/80b0cd23.jpg" width="30px"><span>珅剑</span> 👍（7） 💬（0）<div>1.设置checkpoint时需要指定checkpoint的存储目录，而持久化不管是直接调用cache还是通过persist指定缓存级别都不需要指定存储目录，由系统自己指定
2.checkpoint是将RDD去除依赖关系后将数据直接存储到磁盘，且一般是HDFS，带有备份，因此不容易丢失，恢复时直接获取checkpoint的数据；而持久化一般是直接cache到内存。数据容易丢失，即便是通过设置MEMORY_AND_DISK_2等缓存级别达到内存和磁盘都有备份，也会在每个备份中都缓存RDD的依赖关系，造成不必要的冗余</div>2019-06-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/fe/45/c353f3da.jpg" width="30px"><span>Peter</span> 👍（2） 💬（0）<div>在计算过程中，对于一些计算过程比较耗时的 RDD，我们可以将它缓存至硬盘或 HDFS 中，标记这个 RDD 有被检查点处理过，并且清空它的所有依赖关系。同时，给它新建一个依赖于 CheckpointRDD 的依赖关系，CheckpointRDD 可以用来从硬盘中读取 RDD 和生成新的分区信息。
</div>2019-05-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/48/f3/65c7e3ef.jpg" width="30px"><span>cricket1981</span> 👍（2） 💬（0）<div>RDD的checkpoint会导致写入可靠存储的开销。这可能导致RDD被checkpoint的那些批次的处理时间增加。相反，checkpoint太过不频繁会导致血统链增长和任务大小增加。请问该如何设置合理的checkpoint时间间隔呢？</div>2019-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/06/a0/3da0e315.jpg" width="30px"><span>茂杨</span> 👍（1） 💬（0）<div>Spark的计算是按照Action为单位的，多次的转换在一起只为了组成一个公式，只有真正把数据赋值在公式中并写上等号了才去执行(Action)</div>2020-09-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/bb/56/41cbcda2.jpg" width="30px"><span>Sissi</span> 👍（1） 💬（0）<div>我是否可以这样理解，使用checkpoint，而不是用持久化的RDD来进行数据恢复，是因为当从某一个节点进行回放时，checkpoint的路径比持久化RDD短，更能节省时间，但spark的这种机制也决定了它不支持确定性计算。</div>2019-09-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/28/02/a6d7ece6.jpg" width="30px"><span>refactor</span> 👍（1） 💬（0）<div>cache 和 checkpoint 区别：1.产生过程，cache 是 partition 分区计算完后就执行，而后者是要整个 rdd 计算完再去起新的 job 完成，成本更大；2.执行完后 cache 无论存在内存还是硬盘都会被清理，而 后者不会，除非手动清理；3.cache保存依赖关系，而后者删除所有依赖关系。4.读取一个同时被 cache 和 checkpoint 处理过的 rdd，会先读取前者。</div>2019-07-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4d/49/28e73b9c.jpg" width="30px"><span>明翼</span> 👍（1） 💬（0）<div>checkpoint用的不多，是不是可以对目前所有的rdd均缓存，rdd是针对特定rdd缓存</div>2019-05-17</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqXSb2jAzlMM0JdTjWrNiaq2uR9eeloBYp906POddb9evmuj5f4CUoO6ge8TibibwtZicnl1sRHic9rW7g/132" width="30px"><span>紫龙</span> 👍（0） 💬（0）<div>RD持久化是给使用这优化选择，对外优化；Checkpoint面对复杂计算罗，是系统自动行为，对内部优化。</div>2022-11-03</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erms9qcIFYZ4npgLYPu1QgxQyaXcj64ZBicNVeBRWcYUpCZ9p0BGsrEcX8heibMLCV4Gde4P9pf7PjA/132" width="30px"><span>yanger2004</span> 👍（0） 💬（0）<div>persist和cache什么区别？</div>2022-06-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg" width="30px"><span>piboye</span> 👍（0） 💬（0）<div>是不是map&#47;reduce可以处理更大规模的数据啊？</div>2020-10-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1c/fa/96/4a7b7505.jpg" width="30px"><span>Eden2020</span> 👍（0） 💬（0）<div>checkpoint会清空依赖关系，持久化不会</div>2020-03-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/4e/c7/8c2d0a3d.jpg" width="30px"><span>余泽锋</span> 👍（0） 💬（0）<div>请问spark可以支持多表头的数据吗？</div>2020-02-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/ab/34/981f8480.jpg" width="30px"><span>匿名</span> 👍（0） 💬（0）<div>如果一个DAG图中出现菱形结构，我持久化会提高效率吗？在一个Action的DAG血缘图里，有个父RDD被两个子RDD依赖。</div>2019-08-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/b6/2e/096790e1.jpg" width="30px"><span>淹死的大虾</span> 👍（0） 💬（0）<div>持久化到内存就不说了，用完就没了。和持久化到硬盘比，checkpoint只需要按需在关键节点储存，持久化则所有操作节点都会</div>2019-06-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/dc/c3/e4ba51d5.jpg" width="30px"><span>Flash</span> 👍（0） 💬（0）<div>检查点是Spark的一个容错机制，应该是会自动缓存那些计算比较耗时的RDD，缓存的是进行计算动作的RDD。
持久化是Spark针对转换操作的RDD进行缓存，需要开发人员手动调用persist或cache方法。</div>2019-06-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/71/f6/5bcefe24.jpg" width="30px"><span>徐宁</span> 👍（0） 💬（0）<div>看图一spark sql支持jdbc吗？老师能给个链接不？</div>2019-06-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/0f/71/9273e8a4.jpg" width="30px"><span>时间是最真的答案</span> 👍（0） 💬（0）<div>checkpoint用于数据回滚，持久化用于计算</div>2019-05-22</li><br/>
</ul>