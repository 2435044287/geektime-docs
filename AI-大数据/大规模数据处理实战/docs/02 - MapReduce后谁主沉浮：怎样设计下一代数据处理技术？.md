你好，我是蔡元楠。

在上一讲中，我们介绍了2014年之前的大数据历史，也就是MapReduce作为数据处理的默认标准的时代。重点探讨了MapReduce面对日益复杂的业务逻辑时表现出的不足之处，那就是：1. 维护成本高；2. 时间性能不足。

同时，我们也提到了2008年诞生在Google西雅图研发中心的FlumeJava，它成为了Google内部的数据处理新宠。

那么，为什么是它扛起了继任MapReduce的大旗呢？

要知道，在包括Google在内的硅谷一线大厂，对于内部技术选择是非常严格的，一个能成为默认方案的技术至少满足以下条件：

1. 经受了众多产品线，超大规模数据量例如亿级用户的考验；
2. 自发地被众多内部开发者采用，简单易用而受开发者欢迎；
3. 能通过内部领域内专家的评审；
4. 比上一代技术仅仅提高10%是不够的，必须要有显著的比如70%的提高，才能够说服整个公司付出技术迁移的高昂代价。就看看从Python 2.7到Python 3的升级花了多少年了，就知道在大厂迁移技术是异常艰难的。

今天这一讲，我不展开讲任何具体技术。

我想先和你一起设想一下，假如我和你站在2008年的春夏之交，在已经清楚了MapReduce的现有问题的情况下，我们会怎么设计下一代大规模数据处理技术，带领下一个十年的技术革新呢？
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/ef/a7/6e8f3636.jpg" width="30px"><span>mjl</span> 👍（60） 💬（2）<div>Unify platform和批流统一已经是主要趋势了，而我个人目前只对spark、flink有一定的了解。对于spark来说，无疑是很优秀的一个引擎，包括它的all in one的组件栈，structured streaming出来后的批流api的统一，目前在做的continues Mode。而flink，的确因为阿里的运营，在国内火了。但也展现了它的独有优势，更加贴近dataflow model的思想。同时，基于社区以及阿里、华为小伙伴的努力，flink的table&#47;sql 的api也得到的很大的增强，提供了流批统一的api。虽然底层然后需要分化为dataset和datastream以及runtime层的batchTask和StreamTask，但是现在也在rethink the stack，这个point在2019 SF 的大会也几乎吸引了所有人。但就现状而言，flink的确有着理念上的优势（流是批的超集），同时也有迅猛上升的趋势。</div>2019-04-19</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/jsMMDDzhbsTzhicsGZiaeV0PWSnAS0fBlb1r6CsuB32vr3hRwV9UubmfHQx45v7jtaXajPlQ8kQ17b3zpQzHmqVw/132" width="30px"><span>fy</span> 👍（6） 💬（1）<div>虽然看的不是很懂，毕竟没搞过这方面的，但是每篇文章的知识点逻辑很清楚，学习中，这里尊称一句蔡老师，被老师的回复学者的留言给感动了。期待老师后面精彩的专栏</div>2019-04-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/f3/cf/851dab01.jpg" width="30px"><span>Milittle</span> 👍（6） 💬（1）<div>讲真，这个思路太清晰了。讲到有向图那里，还没看到tf那段，我脑子里第一蹦出来的就是深度学习里面的符号式计算图，可以在图编译的时候进行优化。然后在计算时可以加速运算，还有就是，这里的计算图用拓扑排序结合优先级队列来执行计算。
我还是个学生，有不对的地方请指教，没在真实场景中体验过，但是感觉这些都是通用的，学会了，处处可以用到。期待后续课程给更多的启发，谢谢(*°∀°)=3</div>2019-04-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/c6/f9/caf27bd3.jpg" width="30px"><span>大王叫我来巡山</span> 👍（6） 💬（1）<div>经历了mapreduce到spark, 从最具欺骗性的wordcount开始到发现很多业务本身并不适合mapreduce编程模型，一直做日志处理，现在在政府某部门同时处理批处理任务和流处理任务，老师的课太及时了，感觉对我们的业务模型革新会产生很大的影响，前两篇没有涉及技术，已经感觉醍醐灌顶了。</div>2019-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/d2/34/39a3edef.jpg" width="30px"><span>文洲</span> 👍（5） 💬（2）<div>老师讲的很明白，有个疑问，现在都说flink是下一代实时流处理系统，这里按老师的对比来看，它还比不上spark，可否理解为flink主要还是专注实时流处理而spark有兼具批处理和流处理的优势</div>2019-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/53/d4/2ed767ea.jpg" width="30px"><span>wmg</span> 👍（4） 💬（1）<div>现在使用较多的是hive和sparkSql，这两种技术多使用的都是类似关系数据库的数据模型，对于一些复杂的对象必须要通过建立多张表来存储，查询时可能需要多张表进行join，由于担心join的性能损耗，一般又会设计成大宽表，但这样又会浪费存储空间，数据一致性也得不到约束。想问一下老师，有没有支持类似mongodb这样的文档型数据模型的大数据处理技术？</div>2019-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/40/bd/acb9d02a.jpg" width="30px"><span>monkeyking</span> 👍（3） 💬（1）<div>老师，啥叫dataflow？从字面上来看好像和dag差不多，不知道我理解的是否正确，还请老师指正</div>2019-04-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/53/e3/39dcfb11.jpg" width="30px"><span>来碗绿豆汤</span> 👍（3） 💬（1）<div>蔡老师好，看到您那么认真的回复读者问题，果断决定买了，跟着您一起学习。我们最近在打算重构一个项目，想听听您的建议。系统的输入是将近1TB的数据文件（好多个文件，不是一个大文件），内容就是一条条记录，描述了某个实体的某个属性。我们要做的就是把属于同一个实体的属性整合到一起，然后将数据按实体id排序输出，没100万个实体写一个文件。我现在的思路就是:第一步，把文件重新按照实体id切块，然后排序写成小文件，这一步可以是一个程序；第二步，对id属于某个范围内的（如1-100w）文件，归并排序，这一步一个程序；第三步，对排好序的文件按指定格式输出。因为以前没接触过大数据相关技术，所以现在是用java实现的demo版本，就像你课程里面所示，担心将来各个进程，线程之间，交互通信，异常处理，log处理，等一系列问题都需要自己维护会比较麻烦，想听听您的建议。</div>2019-04-20</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLhMtBwGqqmyhxp5uaDTvvp18iaalQj8qHv6u8rv1FQXGozfl3alPvdPHpEsTWwFPFVOoP6EeKT4bw/132" width="30px"><span>Codelife</span> 👍（3） 💬（2）<div>我们是做车联网业务的，目前实时处理采用的storm，批处理采用的是MR,和您的文章中描述的一样，业务场景和算法中经常出现实时和批处理共存的情况，为了保证实时性，通常是定时执行MR任务计算出中间结果，再由storm任务调用，这样的坏处是MR任务并不及时，而且维护起来很麻烦，效果并不理想。希望能够从apache beam中学到东西</div>2019-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/27/1d/1cb36854.jpg" width="30px"><span>小辉辉</span> 👍（2） 💬（1）<div>看完前三讲，让我对大数据又有一个更新的认识</div>2019-04-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/75/a8/dfe4cade.jpg" width="30px"><span>电光火石</span> 👍（2） 💬（1）<div>我们做风控的，现在每天收的数据比较多，现在都是先通过spark streaming落地hive，然后每天批量跑任务做模型训练和分析，因为现在模型训练还是集中在离线训练，在线训练约束比较大，所以使用场景还比较小，训练处理的模型在通过导出到pmml在线预测，整个作为一个闭环。不知道google在这方面试怎么处理的？谢谢！

另外，老师有个理念很新颖（从处理的数据范围来看批处理和实时计算，批处理的数据是有界的，实时计算的数据是无界的），我一直从处理的间隔来看批处理和实时计算，觉得实时计算是批处理的一种，就是不断的把离线任务处理频率做个极限，就变成了实时计算。</div>2019-04-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4d/49/28e73b9c.jpg" width="30px"><span>明翼</span> 👍（2） 💬（3）<div>老师我补充下我的三个问题:
1.这种两个流都是大数据量的一般业界用什么样计算模型去做匹配，目前我们是用spark写的匹配？
2.由于一个流（假设名字为A流）的数据时间跨度比较大，比如几天前的数据，这就要求另外一个流（假设为B流）必须有缓存，而从缓存中抽取B流数据时候，会根据时间和Ip的hash原一批数据和A流匹配，那这个缓存用什么比较好那？我们原来用Hbase后发现数据量大scan比较慢，改hdfs直接存储了，勉强可以用。
3.我们最终结果数据一天也有几百亿条，目前存Es里面的，业务要求查询性能分钟级别就可以接受，我们查询性能够了，但是索引数据存储空间占用大，入索引性能一般，我们想换个高压缩性能分钟级的存储系统，目前考虑用列式存储➕ SQL引擎来做，这种没经验是否合适？

谢谢老师耐心看完，有空指点下谢谢</div>2019-04-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/34/15/53201a55.jpg" width="30px"><span>王二</span> 👍（2） 💬（1）<div>老师您好：
1.如您所说flink在批流处理上的不统一，目前社区各个厂商也在努力的实现这种基于SQL或其他引擎的一些统一，这块在您看来有什么好的建议。
2.后面文章使用spark举例，这里是用他的struct streaming还是spark streaming呢.
3.感同身受，流系统难的不在开发，在于监控，如何处理背压，如何根据负载动态调整资源，除过开源框架自带的一些监控外，后续在任务流监控这块是否有什么好的建议推荐。</div>2019-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/06/9c/1ee94a9d.jpg" width="30px"><span>dylan</span> 👍（2） 💬（1）<div>有没有这么一个问题,mapreduce在大规模数据处理时，由于每个计算阶段都会落盘，所以计算比较慢，但是数据完整，不会丢失；spark基于内存计算，会有数据丢失的风险？</div>2019-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/2f/fa/191049df.jpg" width="30px"><span>退而结网</span> 👍（1） 💬（1）<div>在极客时间订阅了几个专栏了，有些专栏留言的问题很少得到专栏老师的回复，看了下蔡老师的留言回复，基本上都是有问必答。这两节专栏的内容真的很多干货，同学们的留言也给了我很多启发。作为大数据处理的半入门汉，希望能在这门课程中得到更多的收获，祝愿和大家共同进步！</div>2019-04-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/9a/ba/f5eb2a66.jpg" width="30px"><span>咕噜男爵-Tony</span> 👍（1） 💬（1）<div>喜欢上了这门课程，期待对Spark的深入剖析 ^_^!</div>2019-04-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/dd/2f/7f0d19a8.jpg" width="30px"><span>Edwin</span> 👍（1） 💬（1）<div>Spark 和 Flink 都是通用的开源大规模处理引擎，目标是在一个系统中支持所有的数据处理以带来效能的提升。两者都有相对比较成熟的生态系统。是下一代大数据引擎最有力的竞争者。Spark 的生态总体更完善一些，在机器学习的集成和易用性上暂时领先。Flink 在流计算上有明显优势，核心架构和模型也更透彻和灵活一些。
社区版本的flink有些问题还待进一步完善，比如统一API层、状态管理机制、资源调度等，阿里内部的blink虽然对flink做了大量改造，但依赖内部环境能真正返璞社区还有很长一段路要走～</div>2019-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/48/f3/65c7e3ef.jpg" width="30px"><span>cricket1981</span> 👍（1） 💬（2）<div>请问不定时的来一批大量数据要处理是要用批框架还是流框架呢？</div>2019-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4d/49/28e73b9c.jpg" width="30px"><span>明翼</span> 👍（1） 💬（1）<div>课堂笔记：mr有三个重要问题，一是支持的计算粒度太大，描述麻烦；二是性能差，调优复杂；三是只支持批量处理不支持流处理。针对此设计了有向无环图，好处是描述简单，易在上面进行自动优化；描述和计算引擎分开了，解耦合，可以分别实现进一步提升性能；我一直觉得批量处理和流处理完全两回事，老师的视角是将两者融合，想了下，批量处理可以看做时间间隔很长的流，而流按照spark等时间窗口概念可以看做小范围的批量，这个设计可以这样想，设计起来可能很复杂。另外一个由于可以表达更复杂的事件转换，那好的监控异常处理就是必须的了，以上为总结。

关于遇到问题，我们曾经遇到过两个都是很大的流类的日志数据匹配处理问题，是TB级别，而且数据流不同步的一个流的数据跨度范围大，如何设计高效处理是个难题，在hbase缓存还是在hdfs缓存是个难题，不知道老师有何高见？</div>2019-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/f5/5f/217c6a14.jpg" width="30px"><span>Liu C.</span> 👍（1） 💬（1）<div>目前还在学校科研的现个丑：目前我所做的数据任务是下载科研论文和报告并对其中的文字数据进行分析，用的是自己写的工具，分为两部分：第一部分从网上下载所需数据，第二部分进行内容提取和分析。

目前这是个批处理式的系统：先运行下载工具之后再运行分析。这会导致没法及时更新最新出现的数据。解决方法是，加入一个定时查看的模块，在发现新添加数据时进行下载并处理update分析结果。

另一个缺点是，我没有log那些数据抓取失败的情况。可以添加一个这样的模块来协助优化系统。</div>2019-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/dd/b2/4fe0944a.jpg" width="30px"><span>莫醒醒</span> 👍（0） 💬（1）<div>个人觉得 SQL 才是流批统一的最优选择！</div>2019-05-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/87/6b/0b6cd39a.jpg" width="30px"><span>朱月俊</span> 👍（0） 💬（1）<div>除了map resuce之外，我们还使用了两种流处理技术，简单说就是将任务拆解成一个一个算子，中间勇气kafka连接；还有一个流处理技术就是先将原始数据进行包装，从而屏蔽一条数据和多条数据的区别，然后将数据进行下发，并且通过设计一套diff系统进行重复数据优化。当然，还有一套日志系统用于排错。</div>2019-04-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/9b/06/29b4715f.jpg" width="30px"><span>莫冰</span> 👍（0） 💬（1）<div>番茄牛腩那张图，最左边的流程应该是画错了吧，依然是对番茄的处理？番茄牛腩没有牛腩哦 ：）</div>2019-04-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/9c/47/50cf2cab.jpg" width="30px"><span>Chn.K</span> 👍（0） 💬（1）<div>有点像搭积木？我要搭个房子，我可以选这些积木，我要搭个火车，我又可以选择那些积木，这些积木的接口都是国际标准的。在完成搭房子搭火车过程中，我并不需要去做积木……</div>2019-04-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/80/db/abb7bfe3.jpg" width="30px"><span>dexiao10</span> 👍（0） 💬（1）<div>不是这个行业的，看的有点不懂。
作者可以把 mapreduce 跟 apache beam对比一下，直观展示。
还有apqche beam只是对map reduce的一个封装吗，底层原理还是map reduce？</div>2019-04-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/5a/a8/f25ec64c.jpg" width="30px"><span>long.mr</span> 👍（0） 💬（1）<div>老师，我理解虽然统一了流式和批量，但是，如果流式服务的输入没有对接上游数据的话，对于离线的发压端来讲，还是需要借助mapreduce吧。换句话说，目前Google是完全不用mapreduce了吗，如果用的话现在是用在哪个环节呢。</div>2019-04-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/15/bb/e2c24e25.jpg" width="30px"><span>YzmYU</span> 👍（0） 💬（1）<div>老师，想请问下计算粒度这个概念该怎么理解呢？</div>2019-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/c6/fe/cf8b21ab.jpg" width="30px"><span>尚科</span> 👍（0） 💬（1）<div>greenplum+sas脚本处理，用perl脚本做作业控制、调度、监控，经常出现greenplum集群机器出问题后作业延时，追数的问题</div>2019-04-19</li><br/><li><img src="" width="30px"><span>Chelsea_alpaca</span> 👍（0） 💬（1）<div>现在在用Spark做parallel computing, 比如每一个executor上面来处理一个单独城市的数据，以及训练一个模型。不知道这是不是一个正确的用法…</div>2019-04-19</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJrZb9pm07aictfkWebiaZPQqzuyQ2L3T6VJHMAvRYTuAicYnYP7YTNtoMumXdMibXWMMfdZVfYHic0BiaQ/132" width="30px"><span>xiaowaner</span> 👍（0） 💬（1）<div>😄终于等到更新了。</div>2019-04-19</li><br/>
</ul>