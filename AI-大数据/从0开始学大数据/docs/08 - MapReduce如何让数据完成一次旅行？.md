上一期我们聊到MapReduce编程模型将大数据计算过程切分为Map和Reduce两个阶段，先复习一下，在Map阶段为每个数据块分配一个Map计算任务，然后将所有map输出的Key进行合并，相同的Key及其对应的Value发送给同一个Reduce任务去处理。通过这两个阶段，工程师只需要遵循MapReduce编程模型就可以开发出复杂的大数据计算程序。

那么这个程序是如何在分布式集群中运行起来的呢？MapReduce程序又是如何找到相应的数据并进行计算的呢？答案就是需要MapReduce计算框架来完成。上一期我讲了MapReduce既是编程模型又是计算框架，我们聊完编程模型，今天就来讨论MapReduce如何让数据完成一次旅行，也就是MapReduce计算框架是如何运作的。

首先我想告诉你，在实践中，这个过程有两个关键问题需要处理。

- 如何为每个数据块分配一个Map计算任务，也就是代码是如何发送到数据块所在服务器的，发送后是如何启动的，启动以后如何知道自己需要计算的数据在文件什么位置（BlockID是什么）。
- 处于不同服务器的map输出的&lt;Key, Value&gt; ，如何把相同的Key聚合在一起发送给Reduce任务进行处理。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/icicSvapqLfCWmIofXILE3b20RVDicQvooGnbksVNgz7wSzEfCKtibhIVMwibf778E39fF9hAa1EFMCFyhgljkwicicXg/132" width="30px"><span>张贝贝</span> 👍（118） 💬（3）<div>有个问题，为什么mapper计算完的结果要放到硬盘呢？那再发送到reducer不是还有个读取再发送的过程吗？这中间不就有一个重复的写和读的过程吗？</div>2018-11-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/92/75/d19e479a.jpg" width="30px"><span>冬冬</span> 👍（102） 💬（2）<div>老师您好，有个问题，当某个key聚集了大量数据，shuffle到同一个reduce来汇总，考虑数据量很大的情况，这个会不会把reduce所在机器节点撑爆？这样任务是不是就失败了？</div>2018-11-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/54/19/95ff4cbd.jpg" width="30px"><span>格非</span> 👍（72） 💬（3）<div>MapReduce的思想有点类似分而治之，将一个大任务分割成小任务，分发给服务器去处理，然后汇总结果，这是MapReduce的优势，但是MapReduce也就限制在了只能处理这种可以分割的任务上，比如，统计文本中的不同单词的个数，不知道我这种想法是否正确，还想请老师指教，另外，能否分享一下MapReduce这种技术的局限性呢？</div>2018-11-15</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q3auHgzwzM4op5UXa2fBNlEe9mFiaagibNUTKuYR6X8TEg11EIksR78b413jWFv8lAjCDibQ1GcJOsyoOPVS9W9JA/132" width="30px"><span>still0007</span> 👍（46） 💬（5）<div>有一个疑问，之前讲到“移动计算而不是移动数据”，但是在shuffle的过程中，涉及到大量的移动数据，这又是为什么呢？</div>2018-11-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/d7/d5/b9e3332e.jpg" width="30px"><span>星凡</span> 👍（40） 💬（2）<div>请问一下，map和reduce有绝对的先后关系吗，还是说可以一边map一边reduce</div>2019-10-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/41/27/3ff1a1d6.jpg" width="30px"><span>hua168</span> 👍（38） 💬（4）<div>实际操作中是不是通过hive去完成MapReduce 的？
如果有一台机子一直卡在那里，整个job就差它一个返回数据，是不是整个job在等待状态？这种怎么处理？</div>2018-11-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/08/1c/ef15e661.jpg" width="30px"><span> 臣馟飞扬</span> 👍（21） 💬（5）<div>看其他资料上介绍，shuffle过程从map的输入就已经开始了，与老师介绍的好像不太一致哦，这个过程应该是什么样？</div>2020-02-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/be/bc/62d402da.jpg" width="30px"><span>Goku</span> 👍（20） 💬（3）<div>请问JobTracker和之前讲到的NameNode是在同一个服务器上的吗？</div>2018-12-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/40/07/050a63ee.jpg" width="30px"><span>slam</span> 👍（20） 💬（1）<div>想问下，在Hadoop上跑计算任务，在极端异常的条件下（数据机器down，网络隔离，namenode切换），能保证计算要么返回失败要么给出可信的结果吗？背景是这样的，考量在大数据平台上做资金的清算，非程序的错误，计算结果不能有错有漏，在单机db上这个肯定ok，不考虑事务前提下，Hadoop计算是否也毫无问题？可能考量数据一致性、任务状态一致性等方面，我了解太浅，想请教下老师，这种要求绝对计算准确的场景，hadoop目前胜任吗？</div>2018-11-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/52/bb/225e70a6.jpg" width="30px"><span>hunterlodge</span> 👍（19） 💬（1）<div>老师，您给出的Partitioner的代码所反映的算法不会影响集群的扩展性吗？为什么不是采用一致性哈希算法呢？</div>2018-11-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/e1/bb/cbeae2fa.jpg" width="30px"><span>恐龙虾了个皮了个姜哩个哩个啷</span> 👍（18） 💬（1）<div>看到前边有同学问到shuffle过程为什么不使用一致性hash,感觉老师您的回答没有解决我的疑问，当reduce的机器宕机了的话，如果按照代码中的逻辑是有问题的吧…</div>2019-09-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/36/2a/69c4c1f6.jpg" width="30px"><span>金泽</span> 👍（18） 💬（1）<div>“如果 TaskTracker 有空闲的计算资源（有空闲 CPU 核心），JobTracker 就会给它分配任务”，假设极端情况下，某块数据及其备份数据块所在的服务器一直没空闲，那这一块内容是不是就缺失了？</div>2019-01-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/6a/2d/ec4ed8ce.jpg" width="30px"><span>shawn</span> 👍（13） 💬（1）<div>JobTracker创建JobInProcess ，JobinPrcess根据分片数目和设置reduce数目创建TaskInprocess。 那么它是如何决定具体在哪些服务器创建 task tracker呢？我觉得需要了解这个过程，才能明白大数据如何分配和使用资源的。 请老师解答下，谢谢！</div>2018-11-19</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKibhEIEcmUmz20DNlwHfS8DuqzYTnrqicicicCmHzzxQeHnMEfq4lBY6fytIuVDPQOB9MoZpBl2UuOEQ/132" width="30px"><span>lyuzh</span> 👍（11） 💬（1）<div>老师，您好！一直想不明白一个问题，这里的shuffle过程将map结果中相同的key通过HTTP发送给reduce时这里依然是传递数据呀 以wordcount为例 每个单词map后的结果通过网络传递给reduce时依旧是个耗时操作吧？</div>2020-04-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/32/23/5de4b29a.jpg" width="30px"><span>滴答</span> 👍（11） 💬（1）<div>map进程快要计算完成的时候将执行分区并发送给reduce进程进行排序和合并，那请问老师map完全计算完成的时候是会再次发送给reduce然后reduce再做排序合并计算吗？那这两部分的排序如何保证整体排序，如果是reduce之后再排序的话那之前排序会不会不需要？</div>2018-11-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/1b/df/4caad64d.jpg" width="30px"><span>李慢慢</span> 👍（10） 💬（2）<div>不同的key经过hash计算，也有可能会产生同样的hashcode啊，这种情况怎么处理呢？莫非是跟HashMap一样，搞个链表或者红黑树处理吗？</div>2019-06-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/d4/f3/129d6dfe.jpg" width="30px"><span>李二木</span> 👍（8） 💬（1）<div>文中第一幅图，map输入 中 0 hello world 12 Byte world  ，这里数字代表什么意思了？是map 输入顺序下标吗？
</div>2018-11-15</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJZuwMDaoJviaf3lZ5BOgAvTzLzmbGrMrCZ22krLSRyxpKUrVicU9pSnWsyuSHjksyNldBpXrRzUqeA/132" width="30px"><span>挨踢菜鸟</span> 👍（7） 💬（1）<div>老师怎么还拿hadoop1举例呢，现在都是hadoop2，以及Yarn了</div>2018-12-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/f9/29/56db1441.jpg" width="30px"><span>兴趣 e 族</span> 👍（6） 💬（1）<div>老师，我想问下，如果数据中的个别key数据量很大，会造成数据倾斜，有什么方法可以解决这个数据倾斜的问题呢？</div>2019-04-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/0d/c1/d36816df.jpg" width="30px"><span>M</span> 👍（6） 💬（1）<div>最近在学习Spark，发现Spark中似乎并没有“移动计算而不是移动数据”。因为在Spark中初始化SparkContext时就已经分配好计算资源了，随后再对用户指定的数据进行计算。所以在Spark中还是移动了数据，请问我的想法正确吗？</div>2018-11-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/f3/89/fcfecb46.jpg" width="30px"><span>杰哥长得帅</span> 👍（5） 💬（1）<div>老师我有两个问题：
1、DataNode 和 TaskTracker 有没有不在一个机器上的情况？如果有的话，会怎么处理
2、TaskTracker 的任务参数，比如『要处理的数据在文件中的起始位置和偏移量、数据块多个备份的 DataNode 主机名』根源上是从哪里获取的，理论上不是jar包，因为jar包对不同进程来说应该是同一份逻辑代码</div>2020-03-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/cb/81/14dd3bab.jpg" width="30px"><span>不求</span> 👍（5） 💬（2）<div>老师，您好，我有个疑问？
在计算过程的第4个步骤上：
4.JobInProcess 根据输入数据分片数目（通常情况就是数据块的数目）和设置的 Reduce 数目创建相应数量的 TaskInProcess。

问题：
JobInProcess 是如何根据输入数据分片数目和设置的Reduce数目创建相应数量的TaskInProcess？

JobInProcess是JobTracker进程在主服务器上创建的，这里的根据输入数据分片数目是指的从服务器上的DataNode的数据块的分片数目吗？而DataNode和TaskTracker是在从服务器上，这个JobTracker进程是什么时候知道输入数据分片数目的？是谁在什么时候确认的呢？</div>2018-11-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/41/27/3ff1a1d6.jpg" width="30px"><span>hua168</span> 👍（4） 💬（1）<div>hadoop可以通过实验去练习吧？一般什么配置？官网的说明文档能当扩展阅读吗？选择那个版本？</div>2018-11-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/8d/69/e9886e74.jpg" width="30px"><span>俊刚</span> 👍（3） 💬（1）<div>&quot;MapReduce 框架默认的 Partitioner 用 Key 的哈希值对 Reduce 任务数量取模，相同的 Key 一定会落在相同的 Reduce 任务 ID 上。&quot;没有理解这句话的意思，个人感觉前一句与后一句没有必然联系，请老师不吝赐教，万分感谢！</div>2020-01-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/00/f4/cc5f0896.jpg" width="30px"><span>Jowin</span> 👍（3） 💬（1）<div>老师，有一个问题，在WordCount的例子中，经过map处理之后数据量明细减少了，之后再做shuffle和reduce就比较容易。如果有些类型的数据，map处理并不能明显减小数据量，是否就不适合用mapreduce模型处理？</div>2018-11-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/1b/17/64e18a78.jpg" width="30px"><span>雪候鸟</span> 👍（2） 💬（1）<div>想问一下shuffle过程的前半程的数据流是直接从服务器节点通过hash计算传输到对应的其他服务器节点？还是通过中心服务器JobTracker统一分发？</div>2019-04-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/1b/54/c0f328ab.jpg" width="30px"><span>eden</span> 👍（1） 💬（1）<div>目前云计算里面各大厂商都在推崇 大数据存算分离的方案： 即 数据总量用对象存储（华为云OBS带宽超级大），datanode就可以带比较小的磁盘或者云盘，实现最终计算与存储的分离。
但是我们再基于他们的大数据存算分离方案中，shuffle盘还是要在datanode上面，这个是因为shuffle要求的时延很低吗？  </div>2021-02-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/14/e1/ee5705a2.jpg" width="30px"><span>Zend</span> 👍（1） 💬（1）<div>老师请问 Map输出后 根据key 做partition 分区归并是通过网络发送到指定的reduce做最后的合并排序对吗？</div>2019-11-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/6a/2d/ec4ed8ce.jpg" width="30px"><span>shawn</span> 👍（1） 💬（1）<div>老师，你会讲hdfs存储嘛？ 比如一个任务去哪里拉如何去hdfs上拉取数据文件，一个job 如何估算它需要的资源，您在文章中也说了任务调度本质就是解决 现有多少资源需要什么资源，然后进行匹配。具体如何如果解决估算资源和哪里拉数据文件，老师可以细讲一下嘛？谢谢！</div>2018-11-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/52/bb/225e70a6.jpg" width="30px"><span>hunterlodge</span> 👍（1） 💬（1）<div>老师，请问TaskInProcess是做什么用的呢？为什么它的创建和Reducer有关，却和Mapper无关呢？</div>2018-11-19</li><br/>
</ul>