1943年，美国芝加哥大学的神经科学家沃伦·麦卡洛克和他的助手沃尔特·皮茨发表了论文《神经活动中思想内在性的逻辑演算》（A Logical Calculus of Ideas Immanent in Nervous Activity），系统阐释了他们的想法：**一个极度简化的机械大脑**。麦卡洛克和皮茨首先将神经元的状态二值化，再通过复杂的方式衔接不同的神经元，从而实现对抽象信息的逻辑运算。正是这篇论文宣告了人工神经网络的呱呱坠地，它传奇的故事自此徐徐展开。

与生理学上的神经网络类似，麦卡洛克和皮茨的人工神经网络也由类似神经元的基本单元构成，这一基本单元以两位发明者的名字命名为“**MP神经元**（MP neuron）”。大脑中的神经元接受神经树突的兴奋性突触后电位和抑制性突触后电位，产生出沿其轴突传递的神经元的动作电位；MP神经元则接受一个或多个输入，并对输入的线性加权进行非线性处理以产生输出。假定MP神经元的输入信号是个$N + 1$维向量$(x\_0, x\_1, \\cdots, x\_N)$，第i个分量的权重为$w\_i$，则其输出可以写成

$$ y = \\phi (\\sum\\limits\_{i = 0}^N w\_i x\_i)$$

上式中的$x\_0$通常被赋值为+1，也就使$w\_0$变成固定的偏置输入$b$。

MP神经元中的函数$\\phi (\\cdot)$被称为**传递函数**，用于将加权后的输入转换为输出。传递函数通常被设计成连续且有界的非线性增函数，但**在MP神经元中，麦卡洛克和皮茨将输入和输出都限定为二进制信号，使用的传递函数则是不连续的符号函数**。符号函数以预先设定的阈值作为参数：当输入大于阈值时，符号函数输出1，反之则输出0。这样一来，MP神经元的工作形式就类似于数字电路中的逻辑门，能够实现类似“逻辑与”或者“逻辑或”的功能，因而又被称为“阈值逻辑单元”。
<div><strong>精选留言（8）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/13/63/2c/2750bc59.jpg" width="30px"><span>历尽千帆</span> 👍（4） 💬（1）<div>王老师~有一个问题~我们一直所说的“数据服从高斯分布”是指y服从高斯分布呢，还是x的每个特征都需要服从高斯分布呢？</div>2019-01-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/71/45/abb7bfe3.jpg" width="30px"><span>Andy</span> 👍（3） 💬（1）<div>王老师，在工业界，深度学习是否能解决所谓的算法问题？那相比之前红极一时的SVM今后会不会越来越没落？</div>2018-01-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/8e/8b/38b93ca0.jpg" width="30px"><span>听天由己</span> 👍（7） 💬（0）<div>这两篇人工神经网络的文章读起来有些吃力，我又去翻看了其他的一些介绍材料，突然发现这原来就是一种决策模型，之前也有所涉及。通过多维度因素及其权重来判断最终的方向或是特定类别。文中如果能够加上配图就方便理解了，看到人类神经元与人造神经元的对比，整个体验就不一样了。</div>2018-03-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/b0/78/95b10626.jpg" width="30px"><span>qiang.li</span> 👍（5） 💬（0）<div>现在学习神经网络直接就知道了多层感知器可以解决异或问题，但最开始提出感知器这个模型的人才是真正的了不起！我们都是站在巨人的肩膀上！</div>2018-01-25</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/g1icQRbcv1QvJ5U8Cqk0ZqMH5PcMTXcZ8TpS5utE4SUzHcnJA3FYGelHykpzTfDh55ehE8JO9Zg9VGSJW7Wxibxw/132" width="30px"><span>杨家荣</span> 👍（2） 💬（0）<div>极客时间
21天打卡行动 15&#47;21
&lt;&lt;人工智能基础课17&gt;&gt;神经元与感知器
回答老师问题:虽然存在缺陷，但感知器依然是人工神经网络研究史上里程碑式的模型，那么如何才能让它跨过异或问题这座大山呢？
多层感知机（MLP）实现异或（XOR）,单层表示线性可分,多层表示线性不可分;
今日所学:
1,1943 年，美国芝加哥大学的神经科学家沃伦·麦卡洛克和他的助手沃尔特·皮茨发表了论文《神经活动中思想内在性的逻辑演算》（A Logical Calculus of Ideas Immanent in Nervous Activity），系统阐释了他们的想法：一个极度简化的机械大脑;
2,在 MP 神经元中，麦卡洛克和皮茨将输入和输出都限定为二进制信号，使用的传递函数则是不连续的符号函数;
3,从人工神经网络的角度来看，赫布理论的意义在于给出了改变模型神经元之间权重的准则。如果两个神经元同时被激活，它们的权重就应该增加；而如果它们分别被激活，两者之间的权重就应该降低。如果两个结点倾向于同时输出相同的结果，两者就应具有较强的正值权重；反过来，倾向于输出相反结果的结点之间则应具有较强的负值权重。
4,感知器并不是真实的器件，而是一种二分类的监督学习算法，能够决定由向量表示的输入是否属于某个特定类别;
5,根据 y_j(t) 和样本 j 的给定输出结果 d_j，按以下规则更新权重向量；这是学习算法中最重要的核心步骤;
6,在执行二分类问题时，感知器以所有误分类点到超平面的总距离作为损失函数，用随机梯度下降法不断使损失函数下降，直到得到正确的分类结果;
7,虽然感知器的形式简洁优雅，但它的应用范围也相当有限：只能解决线性分类问题;
8,明斯基和罗森布拉特之间的恩冤;
名词:MP 神经元,传递函数,学习机制,赫布理论;感知器（perceptron）”模型;非参数化特性,自适应性,
总结:
老师讲课重点:
1,人工神经网络的神经元用传递函数对输入的线性加权进行非线性处理以产生输出；
2,感知器是一种二分类的监督学习算法，通过自适应调整权重解决线性分类问题；
3,感知器的神经元之间通过权重传递信息，权重的变化根据误差来进行调节；
4,感知器不能解决以异或为代表的线性不可分问题。</div>2020-01-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/76/9e/dc53669e.jpg" width="30px"><span>zc</span> 👍（2） 💬（1）<div>单层感知器解决不了异或，那就上多层嘛，这就是所谓的神经网络了</div>2018-01-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1a/35/2d/a2bde67e.jpg" width="30px"><span>SapereAude</span> 👍（1） 💬（0）<div>如何打知识的诅咒？</div>2019-12-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg" width="30px"><span>ifelse</span> 👍（0） 💬（0）<div>学习打卡</div>2023-05-06</li><br/>
</ul>