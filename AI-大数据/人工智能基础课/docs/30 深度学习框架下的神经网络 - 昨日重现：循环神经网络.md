今天是除夕，明天就是春节啦，在这里，给你拜个早年，祝你狗年大吉，新春快乐，在新的一年里，福旺运旺！

今天我们继续讨论深度学习框架下的神经网络，聊一聊**循环神经网络**。

2017年，一本名叫《阳光失了玻璃窗》的诗集出版了。这本来是再普通不过的事情，可诗集的作者是赫赫有名的网红机器人微软小冰，或者更确切地说，小冰背后的算法，就让事情变得没那么简单了。

我在网上拜读了一些小冰的诗，实话实说，它们让我想起了几年前那些将简单的旋律和节奏随机排列组合而批量生产出来，至今仍在广场舞音乐中大行其道的网络歌曲。但小冰的诗显然技高一筹，循环神经网络和递归神经网络这些高大上的技术让它的排列组合更加难以捉摸。

在深度学习中，RNN这个缩写有两层含义，它既可以表示循环神经网络（Recurrent Neural Network），也可以表示递归神经网络（Recursive Neural Network）。巧的是，这两个RNN之间的关系还很密切：循环神经网络可以看成是递归神经网络的特例，递归神经网络则可以视为循环神经网络的推广。

**循环神经网络和我们前面介绍的所有神经网络都不一样，它的独特之处在于引入了“时间”的维度，因而适用于处理时间序列类型的数据**。回忆一下上次分享的卷积神经网络，它具有空间上的参数共享的特性，也就是同样的核函数可以应用在图像的不同区域之上。如果把参数共享调整到时间的维度上，让神经网络使用相同的权重系数来处理具有先后顺序的数据，得到的就是循环神经网络。

从结构上看，使用神经网络处理可变长度的输入时，在时间上共享参数是非常有必要的。定义在空间上的数据不会无穷无尽地延伸，即使大如《清明上河图》也有确定的边界存在。在很多图像识别的任务中，输入图像的像素数目甚至是有特定要求的。但对于一个以时间为自变量的变长数据来说，很难说清楚数据的终点在哪里，抑或这个终点根本就不存在。

这种情况之下，如果对每一个时间点上的数据都计算一次神经网络的权重系数，无疑会带来极大的计算负荷。循环神经网络就是将长度不定的输入分割为等长度的小块，再使用相同的权重系数进行处理，从而实现对变长输入的计算与处理。
<div><strong>精选留言（4）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（12） 💬（0）<div>长短时记忆网络(LSTM)可以像人的记忆中选择性地记住一些时间间隔更久远的信息，它会根据组成元素的特性，来判断不同信息是被遗忘或被记住继续传递下去。一般的循环神经网络则因为梯度消失隔着更久的信息难以影响当前的输出。</div>2018-02-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg" width="30px"><span>ifelse</span> 👍（0） 💬（0）<div>学习打卡</div>2023-05-14</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/g1icQRbcv1QvJ5U8Cqk0ZqMH5PcMTXcZ8TpS5utE4SUzHcnJA3FYGelHykpzTfDh55ehE8JO9Zg9VGSJW7Wxibxw/132" width="30px"><span>杨家荣</span> 👍（0） 💬（0）<div>极客时间
21天打卡行动 28&#47;21
&lt;&lt;人工智能基础课30&gt;&gt; 见微知著：循环神经网络
回答老师问题:循环神经网络的记忆机制与人类的记忆机制颇为相似。那么人类记忆还有哪些特点可以借鉴到神经网络的设计当中呢？
其实RNN挺像人类的思考方式的,如延时神经网络,长短期记忆网络,像那些天才总能通过平凡的组合方法找到最优解!
今日所学:
1,RNN:循环神经网络,递归神经网络
2,循环神经网络和我们前面介绍的所有神经网络都不一样，它的独特之处在于引入了“时间”的维度，因而适用于处理时间序列类型的数据,如果把参数共享调整到时间的维度上，让神经网络使用相同的权重系数来处理具有先后顺序的数据，得到的就是循环神经网络。
3,从功能上看，时间维度上的参数共享可以充分利用数据之间的时域关联性;
4,循环神经网络引入了反馈机制，因而具有记忆的功能。正是记忆功能使循环神经网络能够提取来自序列自身的信息，这是传统的前馈神经网络所无法做到的。
5,其实前馈网络在某种程度上同样具有记忆，只要神经网络的参数经过最优化，优化的参数中就会包含着过往数据的踪迹。
6,两种网络代表了两种不同的知识类型:前馈网络适用于表示客观性的知识,循环网络则适用于表示主观性的知识。
7,循环神经网络训练方法也是基于梯度的反向传播算法，但和其他前馈网络不同的是，这里的反向传播是通过时间进行的;
8,由于循环神经网络的每个状态都与之前的所有状态相关，因而在基于时间的反向传播中，对当前时刻的参数求偏导一定会涉及前一时刻的参数。这其实和原始的反向传播算法毫无区别，只不过在链式法则中添加了一组关于时间的中间变量。
9,循环神经网络利用来自未来的信息，就要让当前的状态和以后时刻的状态同样建立起联系，得到的就是双向循环神经网络（bidirectional recurrent neural network）。
10,循环神经网络的特点是在时间维度上共享参数，从而展开处理序列。如果换一种展开方式，将序列数据展开成树状结构，用到的就是递归神经网络;
11,在自然语言处理中，递归神经网络可以解决时间序列无法解决的问题;
12,将数据用树状结构表示后，递归神经网络的作用是将它们进一步表示成向量，映射到表示语义的向量空间之中。在语义空间上既可以度量单个向量的尺度，比如判定句子的感情色彩到底是褒义还是贬义；也可以度量不同向量之间的关系，比如确定两个句子意义上的相似程度
重点:
1,循环神经网络是具有记忆的神经网络，适用于处理序列化数据；
2,循环神经网络引入反馈结构，能够在时间上共享参数，从而具有记忆；
3,循环神经网络的扩展包括双向循环网络和深度循环网络；
4,递归神经网络能够处理具有层次化结构的数据，可以看成循环神经网络的推广</div>2020-01-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/b0/78/95b10626.jpg" width="30px"><span>qiang.li</span> 👍（0） 💬（0）<div>新年快乐</div>2018-02-15</li><br/>
</ul>