2015年，微软上线了一个颜龄识别的机器人网站 how-old.net。这个网站可以根据用户上传的照片从面相上分析人物的年龄，一经推出便火爆全球，判断的正确率也很不赖。

而在背后支撑这个娱乐性网站的，正是微软**基于机器学习和深度学习的人脸特征提取技术**。微软的颜龄识别算法首先执行人脸检测，再利用常见的分类和回归算法实现性别判定和年龄判定，在机器学习的框架下完成所有的任务。

计算机视觉称得上是个古老的学科，它的任务是用计算机实现视觉感知功能，代替人眼执行对目标的识别、跟踪、测量和处理等任务，并从数字图像中获取信息。**传统的计算机视觉方法通常包括图像预处理、特征提取、特征筛选、图像识别等几个步骤**。

对于给定的数字图像，计算机在处理时要先执行二次采样、平滑去噪、对比度提升和尺度调整等预处理操作，再对图像中的线条、边缘等全局特征和边角、斑点等局部特征，乃至更加复杂的运动和纹理特征进行检测，检测到的特征会被进一步用来对目标进行分类，或者估测特定的参数。

虽然取得了不俗的进展，但计算机视觉的传统方法依然存在很大的局限，问题就出在待提取的特征要由人工手动设计，而不能让计算机自主学习。检测图像中的足球需要人为地设计出黑白块的特征，如果检测的对象变成篮球，那就要重新设计曲线纹路的特征。这样的计算机视觉其实是人类视觉的延伸，它的识别本质上讲还是由人类来完成的。

如此一来，良好特征的设计就成为了视觉处理的关键和瓶颈。手工设计特征既需要大量的专门领域知识，也需要不断测试和调整，努力和运气缺一不可。而另一方面，现有的图像分类器都是像支持向量机这样的通用分类器，并没有针对数字图像的特征做出专门的优化。想要对特征设计和分类器训练这两个独立过程做出整体上的联合优化，其难度可想而知。

好在，深度学习的横空出世改变了一切。在2012年的大规模视觉识别挑战赛（Large Scale Visual Recognition Challenge）上，辛顿带着他的深度神经网络AlexNet横扫了所有基于浅层特征的算法，以16.42%的错误率摘得桂冠。相形之下，东京大学26.17%的错误率和牛津大学26.79%的错误率显得黯然失色。

**在图像识别中，应用最广的深度模型非卷积神经网络莫属**。2012年大放异彩的AlexNet采用了包含7个隐藏层的卷积神经网络，总共有65万个神经元，待训练的参数数目更是达到了惊人的6千万。如此复杂的模型在训练上也会颇费功夫：用于训练的图像达到百万级别，这将花费2个GPU一周的时间。

但这样的付出是值得的。和传统的数字图像处理技术相比，卷积神经网络不仅能够实现层次化的特征提取，还具备良好的迁移特性，在包含不同对象的图像中都能取得良好的效果。关于卷积神经网络的原理，你可以回顾一下之前的介绍。

在计算机视觉领域，微软可以说是厚积薄发的巨头。以微软亚洲研究院为主的研究机构深耕于深度学习在计算机视觉中的应用，取得了一系列令人瞩目的成果。2015年，微软亚洲研究院的何恺明研究员提出了**深度残差网络**（Deep Residual Network），又打开了计算机视觉一扇崭新的大门。
<div><strong>精选留言（3）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（8） 💬（1）<div>机器学习和深度学习发展很快，很多局部的常规或简单方法的改进可能会有不错的效果。我觉得现在做这种尝试和验证的资源有点跟不上这个领域宽度的拓展。企业工业化中的优化方法未必愿意分享。

对于大多数人来说有很多工作可以做。在科研领域之外企业在资源投入，效果和时间预期的平衡和节奏挺重要。</div>2018-03-04</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/g1icQRbcv1QvJ5U8Cqk0ZqMH5PcMTXcZ8TpS5utE4SUzHcnJA3FYGelHykpzTfDh55ehE8JO9Zg9VGSJW7Wxibxw/132" width="30px"><span>杨家荣</span> 👍（1） 💬（0）<div>今日所学 :
1,传统的计算机视觉方法通常包括图像预处理、特征提取、特征筛选、图像识别等几个步骤
2,深度残差网络:残差（residual）是残差网络的核心元素，但这个概念却并不复杂。没有引入残差的普通网络将输入 x 映射为 H(x)，训练的意义就在于使用大量训练数据来拟合出映射关系 H(x)。可残差网络独辟蹊径，它所拟合的对象并不是完整的映射 H(x)，而是映射结果与输入之间的残差函数 F(x)=H(x)−x。换句话说，整个网络只需要学习输入和输出之间差异的部分，这就是残差网络的核心思想。
3,残差能够带来优良的效果:因为残差网络在一定程度上解决了深度结构训练难的问题，降低了优化的难度
4,为什么残差网络具有这样良好的性能？一种解释是将残差网络看作许多不同长度训练路径的集合。
5,密集连接卷积网络:指的是网络中的任意两层都有直接的连接，每个层的输入都是之前所有层输出的集合。这样一来，每个层次都要处理所有提取出来的低层与高层特征;
重点:
1,在传统的计算机视觉方法中，特征设计和分类器训练是割裂的；
2,以卷积神经网络为代表的深度结构可以实现通用的物体识别算法；
3,深度残差网络将输出和输入之间的残差作为拟合对象，解决了深度神经网络训练难的问题；
4,密集连接网络采用全连接方式，实现了特征的高度重用，降低了参数数量和训练难度。</div>2020-01-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg" width="30px"><span>ifelse</span> 👍（0） 💬（0）<div>学习打卡</div>2023-05-18</li><br/>
</ul>