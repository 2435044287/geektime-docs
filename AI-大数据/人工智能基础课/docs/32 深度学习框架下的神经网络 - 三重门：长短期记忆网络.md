在之前的专栏中，我和你分享了循环神经网络的原理，而今天要介绍的**长短期记忆网络**就是一类特殊的循环神经网络。这个词的断句方式是“长-短期记忆网络”，表达的含义是**一类可以持续很长时间的短期记忆模型**。对时隙长度的不敏感性是这种模型的优势，因而它适用于序列中信息之间的时滞不确定的情况。

循环神经网络通过在时间上共享参数引入了记忆特性，从而将先前的信息应用在当前的任务上，可这种记忆通常只有有限的深度。有追剧经历的都会知道，国外的电视剧通常是每周更新一集，可即使经历了一周的空窗期，我们依然能将前一集的内容和新一集的情节无缝衔接起来。但循环神经网络的记忆就没有这么强的延续性，别说是一个星期的断片儿，插播一段五分钟广告就足以让它的记忆脱节，造成理解上的混乱。

真实世界中的信息不是静止的，而是不断经历着流转与跃变，如果神经网络不能保存长期记忆的话，它处理信息的能力就会大打折扣。长短期记忆网络（long short-term memory）的作用就是实现长期记忆，更准确地说，是实现任意长度的记忆。精巧的设计使记住长期的信息成为了长短期记忆网络的默认行为，而不是需要付出很大代价才能获得的能力。

**从机制上讲，要实现长期记忆，神经网络既要学会记忆，也要学会遗忘**。长期记忆的基础是足够的存储，但宝贵的存储不能被滥用，它不是收集桶，有用的没用的都一股脑儿往里面扔。**长期记忆要求模型具备对信息价值的判断能力，结合自身的状态确定哪些信息应该保留，而哪些信息应该舍弃**。比方说电视剧里的一段支线情节结束了，模型就应当重置相关的信息，只需保留对应的结果。同理，当收到新的输入信息时，模型也要判断这些信息是否有用，以及是否需要保存。

除了添加遗忘机制之外，**长短期记忆单元还要能够将长期记忆聚焦成工作记忆，也就是哪一部分记忆需要立刻使用**。有用的信息也不会每时每刻都有用，因而记忆单元并不会始终使用所有的长期记忆，而是根据当前的相关性做出取舍，这就类似于人类注意力的工作方式。遗忘和选择使长短期记忆网络能够对记忆做出更细粒度的处理，它不同于循环神经网络一视同仁的方式，因而可以实现对信息进行长期而精确的跟踪。

长短期记忆网络是由相应的基本单元构成的。长短期记忆的基本单元的作用在需要时取出并聚焦记忆，通常包括**四个功能不同的隐藏层：记忆模块（memory cell）、输入门（input gate）、输出门（output gate）和遗忘门（forget gate）**，这比只有一个激活函数的一般循环神经网络要复杂得多。
<div><strong>精选留言（5）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（1） 💬（2）<div>根据问题看了一些中文文章，其中提到“LSTM可以根据上下文之间的关键信息，来推断后序文本当中出现的主体定义。让机器翻译更有可能处理较长的文本甚至整个故事。

LSTM可以帮助理解上下文这种人类特有的表达方式，当然也有助于AI学习从人类文本中梳理逻辑和脉络。而以此为契机反向生成有语境、有逻辑、有伏笔的新文本”。曾读到过AI写文章的新闻，不知道是不是利用到LSTM。

“上下文不仅是在文本当中才有。比如在视频当中，就也会出现前后故事联系的情况，甚至更复杂一点出现通过图像来进行的上下文联系。比如一件衣服穿在不同人物身上的意义；反复出现的关键道具；甚至天气对剧情的推动作用。

目前已经有通过LSTM变体技术来解读电视剧的实验。而更广阔的应用空间，是通过LSTM来对监控视频进行记忆推理。”

从这些文章片段看，机器推理借助LSTM是有实现的可能。我自己还未阅读过，或理解并记住具体实现这些应用的技术手段，有待考证。</div>2018-02-20</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/g1icQRbcv1QvJ5U8Cqk0ZqMH5PcMTXcZ8TpS5utE4SUzHcnJA3FYGelHykpzTfDh55ehE8JO9Zg9VGSJW7Wxibxw/132" width="30px"><span>杨家荣</span> 👍（2） 💬（0）<div>极客时间
21天打卡行动 30&#47;21
&lt;&lt;人工智能基础课32&gt;&gt; 长短期记忆网络
回答老师问题:长短期记忆网络的作用不仅在于做些阅读理解，它可以让人工智能理解事物之间的长序联系。那么长短期记忆网络会不会在训练机器的推理能力上带来突破呢？
老师是不是想问:长短期记忆网络能不能在机器中加上物理条件呢?我是想可以的,那就能针对行业做细分了
今日所学 :
1,长短期记忆网络就是一类特殊的循环神经网络。这个词的断句方式是“长 - 短期记忆网络”，表达的含义是一类可以持续很长时间的短期记忆模型。
2,循环神经网络通过在时间上共享参数引入了记忆特性，从而将先前的信息应用在当前的任务上，可这种记忆通常只有有限的深度;
3,从机制上讲，要实现长期记忆，神经网络既要学会记忆，也要学会遗忘。
4,长期记忆要求模型具备对信息价值的判断能力，结合自身的状态确定哪些信息应该保留，而哪些信息应该舍弃;
5,长短期记忆单元还要能够将长期记忆聚焦成工作记忆，也就是哪一部分记忆需要立刻使用。
6,长短期记忆的基本单元的作用在需要时取出并聚焦记忆，通常包括四个功能不同的隐藏层：记忆模块（memory cell）、输入门（input gate）、输出门（output gate）和遗忘门（forget gate），这比只有一个激活函数的一般循环神经网络要复杂得多。
7,遗忘门的作用是弃旧，输入门的作用则是图新，
8,输出门输出权重系数的作用是对记忆模块的状态进行加权。但加权对象不是记忆状态本身，而是记忆状态的双曲正切函数结果。
9,长短期记忆网络应用:谷歌翻译;
重点:
1,长短期记忆网络可以实现任意长度的记忆，对信息进行长期而精确的跟踪；
2,长短期记忆单元的组成包括记忆模块、输入门、遗忘门和输出门；
3,长短期记忆网络根据当前的输入、当前的记忆和前一时刻的输出确定当前的输出；
4,长短期记忆网络能够解决梯度弥散的问题
</div>2020-01-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg" width="30px"><span>ifelse</span> 👍（0） 💬（0）<div>学习打卡</div>2023-05-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/35/19/4f9dc4b5.jpg" width="30px"><span>帅气潇洒的豆子</span> 👍（0） 💬（0）<div>加油</div>2020-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/af/9c/4fb904e0.jpg" width="30px"><span>BAI</span> 👍（0） 💬（0）<div>老师，文本里的 LaTeX 公式不能正常显示了</div>2018-10-01</li><br/>
</ul>