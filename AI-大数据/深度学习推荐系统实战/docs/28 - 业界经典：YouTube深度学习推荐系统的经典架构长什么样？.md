你好，我是王喆。今天我们一起来开启前沿拓展篇的学习。

如果你是跟着课程安排学到这里的，我可以很自信地说，你几乎已经掌握了推荐系统的全部重点知识。从数据特征的处理，模型构建，到模型的评估和上线，再到推荐服务器的实现，你的知识广度已经覆盖了推荐系统领域的全部要点。但要想成为一名合格的推荐工程师，我们还需要做两件事情，一件是追踪前沿，另一件是融会贯通。

因此，在这一篇中，我会通过详细讲解几个一线大厂的推荐系统解决方案，来帮你追踪行业的热点、创新点。它们既包括一些推荐模型的业界实现，如YouTube和Pinterest的推荐模型，也包括推荐系统的工程落地方案，如Flink的经典应用和美团对于强化学习的落地方案。最后，我还会对算法工程师的所需能力做一个全面的总结。

今天，我们今天先来学习YouTube的经典深度学习推荐系统架构。YouTube这套深度学习解决方案，已经经典到可以成为一个业界标杆式的方案了，也是我在国内外和同学、同事们交流、讨论的时候经常会提到的方案。

话不多说，我们正式开始今天的学习吧！

## YouTube推荐系统架构

提起YouTube，我想你肯定不会陌生，作为全球最大的视频分享网站，YouTube平台中几乎所有的视频都来自UGC（User Generated Content，用户原创内容），这样的内容产生模式有两个特点：
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/l3RGUX8aLnPLmsQsra0yU5d8m7Se5jdVpaC3bkb99FuY11BPQNAsH4MPXbZjCTia9VVwn8lnBnKLkdfSiabOgxKg/132" width="30px"><span>Geek_e0d66a</span> 👍（28） 💬（2）<div>老师，请问召回模型中，输入层已经有了视频的预训练的Embedding向量，最后softmax 的参数也会作为视频的embedding向量。一开始不是都有了视频的Embedding向量了吗？最后ANN的为什么只用训练视频向量，而不用预训练的呢？</div>2020-12-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/28/a1/fd2bfc25.jpg" width="30px"><span>fsc2016</span> 👍（20） 💬（6）<div>思考题：
1，在召回层，对用户历史观看的序列，按照时间衰减因子，对用户观看emb序列进行加权求平均，加强最近观看视频的影响力
2，在排序层，可以加入注意力机制，类似DIN模型中，计算候选emb与用户行为序列中视频emb的权重，然后在进行加权求平均，得到用户行为序列的emb
提问：老师 ，之前讲emb近邻搜索，需要用户emb和物品emb在同一向量空间。那么在召回层relu中提取的用户emb和softmax提取的物品emb，是在同一向量空间的，为什么？难道是因为同一个模型训练出来，输入特征一致才允许这样操作嘛？
</div>2020-12-18</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/4icayE3ic5IA7RWwZcrxpMZE4T1WViakEgPsDC3UnhZwU83ad65IjmxPficy0vNZz6Q6vCiclnmyBDc5IYf7soHAXrQ/132" width="30px"><span>Geek_790c43</span> 👍（9） 💬（1）<div>关于id做输入再embedding vs. 预训练embedding的想法不知道对不对：
1. 视频id作为输入再embedding的end2end模型，受cold start影响比较大，因为每遇到新视频模型就需要重新训练。但是用pretrained的视频embedding作为输入，哪怕遇到新视频也可以仿照airbnb的做法生成一个tmp的embedding再喂给模型。
2. 假如有几亿候选视频，直接id做输入会导致embedding层的参数数量非常大，使用预训练embedding可以避免这一点。（用户塔的embedding可以通过平均观看过的视频的embedding得到）</div>2021-02-04</li><br/><li><img src="" width="30px"><span>SecooHR</span> 👍（9） 💬（2）<div>老师能够讲下 实际 Weighted LR  具体训练过程吗，比如 videoid1 labels=1  weights=15 , 实际中是把这个样本 重复抽样weights 次，放入训练样本吗，还是更改LR 的loss？</div>2020-12-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/22/cb/18/0139e086.jpg" width="30px"><span>骚动</span> 👍（8） 💬（1）<div>思考题：平均池化，在我的理解里，是把N个历史记录平等对待，每个user可能都会有2~4个感兴趣的标签（比如会同时关注音乐和生活的两类视频），平均池化这N个emb的方式，我觉得能更好的反映user的整体趋势，一定程度上关注了EE的问题。我看回答里采用时间加权以及注意力加权的回答，我觉得就是更加关注user最近兴趣的方式，也是非常好的方案，但是就是要考量user兴趣变化的快不快的问题，我觉得视频网站的user应该兴趣变化节奏应该并不快，采用平均池化的方式反而能挖掘用户的潜在兴趣，可能更适合youtube的业务。总体来说，我认为这两种方式孰优孰劣，并不一定，需要更多的数据分析来反映整个user群体的整体状况。

另外，我有这么几个疑问：
1. youtube 大部分都是UGC内容的情况下，怎么进行冷启动的？
2. 候选集生成模型中最近邻索引会不会存在更新速度慢的问题，还是说离线更新？
3. 候选集生成模型中为什么是用的ReLU ？实践得出来得结果吗？有没有先验理论的支撑？
4. 候选集生成模型中样本年龄这种连续型特征在这个模型中不需要归一化吗？</div>2021-01-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/b2/cb/9c6c7bf7.jpg" width="30px"><span>张弛 Conor</span> 👍（7） 💬（1）<div>“YouTube模型结构仅占了30%的价值，剩下的70%价值在于其工程实现细节。”补充王喆老师对YouTube推荐系统十大工程问题的解读文章：https:&#47;&#47;zhuanlan.zhihu.com&#47;p&#47;52504407</div>2020-12-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/6d/c5/c0665034.jpg" width="30px"><span>Wiiki</span> 👍（6） 💬（1）<div>王老师，您好。作为读者，我们热切希望您能够出一个专栏针对大厂推荐系统的工程实践和理论方式面进行详细解析的课程，谢谢~ 还有一个问题想请教您：我司最近也上线了一个文章推荐系统，现实情况是文章大概有4千多篇存量，每天大概会有1到2篇的增量（文章比较少~），但是用户日志比较多，百万级别，每天的活跃用户也有几十万，针对我们的目前情况，您觉得我们是否有做文章推荐的需要？或者说在基于我们现实情况下，您觉得现阶段我们怎么做文章推荐~ 谢谢 ：）</div>2020-12-22</li><br/><li><img src="" width="30px"><span>Van</span> 👍（3） 💬（1）<div>老师您好 还是对于 user embedding 和 item embedding什么时候可以直接用ANN来取近似有些Confused. 想总结一下老师您讲的看看对不对：两者可以做内积的前提是他们必须要在一个向量空间。如何定义是同一向量空间就会是一个问题。我理解的两种方式然他们在一个向量空间：
1. 只要是利用用户历史的item embedding生成的用户embedding，可以说都是在一个向量空间内，这些生成方式包括但不限于average pooling，sum pooling，attention等等
2. 类似于MF的 矩阵分解。双塔模型运用的就是这个道理  

我的问题是 基于此是不是说明只要有user 和 item feature有交叉的情况就不可以提取出他们做ANN了？我看到DeepFM有时也被拿来做召回 所以是因为他们只加入了user 和item feature 各自下的interaction嘛？ </div>2021-08-19</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/qw7rRHUPRzhibxXWLG7kc3zkhZwBn4JZaryzko2eWOjSxDlRvUathHugrIVKhcCqxhtsANUTq0140AlbDkLZmcw/132" width="30px"><span>shenhuaze</span> 👍（3） 💬（1）<div>老师，召回模型里的样本年龄是指的什么意思？这里的样本是指的一条带特征和label的训练样本，还是指的一个视频？</div>2021-03-04</li><br/><li><img src="" width="30px"><span>AstrHan</span> 👍（3） 💬（2）<div>老师 看了之后有个问题，您之前说的模型基本以天作为更新，这个说的是排序层吧？那召回层的呢？召回层模型更新一次，要把候选集几百万的数据重跑一次 开销好大。这种问题如何解决呢？我现在是采用word2vec的与训练模型，这样模型就基本不用更新了。不知道业界这一块怎么做的</div>2021-01-25</li><br/><li><img src="" width="30px"><span>haydenlo</span> 👍（3） 💬（1）<div>老师好，候选集生成模型中，采用softmax获得视频embedding的方法，面对youtube几千万甚至上亿的视频量，是不是要训练很久？如果换成nce加速的方式，由于是采样的，会不会有些视频miss掉</div>2020-12-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/25/42/69/8c56cea0.jpg" width="30px"><span>inkachenko</span> 👍（2） 💬（1）<div>老师您好，我有两个问题想问一下
1.召回的时候是否要采用negative sampling进行训练呢？视频数量有百万级别，负采样的时候我是根据视频pv的0.75次方为weight进行采样的
2.召回的时候一个用户只生成一个训练集吗？感觉训练集有点不够用，我打算根据用户的前i次兴趣预测第i+1次，然后遍历i，这样一个用户就可以有好多个训练集。。最后预测的时候就使用最新的数据生成embedding，不知这样是否可行</div>2021-04-06</li><br/><li><img src="" width="30px"><span>WJing</span> 👍（1） 💬（1）<div>老师，学完本节课受益匪浅，但是同时我也产生了几个疑问：
1. YouTube每天增加的视频量是巨大的，在第一层模型的SoftMax是视频数量，这总感觉不科学。。。
2. YouTube是如何做到最新更新的视频也被加入到训练中的呢？</div>2021-10-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/9c/7c/fdb85fde.jpg" width="30px"><span>xuexiqiu</span> 👍（1） 💬（1）<div>非常赞同“要想成为一名合格的推荐工程师，要追踪前沿”这个观点。我在google上搜相关问题的时候会看到twitter或者pinterest他们有时会有一些medium post，很有启发意义。请问前辈还有没有比较好的追踪业界前沿的渠道？感谢。</div>2021-07-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/27/54/3d/366462d0.jpg" width="30px"><span>Yvonne</span> 👍（1） 💬（1）<div>老师，初学者对这一章有两个疑问，先提前感谢老师解答^^：

1.第十九讲里的YT双塔召回模型和这里的召回模型不是同一个模型，对吗？
第十九讲里面是两个塔分别生成user embeding 和video embeddings。而这里是最后一个relu层输出相当于user embdding(X)，通过预测每一个候选视频的下一个被播放概率(softmax(WX+b))，可得W，每一个wi相当于video embedding？
但这两个模型又都是预测下一个被播放概率最高的视频？

2.关于这里的排序层不可以直接生成用户embedding&#47;视频embedding。这里的模型可以改成双塔模型吗？就是把这个曝光视频id单独进行embedding？如果可以改成双塔模型，是不是也可以得到用户&#47;视频embedding了？</div>2021-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/a9/05/6822b8a5.jpg" width="30px"><span>灯灯灯</span> 👍（1） 💬（2）<div>老师请问，在召回层的模型训练中，被优化的目标函数是什么？对每个用户，模型得到的是Nx1的概率向量，真实的概率向量是在用户观看的k个视频处坐标为1&#47;k其他坐标为0吗？</div>2021-01-24</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/6MVSMTIeZO1ZTxDIa4bNj3mvpOEic3mZ9b8ibrWIdmOKzH2ysBIznNJyr8dh77HpstyXKiaPwQ5zdfxQnxc6Cmdqg/132" width="30px"><span>Geek_03b08e</span> 👍（1） 💬（1）<div>老师您好，我是在银行做数据挖掘的，银行产品种类没有电商那么多，大类也就十几种，细分到小类的话也不会超过100种，那用深度学习模型来推荐的的话会不会有点大材小用了？</div>2021-01-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/d1/27/68543b66.jpg" width="30px"><span>W</span> 👍（0） 💬（1）<div>那么softmax对应的embedding真值是怎么获得的呢？通过训练word2vec，得到权重矩阵获得的吗？</div>2021-07-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/27/f8/05/079444c2.jpg" width="30px"><span>创之巅</span> 👍（0） 💬（1）<div>
理解不了用户向量做一层wx+b怎么就得到某个视频的embedding了？有点无中生有的感觉。为什么这个视频embedding不是视频属性或idembedding得到的？老师麻烦细致讲一下视频embedding的生成吧。输出不是一维？怎么是mxn的矩阵？全文就这个视频向量生成最不好理解。</div>2021-05-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/22/68/1c/d8db6177.jpg" width="30px"><span>Nee</span> 👍（0） 💬（1）<div>如果取出训练好的用户Embedding和视频Embedding用来线上推荐，那么利用相似度搜索某个用户的相似视频Embedding，同一用户得到的相似视频向量岂不是每次都相同吗，那为什么不直接保存每个用户的相似视频id呢？</div>2021-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/b6/f1/a14fbf9d.jpg" width="30px"><span>Cwift</span> 👍（0） 💬（2）<div>不同 Embedding 层的长度可以有区别吗，如果可以有区别，是不是较长的 Embedding 层会比较短的层对结果有更大的影响？ </div>2021-03-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/2d/62/916961ab.jpg" width="30px"><span>大包子</span> 👍（0） 💬（1）<div>老师想问一下，为什么在排序的模型里面没有把用户的Embedding 或者相似度作为一个input</div>2021-02-09</li><br/><li><img src="" width="30px"><span>Geek_91c50b</span> 👍（0） 💬（1）<div>1.YouTube模型的召回层是如何实现与每个人相关的呢?
2.召回层可以理解成只是为了更复杂的生成全量视频的Embedding吗，不是简单的直接对视频id进行Embedding</div>2020-12-23</li><br/><li><img src="" width="30px"><span>Geek_91c50b</span> 👍（0） 💬（1）<div>&quot;因为排序模型的输出层不再是预测视频 ID，所以我们也无法拿到视频 Embedding&quot;,这句话没看懂，在图三中用到的第一个特征不就是视频的Embedding吗</div>2020-12-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/14/34/9a96e8d2.jpg" width="30px"><span>浩浩</span> 👍（0） 💬（1）<div>其实我和一位网友的想法比较相近，既然排序可以采用最近，那找回同样可以采用最近观看视频，或者调整相应的权重来做，也有点兴趣变迁的意味</div>2020-12-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/23/ae/e2/eb1ee1be.jpg" width="30px"><span>会飞的鱼</span> 👍（0） 💬（2）<div>为什么不以一开始item2vec训练视频embedding 平均为用户的embedding呢？是因为维度对不上还是因为不在同一个向量空间?而且这时候输入的视频embedding可以finetune的</div>2020-12-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/e4/a1/2f5b9764.jpg" width="30px"><span>你笑起来真好看</span> 👍（0） 💬（3）<div>YouTube的召回模型中，视频可以用node2vec学习embedding，然后把softmax换成负采样这样做可以吗？</div>2020-12-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/97/8f/ccce7df1.jpg" width="30px"><span>小匚</span> 👍（0） 💬（1）<div>由于平均池化会丢掉原始特征 所以最大池化可能效果更好。池化的目的也是降维，那么是否可以考虑dense等其他层？</div>2020-12-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/2c/bc/5311e976.jpg" width="30px"><span>Emma</span> 👍（0） 💬（0）<div>请问老师，还是不太明白为什么softmax是作为视频的向量，我理解输入是用户的向量，输出也是应该关于用户的?</div>2024-09-18</li><br/><li><img src="" width="30px"><span>Geek_075add</span> 👍（0） 💬（0）<div>老师我想问以下几个问题
1）召回层中召回的候选集，在排序层里的是作为输入特征来用的吗？（想LR或者FM里这样的非深度模型也可以这么用吗？）
2）排序层的输出一般是候选集被点击或观看的概率吗（不考虑观看时间）。</div>2022-08-25</li><br/>
</ul>