你好，我是王喆。

前面几节课，我们学习了Embedding MLP、Wide&amp;Deep、NerualCF等几种不同的模型结构。你有没有深入思考过这样一个问题：这几种模型都是怎么处理特征交叉这个问题的？

比如说，模型的输入有性别、年龄、电影风格这几个特征，在训练样本中我们发现有25岁男生喜欢科幻电影的样本，有35岁女生喜欢看恐怖电影的样本，那你觉得模型应该怎么推测“25岁”的女生喜欢看的电影风格呢？

事实上，这类特征组合和特征交叉问题非常常见，而且在实际应用中，特征的种类还要多得多，特征交叉的复杂程度也要大得多。**解决这类问题的关键，就是模型对于特征组合和特征交叉的学习能力，因为它决定了模型对于未知特征组合样本的预测能力，而这对于复杂的推荐问题来说，是决定其推荐效果的关键点之一。**

但无论是Embedding MLP，还是Wide&amp;Deep其实都没有对特征交叉进行特别的处理，而是直接把独立的特征扔进神经网络，让它们在网络里面进行自由组合，就算是NeuralCF也只在最后才把物品侧和用户侧的特征交叉起来。那这样的特征交叉方法是高效的吗？深度学习模型有没有更好的处理特征交叉的方法呢？

这节课，我们就一起来解决这些问题。同时，我还会基于特征交叉的思想，带你学习和实现一种新的深度学习模型DeepFM。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/21/b2/cb/9c6c7bf7.jpg" width="30px"><span>张弛 Conor</span> 👍（59） 💬（1）<div>关于DeepFM，想请教一下老师：DeepFM的图示中，输入均是类别型特征的one-hot或embedding，请问是因为特征交叉仅适用于类别型特征的交叉吗？数值型特征之间，数值型与类别型特征之间能否进行交叉呢？另外，在DeepFM的wide部分中一阶交叉项是否可以包含未参与特征交叉的数值型特征呢？</div>2020-11-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/b2/cb/9c6c7bf7.jpg" width="30px"><span>张弛 Conor</span> 👍（17） 💬（4）<div>老师您好，请教一个关于FM的问题。原FM中二阶交叉项中隐向量的内积仅作为权重，但从这篇课程的图示和代码来看，他们的内积直接作为了交叉项的结果，而没有了初始特征的交叉，想请问一下，这样做是因为教程里所选的特征是one-hot格式，所以维度可能不一致，从而无法进行初始特征的交叉吗？那对于数值型的特征，他们的初始特征交叉是否应该和隐向量内积相乘再作为二阶交叉项的输出呢？</div>2020-11-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（13） 💬（5）<div>请问老师，文中提到FM 和 DeepFM 中进行特征交叉的方式，都是进行 Embedding 向量的点积操作。FM层中还有个加操作，它的作用是什么？</div>2020-11-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（12） 💬（1）<div>关于课后思考题，处理两个 Embedding 向量间的特征交叉的方法。
1.是否可以把这两个embedding向量组合之后再做一次embedding。
2.对于两个Embedding向量做一次pooling层，采用average&#47;max pooling。

另外，开个脑洞，不是有木有把点积和元素积一起使用的模型呢？</div>2020-11-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/69/92/69c2c135.jpg" width="30px"><span>厚积薄发</span> 👍（11） 💬（2）<div>内积和元素积的区别是什么？都是对应元素相乘然后求和吧</div>2021-02-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/0b/1d/525b5b36.jpg" width="30px"><span>xll</span> 👍（11） 💬（1）<div>老师您好，按FM的交叉方式，不同特征的embedding 向量维度要相同，但实际不同离散特征的维度可能相差很大，如果想用不同的embedding 维度，那应该怎样做交叉，业界有没有这样的处理方式？</div>2020-12-01</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/55lYKUdcPFgUHibRYmaRiaBdrsmnLGOHdPp4OicjBh197X0vyGa9qAwruEqicAPuUgibXO4Lz5jLudlcbtsqq2p3CpA/132" width="30px"><span>Sebastian</span> 👍（9） 💬（1）<div>对特征embedding做concat、average pooling、sum pooling 都可以</div>2020-11-25</li><br/><li><img src="" width="30px"><span>Geek_ddf8b1</span> 👍（6） 💬（1）<div>老师 您好！我准备做推荐项目场景为类似抖音这种的短视频信息流推荐 想请教一下：1、实际生产环境中tensorflow训练这些深度学习模型一般是分布式训练吧？如果是分布式训练的话，您sparrowrec项目中的代码需要做哪些改动？或者能否整体说明一下如果这个项目代码在生产环境使用的话有哪些需要注意应该要修改的地方。2、我看您代码中特征是存在reids中。想请教一下几百万用户（dau几十万）和几十万的视频 用户和物品特征一共300个字段左右 这种规模的数据量适合把用户和视频的特征都存在redis中吗？</div>2020-12-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/c9/f8/72955ef9.jpg" width="30px"><span>浣熊当家</span> 👍（6） 💬（1）<div>这一讲里是关于不同特征之间的交叉，但对于之前提到过Youtube有对单一特征进行平方，开方这样的操作得出新的特征的做法，对于这种单一特征的变换操作有没有什么深度模型可以做到？还是一般都是根据经验和理性进行人工手动的尝试？</div>2020-11-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/22/26/22/2da3db6c.jpg" width="30px"><span>王志文</span> 👍（5） 💬（1）<div>老师好，代码中FM的交叉好像是手工指定了几种交叉，还不是全部特征的两两交叉？进一步，如果是全部特征的两两交叉，会出现user id和 user gener的交叉，这两项都是用户侧特征，不涉及物品侧特征，感觉交叉了也不会对指标提升有作用，这样考虑对吗？如果全部两两交叉不会有作用的话，是不是又得手动做交叉特征的筛选呢？谢谢老师！</div>2021-06-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/c9/f8/72955ef9.jpg" width="30px"><span>浣熊当家</span> 👍（4） 💬（1）<div>想请问下老师， 能简单介绍下因子分解机模型（Factorization Machine）和矩阵分解（matrix decomposition）之间的联系和差别吗？（我对于矩阵的很多模型算法都很懵，比如还有奇异值分解（singular value decomposition，NMF（Non-Negative Matrix Factorization），没有搜好的图示解释他们之间的渊源， 也请教老师和大家有什么好的学习资料）</div>2020-11-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/bd/e7/3cc191d6.jpg" width="30px"><span>遨游</span> 👍（3） 💬（1）<div>老师您好，如果不使用FM模型，单纯使用多层神经网络能否做到两两特征交叉或高阶特征交叉呢？如果可以该怎么处理？谢谢！</div>2021-02-24</li><br/><li><img src="" width="30px"><span>onepencil</span> 👍（3） 💬（3）<div>老师你好，你的代码应该只是一个示例代码吧。FM部分只用到了四个特征，并不是原型FM的全部交叉，而且也没有一阶非交叉的特征，这应该只算是deep网络和手工交叉的组合，不能算是deepfm的实现吧</div>2020-11-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/99/4a/09ea6699.jpg" width="30px"><span>小小的天</span> 👍（2） 💬（1）<div>想问一下，针对多值带权重的特征怎么处理处理进去呢？是look up之后，在做average或者sum pooling那？</div>2020-12-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg" width="30px"><span>范闲</span> 👍（2） 💬（1）<div>1.两个embedding concat以后pooling (max average)都行
2.内积、外积</div>2020-12-02</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erAhtlpeFFwRk5g5LvzLcZgybImECIdKmhG1aPxdbnqWP6LmeNz5ibYibOedUwF7NjTy1asZqUur5uQ/132" width="30px"><span>kenan</span> 👍（2） 💬（3）<div>王老师，您好，我们的课程后续会讲召回后选集排序么？</div>2020-11-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/ba/e3/7196d766.jpg" width="30px"><span>一半</span> 👍（1） 💬（1）<div>老师，我有个想法不一定对，我印象中FM模型中应该是会加入数值类型特征的，deepfm中使用的虽然是embedding向量进行特征交叉，但是想把数值型特征加入其中其实也是有办法的
所以我猜测了一下deepfm不用数值型特征交叉的原因：
因为目标主要是学习到简单的特征交叉规则，所以其实是类别之间的相关性，数值特征相关的规则更容易在深度学习模型中被学习到，不知道对不对，希望老师能帮我梳理一下。</div>2021-11-16</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/OwZuBRbVUkziazePs2xTKskNpZachRtCBZLHlv4dAUgaBC5qHI292xaxvg3atGnHlDwjIOXPKEbc7zOrtMyicSNg/132" width="30px"><span>罗辑</span> 👍（1） 💬（1）<div>依次看了这几个模型，有种想把 Wide&amp;Deep+NerualCF+DeepFM+NFM 融合进一个大模型的想法，取各自的优点，然后把各自的结果拼接在一起，送给最后那个神经元来训练权重。
具体可以理解为：
Wide&amp;Deep负责记忆部分，并抽取一些单个特征的高维特性
NerualCF：负责一些有明显关联关系的协同信息提取
DeepFM：负责交叉特征提取，甚至交叉以后的新特征再次进行二阶交叉。
NFM：负责所有特征的融合
把四个模型的输入都给一个神经元，让神经元来训练分配各自权重。
不知道理论上可行吗？请老师指教。

</div>2021-10-07</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKn2fx2UTaWgMl3fSOSicJEDOibbtYicHUVSG8JsA8j6Njibc9j3YVSvHtMZb2Z20l4NmjibiaSv8m7hz9w/132" width="30px"><span>Geek_de83f6</span> 👍（1） 💬（1）<div>老师 请教个问题，如果用了DeepFM模型后，输入到全连接层的是一个内积值，那还怎么使用反向梯度下降的方法更新FM下边一层的Embedding的值呢？</div>2021-08-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/d1/27/68543b66.jpg" width="30px"><span>W</span> 👍（1） 💬（1）<div>代码中直接用embedding 的点乘结果（也就是一个值？）作为特征交叉结果，但是理论上点乘结果应该是交叉特征的权重值，而交叉特征是由两个one-hot特征做组合得到的，老师这样理解对吗？</div>2021-07-02</li><br/><li><img src="" width="30px"><span>AstrHan</span> 👍（1） 💬（2）<div>老师请问，multi-hot的变量咋处理？要用多个电影风格的字段的话，是转化为多个ont-hot，然后不够的补足，还是有什么别的方法？</div>2021-01-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/28/a1/fd2bfc25.jpg" width="30px"><span>fsc2016</span> 👍（1） 💬（1）<div>前面讲的wide&amp;deep中wide主要是体现记忆性，对原始特征人为的把一些强特征做特征交叉；而deepFM，采用FM层自动的进行二阶特征交叉，并且采用了原始特征的embedding层。所以deepFM从效果上要比wide&amp;deep要好一些，老师，大概是这个原因吧</div>2020-11-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/8e/5d/562e90d6.jpg" width="30px"><span>金鹏</span> 👍（1） 💬（1）<div>老师好，请教个问题？讲了这么多模型，在实际的环境中，怎么做模型的选择，以及不同模型和策略之间叠加，以及不同策略实验的加入，从而增加推荐的精准度。</div>2020-11-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/23/df/e2/3c6e8fff.jpg" width="30px"><span>ぃ霓幻風ルァ</span> 👍（0） 💬（1）<div>我尝试修改epochs为50次，发现AUC已经到1.0了，肯定过拟合了，想请教下王老师一般怎么设置一个比较合理的值呢？工业界一般如何设置？谢谢</div>2021-07-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/f5/8c/82fb5890.jpg" width="30px"><span>抱小星</span> 👍（0） 💬（1）<div>我想请问一下老师，如果应用于CTR预估，DeepFM的损失函数是什么呢？</div>2021-07-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/d1/27/68543b66.jpg" width="30px"><span>W</span> 👍（0） 💬（1）<div>老师，我一直没理解特征交叉具体是怎么做的，网上查到说特征交叉是做笛卡尔积后hash。比如有两个离散的one-hot特征做交叉，两个特征维度分别是2，3，那么交叉获得的特征是不是[[1,0,1,0,0], [1,0,0,1,0],[1,0,0,0,1],[0,1,1,0,0], [0,1,0,1,0],[0,1,0,0,1]]，也就是新的特征是6维度的（这里如果特征交叉的维度过大的话还可以利用hash取模获得最终的新特征）</div>2021-07-02</li><br/><li><img src="" width="30px"><span>Geek_c0fd60</span> 👍（0） 💬（2）<div>老师，你好！我从git看到deepFM v2版本，看到里面的FM部分 变的复杂了，各个特征进行 运算，有的先求和 再乘得到 second_order_sum_square_feature。有的又是先乘再求和。最后又进行相减。这个过程感觉无厘头却 又有道理。相乘是为了 得到权重的连接吗？最后又为什么要相 减 呢？我看上面图二中，没有相减的运算。第一个版本，有您的文字说明和架构图，感觉简单的。第二个版本，能看懂代码怎么运算，但是不知道为啥要这样算。麻烦老师啦。</div>2021-03-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/69/92/69c2c135.jpg" width="30px"><span>厚积薄发</span> 👍（0） 💬（1）<div>总的来说，NFM 并没有使用内积操作来进行特征 Embedding 向量的交叉，而是使用元素积的操作。在得到交叉特征向量之后，也没有使用 concatenate 操作把它们连接起来，而是采用了求和的池化操作，把它们叠加起来。  这一段明明用的是内积，然后做的连接，代码中也是，写这一段有什么意思吗？还一直强调元素积，是什么意思</div>2021-02-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/6d/c5/c0665034.jpg" width="30px"><span>Wiiki</span> 👍（0） 💬（1）<div>王老师，那个Fpix(Vx)中j的求和公式是不是有点问题呀？是不是应该是j=n+1~</div>2020-12-01</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/XVkDvXQDPkUcqwg4RmwZwerBYmfibuLgKUyDUhwkqEQRUuhdZzyVialF3lXgk8E88ib2g4n5aRhR6NMia5Fwdf71Qg/132" width="30px"><span>yangming</span> 👍（1） 💬（0）<div>老师，对于first_order_cat_feature，它其实是一个indicator_column(不是dense column)，相当于onehot，onehot编码为什么能做特征交叉得到新的特征？这个比较疑惑。老师教师节快乐！！</div>2021-09-10</li><br/>
</ul>