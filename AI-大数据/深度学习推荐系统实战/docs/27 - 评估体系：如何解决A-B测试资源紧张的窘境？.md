你好，我是王喆。

我们在进行推荐系统评估时经常会遇到两类问题。

一类是在做线上A/B测试的时候，流量经常不够用，要排队等别人先做完测试之后才能进行自己的测试。线上A/B测试资源紧张的窘境，会大大拖慢我们试验的新思路，以及迭代优化模型的进度。

另一类是，离线评估加上在线评估有那么多种测试方法，在实际工作中，我们到底应该选择哪一种用来测试，还是都要覆盖到呢？

其实，这两个问题的答案是有深刻联系的，并不是孤立的。我认为最好的解决办法就是，建立起一套**推荐系统的评估体系，用它来解决不同评估方法的配合问题，以及线上A/B测试资源紧张的问题。这节课，我就带你一起来厘清如何建立起一整套推荐系统评估体系。**

## 什么是推荐系统的评估体系？

首先，什么是评估体系呢？我先给它下一个定义，**推荐系统的评估体系指的是，由多种不同的评估方式组成的、兼顾效率和正确性的，一套用于评估推荐系统的解决方案**。一个成熟的推荐系统评估体系应该综合考虑评估效率和正确性，可以利用很少的资源，快速地筛选出效果更好的模型。

那对一个商业公司来说，最公正也是最合理的评估方法就是进行线上测试，来评估模型是否能够更好地达成公司或者团队的商业目标。但是，正如我们开头所说，线上A/B测试要占用宝贵的线上流量资源，这些有限的线上测试机会远远不能满足算法工程师改进模型的需求。所以如何有效地把线上和离线测试结合起来，提高测试的效率，就是我们迫切的需求。
<div><strong>精选留言（11）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/13/28/a1/fd2bfc25.jpg" width="30px"><span>fsc2016</span> 👍（32） 💬（1）<div>问题：和选择推荐第一个商品的逻辑一样，如果第一次出现重叠商品，可以随机归入到A或B模型中，以后进行交替并入
老师，实战课程快结束了，学到了很多，非常感谢老师分享和解答问题。请问老师，github还有没有相关的推荐实战项目以供继续学习了。或者在个人提升方面，可以从哪些方面继续提升了。</div>2020-12-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（6） 💬（2）<div>在 Interleaving 方法中，如果模型 A 和模型 B 的结果中有重叠怎么办？我感觉可以随机交替选择模型A或B来显示，如果本次随机选择了模型A，那下次可以选择模型B，这样不丢失模型A和B的信息。

另外，请问老师，线上是否可以同时采用Interleaving方法和AB测试呢？我感觉如果两个测试方法不正交的话，是可以的。</div>2020-12-16</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTI9X140JXPuaDB8PibXpwFWds6mZvg1w7THkyB6NjBkP7x4HqSk2wuUvcmDb9O2l0fCkxvB3ibL0L2A/132" width="30px"><span>科学养牛</span> 👍（3） 💬（1）<div>历史快照怎么办呢？是还要一天一天的补回来吗</div>2021-07-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/22/e2/4e/c3e86856.jpg" width="30px"><span>笑笑是个好孩子</span> 👍（0） 💬（2）<div>时光机里面的S3是什么啊？</div>2021-06-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg" width="30px"><span>范闲</span> 👍（0） 💬（1）<div>1.A模型和B模型交叉选择。详细点说就是上次选A，这次选B
2.不过从现在的情况来看，本质上可以当做同类模型的不同版本，可以对流量做切分。比如80%走A模型，20%走B模型。离线的时候再颠倒过来走。这样其实可以更好的观察效果</div>2021-01-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/c9/f8/72955ef9.jpg" width="30px"><span>浣熊当家</span> 👍（0） 💬（3）<div>对于思考题，我的想法是重合的部分既属于A模型也属于B模型，在评估两个模型的时候都把它算上，比较能真实反映A和B的performance</div>2020-12-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/6d/c5/c0665034.jpg" width="30px"><span>Wiiki</span> 👍（0） 💬（1）<div>王老师，您好，推荐系统实战篇总体快告一段落了，感谢您的倾情分享~ 还想问一下呀，咋们的课程后续会介绍推荐系统实时方面的课程吗，以及flink在实时推荐中的应用~    </div>2020-12-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/20/46/f4/93b1275b.jpg" width="30px"><span>Alan</span> 👍（2） 💬（0）<div>答：我认为在设计一个比较相似度权重累加计算系统。例如：A模型计算结果（a,c,d,a)-(a2,c1,d2)，B模型计算结果(a,b,e,d)-(a1,b1,d1,d1)，于是推荐的结果(a3,b1,c1,d1,e1)，很明显a排在最前面即可。至于保留的问题，可以根据用户点击结果，来调整的A模型与B模型的权重，二者并存。若是必须留存，那就留下推荐模型A（(a2,c1,d2)）与用户反馈结果（a2，c1），相似度最高的A模型。</div>2021-04-08</li><br/><li><img src="" width="30px"><span>Geek_8a732a</span> 👍（1） 💬（0）<div>交替等概率分配到模型A和模型B中去</div>2021-08-23</li><br/><li><img src="" width="30px"><span>Geek_742481</span> 👍（1） 💬（0）<div>关于测试框架的介绍，好像老师的https:&#47;&#47;zhuanlan.zhihu.com&#47;p&#47;68509372 这篇文章介绍的更详细 ^_^</div>2021-06-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/ed/b7/972cd42c.jpg" width="30px"><span>꧁꫞꯭R꯭e꯭i꯭r꯭i꯭꫞꧂</span> 👍（0） 💬（0）<div>对于课后问题：我不太认同随机选择的方法，我觉得把它作为第三类对象处理会不会更好？相当于这类对象即算作模型A，又算作模型B，这样我觉得就比较公平，因为如果只重复一部电影的话，那么随机将导致不公平；另外，如果我的推荐列表对象少的话，比如业务上我只需要推荐五个对象，那么一部电影的随机将造成比较大的误差。因此我不太认同评论区中随机的方法。</div>2023-02-01</li><br/>
</ul>