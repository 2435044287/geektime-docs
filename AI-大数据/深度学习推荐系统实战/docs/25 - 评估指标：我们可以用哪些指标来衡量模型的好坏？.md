你好，我是王喆。今天，我们来学习推荐模型的评估指标。

上节课，我们讲了五种评估方法，清楚了它们都是怎么把样本分割为训练集和测试集的。但是只分割样本是远远不够的，为了比较模型效果的好坏，还得用一些指标进行衡量。就像我们工作中经常说，我的模型提高了“一个点”的效果，那所谓的“一个点”指的是什么呢？它其实说的就是，我们的模型在一些经典的推荐指标上提升了1%的效果，这节课我就带你来捋一捋这些经典的推荐评估指标。

## 低阶评估指标

我按照指标计算的难易程度，和评估的全面性，把推荐系统的评估指标可以分成低阶评估指标和高阶评估指标两大类。对于低阶评估指标来说，准确率、精确率与召回率、对数损失、均方根误差，这四个指标在推荐模型评估中最常用，计算起来也最容易。所以，我们就先来学习一下这几个低阶评估指标的具体含义。

### 1. 准确率

准确率 (Accuracy)是指分类正确的样本占总样本个数的比例，公式1就是：$\\text {Accuracy}=\\frac{n\_{\\text {correct }}}{n\_{\\text {total }}}$。

其中， ncorrect是正确分类的样本个数， ntotal是样本的总数。
<div><strong>精选留言（21）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/21/08/a2/346431a9.jpg" width="30px"><span>Geek_b86285</span> 👍（35） 💬（4）<div>ROC曲线，FPR=FP​&#47;N,TPR=TP​&#47;P，当我们将负样本复制10倍时，TPR显然不会变，FPR是负样本中被预测为正样本的比例，这其实也是不变的，那整个ROC曲线也就没有变。PR曲线，精确率P=TP&#47;(TP+FP)，TP不变，FP增大，而召回率R没有变，显然ROC曲线更稳定一些</div>2020-12-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/b2/cb/9c6c7bf7.jpg" width="30px"><span>张弛 Conor</span> 👍（14） 💬（4）<div>P-R曲线的优点是能够表现精确率与召回率平衡的过程，缺点是无法显示明确的阈值，且缺乏对TN的考量。ROC曲线不仅能表现假阳性率与真阳性率的平衡，还可以表现出具体的阈值，也考量了TN，但缺乏对FN的考量。在正负样本不均衡的情况下，FN会较大，FP会较小，因此正样本性能的改进主要在于降低FN，P-R曲线中的召回率更关注FN，所以使用P-R曲线更好。</div>2020-12-09</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/9A1GRhjFcicWeSs9SmA1ib7Ft0017LLdgIw6o9q1hzmD7rX8PYTHZ2gaC3xn0CdlGriaoGPqpqGDk7UTjfZTHKrHg/132" width="30px"><span>PatrickPro2</span> 👍（5） 💬（1）<div>老师，工业界在用指标评估排序列表结果时，最最常用的指标是啥？我上学期上了cmu的搜索引擎这门课，我们教授说MAP和NDCG是最常用的，其中NDCG应该是效果最好的，因为NDCG考虑到了每个数的实际相关性和模型预测出的排序顺序。
我还有个问题：Diversity在推荐系统中重要吗？如果重要的话，是不是除了以上这些指标，还需要用到诸如Precision-Intent aware@K和alpha-NDCG这些指标进一步分析模型效果呢？</div>2021-05-25</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/55lYKUdcPFgUHibRYmaRiaBdrsmnLGOHdPp4OicjBh197X0vyGa9qAwruEqicAPuUgibXO4Lz5jLudlcbtsqq2p3CpA/132" width="30px"><span>Sebastian</span> 👍（4） 💬（1）<div>老师，想额外问一个关于CTR指标计算的问题：在AB测试中，如何合理的比较AB测试中两者的CTR指标呢？会不会一天内，某个时间段A桶的CTR高于B桶，但是某个时间段A桶又小于B桶，那这种该如何比较AB哪个算法更好？</div>2020-12-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（3） 💬（1）<div>提供一个通过confusion matrix理解precision，recall， roc的文章，https:&#47;&#47;www.biostat.wisc.edu&#47;~page&#47;rocpr.pdf，大家可以参考一下</div>2020-12-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/97/c4/6c92c78a.jpg" width="30px"><span>小强</span> 👍（2） 💬（1）<div>在实际工作中，一般是如何定义正样本和负样本的呢？首先，这个正样本和负样本应该是应用户而异吧？其次，以电影推荐为例，对于某个用户A，我们是把用户A之前看过的电影都定义成正样本，然后没有看过的电影都标记为负样本嘛？还是有其他什么方法？</div>2021-02-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg" width="30px"><span>JustDoDT</span> 👍（2） 💬（2）<div>个性化推荐，不是每个人的推荐结果都不一样吗。为啥说ROC、P-R是全量数据，我认为是针对每个人的全量物品推荐，文中的全量是指全量物品吗。mAP严格意义上说是用到了全量的用户和物品。</div>2020-12-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（2） 💬（1）<div>感觉通过confusion matrix（混淆矩阵）理解precision，recall以及TPR，FPR会更加形象些</div>2020-12-09</li><br/><li><img src="" width="30px"><span>飞行器</span> 👍（1） 💬（1）<div>老师好，召回率（Recall）是分类正确的正样本个数占真正的正样本个数的比例。但是在实际环境中对于召回率的计算比较困难吧，对于实际生产中海量的数据，很难找到所有真正正样本的个数吧？那如何进行离线评估召回率的计算呢？</div>2021-10-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/32/e6/4417c3ce.jpg" width="30px"><span>小峰™ =エ=®</span> 👍（1） 💬（2）<div>老师你好，针对现实数据集中点击率只有1~10%，训练集正负样本数量偏差的问题——使用样本平衡的方法，对负样本进行下采样来，最终实现训练集正负样本1:1，这样的方法是否可行？这样出来准确率是降低了，但模型对正样本的判定会更敏感些，不知道这样理解对不对？</div>2021-07-01</li><br/><li><img src="" width="30px"><span>努力学习</span> 👍（1） 💬（1）<div>请问老师，归一化折扣累计收益（Normalized Discounted Cumulative Gain,NDCG）这个评价指标，我在看论文时发现 TOP K推荐随着K取值的增加，同几种算法在不同的论文里 NDCG有的随K增加而增加 有的随K增加而减小，请问这是什么原因？</div>2021-03-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/28/a1/fd2bfc25.jpg" width="30px"><span>fsc2016</span> 👍（1） 💬（1）<div>在正负样本不均衡的情况下，roc曲线更加稳定和权威，更加稳定的反映模型本身的好坏。</div>2020-12-09</li><br/><li><img src="" width="30px"><span>飞行器</span> 👍（0） 💬（2）<div>老师好，一个follow up的问题，就是当我们选取点击作为正样本的时候，是否会存在曝光偏差或者是不同用户点击不同的问题，即从用户A的角度考虑，item 1是点击作为正样本，但是从用户B考虑，item 1仅只是曝光样本，甚至对于用户B来说可能是一个hard case的负样本，那如果按照合并所有用户点击作为正样本进行评估的话（特别是recall），是否对于某一部分用户是没有代表性的？那如果采用类似gAUC的方式进行评估，数据又会太稀疏，正样本太少。对于这种情况，请教老师在实际工作中是否又一些经验可以借鉴？</div>2021-10-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/25/62/abb7bfe3.jpg" width="30px"><span>PiccoZ</span> 👍（0） 💬（1）<div>老师，这些评价指标是不是都针对精排，请问下召回侧应该使用什么评价指标呢</div>2021-09-26</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/fcftgBsticCicEEkuzB0GTkHIocX62YVTSvnhR1c94sccj42lVaYXrmcZyhzUI3l9NcvuN1rXLhXt2eBrZZ0Tw7A/132" width="30px"><span>idiot</span> 👍（0） 💬（1）<div>“以AUC为主，补充分析mAP”，这里是怎么个标准呢？auc和map都有改进才到后续实验，还是都没有明显下降就到后续实验？如果是前者，有升有降怎么办？</div>2021-05-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/97/c4/6c92c78a.jpg" width="30px"><span>小强</span> 👍（0） 💬（1）<div>请问Hit Rate，Average Reciprocal Hit Rate这一组指标在工业界中应用的是否常见啊？</div>2021-04-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/a9/05/6822b8a5.jpg" width="30px"><span>灯灯灯</span> 👍（0） 💬（1）<div>老师您好， 我还是不理解 ‘’ROC曲线，P-R曲线是对全量样本在一起排序，不区分用户‘’。不区分用户的话样本的真实标签如何确定呢？</div>2021-01-23</li><br/><li><img src="" width="30px"><span>SecooHR</span> 👍（0） 💬（1）<div>文章的FP 定义不对吧， FP 指的是 N 个负样本中被分类器预测为正样本的个数。

另外 P-R  ROC 可以参考 这个 http:&#47;&#47;blog.sina.com.cn&#47;s&#47;blog_17b9e19320102x7ru.html  </div>2020-12-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg" width="30px"><span>JustDoDT</span> 👍（0） 💬（1）<div>ROC曲线右上角的TRP是0÷0=1，可以这么理解吗。</div>2020-12-11</li><br/><li><img src="" width="30px"><span>jxxiao</span> 👍（0） 💬（0）<div>以推荐业务为例，模型通常是以优化ctr和cvr为目标，但是业务指标可能是ARPU，这之间的gap怎么处理呢？</div>2022-06-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/17/2a/65c2b292.jpg" width="30px"><span>Karty</span> 👍（0） 💬（0）<div>老师您好，我想请教一下，新用户AUC较低，老用户AUC较高，一般是哪些原因造成的？</div>2021-07-29</li><br/>
</ul>