你好，我是王喆。

近几年来，注意力机制、兴趣演化序列模型和强化学习，都在推荐系统领域得到了广泛的应用。它们是深度学习推荐模型的发展趋势，也是我们必须要储备的前沿知识。

作为一名算法工程师，足够的知识储备是非常重要的，因为在掌握了当下主流的深度学习模型架构（Embedding MLP架构、Wide&amp;Deep和DeepFM等等）之后，要想再进一步提高推荐系统的效果，就需要清楚地知道业界有哪些新的思路可以借鉴，学术界有哪些新的思想可以尝试，这些都是我们取得持续成功的关键。

所以，我会用两节课的时间，带你一起学习这几种新的模型改进思路。今天我们先重点关注注意力机制和兴趣演化序列模型，下节课我们再学习强化学习。

## 什么是“注意力机制”？

**“注意力机制”来源于人类天生的“选择性注意”的习惯**。最典型的例子是用户在浏览网页时，会有选择性地注意页面的特定区域，而忽视其他区域。

比如，图1是Google对大量用户进行眼球追踪实验后，得出的页面注意力热度图。我们可以看到，用户对页面不同区域的注意力区别非常大，他们的大部分注意力就集中在左上角的几条搜索结果上。

那么，“注意力机制”对我们构建推荐模型到底有什么价值呢？

[![](https://static001.geekbang.org/resource/image/3a/5f/3a3cb86da13876d679c16f4ec955645f.jpg?wh=993%2A848 "图1 Google搜索结果的注意力热度图")](https://www.researchgate.net/figure/Heat-Map-Golden-Triangle-pattern-shown-by-the-heat-map-of-how-users-focus-on-a_fig1_267025472)

价值是非常大的。比如说，我们要做一个新闻推荐的模型，让这个模型根据用户已经看过的新闻做推荐。那我们在分析用户已浏览新闻的时候，是把标题、首段、全文的重要性设置成完全一样比较好，还是应该根据用户的注意力不同给予不同的权重呢？当然，肯定是后者比较合理，因为用户很可能都没有注意到正文最后的几段，如果你分析内容的时候把最后几段跟标题、首段一视同仁，那肯定就把最重要的信息给淹没了。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/1d/c9/f8/72955ef9.jpg" width="30px"><span>浣熊当家</span> 👍（38） 💬（1）<div>图3中DIN的激活单元里我们用到了“外积”， 之前的课程里感觉我们多数是用“内积”。请问老师，如何选择使用“内积”和“外积”， 有什么规则吗？</div>2020-11-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/22/b7/46/0a587042.jpg" width="30px"><span>李元</span> 👍（22） 💬（3）<div>根据NLP的发展，我觉得GRU这种提取序列信息的方式肯定会被Transformer取代。不知道有没有人已经发paper了。</div>2021-01-09</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/55lYKUdcPFgUHibRYmaRiaBdrsmnLGOHdPp4OicjBh197X0vyGa9qAwruEqicAPuUgibXO4Lz5jLudlcbtsqq2p3CpA/132" width="30px"><span>Sebastian</span> 👍（17） 💬（1）<div>老师想问下，DIN模型在工业界的排序阶段使用的多吗？因为我在想在业界每个用户都有比较长的用户行为序列的场景可能还是少数，很多公司的场景可能是，用户进入app端后点击了2-3次后可能就没有后续行为了，那么这种场景下，DIN应该就不适用了吧？</div>2020-11-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/64/b2/18005d2a.jpg" width="30px"><span>Leo Zhao</span> 👍（15） 💬（3）<div>思考题：广告和历史行为 相关性 其实就是  广告物品与历史物品的相关性，可以用一个dot层 或者通过物品embedding 算出similarity 当作feature 直接输入。</div>2020-11-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/28/a1/fd2bfc25.jpg" width="30px"><span>fsc2016</span> 👍（11） 💬（6）<div>1，老师，看了最近几章介绍的推荐模型，发现神经网络的隐层数量都比较少（相对cv），这个是防止模型太复杂，导致线上推断太慢吗
2，请教下老师，业界常用的MLP隐层数量和神经元数量，有没有一个大致的取值范围？</div>2020-12-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/b4/99/79a21147.jpg" width="30px"><span>轩</span> 👍（10） 💬（2）<div>老师您好，我有一个问题请教您：
transformer中有position encoding，而在推荐的领域中，点击的序列中同样有时间间隔的因素，例如取用户最近若干次点击，可能每次间隔时间不等。这个间隔时间应该是有信息可以揭示用户兴趣的变迁速率等信息的吧？但是如何将其引入到推荐序列中呢？
是类似于transformer中 position learned encoding这样么？</div>2021-01-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/d8/52/845a2b36.jpg" width="30px"><span>小红亮</span> 👍（9） 💬（1）<div>老师，请教一下DIEN中用到了GRU，它是串行处理的，那么推理的过程会比较慢，这就不太适合延长要求很高的场景，比如计算广告，那对于电商场景来说它DIEN的推理延迟能满足业务要求吗，或者有什么优化手段可以解决延迟问题吗</div>2021-04-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/c9/f8/72955ef9.jpg" width="30px"><span>浣熊当家</span> 👍（8） 💬（1）<div>想请教老师一个题外问题， 您作为面试官的话，对于MLE的候选人会更注重考察哪方面的能力（比如算法coding， 系统架构设计，机器学习的领域知识）？，然后对于机器学习的各种模型会期待候选人有多深的了解（比如说了解DIEN的各个层级的结构就够了，还是要知道GRU是具体如何实现的）。
随着老师课程，我对深度学习燃起了更大的热情，觉得想真正提高的话，最好的方法还是能从事做深度学习的工作，想知道从面试角度来讲，怎么学习才是性价比最高的选择， （比如注重项目经验，刷题，还是算法的理论公式推到）。</div>2020-11-29</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLaoiaerNMy7eoSA5yfibPNhta51jkhPTTL1dD1HGlnjaGnFQ6Uzbbce82Kpnic3g1JlD7rtm41Y83PA/132" width="30px"><span>Geek_3c29c3</span> 👍（7） 💬（1）<div>老师，我对DIN里面的注意力机制有一点疑问：就是DIN的目标广告的id和usr behavior的id是同一领域的id，那能不能推广到比如我们的广告id和商城内的物品不是同属于一个id系列的。就是广告的内容和商城的内容（包含用户行为）是不一样的，这时候还可以用DIN的注意力机制了吗？如果不能，还有什么方法呢？</div>2020-12-16</li><br/><li><img src="" width="30px"><span>Geek1254</span> 👍（6） 💬（2）<div>老师您好。
1.我看到在Sparrow里面的代码。没有严格意义上使用外积吧？使用的是element-wise sub &amp; multipy。然后用这两个向量去拼接，组成的activation_all。请问这是老师实践之后得到的方法吗？
2. 我看到参考代码中使用的是PRelu()，请问这种激活函数适合哪些场景呢？</div>2021-03-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/97/99/f5e9740a.jpg" width="30px"><span>庄小侠</span> 👍（6） 💬（2）<div>老师，我看了下这节课DIN.py里面的代码，发现 user_behaviors_emb_layer和candidate_emb_layer是两套不同的embding向量，请问这是为什么啊？我的理解是它们都是电影的embding向量，共用一套embding不是参数量更少嘛。实际使用里面，大家都是这样用嘛？</div>2021-02-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/b2/cb/9c6c7bf7.jpg" width="30px"><span>张弛 Conor</span> 👍（6） 💬（7）<div>思考题：可以借鉴FM及DeepFM中特征交叉的计算方式，对两个向量直接计算内积，或者先通过Embedding层转换成维度相等的Embedding再求内积，又或者可以像双塔结构一样，设计一个历史行为物品塔和广告物品塔，在塔的最后通过求内积或者拼接后用全连接层输出权重。
课后疑问：
DIEN模型中输出的用户当前兴趣向量h&#39;(T)是由用户的历史兴趣向量所得，我的问题是，DIEA能否探索到历史兴趣以外的兴趣呢？如果可以的话，是如何在没有其他兴趣向量的参与下做到的呢？如果不行的话，请问老师在实践中是否有什么方法，可以对用户历史兴趣以外的兴趣进行探索的方法呢？</div>2020-11-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（6） 💬（1）<div>DIN 使用了一个结构比较复杂的激活单元来计算注意力权重，能否有其它方法来计算呢？我开始想到的上节课提到的特征交叉，我回顾了下特征交叉，它是加强模型对于特征组合和特征交叉的学习能力以及对于未知特征组合样本的预测能力。而注意力权重是计算历史物品和广告物品相关行。我觉得它们是不同的。</div>2020-11-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/b2/cb/9c6c7bf7.jpg" width="30px"><span>张弛 Conor</span> 👍（5） 💬（1）<div>课后疑问：
请问老师，对于DIN和DIEN这种包含N个历史商品的模型，如果用户历史商品数小于N，那么这些位置应该如何去填充呢？如果用户商品数大于N，是否是选择最近的N个商品呢？</div>2020-11-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg" width="30px"><span>范闲</span> 👍（4） 💬（3）<div>1.历史行为和广告物品直接dot
2.利用双塔模型，取最终的输出做特征</div>2020-12-02</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/l3RGUX8aLnPLmsQsra0yU5d8m7Se5jdVpaC3bkb99FuY11BPQNAsH4MPXbZjCTia9VVwn8lnBnKLkdfSiabOgxKg/132" width="30px"><span>Geek_e0d66a</span> 👍（4） 💬（2）<div>请问老师，DIN中的激活单元，的网络结构中，为什么用户Embedding和候选集的embedding的外积，再拼接在一起？？</div>2020-11-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/fa/73/3b9cbc69.jpg" width="30px"><span>VictorWu</span> 👍（2） 💬（2）<div>DIN.py 文件中第137行 tf.keras没有sum方法，sum方法应该在tf.keras.backend中

我发了个pr哈</div>2021-01-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/20/d4/f2/979e5346.jpg" width="30px"><span>邓生</span> 👍（2） 💬（3）<div>关于sum pooling有一点不明确，假如user1买了good1，对应embedding是[1,2,3]，sum pooling后是[1,2,3]，user2买了good1 good2，对应embedding是[1,2,3]和[4,5,6]，sum pooling 后是［5,7,9]。然后后续都输入到神经网络。这样就实现了神经网络固定维度输入，是这样理解吗？</div>2020-12-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/fa/c1/710de9b5.jpg" width="30px"><span>freedom</span> 👍（2） 💬（3）<div>老师我想问一个问题，在训练模型过程中，在用到BN的时候，经常会出现BN层训练不好的情况，具体表现为训练时候(is＿training=TRUE)准召比较高。但是设置is_training为false的时候 准召降得比较厉害。moving_mean和moving_var也都有更新。请问这是因为什么原因呢，该如何解决呢？</div>2020-11-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/64/d9/79aa9ba5.jpg" width="30px"><span>墨量</span> 👍（1） 💬（1）<div>大佬，这一句（它的输入是当前这个历史行为商品的 Embedding，以及候选广告商品的 Embedding）加几个字，变为：
它的输入是当前这个【用户的】历史行为商品的 Embedding，以及候选广告商品的 Embedding。
是不是更好理解哇
</div>2021-01-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/20/d4/f2/979e5346.jpg" width="30px"><span>邓生</span> 👍（1） 💬（2）<div>关于实现DIN模型有个细节疑问：不同用户有不同的购买记录，形成的用户行为特征不一致，是否有一个固定的特征是“是否买了鼠标”？不然模型如何学习到买鼠标对预测买键盘的这一固定组合？（对不起我组织的语言有点混乱）</div>2020-12-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/b2/cb/9c6c7bf7.jpg" width="30px"><span>张弛 Conor</span> 👍（1） 💬（3）<div>请问老师，DIN模型的Activation Unit中，两个首先会进行out product运算，两个向量的外积运算不应该是一个常数或者nxn的矩阵嘛，但是图示中得到的是和向量相同维度的向量，我查阅了老师的书籍，我看书中的激活单元中相应位置使用的是元素相减，请问老师这是为什么呢？</div>2020-11-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（1） 💬（1）<div>请问老师DIN模型里的concat&amp;flatten作用是什么？</div>2020-11-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4a/4a/fdae1e16.jpg" width="30px"><span>梁栋💝</span> 👍（0） 💬（1）<div>老师好，内容直击要害，获益匪浅，感谢。

想问一下，多个相同维度的embedding向量做sum pooling用tf.keras.layers.Add加起来就行，是吗。</div>2021-01-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/9a/3a/a516329e.jpg" width="30px"><span>董仁广</span> 👍（0） 💬（1）<div>DIN的激活单元相当于一个小型的深度学习模型，那这个激活单元是单独训练的嘛？如果是这样的话 那模型的y又是什么呢？还是说激活单元是作为整个DIN的一部分进行端到端的训练的？</div>2020-11-30</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erAhtlpeFFwRk5g5LvzLcZgybImECIdKmhG1aPxdbnqWP6LmeNz5ibYibOedUwF7NjTy1asZqUur5uQ/132" width="30px"><span>kenan</span> 👍（0） 💬（2）<div>王老师，候选集是这个意思，以点击预估为例，在排序阶段，我们通过把用户特征，item特征和上下文特征放入到模型里面，得到item的点击预估值。然后根据候选集里面每个item的点击预估值从大到小排序，然后取出topN。现在候选集只有item，是如何建模。有没有工程上的demo，或者资料推荐。</div>2020-11-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/55/89/6ee4424c.jpg" width="30px"><span>passenger</span> 👍（0） 💬（0）<div>为什么不直接用余弦相似度表示两个商品的关联程度？</div>2022-03-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/72/1d/abb7bfe3.jpg" width="30px"><span>顾小平</span> 👍（0） 💬（1）<div>老师你好，实际工作中发现DIN网络计算量占比比较大，有没有比较好的优化手段呢？（用户的行为系列有长也又短的情况下）</div>2022-02-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/9a/71/7347008c.jpg" width="30px"><span>小泥鳅</span> 👍（0） 💬（0）<div>老师您好：dien 利用用户历史购买行为预测下一个购买的，但是如果用户没有历史购买行为呢，或者有浏览行为呢。也可以利用这些序列么</div>2022-01-16</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/60UgZMiaYPUp1xRqRuRLCclg25KuKyL81pwwj9meQwF7ribZU3t7AhxVC2AxUia4iawcsb3fuiaJJx2BsrWeYGoDERA/132" width="30px"><span>haolison</span> 👍（0） 💬（0）<div>王老师好，运行DIN.py报错：
    activation_unit = tf.keras.layers.Flatten()(activation_unit)
    &#39;but was passed an input_mask: &#39; + str(mask))
TypeError: Layer flatten does not support masking, but was passed an input_mask: Tensor(&quot;concatenate&#47;All:0&quot;, shape=(?, 5), dtype=bool)
网上找不到答案，调试很难，请问是bug还是数据问题呢？</div>2021-03-15</li><br/>
</ul>