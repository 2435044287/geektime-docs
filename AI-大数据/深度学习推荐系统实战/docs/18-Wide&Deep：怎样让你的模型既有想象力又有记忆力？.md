你好，我是王喆。

今天，我们来学习一个在业界有着巨大影响力的推荐模型，Google的Wide&amp;Deep。可以说，只要掌握了Wide&amp;Deep，我们就抓住了深度推荐模型这几年发展的一个主要方向。那Wide&amp;Deep模型是什么意思呢？我们把它翻译成中文就是“宽并且深的模型”。

这个名字看起来好像很通俗易懂，但你真的理解其中“宽”和“深”的含义吗？上一节课我们讲过Embedding+MLP的经典结构，因为MLP可以有多层神经网络的结构，所以它是一个比较“深”的模型，但Wide&amp;Deep这个模型说的“深”和MLP是同样的意思吗？“宽”的部分又是什么样的呢？宽和深分别有什么不同的作用呢？以及我们为什么要把它们结合在一起形成一个模型呢？

这节课，就让我们就带着这诸多疑问，从模型的结构开始学起，再深入到Wide&amp;Deep在Google的应用细节中去，最后亲自动手实现这个模型。

## Wide&amp;Deep模型的结构

首先，我们来看看Wide&amp;Deep模型的结构，理解了结构再深入去学习细节，我们才能掌握得更好。

![](https://static001.geekbang.org/resource/image/fb/e0/fb17112c951ebb2a515f12dace262de0.jpg?wh=1316%2A600 "图1 Wide&Deep模型结构 [br]（出自Wide & Deep Learning for Recommender Systems ）")

上图就是Wide&amp;Deep模型的结构图了，它是由左侧的Wide部分和右侧的Deep部分组成的。Wide部分的结构太简单了，就是把输入层直接连接到输出层，中间没有做任何处理。Deep层的结构稍复杂，但我相信你也不会陌生，因为它就是我们上节课学习的Embedding+MLP的模型结构。
<div><strong>精选留言（27）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/18/d2/7e/38f369b5.jpg" width="30px"><span>giraffa126</span> 👍（45） 💬（3）<div>冒昧问一下，deep的输出是128，wide是10000，两个不在一个量纲，感觉直接这么concate，会不会削弱deep的效果，模型退化成LR？</div>2020-12-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/20/46/f4/93b1275b.jpg" width="30px"><span>Alan</span> 👍（30） 💬（1）<div>答：改进空间大致上我能想到两种方式：我选2
1、手动人工两个特征交叉或求解相关性（即，电影风格类型较低情况下，数据维度较低、数据量较小情况下是可以的，但是在实际工业应用领域是不切实际的），
2、改进算法的wide部分，提升记忆能力，使用端到端模型，减少人工操作。例如DCNMix、DeepFM。以DeepFM这个模型都可以很好学习到高低特征与交叉。（实际业界常用，推荐）
普及一下高低阶特征知识：
低阶特征：是指线性-线性组合，只能算一个有效的线性组合，线性-非线性-线性，这样算两个有效的线性组合，一般常说的低阶特征只有小于等于2阶；
高阶特征：说高阶特征，可以理解为经过多次线性-非线性组合操作之后形成的特征，为高度抽象特征，一般人脑很难解析出原有的特征了</div>2021-03-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg" width="30px"><span>范闲</span> 👍（19） 💬（1）<div>电影本身风格和用户倾向风格可以做个融合~~用户偏离本身风格的程度~~</div>2020-12-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（16） 💬（2）<div>请问老师，文中例子中把类别型特征放入到wide里，如果把数值型特征放到wide部分，是否需要做normalization呢？</div>2020-11-20</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erUKWZy1fBBcJncWRNh9M3TkjThqgsIIpmGOTCyg2IN80IDf3COkeWyTLHliczAppIkfBgCJTsUn1g/132" width="30px"><span>马龙流</span> 👍（14） 💬（1）<div>用户喜欢的风格和电影本身自己的风格，做attention做为一个值喂给mlp，这种做法是否可以</div>2020-11-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/22/cb/18/0139e086.jpg" width="30px"><span>骚动</span> 👍（5） 💬（3）<div>请问老师，我觉得Wide&amp;Deep和GBDT+LR在逻辑上很像，Wide对应LR，Deep对应GBDT，不知道我的想法对不对？这两个模型对比，老师能给我讲下吗，有什么共性？另外，GBDT+LR中输入LR的数据，也是原始特征+GBDT训练的特征，是否可以理解为原始特征就是模型的记忆能力，GBDT训练的组合特征就是泛化能力？</div>2021-01-16</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTL357Eqdgfv7hVpPql5WYshNkd4YGtJ3PD801zjJs2nVpJIia92YZAjsK9dKJoN5rwLUEBEk6T4Xmg/132" width="30px"><span>Geek_b027e7</span> 👍（5） 💬（2）<div>老师，deepfm中crossed_column是不是只写了一个好评电影的交叉例子，按文中意思是把所有好评过的历史电影与所有电影做交叉</div>2020-12-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/6f/ab/4fc3f494.jpg" width="30px"><span>江峰</span> 👍（4） 💬（2）<div>在工业界应用wide deep模型的时候，wide侧和deep侧分别应该放什么样的特征呢？ 我在实践过程中都是把 原始id特征放到deep侧，把id类别大的，和其他id特征的交叉放在wide侧。比如adid和分词交叉，memberid和分词交叉等。这样处理合适吗？ 把这种交叉特征同时放在wide侧和deep侧，是不是会更好？</div>2021-02-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/23/ac/20/0f1eefaf.jpg" width="30px"><span>王继伟</span> 👍（4） 💬（1）<div>请问老师，文中说Wide 部分就是把输入层直接连接到输出层。
1、如果输入层特征特别稀疏（上千万维的one_hot）这样即使是直接连接到输出层也会增加上千万个参数，这样会降低模型训练速度吗？
2、如果Wide 部分输入的稀疏特征维度上亿，那wide部分的训练的参数会比deep部分训练的参数还要多，这样合理吗？
还是说wide部分的输入是要控制特征维度的？</div>2021-02-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/eb/f1/77b9d336.jpg" width="30px"><span>Jacky</span> 👍（4） 💬（8）<div>老师，您好！我想咨询一下，我在pycharm里运行py文件的时候，出现了cast string to int32 is not supported的问题，想咨询一下如何修改代码。谢谢您！感谢！</div>2021-01-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/c9/f8/72955ef9.jpg" width="30px"><span>浣熊当家</span> 👍（4） 💬（1）<div> 图二模型中Relu层从下到上分别是1024， 512， 256， 很好奇这些数字的设定有什么讲究吗？ 比如1）是不是设置成这种2进制相关的数字比较有效率？ 2）神经网络的维度一般都是往上每层除2这种规则吗？</div>2020-11-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/51/6e/a226e158.jpg" width="30px"><span>石忠会</span> 👍（2） 💬（1）<div>老师，我看代码里面的优化器只给出了Adam 但是在在tf单独给接口或者理论中不是宽度模型使用FTRL进行优化，深度模型用 adgrad 或者Adam进行优化 这其中有什么深意吗</div>2021-07-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1c/bc/4c/fb5452bd.jpg" width="30px"><span>hurun</span> 👍（2） 💬（1）<div>王老师好，你在代码注释详细，个人学完后收获良多，感谢你的付出。
我参考代码和你的讲解文档，对crossed_feature特征的生成及其在训练集、测试集的使用，有一点小小的疑惑：在代码WideNDeep.py的72行，使用了userRatedMovie1特征，我查看trainingSamples.csv和testSamples.csv，发现训练集的userRatedMovie特征movie_id，出现在测试集movie_id列，这样会不会有future feature问题呢，比如训练集中(user_id, movie_id, userRatedMovie1) =(3033, 970, 969) 出现在训练集(user_id, movie_id, userRatedMovie1) =(3033, 969, 288) ，相当于在训练集中提前告诉模型，对于3033这个用户，969是高质量评价的电影


</div>2021-02-02</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/55lYKUdcPFgUHibRYmaRiaBdrsmnLGOHdPp4OicjBh197X0vyGa9qAwruEqicAPuUgibXO4Lz5jLudlcbtsqq2p3CpA/132" width="30px"><span>Sebastian</span> 👍（2） 💬（2）<div>可以在deep网络中加入attention机制，比如用户行为序列作为特征时，近期的行为一般比远期行为更加能反映user的兴趣，这种时候可以对行为序列做attention处理。</div>2020-11-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/f5/8a/dc9a23a1.jpg" width="30px"><span>续费专用</span> 👍（1） 💬（3）<div>我就是想问问，25 岁的男性用户喜欢看电影 A，35 岁的女性用户也喜欢看电影 A，那么按照常识，这部电影A大概是部什么样的电影呢？🤔</div>2021-02-20</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/4icayE3ic5IA7RWwZcrxpMZE4T1WViakEgPsDC3UnhZwU83ad65IjmxPficy0vNZz6Q6vCiclnmyBDc5IYf7soHAXrQ/132" width="30px"><span>Geek_790c43</span> 👍（1） 💬（3）<div>请问 crossed_feature具体含义是什么？怎么个交叉法？</div>2021-01-29</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83epW1MiaFR2RTu5YTIBLzZLVm8GJNphfRltWWgRPnKMQJsrpvCXZQa5K0U9jozbfLNWKkTSPlSNkiaSg/132" width="30px"><span>kakaymi</span> 👍（0） 💬（1）<div>logloss是logistic回归吗?最终输出的是一个0-1之间的标量?这个标量的含义是什么呢？</div>2021-08-29</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/60UgZMiaYPUp1xRqRuRLCclg25KuKyL81pwwj9meQwF7ribZU3t7AhxVC2AxUia4iawcsb3fuiaJJx2BsrWeYGoDERA/132" width="30px"><span>haolison</span> 👍（0） 💬（2）<div>王老师好，用pycharm运行WideNDeep.py
此行代码model.fit(train_dataset, epochs=5)报错，信息如下：
tensorflow.python.framework.errors_impl.FailedPreconditionError: Table not initialized.
	 [[{{node dense_features&#47;movieGenre3_embedding&#47;hash_table_Lookup&#47;LookupTableFindV2}}]]
请问是bug呢？还是数据出了问题呢？
</div>2021-03-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/f3/d1/0663e55c.jpg" width="30px"><span>FayeChen</span> 👍（0） 💬（1）<div>我理解wide的部分是待评分的电影和 评分完成的电影 做笛卡尔积，然后hash再输入LR中。但是如果看过的电影有多个，比如一共有n个电影，那不是有2的n次方种记忆的选择。对于历史点继续列这种多值离散的特征怎么处理比较好呢</div>2021-03-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/90/6b/24ca47da.jpg" width="30px"><span>黄佳恒</span> 👍（0） 💬（1）<div>老师，请教一个问题。在wide deep中的wide部分，使用movieid与历史点击的item做交叉，那当模型上线的时候，tf serving的输入的历史item应该是什么样子的</div>2021-02-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4a/4a/fdae1e16.jpg" width="30px"><span>梁栋💝</span> 👍（0） 💬（2）<div>老师好，我下面的理解对吗。

如果是1个历史ID和当前ID做交叉后hash取模bucket，应该onehot向量只有1个非0。
如果是N个历史ID和当前ID做交叉，得到的是不是多个hash值各自取模，得到multihot向量。
</div>2021-01-07</li><br/><li><img src="" width="30px"><span>Yang Hong</span> 👍（2） 💬（1）<div>老师，我理解的Embedding+MLP中对于low dimension的feature和embedding后的feature在连接层的拼接，与Wide&amp;Deep中对wide部分和deep部分的feature的拼接原理一样，都是stack的方式。

但为什么在代码中它们不一样呢？比如在Embedding+MLP中我们用的是+号拼接： tf.keras.layers.DenseFeatures(numerical_columns + categorical_columns)，但是在Wide&amp;Deep中我们是用tf.keras.layers.concatenate([deep, wide])的方式拼接。</div>2021-07-26</li><br/><li><img src="" width="30px"><span>Geek_8a732a</span> 👍（1） 💬（0）<div>不应该，“用户喜欢的电影风格”和“电影本身的风格”，可以考虑做合并成一个变量。</div>2021-08-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/88/5d/7b02da07.jpg" width="30px"><span>白马飞飞</span> 👍（0） 💬（0）<div>请问含有crossed_column特征处理的模型，如何保存模型？ 推理时，如何crossed_column这部分特征如何输入模型。</div>2021-11-25</li><br/><li><img src="" width="30px"><span>Geek_3cdb56</span> 👍（0） 💬（0）<div>哪些特诊适合放在wide里面，哪些特征适合放在deep里面</div>2021-11-24</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/4icayE3ic5IA7RWwZcrxpMZE4T1WViakEgPsDC3UnhZwU83ad65IjmxPficy0vNZz6Q6vCiclnmyBDc5IYf7soHAXrQ/132" width="30px"><span>Geek_790c43</span> 👍（0） 💬（1）<div>交叉之后为何是10000维度，如何选取</div>2021-07-21</li><br/><li><img src="" width="30px"><span>Sanders</span> 👍（0） 💬（0）<div>可否在Wide层加入某个激活函数输出后跟Deep层Concat？这样会对模型的记忆和泛化能力会有什么影响？</div>2021-02-05</li><br/>
</ul>