你好，我是王喆，今天，我们来学习协同过滤的深度学习进化版本，NeuralCF。

在[第15讲](https://time.geekbang.org/column/article/305182)里，我们学习了最经典的推荐算法，协同过滤。在前深度学习的时代，协同过滤曾经大放异彩，但随着技术的发展，协同过滤相比深度学习模型的弊端就日益显现出来了，因为它是通过直接利用非常稀疏的共现矩阵进行预测的，所以模型的泛化能力非常弱，遇到历史行为非常少的用户，就没法产生准确的推荐结果了。

虽然，我们可以通过矩阵分解算法增强它的泛化能力，但因为矩阵分解是利用非常简单的内积方式来处理用户向量和物品向量的交叉问题的，所以，它的拟合能力也比较弱。这该怎么办呢？不是说深度学习模型的拟合能力都很强吗？我们能不能利用深度学习来改进协同过滤算法呢？

当然是可以的。2017年，新加坡国立的研究者就使用深度学习网络来改进了传统的协同过滤算法，取名NeuralCF（神经网络协同过滤）。NeuralCF大大提高了协同过滤算法的泛化能力和拟合能力，让这个经典的推荐算法又重新在深度学习时代焕发生机。这节课，我们就一起来学习并实现NeuralCF！

## NeuralCF模型的结构

在学习NeuralCF之前，我们先来简单回顾一下协同过滤和矩阵分解的原理。协同过滤是利用用户和物品之间的交互行为历史，构建出一个像图1左一样的共现矩阵。在共现矩阵的基础上，利用每一行的用户向量相似性，找到相似用户，再利用相似用户喜欢的物品进行推荐。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/19/78/9a/296b3983.jpg" width="30px"><span>Evan-wyl</span> 👍（26） 💬（1）<div>不可以，如果是新闻推荐的话，地点信息会产生很大的影响；这时把地点信息仅仅是加入到用户侧没有任何作用。</div>2020-11-25</li><br/><li><img src="" width="30px"><span>AstrHan</span> 👍（19） 💬（4）<div>embedding之后，如果使用点积，那么这两个embedding是在同一个向量空间；如果使用的MLP则不在同一个向量空间。因为点积不影响向量空间，线性变换矩阵会影响。老师这么说对吧。</div>2021-01-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/c4/d9/61705b32.jpg" width="30px"><span>定春一号</span> 👍（18） 💬（3）<div>把context特征放进user塔或者item塔，那么离线生成user embedding或者item embedding的数量就要翻好多倍，能否考虑把context特征单独作为context塔呢？</div>2020-11-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/99/4a/09ea6699.jpg" width="30px"><span>小小的天</span> 👍（17） 💬（2）<div>双塔模型对于新闻场景是不是也不太好？新闻时效性很强，在我们公司的数据里，大部分新闻曝光在2个小时内，双塔的训练数据有足够的曝光时，新闻的价值也失去了很多了</div>2020-12-15</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/55lYKUdcPFgUHibRYmaRiaBdrsmnLGOHdPp4OicjBh197X0vyGa9qAwruEqicAPuUgibXO4Lz5jLudlcbtsqq2p3CpA/132" width="30px"><span>Sebastian</span> 👍（15） 💬（2）<div>老师，我还是没理解为什么不能加入context的特征。在训练DSSM的时候除了user和item的特征外，在user塔加入context的特征，比如用户的地理位置、手机型号等等，训练完后，将user和item的embedding存入redis后。线上请求时，将user的静态特征和实时context特征再过一遍DSSM，得到新的user embedding后，与存入redis的item emebdding取topN即可，为什么不妥呢？</div>2020-12-01</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/4icayE3ic5IA7RWwZcrxpMZE4T1WViakEgPsDC3UnhZwU83ad65IjmxPficy0vNZz6Q6vCiclnmyBDc5IYf7soHAXrQ/132" width="30px"><span>Geek_790c43</span> 👍（11） 💬（1）<div>不可以，因为如有地点或者时间这种波动比较大的特征就不能用预存embedding来表示当前的用户或者当前的物品了。例如外卖推荐，在公司和家时用户的embedding应该是不同的。或者新闻网站早晨和晚上的也应该不同</div>2021-01-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/1f/1e/f3365200.jpg" width="30px"><span>🍃</span> 👍（9） 💬（2）<div>老师，我还是不理解为什么用用户id和物品id做one-hot编码？直接数值特征不好么？</div>2021-05-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/3a/95/e8fc39d5.jpg" width="30px"><span>Eayon</span> 👍（6） 💬（1）<div>老师前面提到Embedding+MLP中的物品，Embedding不能计算物品和用户的相似度，提到不在一个空间向量（也说不能点乘就不在一个空间，其实还是不太理解）这里就有两个问题
1.不在一个空间究竟是什么概念，真就是不能点积就行了，还是跟里面数据内涵有点关系？
2.另外Embedding+MLP 中的Embedding能不能计算物品与物品之间的相似度呢？
然后是这节课双塔模型中又可以得到物品和用户的Embedding，可以通过点积得到相似度
3.那这时候的物品embedding能用来计算物品间的相似度吗？</div>2021-04-26</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/4icayE3ic5IA7RWwZcrxpMZE4T1WViakEgPsDC3UnhZwU83ad65IjmxPficy0vNZz6Q6vCiclnmyBDc5IYf7soHAXrQ/132" width="30px"><span>Geek_790c43</span> 👍（6） 💬（4）<div>图二中，和之前deep crossing 以及 wide&amp;deep，把用户id的one hot向量作为输入, 如果有几亿的用户也这么处理么？</div>2021-01-29</li><br/><li><img src="" width="30px"><span>AstrHan</span> 👍（6） 💬（2）<div>双塔版本的模型是不是有些问题，点积之后应该还要加一层输出层吧？
output = tf.keras.layers.Dense(1, activation=&#39;sigmoid&#39;)(output)</div>2021-01-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/20/46/f4/93b1275b.jpg" width="30px"><span>Alan</span> 👍（5） 💬（2）<div>答：肯定会有影响的！
首先，NeuralCF 模型计算的用户与物品之间的协同过滤后的计算结果，加入任何的维度，都会导致矩阵变化，失去其意义。
其次，因为时间、地点这两类特征因素具有很强的影响力！基于用户-物品的协同过滤在此情况下失去意义。就以视频推荐类App来说，白天推荐给我（在公司工作）的新闻、娱乐短视频的协同过滤的结果，到了晚上推荐给我（在校学习）学习类、游戏类长视频为主</div>2021-03-18</li><br/><li><img src="" width="30px"><span>Geek_8ac51c</span> 👍（4） 💬（1）<div>老师，mlp层为啥可以替代点积操作。有理论资料学习吗？</div>2021-01-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg" width="30px"><span>范闲</span> 👍（4） 💬（2）<div>不可以直接加入用户侧或者物品侧，会产生组合爆炸的问题。
可以考虑变成3塔的结构，加个other塔~~，other embedding也可以预存。但是有个问题other的这些变化可能会比较快，对模型、embedding的更新要求会很高~~</div>2020-12-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/68/98/522e034c.jpg" width="30px"><span>lyx</span> 👍（2） 💬（1）<div>请问下DenseFeatures这层是做embedding的么，搜了半天不知道这层是干嘛的。</div>2021-10-05</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/5EgbE7BFRtWHIchE5eCoaXFX4RWxg3iblIbC8G9X2cV4sYlW9qCib1sMiaJusda6p3L5UUq8aoUfOPU1QSia7caibqA/132" width="30px"><span>Geek_71fed1</span> 👍（2） 💬（1）<div>老师，为什么两个embedding向量是在同一向量空间？</div>2021-03-22</li><br/><li><img src="" width="30px"><span>Geek1254</span> 👍（2） 💬（2）<div>老师您好，Youtube的案例中。用户侧有用户正在观看的视频ID，这是需要及时获取的，然后视频的views和likes也需要及时更新。那么这些信息在变化，需要即时获取。那么u(x)和v(y)需要重新计算，请问是在什么时候放入特征数据库呢？</div>2021-03-02</li><br/><li><img src="" width="30px"><span>努力学习</span> 👍（2） 💬（1）<div>关于课后思考请问老师，如果只考虑已有数据是不是就可以添加位置等信息了？
如果就是做位置推荐，那么位置信息还算是context吗？位置推荐若不能使用双塔模型应该优选什么模型那？谢谢老师</div>2021-02-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/dc/93/bdbc45cc.jpg" width="30px"><span>LUO FAN</span> 👍（2） 💬（1）<div>请问在neuralCF的实现中，为什么是把物品特征和用户特征拼接起来送入网络，而不是先分别过embedding 层然后再拼接</div>2021-02-05</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/OwZuBRbVUkziazePs2xTKskNpZachRtCBZLHlv4dAUgaBC5qHI292xaxvg3atGnHlDwjIOXPKEbc7zOrtMyicSNg/132" width="30px"><span>罗辑</span> 👍（1） 💬（1）<div>老师，tf.feature_column.embedding_column 中得到embedding向量是通过矩阵分解还是通过神经网络得到的？</div>2021-10-07</li><br/><li><img src="" width="30px"><span>Geek_fdb832</span> 👍（1） 💬（1）<div>Youtube的双塔模型，serving的时候，每次用户点击都要整个模型跑一遍吗？那线上cost不会太高？</div>2021-06-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/0c/f6/8ae0beb3.jpg" width="30px"><span>维真</span> 👍（1） 💬（1）<div>如果双塔模型用在召回层，那么之前您将的那个graph embedding据说也用在召回层呢，这两个召回层的区别是什么呀？</div>2021-05-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/22/cb/18/0139e086.jpg" width="30px"><span>骚动</span> 👍（1） 💬（1）<div>这样看，双塔应该在实时里特别适用？但是emb的更新又是个问题，所以在一些emb更新节奏慢的实时业务情景下，是不是特别适用？</div>2021-01-16</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/dliaGpsxSic6Km3NGL5A3FVOBuQ9qiaUZ1ewCSNPaxxqHBPQ66rc19bRKA9EDy3H1P1wfSMPF4CuTx7X7GPs57CRQ/132" width="30px"><span>Geek_033ad5</span> 👍（1） 💬（2）<div>老师，我有个疑惑，双塔如果用在召回层在最后输出候选集阶段是怎么做呢？因为像item2vec这种方法是通过哈希去比较相似度可以提高效率，但双塔却是计算user和item两个embedding的softmax，那岂不是会one by one的去做运算导致计算量非常大？</div>2021-01-10</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erUKWZy1fBBcJncWRNh9M3TkjThqgsIIpmGOTCyg2IN80IDf3COkeWyTLHliczAppIkfBgCJTsUn1g/132" width="30px"><span>马龙流</span> 👍（1） 💬（4）<div>双塔模型一般用在召回吧?用户向量线上现算，物品向量存储起来?</div>2020-11-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg" width="30px"><span>JustDoDT</span> 👍（1） 💬（3）<div>老师不讲武德，共现矩阵没交代怎么来的啊
共现矩阵的制作大致流程：
1、用户-物品喜好矩阵UI
2、物品-物品相似度方阵II
3、UI·II 得到 共现矩阵
参考：https:&#47;&#47;best-yz.cn&#47;2019&#47;07&#47;28&#47;ji-yu-xie-tong-guo-lu-cf-suan-fa-de-tui-jian-xi-tong&#47;</div>2020-11-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/b2/cb/9c6c7bf7.jpg" width="30px"><span>张弛 Conor</span> 👍（1） 💬（1）<div>不可以，因为生成的Embedding未包含新的场景特征</div>2020-11-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/27/54/3d/366462d0.jpg" width="30px"><span>Yvonne</span> 👍（0） 💬（1）<div>老师，这种预存embedding的，是不是就不算End2End训练了?之前学习13讲的时候，就不太明白End2End怎么和embedding结合起来</div>2021-05-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/3a/95/e8fc39d5.jpg" width="30px"><span>Eayon</span> 👍（0） 💬（1）<div>老师有点懵，问个小白的问题，前面提到Embedding是基于时序item2vec得来的，深度学习里面，似乎都用的是反向传播得出的？是两种么？那这两种emb表达的内涵应该都不是一回事了吧？是不是可以认为已经没有item2vec什么事了，而更多是基于rating中label的0、1来决定emb的内涵</div>2021-04-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/f3/d1/0663e55c.jpg" width="30px"><span>FayeChen</span> 👍（0） 💬（2）<div>如果想线上比较好友好地运用双塔模型是不是T+1生成user_embeding 比较好，因为用户的实时兴趣是很难实时存储的，跟据实时行为用户的embedding都一直在变化。个人认为，对于老用户，当日第一次访问用双塔模型就非常适合，但是随着用户行为的累计还是需要embeding + MLP这种方式</div>2021-03-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1c/bc/4c/fb5452bd.jpg" width="30px"><span>hurun</span> 👍（0） 💬（2）<div>王老师好，想请教个编程问题
# movie id embedding feature
movie_col = tf.feature_column.categorical_column_with_identity(key=&#39;movieId&#39;, num_buckets=1001)
movie_emb_col = tf.feature_column.embedding_column(movie_col, 10)

这里的id是整型，但生产环境的id一般是字符串，我想到到是把字符串数据先做处理映射到整型，然后再传给NeuralCF进行训练。有没有更好到方法可以在NeuralCF一步到位处理好，是不是可以使用tf.feature_column.categorical_column_with_vocabulary_list方法实现</div>2021-01-20</li><br/>
</ul>