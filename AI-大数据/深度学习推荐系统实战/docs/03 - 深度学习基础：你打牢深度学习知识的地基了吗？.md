你好，我是王喆。

今天，我想用一节课的时间，带你梳理巩固一下深度学习的相关基础知识。打好基础之后，我们再去学习深度学习推荐系统的技术细节，就能更加得心应手了。

具体来说，我会从一个基本的神经元开始，讲到多神经元组成的神经网络，再到结构各异的深度学习网络，最后再讲一讲深度学习和推荐系统是怎么结合的。这样，从0到1带你体会深度学习网络生长的整个过程。

是不是已经迫不及待想要开始今天的课程啦？接下来，我们就一起“钻”进一个神经元里面，跟它一起成长吧。

## 一切要从一个神经元开始

上中学的时候，你肯定在生物课上学到过，神经元是我们神经系统的最基本单元，我们的大脑、小脑、脊髓都是由神经元组成的。比如，大脑大概包含了1000亿个神经元！正是这些小小的神经元之间互相连接合作，让大脑能够完成非常复杂的学习任务，这是一个多么神奇的过程！

于是，计算机科学家们就有一个设想，是不是我们也能从神经元出发，创造出一个人造大脑，来帮我们完成各种不同的任务呢？这其中当然也包括我们课程要讲的推荐任务。事实上，随着近十年深度学习网络的快速发展，这个设想已经被成功应用到图像识别、语音处理、推荐搜索等多个领域了！那组成这个“人造大脑”的基础，也就是神经元到底是什么样子的呢？
<div><strong>精选留言（28）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/24/ba/16/5b2c3246.jpg" width="30px"><span>Ultradatastream</span> 👍（50） 💬（2）<div>喆哥, 有个问题想请教下,  曾经有段时间比较关注Meta Learning(元学习), Meta Learning 可解决Deep Learning &quot;大量喂数据, 暴力迭代&quot;的&quot;诟病&quot;, Meta Learning算法如果结合部分深度推荐算法使用得当, 效果可能会好些, 工业界目前也有部分实现, 如阿里、华为等,   请问下Meta Learning会是未来推荐系统算法的&quot;一大爆点&quot;吗？</div>2021-01-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/7e/0c/9ba6ba1b.jpg" width="30px"><span>明月</span> 👍（30） 💬（2）<div>任务影响网络的架构，比如关注时间信息多一些，RNN就更适合，关注局部信息，CNN就更适合。网络不适合过深，容易过拟合，而且也会存在太深对任务不会有显著的提高，反而对资源有过多的浪费，比如，lstm在做语义理解的时候，通常只会最多两层</div>2020-11-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/1d/64/52a5863b.jpg" width="30px"><span>大土豆</span> 👍（26） 💬（5）<div>老师，我想问下，您有见过服务端或者客户端的同学，转型AI开发成功的例子吗？可不可以分享下，我们的订阅听众可能大多数都不是AI出身，都是服务端或者客户端半路出家AI的</div>2020-09-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/9b/93/0d0be616.jpg" width="30px"><span>何去何从</span> 👍（21） 💬（1）<div>请问老师画图使用什么工具？谢谢</div>2020-09-28</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erBkHFLUBpftqQlK5brd3EDaQFaEfYLfc9iaQrDNJv4eHeSRnSgE5vKnSibJvjUb5hJx5r5nOwa2bRw/132" width="30px"><span>w1sl1y</span> 👍（20） 💬（1）<div>https:&#47;&#47;github.com&#47;w1sl1y&#47;bpnn
之前用java写的一个BPNN的demo，新手可以看一下代码，加深反向神经网络的了解</div>2020-09-29</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ3q0LkadjOv4zicr7xQufgXyh8o1Usno8RZdeBPOqzsoH8DRiaMdYjs0OyEuTknHwHxfQ4AnBHdBCA/132" width="30px"><span>Geek_f676f3</span> 👍（13） 💬（1）<div>单从推荐领域来看，深度学习模型并非越深越好，模型的构建需要对数据及业务有深刻的洞察，没有更好的模型，只有更适合的模型</div>2021-02-28</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/ibbg35VbtSTXrcBE1AWgwXAHmKBjru5HzSzEUaxiaTeahQqDVxr4ZATHibn67aanoMmT4uG34PNRv3norpmOqjwMw/132" width="30px"><span>嘿人</span> 👍（10） 💬（1）<div>数据量大，特征多，就需要更深的神经网络来充分学习，如果数据量少，还用深层的神经网络，会容易出现过拟合，过拟合可以加正则项来对网络中的权值进行惩罚，但数据量是个根本性的问题。当然，收集了足够多的数据后，网络的深度和结构的设计也有关系。加了短连接的Resnet、DenseNet能搭建起更深的网络模型，其为梯度的反向传播提供了捷径，使得深层的神经网络不再难以训练。</div>2020-12-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/8e/1a/c463d0c7.jpg" width="30px"><span>Chris</span> 👍（10） 💬（1）<div>希望老师更新快一些，一周只等来了一节课，有点慢啊。</div>2020-09-28</li><br/><li><img src="" width="30px"><span>李@君</span> 👍（9） 💬（2）<div>不同应用领域(图片分类，NLP)的模型结构会有所不同。模型深度越深，就需要更多的训练数据，和更强大的算力。但是深度和预测结果是否成正相关呢。现在的模型是结构越来越复杂，参数越来越多。</div>2020-09-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/f5/8c/82fb5890.jpg" width="30px"><span>抱小星</span> 👍（8） 💬（1）<div>影响网络结构的，一个是问题规模的复杂程度，会影响深度学习神经网络的&quot;假设空间&quot;，如果参数的假设空间不够，无法完全拟合问题的解决方案，会造成信息瓶颈，这个是下限。第二个是算力、数据和工程资源限制，如果需要过多的数据去训练，那应该降低模型复杂度，又或者是算力和线上存储资源不足，也应该削减模型部分的开销。这个是上限。</div>2021-06-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/20/46/f4/93b1275b.jpg" width="30px"><span>Alan</span> 👍（8） 💬（2）<div>课后思考：
1、数据类别、数据维度与数据量大小影响深度网络结构，emmbeding是处理高维特征主要技术手段，又衍生出特征交叉等DeepFM等，后续算法优化都是基于（DNN与FM，线性与非线性），即是否有更好的（专家知识）算法学习到更多有用特征，最后甚至是业务需求拓展（Attention等时间序列机制）
2、不是的，越深越复杂，需要计算资源的需求更大不太符合工业需求的，我们需要通过优化评估一个算法在某个点达到收敛即可，截取在这个点所需的最优参数，即可解约时间成本与硬件成本！</div>2021-03-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/b4/99/79a21147.jpg" width="30px"><span>轩</span> 👍（6） 💬（2）<div>课后思考：
一般而言 deep is better，更省参数更强能力，例如两个3＊3conv和单层5＊5conv，但限于线上推断的响应时间要求，过深会影响推断时间。Google有论文是关于响应时间和点击率之间的关系，个人观点，控制在总时间200ms之内？
关于结构，由于推荐和NLP之间具有一点的相似性，都是序列预测，可以借鉴很多。rnn，attention，conv，诸如此类。</div>2021-01-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/de/3b/c15d2d9f.jpg" width="30px"><span>DAMIAN</span> 👍（5） 💬（2）<div>作业：
1. 我认为影响网络结构的最大因素是任务及数据，比如cv任务的数据多是H x W x C，这时候CNN就很合适。nlp任务的数据多是时序相关，所以RNN和Seq2Seq能work。
2. 网络不是越深越好，模型空间太大容易出现过拟合问题。此外网络层数深了可能会出现梯度弥散问题。并且网络层数多对存储和算力也会有更高要求。何凯明大神在ResNet论文中有更深入的讨论。</div>2021-04-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/22/8e/67/afb412fb.jpg" width="30px"><span>Sam</span> 👍（5） 💬（1）<div>我倒希望老师慢慢来，慢工出细活，这样老师的压力也没有大，我们也有时间加强练习和消化！~</div>2020-10-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/44/a4/7a45d979.jpg" width="30px"><span>IT蜗壳-Tango</span> 👍（4） 💬（3）<div>这节课的内容都懂，是不是就具备了入门的条件啦。希望后面的也能听懂。</div>2020-10-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/31/a1/0967d1cc.jpg" width="30px"><span>rookie</span> 👍（2） 💬（1）<div>问题的复杂程度决定假设空间维度，可获得有效数据量决定空间的参数量，即模型的的复杂度。问题的属性决定模型的底层结构，比如图像问题，一般选择CNN ,序列问题一般般选择LSTM等序列模型等等。实际工作环境中的算力、资源限制（时间、空间）决定你最终可以选择使用的模型的复杂度。
深度显然并不是越深越好，要与自己的问题与业务需求相匹配。一般越深的网络需要的数据也就越多，对算力要求就越高。其次深层次的网络结构可能出现梯度弥散的问题。
最终，模型的构建需要对数据和业务有较深的理解，并不是越复杂越卓越就越好。最终的结果一般是性能和成果的综合，既满足用户需求，又有较低的成本。
</div>2021-07-24</li><br/><li><img src="" width="30px"><span>Geek_0d974b</span> 👍（2） 💬（1）<div>请教两个问题：1 现行的DL包是不是只局限于有限种的activation function? 能不能用户自定义一个activation function? 2. 想知道业界有tensorflow这些DL包推出之前怎么implement DL？</div>2021-02-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/ca/d8/767d8e6e.jpg" width="30px"><span>强者自强</span> 👍（2） 💬（4）<div>老师，有个问题一直困扰了我很久，就是假如我们的模型有上亿个参数需要去优化，如果用前向传播的话，优化一轮参数，梯度下降是不是就需要进行上亿次，而反向传播只需要进行一次梯度下降就可以优化一轮参数呢？</div>2021-01-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/a9/98/c1841f3e.jpg" width="30px"><span>一天</span> 👍（2） 💬（2）<div>工业上数据特征规模、算力、平台架构都会影响深度学习的网络结构。深度学习模型的深度越深是不是越好，得做实验对比了，好像最近的图深度学习有实验说，深度越深效果反而变差了。</div>2020-10-09</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEKyGpC3C76tQAxDrw6Xaa6FibdVNyHBvicMQnX3iadbX5KGHaeaibvP2NOMukoWriaJJOfbP1Oo5FVzUAQ/132" width="30px"><span>想听家乡话</span> 👍（2） 💬（1）<div>老师，做推荐平台的不生产数据，只是数据的搬运工。推荐数据由算法同事去生产。做推荐系统平台的，有必要学习这门课吗？</div>2020-09-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/96/ee/9b21c199.jpg" width="30px"><span>咸</span> 👍（1） 💬（3）<div>老师好，我看文章内有很多数学，算法知识，有没有什么途径可以快速切入的，否则听起来有点跟不上节奏</div>2020-09-29</li><br/><li><img src="" width="30px"><span>Geek_8a732a</span> 👍（0） 💬（1）<div>任务和数据量会影响深度学习网络的结构吧。
不是越深越好，要是数据量少，模型很深，容易过拟合，需要加入正则化来优化；另外，模型多深，主要得考虑深的计算成本是否可以带来效果的显著提升，要做到成本和收益的平衡吧。</div>2021-08-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/64/e3/6e469d05.jpg" width="30px"><span>braincy</span> 👍（0） 💬（1）<div>老师，最近公司业务涉及到重新搭建画像系统，但目前还不太了解，请问这门课会涉及用户画像方面的知识吗？或者老师可以推荐一下怎么入手这个方向吗？</div>2021-07-31</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqHa1TniaV1VibauX4iayvICUiclCibKCt9DwCM0jr3FE73mOMfHfAT5250c9JE6YBQbYnnib7dv1d52bpQ/132" width="30px"><span>82</span> 👍（0） 💬（1）<div>楼主，“通过链式法则我们可以解决梯度逐层反向传播的问题。最终的损失函数到权重 w1的梯度是由损失函数到神经元 h1输出的偏导，以及神经元 h1输出到权重 w1的偏导相乘而来的 ” 这块不懂哦，实在是画不出来</div>2021-07-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/3b/5b/41/ac4cced1.jpg" width="30px"><span>_jordan</span> 👍（0） 💬（0）<div>模型太复杂，浪费算力（模型参数过多，计算和存储太非资源）和泛化能力（过拟合）变差。</div>2024-09-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/db/30/97ca195e.jpg" width="30px"><span>彦如</span> 👍（0） 💬（0）<div>不是越深越好，容易overfiing.</div>2024-01-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/67/98/d5e08eb7.jpg" width="30px"><span>yangchao</span> 👍（0） 💬（0）<div>思考题
数据量和计算复杂度影响神经网络的模型结构。
不是越深越好，一方面计算时间长，性价比不高 ；另一方面可能出现过拟合；</div>2022-02-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/27/6d/78/c4a02882.jpg" width="30px"><span>谁将新樽盛旧月</span> 👍（0） 💬（0）<div>五一假期前最后半天工作日来学习，希望五一掌握百分之70的内容。</div>2021-04-30</li><br/>
</ul>