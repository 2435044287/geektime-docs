你好，我是徐文浩。

不知道课程上到这里，你账户里免费的5美元的额度还剩下多少了？如果你尝试着完成我给的几个数据集里的思考题，相信这个额度应该是不太够用的。而ChatCompletion的接口，又需要传入大量的上下文信息，实际消耗的Token数量其实比我们感觉的要多。

而且，除了费用之外，还有一个问题是数据安全。因为每个国家的数据监管要求不同，并不是所有的数据，都适合通过OpenAI的API来处理的。所以，从这两个角度出发，我们需要一个OpenAI以外的解决方案。那对于没有足够技术储备的中小型公司来说，最可行的一个思路就是利用好开源的大语言模型。

## 在Colab里使用GPU

因为这一讲我们要使用一些开源模型，但不是所有人的电脑里都有一个强劲的NVidia GPU的。所以，我建议你通过Colab来运行对应的Notebook，并且注意，要把对应的运行环境设置成GPU。

![图片](https://static001.geekbang.org/resource/image/1c/21/1c0791bd5c1e088eeb527f2acb81a021.png?wh=1255x584)

1. 你先选择菜单栏里的Runtime，然后点击Change runtime type。

<!--THE END-->

![图片](https://static001.geekbang.org/resource/image/50/23/502a4baceab267e949957c6477bc5823.png?wh=1257x489)

2. 然后在弹出的对话框里，把Hardware accelerator换成GPU，然后点击Save就可以了。

只要用得不是太多，Colab的GPU是可以免费使用的。

## HuggingfaceEmbedding，你的开源伙伴
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg" width="30px"><span>Toni</span> 👍（6） 💬（1）<div>在第二讲中，用亚马逊提供的用户对一些食物评价的真实数据集进行了情感分析。当时为了避免重新调用 OpenAI 的 API 浪费钱，老师推荐使用已经计算好的含有 Embedding 的数据。用openai.embeddings_utils 中的 get_embedding (EMBEDDING_MODEL = &quot;text-embedding-ada-002&quot;)不仅费钱还耗时。我试着跑过100个数据，好像用了20分钟，花费也不少。

本节课中老师介绍了免费的 sentence_transformers 正好可以拿来用在情感数据分析上，
选用 model = SentenceTransformer(&#39;paraphrase-multilingual-mpnet-base-v2&#39;)。同样计算1000个数据的 embedding，速度很快，且无费用，适合练手。

测试结果如下:
                     precision    recall  f1-score   support
        negative      0.77      0.78      0.77       148
         positive      0.96      0.95      0.96       773
       accuracy                               0.93       921
    macro avg       0.86      0.87      0.86       921
weighted avg       0.93      0.93      0.93       921

为了对比，将第二讲中老师用 OpenAI 的方法得到的结果放在了这里:

                    precision    recall  f1-score   support
        negative      0.98      0.73      0.84       136
         positive      0.96      1.00      0.98       789
       accuracy                               0.96       925
    macro avg       0.97      0.86      0.91       925
weighted avg       0.96      0.96      0.96       925

使用的方法不用，结果也不同。OpenAI 的准确率更高。</div>2023-04-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/f5/80/baddf03b.jpg" width="30px"><span>zhihai.tu</span> 👍（5） 💬（1）<div>老师，想请教一下，我发现我用colab跑了程序，如果第二天再打开这个程序，相应的已经跑过得脚本，效果都失效了，比如pip安装过的都还原了，另外磁盘目录上生成的文件夹和文件也没了。想请问下如何解决这个问题呢？不然相当的麻烦。谢谢。</div>2023-04-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/ac/62/37912d51.jpg" width="30px"><span>东方奇骥</span> 👍（4） 💬（3）<div>老师，是不是要4080显卡才跑得动？单机能跑得动吗</div>2023-04-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/c1/32/778f18b9.jpg" width="30px"><span>胖子</span> 👍（2） 💬（5）<div>AttributeError                            Traceback (most recent call last)
&lt;ipython-input-54-086bfff09511&gt; in &lt;cell line: 8&gt;()
      6 Q: 你们的退货政策是怎么样的？
      7 &quot;&quot;&quot;
----&gt; 8 response, history = model.chat(tokenizer, question, history=[])
      9 print(response)

21 frames
&#47;usr&#47;local&#47;lib&#47;python3.9&#47;dist-packages&#47;google&#47;protobuf&#47;unknown_fields.py in &lt;module&gt;
     42 from google.protobuf.internal import api_implementation
     43 
---&gt; 44 if api_implementation._c_module is not None:  # pylint: disable=protected-access
     45   UnknownFieldSet = api_implementation._c_module.UnknownFieldSet  # pylint: disable=protected-access
     46 else:

AttributeError: module &#39;google.protobuf.internal.api_implementation&#39; has no attribute &#39;_c_module&#39;


搞不定</div>2023-04-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/36/9e/2e/e46ab171.jpg" width="30px"><span>川月</span> 👍（2） 💬（2）<div>使用这个开源模型获取的index怎么保存啊，使用之前的方法并不行，还有生成的index可以追加吗，不然每次有新数据的时候都要重新跑一边，或者可以使用数据库存储吗，希望老师讲解一下</div>2023-04-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2d/ec/19/38511eaf.jpg" width="30px"><span>༺ღ天口²º²²ღ༻</span> 👍（1） 💬（1）<div>老师，FAQ数据在哪里？</div>2023-05-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/f5/99/5bf198e3.jpg" width="30px"><span>孟健</span> 👍（1） 💬（1）<div>Meta最近也开源了大语言模型，好像更好一些？</div>2023-04-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/9d/2a/3e57b54a.jpg" width="30px"><span>地平线</span> 👍（0） 💬（2）<div>由于llama-index 升级，我使用的版本是0.6.8，修改了llama-index代码，程序运行没有报错，但是没有输出内容

from langchain.text_splitter import SpacyTextSplitter

llm_predictor = LLMPredictor(llm=CustomLLM())

text_splitter = CharacterTextSplitter(separator=&quot;\n\n&quot;, chunk_size=100, chunk_overlap=20)
parser = SimpleNodeParser(text_splitter=text_splitter)
documents = SimpleDirectoryReader(&#39;.&#47;drive&#47;MyDrive&#47;colab_data&#47;faq&#47;&#39;).load_data()
nodes = parser.get_nodes_from_documents(documents)

embed_model = LangchainEmbedding(HuggingFaceEmbeddings(
    model_name=&quot;sentence-transformers&#47;paraphrase-multilingual-mpnet-base-v2&quot;
))
service_context = ServiceContext.from_defaults(embed_model=embed_model, llm_predictor=llm_predictor)

dimension = 768
faiss_index = faiss.IndexFlatIP(dimension)

# index = GPTListIndex(nodes=nodes, faiss_index=faiss_index, service_context=service_context)
index = GPTListIndex(nodes=nodes, service_context=service_context)

from llama_index import QuestionAnswerPrompt

QA_PROMPT_TMPL = (
    &quot;{context_str}&quot;
    &quot;\n\n&quot;
    &quot;根据以上信息，请回答下面的问题：\n&quot;
    &quot;Q: {query_str}\n&quot;
    )
QA_PROMPT = QuestionAnswerPrompt(QA_PROMPT_TMPL)

query_engine = index.as_query_engine(
    retriever_mode=&quot;embedding&quot;, 
    verbose=True, 
    text_qa_template=QA_PROMPT,
)
response = query_engine.query(&quot;请问你们海南能发货吗？&quot;)
print(response)</div>2023-05-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/22/65/a2/88aca8f7.jpg" width="30px"><span>茶桁</span> 👍（0） 💬（1）<div>老师，“GPTFaissIndex”这个方法似乎没有了，替换的其他方法不知道是什么，怎么用。</div>2023-05-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/37/42/33/13b19797.jpg" width="30px"><span>horn</span> 👍（0） 💬（1）<div>Colab报错怎么回事呢
ImportError: cannot import name &#39;GPTFaissIndex&#39; from &#39;llama_index&#39; (&#47;usr&#47;local&#47;lib&#47;python3.10&#47;dist-packages&#47;llama_index&#47;__init__.py)</div>2023-05-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/e4/8b/8a0a6c86.jpg" width="30px"><span>haha</span> 👍（0） 💬（1）<div>PaLM2呢，今天被公众号刷屏了</div>2023-05-11</li><br/><li><img src="" width="30px"><span>Geek_9znsx3</span> 👍（0） 💬（1）<div>在colab运行11_colab_chatglm_opensource.ipynb，安装python包时报错，protobuf包版本冲突，请问这个怎么解决？从报错信息看是由于tensorflow-2.12.0依赖protobuf3.20.3，但是icetk-0.0.7依赖 protobuf-3.18.3
Installing collected packages: protobuf, icetk
  Attempting uninstall: protobuf
    Found existing installation: protobuf 3.20.3
    Uninstalling protobuf-3.20.3:
      Successfully uninstalled protobuf-3.20.3
ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
........
tensorflow 2.12.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,&lt;5.0.0dev,&gt;=3.20.3, but you have protobuf 3.18.3 which is incompatible.
tensorflow-datasets 4.9.2 requires protobuf&gt;=3.20, but you have protobuf 3.18.3 which is incompatible.
tensorflow-hub 0.13.0 requires protobuf&gt;=3.19.6, but you have protobuf 3.18.3 which is incompatible.
tensorflow-metadata 1.13.1 requires protobuf&lt;5,&gt;=3.20.3, but you have protobuf 3.18.3 which is incompatible.
Successfully installed icetk-0.0.7 protobuf-3.18.3</div>2023-05-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/5a/82/4d55f0b7.jpg" width="30px"><span>李文龙</span> 👍（0） 💬（3）<div>请问使用 llama_index 0.6.1 版本，使用 Faiss，代码如下，有报错。
import faiss
from llama_index.vector_stores import FaissVectorStore
from llama_index import GPTVectorStoreIndex, StorageContext

dimension = 768
faiss_index = faiss.IndexFlatIP(dimension)
storage_context = StorageContext.from_defaults(
    vector_store=FaissVectorStore(faiss_index)
)
print(len(nodes))
index = GPTVectorStoreIndex(nodes, storage_context=storage_context)

query_engine = index.as_query_engine(
    retriever_mode=&quot;embedding&quot;,
    verbose=True,
    service_context = service_context,
)

报错：
&#47;usr&#47;local&#47;lib&#47;python3.10&#47;dist-packages&#47;faiss&#47;__init__.py in replacement_add(self, x)
    212 
    213         n, d = x.shape
--&gt; 214         assert d == self.d
    215         self.add_c(n, swig_ptr(x))
    216 </div>2023-05-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/36/82/5b/df97e03c.jpg" width="30px"><span>Santiago</span> 👍（0） 💬（4）<div>老师我想问一下 我用colab报错 
KeyError: &#39;-1&#39;
这是咋回事呀，还有就是我用3060的显卡6G，直接爆显存了</div>2023-04-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/36/82/5b/df97e03c.jpg" width="30px"><span>Santiago</span> 👍（0） 💬（1）<div>RuntimeError: Failed to import transformers.models.t5.configuration_t5 because of the following error (look up to see its traceback):
Failed to import transformers.onnx.config because of the following error (look up to see its traceback):
DLL load failed while importing _imaging: 找不到指定的模块。</div>2023-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/66/73/fd1e37a2.jpg" width="30px"><span>良辰美景</span> 👍（0） 💬（1）<div>老师， 问一个工程上的问题， 像这种要求大量计算资源AI系统， 在工程上如何能做到可用呢， 需要购买大量的GPU这个可以想到。 购买的这些芯片如何能够串联形成类似“云”的能力？ 这个是各个公司需要有自己的解决方案还是业界已经有成熟的解决方案了？ </div>2023-04-18</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTISHN4HwTsOicDUzB1jyzlxzriaI3S7tAfoPzicSfuTbxLxRjkCic2eBwRWxJTrwTpiaYP8Hg8vqWgNE2w/132" width="30px"><span>Geek_3d7708</span> 👍（0） 💬（1）<div>dimension = 768faiss_index = faiss.IndexFlatIP(dimension)index = index=GPTFaissIndex(nodes=nodes,faiss_index=faiss_index, service_context=service_context)

这个 index  结果怎么保存？ 我折腾2天了都不行，没有save，没index , 老师能告诉我怎么保存吗？</div>2023-04-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/88/df/e7bf1bdb.jpg" width="30px"><span>银河系</span> 👍（0） 💬（3）<div>openai.api_key = os.environ.get(&quot;OPENAI_API_KEY&quot;)

logging.basicConfig(stream=sys.stdout, level=logging.INFO)
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))

# dimensions of text-ada-embedding-002
d = 768
faiss_index = faiss.IndexFlatL2(d)
text_splitter = CharacterTextSplitter(separator=&quot;\n\n&quot;, chunk_size=100, chunk_overlap=20)
parser = SimpleNodeParser(text_splitter=text_splitter)
documents = SimpleDirectoryReader(&#39;.&#47;data&#47;test&#39;).load_data()
nodes = parser.get_nodes_from_documents(documents)
llm_predictor = LLMPredictor(llm=ChatOpenAI(temperature=0, model_name=&quot;gpt-3.5-turbo&quot;, max_tokens=1024))
embed_model = LangchainEmbedding(HuggingFaceEmbeddings(
        model_name=&quot;sentence-transformers&#47;paraphrase-multilingual-mpnet-base-v2&quot;
    ))
service_context = ServiceContext.from_defaults(llm_predictor=llm_predictor, embed_model=embed_model)
index = GPTFaissIndex(nodes=nodes, faiss_index=faiss_index, service_context=service_context)
# save index to diskIM5最有特色的使用场景
index.save_to_disk(
    &#39;index_faiss.json&#39;,
    faiss_index_save_path=&quot;index_faiss_core.index&quot;
)

# load index from disk
index = GPTFaissIndex.load_from_disk(&#39;index_faiss.json&#39;,faiss_index_save_path=&quot;index_faiss_core.index&quot;)
response = index.query(&quot;xxxxx&quot;,mode=QueryMode.EMBEDDING,verbose=True)
print(response)
这个代码报错呢</div>2023-04-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/88/df/e7bf1bdb.jpg" width="30px"><span>银河系</span> 👍（0） 💬（1）<div>faiss保存在本地而且使用自己的embedding的可否给个demo？</div>2023-04-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/60/ad/03351e6e.jpg" width="30px"><span>xbc</span> 👍（0） 💬（4）<div>```

import openai, os
import faiss
from llama_index import SimpleDirectoryReader, LangchainEmbedding, GPTFaissIndex, ServiceContext
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from llama_index.node_parser import SimpleNodeParser

openai.api_key = &quot;&quot;

text_splitter = CharacterTextSplitter(separator=&quot;\n\n&quot;, chunk_size=100, chunk_overlap=20)
parser = SimpleNodeParser(text_splitter=text_splitter)
documents = SimpleDirectoryReader(&#39;.&#47;data&#47;faq&#47;&#39;).load_data()
nodes = parser.get_nodes_from_documents(documents)

embed_model = LangchainEmbedding(HuggingFaceEmbeddings(
    model_name=&quot;sentence-transformers&#47;paraphrase-multilingual-mpnet-base-v2&quot;
))
service_context = ServiceContext.from_defaults(embed_model=embed_model)

dimension = 768
faiss_index = faiss.IndexFlatIP(dimension)
index = GPTFaissIndex(nodes=nodes,faiss_index=faiss_index, service_context=service_context)
```

这段代码会报错，老师的环境里面可能有了 env OPENAI_API_KEY.

我这里放的py文件执行：
  Did not find openai_api_key, please add an environment variable `OPENAI_API_KEY` which contains it, or pass  `openai_api_key` as a named parameter. (type=value_error)

</div>2023-04-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg" width="30px"><span>Toni</span> 👍（0） 💬（2）<div>将第二讲情感分析中的这段代码

good_restraurant = get_embedding(&quot;这家餐馆太好吃了，一点都不糟糕&quot;)
bad_restraurant = get_embedding(&quot;这家餐馆太糟糕了，一点都不好吃&quot;)
good_score = get_score(good_restraurant)
bad_score = get_score(bad_restraurant)
print(&quot;好评餐馆的评分 : %f&quot; % (good_score))
print(&quot;差评餐馆的评分 : %f&quot; % (bad_score))

用sentence_transformers 替代openai.embeddings_utils 又跑了一下
在选用 model = SentenceTransformer(&#39;paraphrase-multilingual-mpnet-base-v2&#39;) 的情况下
得到的如下结果
好评例子的评分 : 0.215761
差评例子的评分 : -0.361450
比 openai.embeddings_utils import cosine_similarity, get_embedding
EMBEDDING_MODEL = &quot;text-embedding-ada-002&quot; 的结果更好些
好评例子的评分 : 0.062719
差评例子的评分 : -0.074591</div>2023-04-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/60/ad/03351e6e.jpg" width="30px"><span>xbc</span> 👍（0） 💬（1）<div>WARNING:root:Created a chunk of size 130, which is longer than the specified 100

一大堆这些，不过可以忽略。

最好改用： text_splitter = SpacyTextSplitter(pipeline=&quot;zh_core_web_sm&quot;, chunk_size = 2048)</div>2023-04-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/02/1c/a0aba121.jpg" width="30px"><span>mao</span> 👍（0） 💬（1）<div>ChatGLM 是不是可以通过对QA数据集进行微调，得到一个专用的问答模型。</div>2023-04-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c2/72/fb00cd31.jpg" width="30px"><span>BashBIGBANG</span> 👍（0） 💬（1）<div>llama 两个 l 只读一个l 的音</div>2023-04-06</li><br/><li><img src="" width="30px"><span>Geek_78a551</span> 👍（1） 💬（0）<div>更新到llma-index 0.11了, 代码全不能运行</div>2024-09-20</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoWZh2ibhHevq5ndQFMK0Z28fO0bFVd3WxslfkHUlX5YPMPhSq0dqyn4F1ozeLcf8wHGfwG6EiaV5Qw/132" width="30px"><span>Geek_6bdac7</span> 👍（1） 💬（0）<div>【解决】colab运行模式改为gpu，可以pip安装 pip install faiss-gpu  


老师请问下colab上faiss怎么安装，试了不同方法还是在import faiss时导入报错，无faiss模块 
!wget  https:&#47;&#47;anaconda.org&#47;pytorch&#47;faiss-gpu&#47;1.2.1&#47;download&#47;linux-64&#47;faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2
!tar xvjf faiss-gpu-1.2.1-py36_cuda9.0.176_1.tar.bz2
!cp -r lib&#47;python3.6&#47;site-packages&#47;* &#47;usr&#47;local&#47;lib&#47;python3.6&#47;dist-packages&#47;
!pip install mkl</div>2023-06-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg" width="30px"><span>aoe</span> 👍（1） 💬（0）<div>看完后我还是用显卡玩游戏吧</div>2023-04-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/69/ad/608188c2.jpg" width="30px"><span>4thirteen2one</span> 👍（0） 💬（0）<div>GPTListIndex 找不到额</div>2025-01-22</li><br/><li><img src="" width="30px"><span>Geek_78a551</span> 👍（0） 💬（0）<div>我把你github上的代码下载下来执行后, 会请求gpt, 跟你说的不符合, 报错信息是api_key错误</div>2024-09-21</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/4EspenNOwzy5VI6PiaT5nDbibhGa3utic5UTTv42ib8MCj0lFv83WHtcCfxxiadbp95XpdiafazhmHfYVstmUGKvVBgQ/132" width="30px"><span>学习中的安老师</span> 👍（0） 💬（0）<div>写的代码一点注释都不写，让人怎么看</div>2024-05-19</li><br/>
</ul>