你好，我是徐文浩。

在之前介绍llama-index和LangChain的几讲里面，我们学习了如何将大语言模型和你自己的知识库组合到一起来解决问题。这个方法中，我们不需要对我们使用的模型做任何调整，而是通过将我们的数据用Embedding向量索引起来，然后在使用的时候查询索引来解决问题。

不过，其实我们也完全可以利用我们自己的数据，创建一个新的模型来回答问题。这个方法，就是OpenAI提供的模型微调（Fine-tune）功能。这也是我们要探讨的大语言模型的最后一个主题。

## 如何进行模型微调？

模型微调，是因为无论是ChatGPT还是GPT-4都不是全知全能的AI。在很多垂直的领域，它的回答还是常常会出错。其中很大一部分原因，是它也缺少特定领域的训练数据。而如果我们有比较丰富的垂直领域的数据，那么就可以利用这些数据来“微调”一个特别擅长这个垂直领域的模型。在这个模型“微调”完成之后，我们就可以直接向模型提问了。而不用再像之前使用llama-index或者LangChain那样，先通过Embedding来查询相关资料，然后把查找到的资料也一并提交给OpenAI来获得所需要的答案。

OpenAI模型微调的过程，并不复杂。你只需要把数据提供给OpenAI就好了，对应的整个微调的过程是在云端的“黑盒子”里进行的。需要提供的数据格式是一个文本文件，每一行都是一个Prompt，以及对应这个Prompt的Completion接口会生成的内容。
<div><strong>精选留言（22）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/17/ca/58/6fe1854c.jpg" width="30px"><span>金</span> 👍（6） 💬（2）<div>只要能加载微调后的模型，是不是就可以不用openai了？</div>2023-04-18</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ5sXrTGCq7nlvg8bBzjWtgFU0bXnSiangWBF6Uss3lfnyHeEaplKDBaWWZQNMvhQVxLXyrEEw7rNw/132" width="30px"><span>weiwei</span> 👍（3） 💬（1）<div>徐老师，我们AI部门主要做 “异常数据检测”业务。就是离线把金融的异常数据捕获出来。
之前这块是用规则引擎+人工审核来做的，人力成本挺大。

这块业务，理论上能用fine tunning模型来做吗？</div>2023-04-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/6a/f2/db90fa96.jpg" width="30px"><span>Oli张帆</span> 👍（2） 💬（1）<div>从成本的角度看，微调是不是更适合用来做意图分析的分类任务？我这样想的理由是，因为分类任务相对简单可以用比较便宜的模型来微调，第二，训练好之后，每次调用不必发大量context的提示，这样消耗的token会少很多。请老师指正。</div>2023-04-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/1b/15/75c16cb5.jpg" width="30px"><span>朱朱</span> 👍（1） 💬（3）<div>老师，请教下，微调之后的模型在 openai 的云端会存在多久，我直接用您微调后的模型，提示无法找到了</div>2023-05-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/67/58/960b71b7.jpg" width="30px"><span>蔡雪钧</span> 👍（1） 💬（1）<div>如果用 A，B，C三个垂直领域的数据做模型微调，那么微调后的模型是同时增强了A，B，C三块的能力么？比如把数理化的题喂给大模型，后面大模型是不是数理化整体都会变强？</div>2023-05-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/36/95/50/01199ae9.jpg" width="30px"><span>一叶</span> 👍（1） 💬（2）<div>老师,问下,Langchain的流式生成似乎不支持迭代的显示方式,好像是通过callback来实现,但是这样在开发web的时候似乎就没办法做成应用了</div>2023-04-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/5f/81/1c614f4a.jpg" width="30px"><span>stg609</span> 👍（0） 💬（1）<div>stop到底是怎么发挥作用的？一遇到stop的字符就停止生成了？如果我们喂给它的csv数据中就有很多. 会怎么样？</div>2023-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/36/9d/94/c606d61d.jpg" width="30px"><span>莱森</span> 👍（0） 💬（1）<div>可以请教一下老师如果用了链式调用，怎么样才能更好地实现流式生成呢？</div>2023-04-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/19/e1/a7fbc963.jpg" width="30px"><span>Warren</span> 👍（0） 💬（1）<div>在这一讲生成数据的时候，我们一条条去生成故事特别慢，而且每个组合的故事都要生成三条，特别消耗 Token。你想想这部分的代码，如何根据之前学到的内容优化一下呢？
是不是可以把completion接口的n设为3，一次返回3个故事，可以减少提交的token？</div>2023-04-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/f5/80/baddf03b.jpg" width="30px"><span>zhihai.tu</span> 👍（0） 💬（1）<div>能不能联动tts，把故事实时播报出来。</div>2023-04-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/30/ef/2d/757bb0d3.jpg" width="30px"><span>Toni</span> 👍（8） 💬（0）<div>模型的微调(GPT fine-tuning)本质上就是将 GPT 过于宽泛化的处理调窄到某个特殊的范围，而这个在GPT大环境下的特殊范围需要使用满足一定条件的&#39;数据集&#39;来打造，可能还需要反复打造。

读过并记住了全部牛津大字典，莎翁作品的 GPT，实力摆在那儿了，能聊，上知天文下晓地理，侃功盖世。但使用好 GPT 的超能力并不是一件容易事，尤其是当你并不满足于它的夸夸其谈，那么就微调吧。

微调容易吗? 看怎么说了，用于微调的代码已经是简单到不能再简单了，不会编程照样上手，但要达到一特定目的，就不那么容易了。比如: 让 GPT 用鲁迅的笔法来生成一篇短文来抨击环保中的问题。难在以鲁迅的口吻。

那就微调吧，喂给 GPT 大量鲁迅写的文章，让 GPT 再学习。本来想借老师这课讲故事的例子来试试将故事员变成鲁迅，但短时间内是无法完成了。

既然无法微调，那就试试 GPT 中的 Prompt，提示词的本质就是收窄范围，与 fine-tuning 有异曲同工之妙。用 OpenAI 的 Completion 在 engine=&quot;text-davinci-003&quot; 的驱动下，生成了下面这段文例:

&quot;垃圾分类，一种&#39;新时尚&#39;，连阿贵都在谈论它。每个人似乎都很努力，然而，在许多人的心中，它只不过是一种无聊的行为，他们只是为了显得出色而做。

只有少数真正的尝试改变者，多数人只是在虚情假意下，把它当成一种&#39;潮流&#39;。

追求&#39;时尚&#39;的&#39;环保&#39;是空洞的。与其虚情假意，不如从自身出发，努力去改变。&quot;

还是太平淡，太啰嗦了。如何给出提示词使它更像鲁迅? 但也许鲁迅喜欢: &quot;你们的白话文讲得比我好。&quot;

在无法微调时就尝试一下 Prompt。</div>2023-04-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/c5/52/63008fc7.jpg" width="30px"><span>xuwei</span> 👍（2） 💬（0）<div>openai微调太贵了，使用微调模型也太贵了。散了</div>2023-08-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/55/4a/8a841200.jpg" width="30px"><span>ACK</span> 👍（1） 💬（1）<div>我家孩子喜欢听恐龙大战奥特曼的故事。
用 GPT-4 来直接生成吧，故事太老套，每次生成的情节很相近。还要人工来润色。</div>2023-04-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/30/bb/2e/3e0bd0e1.jpg" width="30px"><span>SlgGrlGwy</span> 👍（0） 💬（0）<div>Error: Invalid response object from API: &#39;{&quot;message&quot;:&quot;Invalid URL (GET &#47;v1&#47;files&#47;data&#47;prepared_data_prepared.jsonl)&quot;,&quot;type&quot;:&quot;invalid_request_error&quot;,&quot;param&quot;:null,&quot;code&quot;:null}&#39; (HTTP response code was 404) (HTTP status code: 404) 报这个错，怎么解决呢</div>2024-01-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/22/28/40/82d748e6.jpg" width="30px"><span>小理想。</span> 👍（0） 💬（0）<div>老师，为什么我的没有微调出模型，也没有报错，但是查看列表没有创建出模型
subprocess.run(&#39;openai tools fine_tunes.prepare_data --file data&#47;prepared_data.csv --quiet&#39;.split())</div>2023-10-02</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/nLTf90gG8icMt34D9KgqnLWRo6Fia6EwOd8v8jh1QyHlw8C959TeVeb3S9X9s2KrqK7CDTiblrO1axmFO61pecaLA/132" width="30px"><span>Geek_0b68a4</span> 👍（0） 💬（0）<div>执行subprocess.run(&#39;openai api fine_tunes.list&#39;.split())后只输出了CompletedProcess(args=[&#39;openai&#39;, &#39;api&#39;, &#39;fine_tunes.list&#39;], returncode=0)  没有JSON，看不到微调模型代码，单独调用了下response = openai.FineTune.list()，输出response，看到training_files节点信息都有的，但是最终的fine_tuned_model字段是null的</div>2023-08-23</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaELVtQAW8IIDLKcn36XM9noEfKuAKpJQrwruJzXeibDfmibIiawicj5vaoflct0LuTAiaKcmCY3gK9MknEw/132" width="30px"><span>远方</span> 👍（0） 💬（0）<div>我微调好的模型提示不存在？怎么回事</div>2023-08-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/75/b9/6fbd82b2.jpg" width="30px"><span>Trueno</span> 👍（0） 💬（0）<div>这个能和自己的知识库结合吗，如果是更小的领域，那这种方式prompt就要包含很多数据了吧</div>2023-08-20</li><br/><li><img src="" width="30px"><span>Geek_3caf06</span> 👍（0） 💬（1）<div>subprocess.run(&#39;openai api fine_tunes.create --training_file data&#47;prepared_data_prepared.jsonl --model curie --suffix &quot;ultraman&quot;&#39;.split())
这一步微调运行要多久，我的跑了6个多小时了还没跑完，是不哪里不正常？</div>2023-07-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/d9/ce/4528cb4b.jpg" width="30px"><span>呼呼</span> 👍（0） 💬（0）<div>后面的这几讲都是针对openai的chatgpt了，如果使用其它如chatglm该怎么做呢？</div>2023-06-27</li><br/><li><img src="" width="30px"><span>Geek_75e474</span> 👍（0） 💬（0）<div>老师说的ultraman_stories.csv在哪里可以获取</div>2023-06-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/71/25/e9bad0b3.jpg" width="30px"><span>树静风止</span> 👍（0） 💬（0）<div>面向模型编程</div>2023-04-17</li><br/>
</ul>