你好，我是黄佳，欢迎来到LangChain实战课！

从今天开始，我要用4节课的篇幅，带着你设计两个有趣而又实用的应用程序。设计这两个应用程序的目的，是为了让你能够把LangChain中的各个组件灵活地组合起来，融会贯通，并以此作为启发，在你熟悉的业务场景中，利用LangChain和LLM的能力，开发出更多、更强大的效率工具。

第一个应用程序，是用LangChain创建出一个专属于“易速鲜花”的网络人脉工具。光这么说，有些模糊，这个人脉工具长啥样？有些啥具体功能？

动手之前，让我先给你把这个所谓“人脉”工具的能力和细节说清楚。

## “人脉工具”项目说明

**项目背景**：易速鲜花电商网络自从创建以来，通过微信、抖音、小红书等自媒体宣传推广，短期内获得了广泛流量展示。目前，营销部门希望以此为契机，再接再厉，继续扩大品牌影响力。经过调研，发现很多用户会通过微博热搜推荐的新闻来购买鲜花赠送给明星、达人等，因此各部门一致认为应该联络相关微博大V，共同推广，带动品牌成长。

然而，发掘并选择适合于“鲜花推广”的微博大V有一定难度。营销部门员工表示，这个任务比找微信、抖音和小红书达人要难得多。他们都希望技术部门能够给出一个“人脉搜索工具”来协助完成这一目标。
<div><strong>精选留言（6）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/ff/67/6ffe3a52.jpg" width="30px"><span>马里奥的马里奥</span> 👍（2） 💬（2）<div>2个问题
1.虽然修改了获取link的方式，依然是会有错误，在我这里解析到的是 https:&#47;&#47;weibo.com&#47;p&#47;xxx后的这个xx数字；
2.我尝试修改提示词，只搜索粉丝超过一百万的账号，似乎也不生效。</div>2023-12-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/d4/1b/6444e933.jpg" width="30px"><span>Liberalism</span> 👍（0） 💬（1）<div>在爬取微博用户资料时报 400 错误，请问是哪里出了问题？？？？

def scrape_weibo(url: str):
    &quot;&quot;&quot;爬取相关鲜花服务商的资料&quot;&quot;&quot;
    headers = {
        &quot;User-Agent&quot;: &quot;Mozilla&#47;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#47;537.36 (KHTML, like Gecko) &quot;
                      &quot;Chrome&#47;89.0.4389.82 Safari&#47;537.36&quot;,
        &quot;Referer&quot;: &quot;https:&#47;&#47;weibo.com&quot;}
    cookies = {
        &quot;cookie&quot;: &#39;&#39;&#39;SINAGLOBAL=6620500101466.929.1684124696145; 
        ULV=1701318517344:5:1:1:2994044278409.513.1701318517342:1695626334231; 
        SUB=_2A25IbH_LDeRhGedJ71EX9C3Kwz6IHXVrAP0DrDV8PUNbmtAGLWP8kW9NVhncgwwKDAJC-BEIEyWCj9aAZiYRqGGn; 
        SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9WF1hJoCEpSf.bqAJzfD-UMO5JpX5KzhUgL.Fo2NShecShec1hz2dJLoI7peIgiLMJ8jIPS_qgRt; 
        ALF=1732854554; XSRF-TOKEN=Dr6hVUuVr5JfuRn3NHntHjk7; 
        WBPSESS=qWBqMfNAAnlnO3TmyuUMG1qvHg86Rz2Zv7YHVRzN1MJAsJSyBhxx0_AUvWsjCUhaTWJpEmAC3UJ6u4OKi_zznpkRnRQ8ciUPXXDldaaw58i1fvBUm_1oDKnjo6sGr9qeK-zdbnLVltKplYXJysV88A==&#39;&#39;&#39;
    }
    response = requests.get(url, headers=headers, cookies=cookies)

    time.sleep(3)  # 加上3s 的延时防止被反爬
    return response.text</div>2023-12-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/d4/1b/6444e933.jpg" width="30px"><span>Liberalism</span> 👍（0） 💬（1）<div>def scrape_weibo(url: str):
    &quot;&quot;&quot;爬取相关鲜花服务商的资料&quot;&quot;&quot;
    headers = {
        &#39;Accept&#39;: &#39;text&#47;html,application&#47;xhtml+xml,application&#47;xml;q=0.9,image&#47;webp,*&#47;*;q=0.8&#39;,
        &#39;Cache-Control&#39;: &#39;max-age=0&#39;,
        &#39;Connection&#39;: &#39;keep-alive&#39;,
        &#39;Referer&#39;: &#39;http:&#47;&#47;www.baidu.com&#47;&#39;,
        &#39;User-Agent&#39;: &#39;Mozilla&#47;5.0 (Windows NT 6.1; WOW64) AppleWebKit&#47;537.36 (KHTML, like Gecko)&#39;
    }
    cookies = {
        &quot;cookie&quot;: &#39;&#39;&#39;SINAGLOBAL=6620500101466.929.1684124696145; 
        ULV=1701318517344:5:1:1:2994044278409.513.1701318517342:1695626334231; 
        SUB=_2A25IbH_LDeRhGedJ71EX9C3Kwz6IHXVrAP0DrDV8PUNbmtAGLWP8kW9NVhncgwwKDAJC-BEIEyWCj9aAZiYRqGGn; 
        SUBP=0033WrSXqPxfM725Ws9jqgMF55529P9D9WF1hJoCEpSf.bqAJzfD-UMO5JpX5KzhUgL.Fo2NShecShec1hz2dJLoI7peIgiLMJ8jIPS_qgRt; 
        ALF=1732854554; XSRF-TOKEN=Dr6hVUuVr5JfuRn3NHntHjk7; 
        WBPSESS=qWBqMfNAAnlnO3TmyuUMG1qvHg86Rz2Zv7YHVRzN1MJAsJSyBhxx0_AUvWsjCUhaTWJpEmAC3UJ6u4OKi_zznpkRnRQ8ciUPXXDldaaw58i1fvBUm_1oDKnjo6sGr9qeK-zdbnLVltKplYXJysV88A==&#39;&#39;&#39;
    }
    response = requests.get(url, headers=headers, cookies=cookies)

    time.sleep(3)  # 加上3s 的延时防止被反爬
    return response.text


爬取数据这里一直报错  400 </div>2023-12-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/62/b8/0e1b655e.jpg" width="30px"><span>fireshort</span> 👍（0） 💬（2）<div>黄老师，这里的Agent感觉没有发挥作用，没有太多智能，LLM就加了“微博”去搜索。
ID = agent.run(prompt_template.format_prompt(flower=flower_type))
改成
ID = get_UID(flower_type+&quot; 微博&quot;)
得到一样的结果。


</div>2023-11-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/eb/37/a2f4c9f8.jpg" width="30px"><span>starj</span> 👍（0） 💬（2）<div>github上没有代码？</div>2023-10-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/ba/1f/7551f182.jpg" width="30px"><span>卓丁</span> 👍（0） 💬（1）<div>我遇到一个报错：
    raise JSONDecodeError(&quot;Expecting value&quot;, s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 2 column 3 (char 3)

看着好像是 json.loads解析失败了。
进一步看报错栈，是报 400 的状态码。

于是我尝试将get_data方法所请求的url打印出来了一下。

```
# 根据UID构建URL爬取信息
def get_data(id):
    url = &quot;https:&#47;&#47;weibo.com&#47;ajax&#47;profile&#47;detail?uid={}&quot;.format(id)
    print(&quot;url-&gt;&quot;,url)
    html = scrape_weibo(url)
    print(html)
    response = json.loads(html)

    return response
```

结果如下：

&gt; Finished chain.
这位鲜花大V的微博ID是 100808
url-&gt; https:&#47;&#47;weibo.com&#47;ajax&#47;profile&#47;detail?uid=100808
&lt;h2&gt;400 Bad Request&lt;&#47;h2&gt;
Traceback (most recent call last):
  File &quot;&#47;Users&#47;bawenmao&#47;PycharmProjects&#47;socializer_v0&#47;findbigV.py&quot;, line 23, in &lt;module&gt;
    person_info = get_data(UID)
                  ^^^^^^^^^^^^^
  File &quot;&#47;Users&#47;bawenmao&#47;PycharmProjects&#47;socializer_v0&#47;tools&#47;scraping_tool.py&quot;, line 26, in get_data
    response = json.loads(html)
               ^^^^^^^^^^^^^^^^
  File &quot;&#47;Library&#47;Frameworks&#47;Python.framework&#47;Versions&#47;3.11&#47;lib&#47;python3.11&#47;json&#47;__init__.py&quot;, line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;&#47;Library&#47;Frameworks&#47;Python.framework&#47;Versions&#47;3.11&#47;lib&#47;python3.11&#47;json&#47;decoder.py&quot;, line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File &quot;&#47;Library&#47;Frameworks&#47;Python.framework&#47;Versions&#47;3.11&#47;lib&#47;python3.11&#47;json&#47;decoder.py&quot;, line 355, in raw_decode
    raise JSONDecodeError(&quot;Expecting value&quot;, s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)



是不是所请求的那个url 本身不对；
请教下老师，这是哪里的问题；</div>2024-02-21</li><br/>
</ul>