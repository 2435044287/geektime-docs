你好，我是吴磊。

上一讲，我们探讨了“大表Join小表”场景的调优思路和应对方法。那么，除了大表Join小表的场景，数据分析领域有没有“大表Join大表”的场景呢？确实是有的，它指的是参与Join的两张体量较大的事实表，尺寸相差在3倍以内，且全部无法放进广播变量。

但是通常来说，在数据分析领域，用一张大表去关联另一张大表，这种做法在业内是极其不推荐的。甚至毫不客气地说，“大表Join大表”是冒天下之大不韪，犯了数据分析的大忌。如果非要用“大表Join大表”才能实现业务逻辑、完成数据分析，这说明数据仓库在设计之初，开发者考虑得不够完善、看得不够远。

不过，你可能会说：“我刚入职的时候，公司的数仓就已经定型了，这又不是我的锅，我也只能随圆就方。”为了应对这种情况，今天这一讲我们就来说说，当你不得不面对“大表Join大表”的时候，还有哪些调优思路和技巧。

要应对“大表Join大表”的计算场景，我们主要有两种调优思路。**一种叫做“分而治之”，另一种我把它统称为“负隅顽抗”。**今天这一讲，我们先来说说“分而治之”，“负隅顽抗”我们留到下一讲再去展开。

值得一提的是，即便你不需要去应对“大表Join大表”这块烫手的山芋，“分而治之”与“负隅顽抗”所涉及的调优思路与方法，也非常值得我们花时间去深入了解，因为这些思路与方法的可迁移性非常强，学习过后你会发现，它们完全可以拿来去应对其他的应用场景。
<div><strong>精选留言（13）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/13/3a/96/9fddfb4a.jpg" width="30px"><span>赵鹏举</span> 👍（4） 💬（1）<div>1 优化过程是scalla写的，纯SQL有没有实现吗？
2 spark版本为2.4.3有办法达到类似效果吗？</div>2021-12-21</li><br/><li><img src="" width="30px"><span>licl1008</span> 👍（3） 💬（1）<div>老师 现实中用orderID作为分区键 是不是分区会太多 感觉订单ID基数很大</div>2021-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/11/20/9f31c4f4.jpg" width="30px"><span>wow_xiaodi</span> 👍（2） 💬（4）<div>老师，对于评论区里的说到的colocated joins，可否简单说下运行机制？</div>2021-08-14</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eo2GMhevabZrjINs2TKvIeGC7TJkicNlLvqTticuM5KL8ZN80OC2CnrsUyzPcZXO4uptj4Q1S4jT2lQ/132" width="30px"><span>jerry guo</span> 👍（2） 💬（2）<div>如果外表是bucket表，内表也是相同的bucket表，那么也是可以避免多次扫描外表的。这种情况说不定币shj更好，因为不需要shuffle</div>2021-05-17</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ2tyVlQiaqp5kEOf1LlZB6nJPicN8lzcEkAsSEDmicvib8T3xUEcDibRichLrh3Qiclo3UyuAhhKNGQxGmg/132" width="30px"><span>威猛的小老虎</span> 👍（1） 💬（2）<div>笛卡尔积 如何优化呢</div>2021-05-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/22/8e/67/afb412fb.jpg" width="30px"><span>Sam</span> 👍（0） 💬（2）<div>问题回答：
除了shuffle，想不出其他办法....哭~</div>2021-07-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/81/45/37db494c.jpg" width="30px"><span>空格</span> 👍（0） 💬（2）<div>老师，demo中按照date循环查询的sql直接使用spark sql执行可以实现外边扫描一次嘛？</div>2021-07-06</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/cojb2AA3eM620kb7hj7YoG8k56TKsdCmVletmYKYwibickH5Ced8UyxicpY9icZEM2ZTcqyUaEk2PRmH1FVLtGTggw/132" width="30px"><span>orangelin</span> 👍（0） 💬（2）<div>虽然orderid作为分区键有点太多，是否可以考虑按照orderid的数据特征，比如id是字母结尾亦或者是数字结尾，按这个列去做分区是可以减少一定的分区数，举个例子，我的分区关联条件是 数字id的尾号，那么关联的分区最多就是从0-9的10个数字，用这种方式的话是可以触发dpp呢</div>2021-06-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/25/87/f6/bc199560.jpg" width="30px"><span>天翼</span> 👍（0） 💬（1）<div>请问一下，老师的内表和外表的定义是怎么来的，是根据表的大小吗？还是说有什么其他的判断依据？</div>2021-05-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/d4/78/66b3f2a2.jpg" width="30px"><span>斯盖丸</span> 👍（0） 💬（3）<div>老师，你的例子里，tx表的join条件没有用到date，而DPP的实现必须依赖join条件里包含分区字段，也就是date才可以的，这样好像不能实现优化吧？</div>2021-05-17</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJ4VFiaGZicIG5Fx9pMd8vibntD6E91IdzKgER10wJUSas2G8zib1pl5yzMFvkIA5zLBDB8Wa21xkynIw/132" width="30px"><span>sweet smile</span> 👍（1） 💬（2）<div>老师，有个疑问，就是咱们使用DPP的机制来防止外表进行重复扫描，但是DPP机制要求joinkey是分区字段。但是日常中joinkey往往是业务主键，如果把业务主键设计成分区字段，这样是不是不太合理呀。比如说咱们案例里面的orderID字段。</div>2022-04-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/b4/20/c9058450.jpg" width="30px"><span>DarrenChan陈驰</span> 👍（0） 💬（0）<div>感觉最完美的方式还是通过分桶JOIN</div>2024-11-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/6c/8e/793a85d4.jpg" width="30px"><span>DaLi443</span> 👍（0） 💬（0）<div>文中的demo sql，内表的过滤条件是不是应该写在on条件里边，我记得关系型数据库里是应该写在on条件里，难道spark sql谓词下推功优化能自己解决？</div>2023-06-23</li><br/>
</ul>