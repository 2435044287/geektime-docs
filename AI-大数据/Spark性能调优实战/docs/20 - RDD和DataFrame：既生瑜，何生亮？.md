你好，我是吴磊。

从今天开始，我们进入Spark SQL性能调优篇的学习。在这一篇中，我会先带你学习Spark SQL已有的优化机制，如Catalyst、Tungsten这些核心组件，以及AQE、DPP等新特性。深入理解这些内置的优化机制，会让你在开发应用之初就有一个比较高的起点。然后，针对数据分析中的典型场景，如数据关联，我们再去深入探讨性能调优的方法和技巧。

今天这一讲，我们先来说说RDD和DataFrame的渊源。这也是面试的时候，面试官经常会问的。比如说：“Spark 3.0大版本发布，Spark SQL的优化占比将近50%；而像PySpark、Mllib和Streaming的优化占比都不超过10%，Graph的占比几乎可以忽略不计。这是否意味着Spark社区逐渐放弃了其他计算领域，只专注于数据分析？”

[![](https://static001.geekbang.org/resource/image/47/75/479cd67e687a3a7cdc805b55b5bdef75.jpg?wh=1600%2A1358)](https://databricks.com/blog/2020/06/18/introducing-apache-spark-3-0-now-available-in-databricks-runtime-7-0.html)

这个问题的标准答案是：“Spark SQL取代Spark Core，成为新一代的引擎内核，所有其他子框架如Mllib、Streaming和Graph，都可以共享Spark SQL的性能优化，都能从Spark社区对于Spark SQL的投入中受益。”不过，面试官可没有那么好对付，一旦你这么说，他/她可能会追问：“为什么需要Spark SQL这个新一代引擎内核？Spark Core有什么问题吗？Spark SQL解决了Spark Core的哪些问题？怎么解决的？”
<div><strong>精选留言（14）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/12/1d/22/f04cea4c.jpg" width="30px"><span>Fendora范东_</span> 👍（15） 💬（2）<div>对RDD和DataFrame的理解
1.首先区分这两个东西，RDD分布式数据集;DF是带数据模式的结构化分布式数据集。核心区别在于DF带数据模式(感觉像传统分布式数据库中的一张表)，RDD不带数据模式或者说是泛型的。
2.其次是这两者分别提供的API，RDD API优化引擎是Spark Core(没理解这句话，我理解Spark Core负责task调度计算存储，和优化的联系在哪呢？);DF API优化引擎是SparkSQL，包括Catalyst执行过程优化和Tungsten数据结构优化。两者API的区别在于一个提供标量算子一个高阶算子和两者底层优化引擎不一致。
3.上面两组概念应该区分开。之前子框架如Streaming，mlib,graph都是采用RDD API来编写，现在都是采用DF API来重新编写。
4.调用DF API生成DF，但DF 的action算子触发执行后最终还是生成RDD，通过Spark Core框架来进行调度计算。所以可不可以认为DF API+SparkSQL就是代替了之前的RDD API？目的就是为了提供更简单的API，让Spark做统一优化，在rdd计算时更高效？</div>2021-04-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/c6/09/7f2bcc6e.jpg" width="30px"><span>sky_sql</span> 👍（11） 💬（1）<div>老师好，DataFrame和RDD这两套独立的API，最终还是会转化为RDD之上的计算吧？</div>2021-04-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/a1/2d/599e9051.jpg" width="30px"><span>CycleGAN</span> 👍（7） 💬（5）<div>老师好，我们的业务有很复杂的计算udf，用dsl或者sql无法描述，PySpark嵌入udf，使得优化无能为力，性能也一直很低，我们对于反复使用的数学操作会编译成so执行，也在提升udf本身的执行效率，请问将python的udf改写成scala提升会大吗？老师对于我们写复杂udf有什么建议吗？</div>2021-05-16</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIiaeebUYxl7e4jicPshDRKMbiculHUjKgZZ2ygDibn2S7bbsjeqYIdsEUdVyoryKNa43ZGnDQmWjv3ibQ/132" width="30px"><span>Geek_d794f8</span> 👍（7） 💬（1）<div>磊哥，Tungsten 使用定制化的数据结构 Unsafe Row 来存储数据，是不是指的cache缓存的时候使用Unsafe Row存储的数据，或是shuffle溢写到磁盘的时候存储的结构，还是说从数据源读进来的时候会转化成Unsafe Row的结构？</div>2021-04-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg" width="30px"><span>西南偏北</span> 👍（6） 💬（1）<div>PySpark应用中如果用到了Python里面的数据结构都会导致在JVM进程和Python进程间进行交互的吧</div>2021-05-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/63/6e/6b971571.jpg" width="30px"><span>Z宇锤锤</span> 👍（5） 💬（4）<div>Java Object 在对象存储上为什么会有比较大的开销？
我查阅了了一些资料，Java对象的存储在JVM上至少需要32或64Bit的字节存储对象自身信息，哈希码（HashCode）、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳。
&quot;ABCD&quot;的存储至少需要8个字节。</div>2021-05-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/cd/7b/31a6bf42.jpg" width="30px"><span>强</span> 👍（4） 💬（1）<div>曾经看到一个视频,说是Dataset后续要取代DataFrame。Dataset和DataFrame这两者之间有什么关系？实际项目中用的哪个偏多些？</div>2021-11-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/63/6e/6b971571.jpg" width="30px"><span>Z宇锤锤</span> 👍（2） 💬（2）<div>RDD和DataFrame的最大区别，DF像是一张二维表，可以用来写SQL。RDD只能使用算子。</div>2021-05-02</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIiaeebUYxl7e4jicPshDRKMbiculHUjKgZZ2ygDibn2S7bbsjeqYIdsEUdVyoryKNa43ZGnDQmWjv3ibQ/132" width="30px"><span>Geek_d794f8</span> 👍（2） 💬（3）<div>Tungsten的这种存储数据结构，感觉和parquet类似，他们之间有什么关联吗</div>2021-04-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/c6/09/7f2bcc6e.jpg" width="30px"><span>sky_sql</span> 👍（2） 💬（3）<div>RDD是Spark对于分布式数据模型的抽象，调度、存储都是RDD维度的，DataFrame底层是使用RDD的算子实现的吧？
对于普通开发者后面使用DataFrame实现业务逻辑，尽量不使用RDD？</div>2021-04-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/5c/d7/e4673fde.jpg" width="30px"><span>October</span> 👍（1） 💬（2）<div>老师好，还是不是很理解什么是标量函数和标量算子。为什么标量算子就即能知道做什么，又能知道怎么做</div>2022-02-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/cb/4f/7466a488.jpg" width="30px"><span>Pengyuan Li</span> 👍（1） 💬（1）<div>老师， 我觉得有个重要的优化没有讲到呀， 用pyspark + data frame开发的时候，使用pandas udf可以比普通的UDF快几倍到十几倍 。  可以加餐一个pandas UDF的使用？ </div>2021-12-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/a5/65/898bc6c5.jpg" width="30px"><span>wayne</span> 👍（1） 💬（3）<div>老师，既然pyspark和spark(scala)性能差距巨大，那么pyspark-sql和spark-sql(sql)的性能差异也是巨大吗？目前我们公司采用的是向yarn集群中提交.py文件，然后使用pyspark =&gt; spark.sql()的方式执行sql</div>2021-12-05</li><br/><li><img src="" width="30px"><span>Horse_Lion</span> 👍（2） 💬（1）<div>如果df中scheme字段全是字符串这种可变长度类型，Tungsten怎么将其转换为unsafe row？</div>2023-02-08</li><br/>
</ul>