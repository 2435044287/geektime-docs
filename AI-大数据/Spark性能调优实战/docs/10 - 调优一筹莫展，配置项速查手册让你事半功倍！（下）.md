你好，我是吴磊。

上一讲，我们讲了硬件资源类的配置项。这一讲，我们继续说说Shuffle类和Spark SQL大类都有哪些配置项，它们的含义和作用，以及它们能解决的问题。同时，和上一讲一样，我们今天讲到的配置项也全部会围绕Executors展开。

## Shuffle类配置项

首先，我们来说说Shuffle类。纵观Spark官网的[Configuration页面](http://spark.apache.org/docs/latest/configuration.html)，你会发现能调节Shuffle执行性能的配置项真是寥寥无几。其实这也很好理解，因为一旦Shuffle成为应用中不可或缺的一环，想要优化Shuffle本身的性能，我们能做的微乎其微。

不过，我们也不是完全束手无策。我们知道，Shuffle的计算过程分为Map和Reduce这两个阶段。其中，Map阶段执行映射逻辑，并按照Reducer的分区规则，将中间数据写入到本地磁盘；Reduce阶段从各个节点下载数据分片，并根据需要实现聚合计算。

那么，我们就可以通过spark.shuffle.file.buffer和spark.reducer.maxSizeInFlight这两个配置项，来分别调节Map阶段和Reduce阶段读写缓冲区的大小。具体该怎么做呢？我们一一来看。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/12/07/a6/662bcc6b.jpg" width="30px"><span>来世愿做友人 A</span> 👍（23） 💬（6）<div>请教老师一个问题，对于小文件合并，上边说的是某个 executor 的大小排序后合并。比如两个 executorA 和 B，分别有两个 task 运行，groupby 并且各自产生了3个分区，分别是 a.0,a.1,a.2 和 b.0,b.1,b.2，在没有合并小分区的情况下，reduce端会有三个任务拉取各自的012分区。但是，打开小分区合并，在满足合并的条件下，a.0和a.1合并成 a.01，b.1和b.2合并成b.12。这时候两个 task 各有两个分区，但是他们的分区 key 相当于混在一起了。shuffle的 reduce 是怎么拉取。因为目前只看过 raw rdd的相关，目前没想到是怎么解决这个问题的？比如又会多引入一层 shuffle？或者有其它判断，最终判断这次的 reduce 只能有一个 task，然后拉取所有 map 端的分区？</div>2021-04-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/04/30/7f2cb8e3.jpg" width="30px"><span>CRT</span> 👍（21） 💬（2）<div>spark.shuffle.sort.bypassMergeThreshold 这个阈值为什么是跟Reduce 端的分区数有关，Reduce 端的分区数过大的话，取消排序会有不好的影响吗？</div>2021-05-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/20/d6/b9513db0.jpg" width="30px"><span>kingcall</span> 👍（11） 💬（2）<div>其实我们的调优很多都是发生在数据规模比较大的情况下,对于比较大的shuffle 可以对下面的参数进行调节，提高整个shuffle 的健壮性

spark.shuffle.compress 是否对shuffle 的中间结果进行压缩，如果压缩的话使用`spark.io.compression.codec` 的配置进行压缩

spark.shuffle.io.maxRetries  io 失败的重试次数，在大型shuffle遇到网络或者GC 问题的时候很有用。

spark.shuffle.io.retryWait io 失败的时候的等待时间</div>2021-04-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/25/f1/bb/547b580a.jpg" width="30px"><span>苏子浩</span> 👍（7） 💬（2）<div>老师好！我想讨论一下文中“自动数据倾斜处理”部分。其中我们提到“advisoryPartitionSizeInBytes”这个参数。我通过查看源代码发现：拆分的时候我们具体使用的拆分粒度(targetSize)不仅会考虑该参数的数值，同时会考虑非倾斜的分区(non-skewedPartition)的平均大小。用数学表示的话应该是“Math.max(advisortSize, nonSkewSizes.sum &#47; nonSkewSizes.length)”。其中nonSkewSizes表示“所有分区中过滤掉倾斜分区后所剩余分区，其分区大小所构成的列表”。
我想表达的是：在‘自动倾斜处理’中所用到的思想与‘自动分区合并’中相似！
并不是指定了 advisoryPartitionSizeInBytes 是多少，Spark 就会完全尊重开发者的意见，还要考虑非倾斜分区的平均大小。
那么这样来看的话，文中所举的例子“检测到倾斜分区之后，接下来就是对它拆分，拆分的时候还会用到 advisoryPartitionSizeInBytes 参数。假设我们将这个参数的值设置为 256MB，那么，刚刚那个 512MB 的倾斜分区会以 256MB 为粒度拆分成多份，因此，这个大分区会被拆成 2 个小分区（ 512MB &#47; 256MB =2）。拆分之后，原来的数据表就由 3 个分区变成了 4 个分区，每个分区的尺寸都不大于 256MB。“其实在这里其实是比较了Math( ((80+100) &#47; 2),  256) = 256后，我们才最终确定以 256MB 为粒度拆分存在倾斜的分区。
接着是我的一点看法，AQE中对于认定倾斜分区的条件看起来非常苛刻，首先要满足该分区的大小高于
spark.sql.adaptive.skewJoin.skewedPartitionThresholdInBytes 参数的设定值。同时，取所有数据分区大小排序后的中位数作为放大基数，尺寸大于中位数指定倍数的分区才会被判定为倾斜分区。那么是不是可以看到其实做倾斜分区处理这件事的成本还是很高的。因为在数据关联场景中，如果两边的表都存在数据倾斜的话，会出现笛卡尔积的显现。哪怕是只有一边的表存在数据倾斜，另外一边的分区复制也是不小的开销。在关联场景中涉及到更多的网络开销。以及需要涉及到reducer任务从一个分区中读取部分数据，其中涉及到的数据划分成本很高？
其实我看到的第一反应是想到了Shuffle Hash Join激活的先决条件，感觉激活的条件都非常苛刻。</div>2021-05-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/25/87/f6/bc199560.jpg" width="30px"><span>天翼</span> 👍（6） 💬（2）<div>老师，请问一下，spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin 这个配置在官网的 Configuration 中没有找到，是改名了吗？</div>2021-05-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1a/20/7f/6ce7762d.jpg" width="30px"><span>木子中心</span> 👍（5） 💬（1）<div>老师好，有一个问题：文章里面说建议设置spark.sql.autoBroadcastJoinThreshold为2G，如果数据是parquet格式的话，将数据加载到内存中会膨胀比较大，这个时候，driver端内存应该配置多少才能不oom呢？</div>2021-09-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/d4/78/66b3f2a2.jpg" width="30px"><span>斯盖丸</span> 👍（5） 💬（1）<div>老师，我看Spark 3.1.1的文档，spark.sql.adaptive.nonEmptyPartitionRatioForBroadcastJoin这个参数已经被去除了。。由此想到一个重大问题：像这种重大的参数配置变更老师是怎么第一时间获悉的并跟上版本更新的节奏，而不像我们这样没人告知，只能被动地获悉呢？</div>2021-06-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1a/20/7f/6ce7762d.jpg" width="30px"><span>木子中心</span> 👍（3） 💬（1）<div>吴老师好！有个问题想请教下：
    spark广播join经常造成driver oom，spark.sql.autoBroadcastJoinThreshold使用默认值，driver为4-5G左右，文件存储格式为parquet。查阅资料发现spark是直接通过扫描文件的总大小及多少列来判断是否小于阈值，进行广播。由于使用了parquet格式，在扫描少数列的情况下，由于压缩率较高，在某些情况下，上百万数据的结果集也进行广播，造成driver段oom。</div>2021-09-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/51/8b/29ed1c41.jpg" width="30px"><span>耳东</span> 👍（3） 💬（2）<div>问下老师，如果某个表的大小是10m，但是它的条数超过了1千万条，这种表属不属于小表</div>2021-04-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/26/db/27724a6f.jpg" width="30px"><span>辰</span> 👍（3） 💬（1）<div>这个aqe规则是在3.0版本才有的，但是我公司目前用的版本是2.2，有什么其他的参数设置吗</div>2021-04-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/d4/78/66b3f2a2.jpg" width="30px"><span>斯盖丸</span> 👍（3） 💬（2）<div>spark.shuffle.file.buffer 和 spark.reducer.maxSizeInFlight 这两个配置项听起来应该越大越好，这样可以降低落盘的频次和数据shuffle的频次。请问老师这两个参数如果调太大会有什么副作用呢？</div>2021-04-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/f5/8a/dc9a23a1.jpg" width="30px"><span>续费专用</span> 👍（2） 💬（1）<div>老师好，动态分区裁剪和AQE哪个对spark的优化性能更大呢？AQE默认是关闭的，是不是说明spark更推荐用户使用动态分区裁剪功能呢？</div>2021-06-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/20/46/f4/93b1275b.jpg" width="30px"><span>Alan</span> 👍（1） 💬（2）<div>2、看似AQE 数据倾斜策略确实不错，但是数据倾斜优化后的sort merge join，使用skew Shuffle reader，也就是存在shuffle的操作，会影响总体的性能，所以skewedPartitionFactor、spark.sql.adaptive.advisoryPartitionSizeInBytes 和 spark.sql.adaptive.coalescePartitions.minPartitionNum两项值设置的合理性，非常重要，最好数据量刚好适用，整数倍最好！</div>2021-05-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg" width="30px"><span>西南偏北</span> 👍（1） 💬（2）<div>1. AQE的自动分区合并算法目前的实现，可能会造成合并之后，各分区数据不均衡，从而导致后续计算出现小的数据倾斜？合并算法是不是可以在得出合并前各分区大小之后，进行均衡的组合合并？
2. 因为AQE数据倾斜处理机制，是取中位数，那比如有10个分区：80MB  100 100 100 100 512 512 512 512MB，skewedPartitionFactor为5，skewedPartitionThresholdInBytes为256MB。那么这样一来的话，就会造成将近一半的分区被判定为倾斜分区，这种情况下，后续的分区拆分处理是不是代价就比较大了</div>2021-05-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/9b/3b/dc3f819f.jpg" width="30px"><span>小灵芝</span> 👍（1） 💬（2）<div>老师您好呀！ 请教2个问题：

“因此，在不需要聚合，也不需要排序的计算场景中，我们就可以通过设置 spark.shuffle.sort.bypassMergeThreshold 的参数，来改变 Reduce 端的并行度”

1. 请问还有哪些类似于repartition, groupby 这种“不需要聚合，也不需要排序的计算场景”呢？
2. groupby 不是需要聚合的吗？</div>2021-04-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/df/e5/65e37812.jpg" width="30px"><span>快跑</span> 👍（1） 💬（3）<div>文章结尾图片中spark.shuffle.sort.bypassMergeThreshold为什么归类为Reduce端的参数呢？</div>2021-04-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/ec/6d/d93587e8.jpg" width="30px"><span>坏耗子</span> 👍（1） 💬（1）<div>问下老师，目前spark版本为2.3， 主要用spark sql为主进行开发，有什么好的sql方面的调优思路？</div>2021-04-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/b2/ef/a0b79b16.jpg" width="30px"><span>欧阳硕</span> 👍（0） 💬（1）<div>AQE 中数据倾斜的处理机制隐患：（假设倍数10，分区大小10m）
有一种场景是100个分区99个分区都超过了100m一个分区是1m，按照中位数倍数和分区，那大部分的数据分区都要进行切分，这种极端情况是否会有小文件和调度压力增大的问题么？
</div>2022-03-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/f5/9a/63dc81a2.jpg" width="30px"><span>Geek1185</span> 👍（0） 💬（1）<div>请教老师个问题，我们生产环境一个版本是1.6，有个任务代码逻辑没变，数据量翻倍后一直无法结束，也不报错，UI显示在cache的时候卡住，executor jstack显示一直运行在BypassMergeSortShuffleWriter这块的代码，spark.shuffle.sort.bypassMergeThreshold这个参数并没有配置，老师有什么思路排查或者解决么，期待回复</div>2021-12-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/00/3f/a0f84788.jpg" width="30px"><span>Sean</span> 👍（0） 💬（1）<div>
根据文中的内容有两个问题想要咨询下老师:
①老师上文中提到的map端缓冲区和reduce端缓冲区大小,理论上来说,是不是map端的值应该大于或等于reduce端缓冲区大小更优呢?如果map端缓冲区小,表示溢出的文件可能或更多,分散到更多的节点中去,导致reduce端拉取时的io更大,所以调大reduce依然解决不了map端溢写带来的io问题,不知道这样理解是否正确?
2.对于磁盘spark.local.dir参数,默认是在&#47;tmp目录下,主要还是依耐于硬件,如果是普通的HDD盘其实没有什么作用,如果有SSD,那可以把目录配置到SSD上才能达到优化的目的。</div>2021-08-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/df/e5/65e37812.jpg" width="30px"><span>快跑</span> 👍（0） 💬（4）<div>老师你好，设置.shuffle.sort.bypassMergeThreshold参数，能避免shuffle过程中引入排序。
1、这个结论怎么能验证呢。主要是想了解从怎样才能看到一个spark任务执行过程中采用的是什么Shuffle。
2、我的场景是Hive On Spark，也想看看这个参数在Hive On Spark是否也生效</div>2021-05-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/ee/54/b5011c70.jpg" width="30px"><span>揣瞌睡的叮叮猫儿</span> 👍（0） 💬（1）<div>请教老师 spark.sql.shuffle.partitions参数值对 AQE的执行有什么影响？本地构造数据测试Sort Merge Join-&gt;Broadcast Join是否有效，开启AQE后，但spark.sql.shuffle.partitions设置个数会影响是否降级join, 不懂为什么</div>2021-05-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/a2/4b/b72f724f.jpg" width="30px"><span>zxk</span> 👍（0） 💬（2）<div>问题1：在用户不指定 RDD 大小推荐值或者分区数时，默认情况下我会将合并的推荐大小设置为总的数据量除以所有 executor 的核心数，然后在 map 端对将要 shuffle 到相同 partition 的分片先进行一次合并，减少需要 shuffle 的文件数量。
问题2：如果是那些需要某个分片全量数据才能得到正确结果的业务场景，那么自动数据倾斜可能会导致结果不符合预期。比如需要求该分片的某列数据的中位数，那么将该分片拆为两份后，即使后面再做聚合，也无法得到预期的结果。</div>2021-04-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/fe/a2/5252a278.jpg" width="30px"><span>对方正在输入。。。</span> 👍（0） 💬（1）<div>我来设计分区合并思路的话，会先按照每个partitionid的总体size来从大到小排序，然后按照背包算法来装包</div>2021-04-12</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/usX58SweWDFqjCmtkvPOWIfjqN2GqydQYqW53bIcFI4DGBmp6O2LZxZL1UYsVPRuEP03dEJcK3d9jHdYZVn8ug/132" width="30px"><span>maben996</span> 👍（0） 💬（1）<div>老师请教个问题，对于 spark.shuffle.sort.bypassMergeThreshold 这个参数，默认值为200。假如我的场景是需要排序的，但是reduce端的分区数又小于200，那这个参数会不会生效，触发bypass，绕过排序shuffle？</div>2021-04-08</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIO6eRuuA6V34kREveXkNaebicNzy3oUvEM3t48ehMRJIuCnYNe9B54VuAndjo1cZZ5ykHDHL8ZlhA/132" width="30px"><span>onee</span> 👍（0） 💬（3）<div>请问spark.sql.shuffle.partitions是只有sparksql时有用还是所有？如果一个数据partitionby成1024份了，那spark.default.parallelism和spark.sql.shuffle.partitions是不是都无效了？</div>2021-04-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/8c/0d/42e16041.jpg" width="30px"><span>白音</span> 👍（0） 💬（1）<div>问下老师，spark 2.x 的版本中 AQE 的这些特性都无法使用是吧？</div>2021-04-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/d0/0b/6504c7b1.jpg" width="30px"><span>geegeek</span> 👍（0） 💬（0）<div>最近在看这个：https:&#47;&#47;books.japila.pl&#47;apache-spark-internals&#47;overview&#47;
感觉挺好</div>2023-03-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/15/7a/db9879e1.jpg" width="30px"><span>陌臣</span> 👍（0） 💬（0）<div>老师，公司业务主要用到Spark SQL ，现在升级到了3.1.2，想知道怎么在Spark UI 界面上看到AQE设置后效果呢？升级之后任务运行时间比原来缩短了30%，但是启用AQE之后任务运行时间没啥变化</div>2023-02-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/0a/49/f88b414a.jpg" width="30px"><span>Abel</span> 👍（0） 💬（0）<div>如果shuffle过后的数据是50g，那个每个分区的尺寸是50gb&#47;200=250mb，advisoryPartitionSizeInBytes 设置为 200MB，最终的目标分区尺寸就是取（250MB，200MB）之间的最小值，也就是 200MB，那么分区数就变成了250个，这不是个最小分区数200这个配置项矛盾么</div>2022-11-20</li><br/>
</ul>