你好，我是吴磊。

上一讲我们说，想要提升CPU利用率，最重要的就是合理分配执行内存，但是，执行内存只是Spark内存分区的一部分。因此，想要合理分配执行内存，我们必须先从整体上合理划分好Spark所有的内存区域。

可在实际开发应用的时候，身边有不少同学向我抱怨：“Spark划分不同内存区域的原理我都知道，但我还是不知道不同内存区域的大小该怎么设置，纠结来、纠结去。最后，所有跟内存有关的配置项，我还是保留了默认值。”

这种不能把原理和实践结合起来的情况很常见，所以今天这一讲，我就从熟悉的Label Encoding实例出发，**一步步带你去分析不同情况下，不同内存区域的调整办法，**帮你归纳出最大化内存利用率的常规步骤。这样，你在调整内存的时候，就能结合应用的需要，做到有章可循、有的放矢。

## 从一个实例开始

我们先来回顾一下[第5讲](https://time.geekbang.org/column/article/355028)中讲过的Label Encoding。在Label Encoding的业务场景中，我们需要对用户兴趣特征做Encoding。依据模板中兴趣字符串及其索引位置，我们的任务是把千亿条样本中的用户兴趣转换为对应的索引值。模板文件的内容示例如下所示。

```
//模板文件
//用户兴趣
体育-篮球-NBA-湖人
军事-武器-步枪-AK47
```

实现的代码如下所示，注意啦，这里的代码是第5讲中优化后的版本。
<div><strong>精选留言（19）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/13/37/6f/b3337e6d.jpg" width="30px"><span>金角大王</span> 👍（38） 💬（1）<div>老师，为何UserMemory中自定义数据结构不能像bc那样在StorageMemory中只存一份？</div>2021-04-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/1d/22/f04cea4c.jpg" width="30px"><span>Fendora范东_</span> 👍（27） 💬（1）<div>还有个疑问，想请教下磊哥
文中说的数据集大小是内存中的数据集吧
文件落盘后数据集大小可以很方便查看，那内存中数据集大小怎么看呢</div>2021-04-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/4e/29/adcb78e7.jpg" width="30px"><span>静心</span> 👍（20） 💬（1）<div>老师，我发现14讲中，计算合理的并行度，依赖之一是在执行内存大小给定的前提下。而15讲中，计算执行内存大小，依赖之一是在并行度给定的前提下。所以到底如何破局呢？</div>2021-05-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/a2/4b/b72f724f.jpg" width="30px"><span>zxk</span> 👍（20） 💬（1）<div>老师，这边想请教两个问题。
问题一：User Memory、Execution Memory、Storage Memory 是属于 Spark 自身对内存区域的划分，但 Spark 的 executor 实际上又是一个 JVM，假如我把 User Memory 设置的非常小，又自定义了一个很大的数据结构，此时 User Memory 不够用了，而 Execution Memory、Storage Memory 还有很大的空闲，那么这时候会不会 OOM？如果是 GC 又不太符合 JVM 的 GC 条件。
问题二：在使用 mapPartition 算子的时候，如果我在进入迭代前外部定义了一个 map，然后迭代中往这个 map 添加数据，那么这个 map 又是占用哪部分内存的？</div>2021-04-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg" width="30px"><span>西南偏北</span> 👍（16） 💬（2）<div>老师讲的预估内存占用非常细，但就像老师给出的第二题中说的那样，如果Spark应用程序中的计算逻辑很多，这样预估自然是很精确，但是会花费大量时间，成本巨大！分享一下自己平时粗略估算内存占用的方法（如有不对，还望老师纠正）：
1、Storage Memory估算：将要缓存到内存的RDD&#47;Dataset&#47;Dataframe或广播变量进行cache，然后在Spark WEBUI的Storage标签页下直接查看所有的内存占用，大致就对应Storage Memory。

2、Execution Memory估算：有了Storage Memory，因为默认情况下Execution Memory和Storage Memory占用Spark Memory的比例是相同的，这里可以将Execution Memory和Storage Memory设置为相同。

3、User Memory：如果应用中没有使用太多自定义数据类型，保持默认值即可；如果使用了很多自定义数据类型，按老师说的方式进行估算即可。

上面只是一个粗略的估算，可能需要根据任务的执行情况进行一些调整。</div>2021-05-04</li><br/><li><img src="" width="30px"><span>licl1008</span> 👍（14） 💬（4）<div>老师 课后思考中提到内存规划第一步很麻烦 您在留言回复中提到可以根据sparkUI估算&#39;数据放大倍数&#39;，然后粗略估算内存。请问具体是如何操作？ 根据您这个方法，可以同时得出 user execution storage三个空间的内存大小？ 谢谢指导</div>2021-05-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/df/e5/65e37812.jpg" width="30px"><span>快跑</span> 👍（14） 💬（1）<div>REPL 中，通过 Java 的常规方法估算数据存储大小
老师，这个过程具体是怎么做呢。</div>2021-04-19</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIiaeebUYxl7e4jicPshDRKMbiculHUjKgZZ2ygDibn2S7bbsjeqYIdsEUdVyoryKNa43ZGnDQmWjv3ibQ/132" width="30px"><span>Geek_d794f8</span> 👍（4） 💬（2）<div>老师，我有一个疑惑，对于有多个stage的任务，每个stage的内存预估的情况可能不一样。那样就无法给一个比较适合所有stage得内存配置？</div>2021-04-18</li><br/><li><img src="" width="30px"><span>licl1008</span> 👍（3） 💬（1）<div>老师 我是接着昨天的提问再问一下😂  execution mem内存估算中，#dataset不用算#bc过的数据集。但我的疑惑是：#bc只是把文件系统的数据搬到了内存，同样只是一个Relation而已，和执行要的内存似乎没什么联系。execution时，比如一些aggregate操作，不是同样也要把这个#bc relation的数据读出来，然后驻留在内存中处理吗。那岂不是也是要算入执行内存？或者我没懂算执行内存的理论依据到底是什么？我理解的执行内存是做aggregate sort等操作需要的内存空间，也是就pairedbuffer这之类的结构的大小   谢谢老师不吝赐教😄</div>2021-05-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/26/db/27724a6f.jpg" width="30px"><span>辰</span> 👍（2） 💬（9）<div>老师，结合这一节内容和之前的，自定义数据结构其实和hive中的表关系不大，不涉及自定义，那么这时候是不是就可以把存储自定义这部分的内存匀出来给到统一内存身上</div>2021-04-16</li><br/><li><img src="" width="30px"><span>Geek_1564ee</span> 👍（1） 💬（1）<div>老师，你好，想问下shuffle map阶段和reduce阶段写入和读取缓冲区是消耗的storage memory内存区域么？另外spark.shuffle.file.buffer和spark.reducer.maxSizeInFlight是以task为粒度的么？</div>2022-01-26</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/icJzoUc02ECdBbFgGzVIwYfpRgL3TXuRRE5GsDqZFmAlAAm1KUQS1rHewgj5FB4TChovo3YaceicEZE2MgZJ1ftw/132" width="30px"><span>Geek_eb29a4</span> 👍（1） 💬（1）<div>利用高阶函数，我们就避免了让 Executor 中的每一个 Task 去读取模板文件，以及从头构建 Map 字典这种执行低效的做法。

这个原理 有什么参考资料可以看一下？
</div>2021-12-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/11/20/9f31c4f4.jpg" width="30px"><span>wow_xiaodi</span> 👍（1） 💬（1）<div>老师，比如一个filter算子里的自定义函数我用了一个自定义数据结构，但是filter算子是RDD里N条都要去执行的，那么这个自定义数据结构将会存在N份，直到GC回收为止。这里这个内存占用大小就很难估算了，算他是1份的占用明显不合理，但是我又不知道有多少条数据会调用，这时如何估算比较好呢？</div>2021-08-06</li><br/><li><img src="" width="30px"><span>licl1008</span> 👍（1） 💬（1）<div>老师  算execution mem时，比如两个数据集join的场景, 有一个小数据集broadcast了, 那#dataset要包括#bc吗？ 还是只用算那个没有被广播的数据集的大小？</div>2021-05-19</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJt9RvLXn5KxqNiccCyxRGy0IDHdqOOiazoH7aqku4GlELB4guibOGibEqPF740iaNwKoe6BjicgmgjR6Vw/132" width="30px"><span>Geek_81beba</span> 👍（1） 💬（1）<div>如何配置spark的参数选项，让他像hive一样自动划分内存和cpu然后稳定的运行呢</div>2021-05-07</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/icJzoUc02ECdBbFgGzVIwYfpRgL3TXuRRE5GsDqZFmAlAAm1KUQS1rHewgj5FB4TChovo3YaceicEZE2MgZJ1ftw/132" width="30px"><span>Geek_eb29a4</span> 👍（0） 💬（1）<div>
利用高阶函数，我们就避免了让 Executor 中的每一个 Task 去读取模板文件，以及从头构建 Map 字典这种执行低效的做法。

麻烦吴老师结合这个网址，讲解下 高阶匿名函数的优化点吗？
我找了很多资料，大概这个有点对得上 https:&#47;&#47;www.jianshu.com&#47;p&#47;0a3150afb7ed


</div>2021-12-14</li><br/><li><img src="" width="30px"><span>Geek_0419b7</span> 👍（0） 💬（1）<div>吴老师您好！在Spark算子中创建的对象属于哪一部分的内存呢？就比如说在map函数里创建的对象。</div>2021-07-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/df/e5/65e37812.jpg" width="30px"><span>快跑</span> 👍（0） 💬（1）<div>新一点版本的spark 对应Storage和Execution的内存是不是可以相互抢占的。这样的话，还需要特殊配置两个内存的配置占比么</div>2021-06-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/1d/22/f04cea4c.jpg" width="30px"><span>Fendora范东_</span> 👍（0） 💬（2）<div>1.C&#47;C++党，阅读修改spark源码无障碍，虽然有些scala高级语法叫不上名，不影响理解源码。就是不懂java。。😅
2.我觉得应该根据使用场景直接预估。比如如果仅仅使用sql，那么fraction和storageFraction尽量调小就行;如果是使用DataSet API较多，省略保留内存情况下，#user,#storage,#execution各占1&#47;3，然后根据代码中自定义数据结构和cache方法在代码总行数中出现的频率，对原本1&#47;3做微调。
不知道对不对，磊哥看下。</div>2021-04-16</li><br/>
</ul>