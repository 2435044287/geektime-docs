你好，我是吴磊。

对于Spark性能调优来说，应用开发和配置项设置是两个最主要也最常用的入口。但在日常的调优工作中，每当我们需要从配置项入手寻找调优思路的时候，一打开Spark官网的Configuration页面，映入眼帘的就是上百个配置项。它们有的需要设置True或False，有的需要给定明确的数值才能使用。这难免让我们蒙头转向、无所适从。

所以我经常在想，如果能有一份Spark配置项手册，上面分门别类地记录着与性能调优息息相关的配置项就好了，肯定能省去不少麻烦。

那么，接下来的两讲，我们就来一起汇总这份手册。这份手册可以让你在寻找调优思路的时候，迅速地定位可能会用到的配置项，不仅有章可循，还能不丢不漏，真正做到事半功倍！

## 配置项的分类

事实上，能够显著影响执行性能的配置项屈指可数，更何况在Spark分布式计算环境中，计算负载主要由Executors承担，Driver主要负责分布式调度，调优空间有限，因此对Driver端的配置项我们不作考虑，**我们要汇总的配置项都围绕Executors展开**。那么，结合过往的实践经验，以及对官网全量配置项的梳理，我把它们划分为3类，分别是硬件资源类、Shuffle类和Spark SQL大类。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/dd/2d/9fd44ed5.jpg" width="30px"><span>Joe</span> 👍（40） 💬（1）<div>老师，针对spark.sql.shuffle.partitions的使用有一些疑问？

1. 如果df1.join(df2)，df1用的是hash partitioner并且分区数是3，这种情况在reduce端参数spark.sql.shuffle.partitions会生效吗？还是以df1的分区为准？

2. 这个参数是针对所有的Dataframe，DataSet和SQL，还是只有SQL生效？

</div>2021-04-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/d4/78/66b3f2a2.jpg" width="30px"><span>斯盖丸</span> 👍（18） 💬（5）<div>关于spark.sql.shuffle.partitions 老师实际工作中我发现这个参数不管用。比如我把它设成2000，并去读parquet文件，大约几百个文件吧，但我看task数量只有80个，而且还一直在变，有时会更少。网上说spark-sql的并行度不管用，要自己手动repartition，是这样吗？task数量一直在变是因为不断地在做groupBy和join吗？那为什么task数量始终达不到我设的spark.sql.shuffle.partitions = 2000呢？</div>2021-04-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/92/6b/6f324fc8.jpg" width="30px"><span>断笔画墨</span> 👍（14） 💬（3）<div>spark读取oracle表，oracle表结构没有数值类型，大部分都是varchar，数据量上亿，怎么在源端做高并发读取啊</div>2021-04-24</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIiaeebUYxl7e4jicPshDRKMbiculHUjKgZZ2ygDibn2S7bbsjeqYIdsEUdVyoryKNa43ZGnDQmWjv3ibQ/132" width="30px"><span>Geek_d794f8</span> 👍（13） 💬（1）<div>Spark.task.cpus这个参数的设置，我之前理解就是一个cpu核运行一个task。难道还可以0.5个cpu或者多个cpu运行一个task吗？</div>2021-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/df/e5/65e37812.jpg" width="30px"><span>快跑</span> 👍（11） 💬（4）<div>Class Student是存在User Memory? new Student(&quot;小明&quot;)是存在Executor Memory？</div>2021-04-13</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIiaeebUYxl7e4jicPshDRKMbiculHUjKgZZ2ygDibn2S7bbsjeqYIdsEUdVyoryKNa43ZGnDQmWjv3ibQ/132" width="30px"><span>Geek_d794f8</span> 👍（7） 💬（1）<div>老师是不是可以这样理解，spark-submit提交任务的时候申请的总cores数为10，yarn调度系统会分配10个v-core，如果集群资源充足，实际上一个v-core就是对应一个cpu核，如果资源不够，相当于就不是一对一，此时集群最大的task并行度并不是10，而是并发度为10。
以上理解对吗？</div>2021-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/df/e5/65e37812.jpg" width="30px"><span>快跑</span> 👍（6） 💬（3）<div>一个任务报错Container Killed by Yarn For Exceeding Memory Limits Consider boosting spark.yarn.executor.memoryOverhead
我按照提示增加spark.yarn.executor.memoryOverhead，任务的确执行通过。
请教老师spark.yarn.executor.memoryOverhead参数控制哪部分内存，主要负责什么？什么情况下会用到这部分内存。文章中关于内存的好像没有提到这部分。</div>2021-04-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/26/db/27724a6f.jpg" width="30px"><span>辰</span> 👍（5） 💬（1）<div>老师，这个自定义结构不是很懂，什么样的数据格式是自定义数据格式，我现在经常接触到的是spark-submit 提交sparksql这一块，用的是hive表，这个涉及自定义数据结构吗</div>2021-04-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/00/3f/a0f84788.jpg" width="30px"><span>Sean</span> 👍（4） 💬（3）<div>根据老师的回回复,个人总结如下,不知是否正确:在不使用yarn,k8s模式下,完全没有必要启用off heap,而且在钨丝计划的加持下,可以理解为使用堆内内存,不会对任务有任何影响,但在使用yarn或k8s模式下,必须要开启off heap,否则会出现t Container Killed by Yarn For Exceeding Memory Limits Consider boosting spark.yarn.executor.memoryOverhead报错,需要调大spark.yarn.executor.memoryOverhead</div>2021-08-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg" width="30px"><span>西南偏北</span> 👍（4） 💬（1）<div>并行度太高可能会造成任务调度耗时超过任务处理耗时，如果不进行后续分区合并，还有会造成小文件问题（比如写入Hive）</div>2021-05-04</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/ia89MwaRSP6iaeQB4789roUntH7tia9EXyoDOnlibE8ABibAzFPiamP0SAU54NNTRiaVtkOtmLaWRH5OXbTOhUZl46scw/132" width="30px"><span>Geek_01fccd</span> 👍（3） 💬（2）<div>在hive on spark模式下，是否可以忽略user memory，设置spark.memory.fraction=0.9，这里应该不涉及用户自定义数据结构吧？</div>2021-05-11</li><br/><li><img src="" width="30px"><span>勿更改任何信息</span> 👍（3） 💬（3）<div>如果我把堆外内存关闭，会不会导致spark sql执行失败？也就是spark sql有没有必须使用堆外内存的场景？</div>2021-04-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/86/d4/98216895.jpg" width="30px"><span>铜镜</span> 👍（3） 💬（1）<div>1.资源浪费,并行度设置过大会增加调度开销,CPU利用率会变低
2.不好意思没看明白这个是在问啥😁, int,char这种?还是dataframe这种?还是AppendOnlyMap这种?
3.如果需要频繁操作反序列化出来的实际值的话,使用堆外内存会大幅增加cpu开销
4.alluxio?
</div>2021-04-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/d9/67/9bca6a6e.jpg" width="30px"><span>薛峰</span> 👍（2） 💬（1）<div>醍醐灌顶，真希望是在过去的面试之前看到这篇。</div>2021-04-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/f2/f5/b82f410d.jpg" width="30px"><span>Unknown element</span> 👍（1） 💬（1）<div>老师问下自己定义的dataframe是不是也属于自定义数据结构（从而存储在user memory）？</div>2021-12-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/df/e5/65e37812.jpg" width="30px"><span>快跑</span> 👍（1） 💬（2）<div>老师你好，
对于“对于没有明确分区规则的 RDD 来说，我们用 spark.default.parallelism 定义其并行度。”
没有明确分区规则的 RDD是指什么，有什么场景属于没有分区规则的RDD？</div>2021-04-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/d4/78/66b3f2a2.jpg" width="30px"><span>斯盖丸</span> 👍（1） 💬（2）<div>这一讲有好多实操中不理解的问题，请老师不吝赐教。

1 老师多次强调要确保硬件资源的平衡。但我们应该怎么查作业是否平衡呢？比如在Yarn上，我能看到我的job占用的总内存和总v-core（顺便问一下，一个v-core是一个CPU的核吗？），但我应该从哪个界面看出CPU是太空闲还是太忙了？

2 开启堆外内存，Spark会把复杂的schema放到堆外内存吗？比如我读parquet表生成一个几亿条的DF，对它做了一些collect_list操作，那它会把简单的数据结构放堆里而把复杂的list放到堆外吗，要是反过来怎么办，岂不是更糟？

3 自己写了一个函数，传入一个sparkSession，返回一个DF，我在外面用个val变量去接，请问在函数返回的最后一步要cache一下吗？因为我觉得这算是两个变量复用一个RDD了，应该要cache()。但我同事说不用cache的，我俩究竟谁对？麻烦老师都回答一下吧~</div>2021-04-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/00/3f/a0f84788.jpg" width="30px"><span>Sean</span> 👍（0） 💬（4）<div>老师提到&quot;只有在计算中涉及Joins或是聚合，spark.sql.shuffle.partitions，这个参数的设置，才会影响Shuffle Reduce阶段的并行度。如果你的作业没有Joins或是聚合计算，这个参数是个摆设&quot;
那么比如在使用spark-sql跑任务时,sql没有涉及到join或聚合操作(可以理解为sql不会涉及到shuffle),那么spark.sql.shuffle.partitions的设置就不会生效,但是要增大并行度,正确的操作因该是怎么的呢?</div>2021-08-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/11/20/9f31c4f4.jpg" width="30px"><span>wow_xiaodi</span> 👍（0） 💬（1）<div>老师，有个问题不是很清楚，假如我自定义一个case class Student，然后将数据源RDD[Row]变为RDD[Student]，第一，RDD[Sstudent]的聚合操作是消耗了Execution Memory？第二，假如我将RDD[Student].cache起来了，是消耗了Storage Memory?第三，假如执行RDD[Sstudent].filter()，flilter里的自定义函数，我new了一个array或map来处理逻辑，那么这些array或map是不是消耗user memory呢？期待老师的回答，不然我的xmind无法产生了</div>2021-07-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/92/16/558ff49c.jpg" width="30px"><span>ctf小白</span> 👍（0） 💬（2）<div>老师，想请教下，现在主要是在hive数仓的场景下使用spark，现在经常出现hive on mr可以顺利执行，hive on spark 各种内存报错执行任务失败，想问下老师针对hive on spark的场景，有什么调优的建议?谢谢老师</div>2021-06-23</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83errHypG6kuO0V0bRwp74rm8srjoQ4zXUBNNLMcY19uNdz8Ea3rOFuBJibXMHWePMwBYpGsyyxiav0ibw/132" width="30px"><span>闯闯</span> 👍（0） 💬（4）<div>请教个问题：21.3 GB of 20 GB physical memory used. Consider boosting spark.executor.memoryOverhead 参数调整前后还是报这个错误
背景：100个400M的文件
代码：orc文件复制到parquet表
spark.read.format(&quot;orc&quot;).load(path).mode(SaveMode.Overwrite).insertInto(&quot;mydb.mytable&quot;)
配置：
spark.driver.cores=1
spark.driver.memory=2G
--num-executors 2
--executor-cores 1 调整前是2
spark.executor.memory=12G 调整前是6G
spark.executor.memoryOverhead=8G 调整前是3G
spark.memory.fraction=0.8
spark.files.maxPartitionBytes=256M
spark.default.parallelism=300 不行然后调到 600，调整600后，每隔Task input size是60~90M，输出100M，按理来说这个配置每Executor(1个cpu core)就一个同时运行Task，仅仅60M的输入，内存应该是足够的
spark.sql.shuffle.partitions=300 不行然后调到 600
spark.dynamicAllocation.enabled=true
spark.dynamicAllocation.maxExecutors=16
spark.sql.autoBroadcastJoinThreshold=-1
spark.sql.adaptive.shuffle.targetPostShuffleInputSize=256MB</div>2021-05-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/f5/9d/104bb8ea.jpg" width="30px"><span>Geek2014</span> 👍（0） 💬（4）<div>老师你上一讲说tungsten是使用的Java unsafe api，这个时候就是使用的堆外内存吧？只是这时的堆外内存，不受spark.memory.offHeap.size的控制，而是spark.yarn.executor.memoryOverhead的控制？</div>2021-04-10</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIyPPFIyvytj0LJrpHicVrTqibuLWLWcR5VqzArSHZicwJYC6gKrIF6GTxx4MakS6xiaxZBCw8icCPB8wQ/132" width="30px"><span>Geek_2e6a7e</span> 👍（0） 💬（3）<div>老师描述了executor端的内存管理，但是在生产环境中，当并发高使用spark sql时，spark driver(常驻)端的OOM问题是比较严重的，因为spark sql解析、dag划分、调度开销还是比较大的？这块老师有碰到相关问题么？</div>2021-04-02</li><br/><li><img src="" width="30px"><span>Geek_73cee2</span> 👍（1） 💬（1）<div>老师每个计算任务 是指每个stage还是同一个stage的不同分区对应的任务  还是其他的。。。有点学晕了</div>2022-06-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/65/35/d0e0d2ee.jpg" width="30px"><span>夏国秦</span> 👍（1） 💬（0）<div>老师 请教一下 怎样才能够用scala去写spark写的很顺利 有不有好的学习资料推荐</div>2022-04-05</li><br/><li><img src="" width="30px"><span>Geek_197707</span> 👍（0） 💬（0）<div>老师，我是使用spark sql的， 有2个问题:
问题1.User Memory:我看你的解释是自定义数据结构，那用的是纯spark sql，基本上读的数据都是Hive表，没有自定义数据结构，是不是可以把spark.memory.fraction调大
问题2:Tungsten计划提出了使用二进制字节数组来代替JVM的java对象，我在看源码的时候，遇到了PartitionedAppendOnlyMap和ParititonedPairBuffer,他的实现也是数组，这两个是一个东西么</div>2023-02-05</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIFSW0PJiaSBqSAEBstv4OBkHtgTQgZpcLicueXlZoHiclia7pwSrntfnp5Yd8MYdhPF3Va2PsuhVHIibw/132" width="30px"><span>Geek_52bf8d</span> 👍（0） 💬（1）<div>老是，请求个问题，driver端内存，如果只是insert操作把数据写入表，那么driver端内存只要能存下广播变量差不错就可以了吧？给个1G2G足够了吧？</div>2022-09-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/27/d3/0a/92640aae.jpg" width="30px"><span>我爱夜来香</span> 👍（0） 💬（0）<div>老师,spark.sql.shuffle.partitions,这个是代表会有多少个reducer数量吧,其中一轮的并发量是不是可以理解为spark.sql.shuffle.partitions&#47;spark.executor.instance * spark.executor.cores</div>2022-05-02</li><br/><li><img src="" width="30px"><span>孙福</span> 👍（0） 💬（1）<div>老师您好，请问spark.memory.offHeap.size与spark.yarn.executor.memoryOverhead区别是什么，这两个参数在spark中使用在什么场景</div>2022-03-10</li><br/><li><img src="" width="30px"><span>孙福</span> 👍（0） 💬（1）<div>老师，请问下，如果堆内和堆外内存同时开始，什么数据放堆内，什么数据放堆外，spark是怎么决定的？</div>2022-03-10</li><br/>
</ul>