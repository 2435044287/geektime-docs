你好，我是吴磊。

在日常的开发与调优工作中，为了充分利用硬件资源，我们往往需要手工调节任务并行度来提升CPU利用率，控制任务并行度的参数是Spark的配置项：spark.default.parallelism。增加并行度确实能够充分利用闲置的CPU线程，但是，parallelism数值也不宜过大，过大反而会引入过多的调度开销，得不偿失。

这个调优技巧可以说是老生常谈了，网上到处都可以搜得到。那你知道为什么parallelism数值过大调度开销会呈指数级增长吗？调度开销具体又是指什么呢？以及，如果不想一个数值一个数值的尝试，parallelism数值究竟该怎么设置，才能以最少的时间获得最好的效果？如果你还没有答案，或者说还没有把握答对，接下来你就要好好听我讲。

这一讲，我会通过一个机器学习案例，来和你一起聊聊调度系统是什么，它是怎么工作的，从而帮助你摆脱调优总是停留在知其然、不知其所以然的尴尬境地。

## 案例：对用户兴趣特征做Label Encoding

在机器学习应用中，特征工程几乎占据了算法同学80%的时间和精力，毕竟，一份质量优良的训练样本限定了模型效果的上限和天花板，我们要讲的案例就来自特征工程中一个典型的处理场景：Label Encoding（标签编码）。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/IcDlyK6DaBrssVGlmosXnahdJ4bwCesjXa98iaapSDozBiagZTqSCok6iaktu2wOibvpNv9Pd6nfwMg7N7KTSTzYRw/132" width="30px"><span>慢慢卢</span> 👍（52） 💬（2）<div>任务调度的时候不考虑可用内存大小吗</div>2021-06-19</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIiaeebUYxl7e4jicPshDRKMbiculHUjKgZZ2ygDibn2S7bbsjeqYIdsEUdVyoryKNa43ZGnDQmWjv3ibQ/132" width="30px"><span>Geek_d794f8</span> 👍（21） 💬（6）<div>老师，数据尽量不动，比如有部分数据在节点A，那么移动计算难道不是要在节点A上启动Excutor才可以进行计算吗？但是Excutor不是在申请资源的时候就确定了在哪几个节点上启动Excutor吗？老师请指教一下</div>2021-03-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/65/75/f9d7e8b7.jpg" width="30px"><span>L3nvy</span> 👍（18） 💬（3）<div>1. 
位置信息通过特定的字符串前缀格式标识 
executor_[hostname]_[executorid]
[hostname]
hdfs_cache_[hostname]

DAGScheduler会尝试获取RDD的每个Partition的偏好位置信息，a.如果RDD被缓存，通过缓存的位置信息获取每个分区的位置信息；b.如果RDD有preferredLocations属性，通过preferredLocations获取每个分区的位置信息；c. 遍历RDD的所有是NarrowDependency的父RDD，找到第一个满足a,b条件的位置信息

DAGScheduler将生成好的TaskSet提交给TaskSetManager进行任务的本地性级别计算

2.
感觉像是Spark on Kubernetes这种场景
应该和相关存储配置有关；不太了解，猜想的话。如果是配置的Spark中间过程使用的存储是分布式存储，Node Local应该不成立；如果就是单个容器的内部空间，或者挂载到主机上的空间，应该可以成立
</div>2021-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/d4/78/66b3f2a2.jpg" width="30px"><span>斯盖丸</span> 👍（16） 💬（6）<div>老师，我这是二刷您的课程了，但我想说课程的例子没看懂。第二种用部分函数的例子里，是节约了哪步操作呢？读文件应该只要Driver读一次就够了。但是zipWithIndex生成的map呢，由于没有把它广播出去，那应该还是每个task都会被拷贝一份全量的map吧。我这样的理解对吗？如果是对的，那感觉性能提升也不应该那么明显吧…</div>2021-04-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/ea/20/78ab5f92.jpg" width="30px"><span>小学生敬亭山</span> 👍（9） 💬（1）<div>老师正例这个，先建map，再broadcast map 是不是一样的逻辑</div>2021-03-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/11/20/9f31c4f4.jpg" width="30px"><span>wow_xiaodi</span> 👍（7） 💬（1）<div>老师，请问对于第一种函数的写法和调用，为何是每个executor只处理一次，而不是对RDD里的每一条数据都去运行一遍函数，然后都加载一次map呢？请问这个函数在spark内核里如何解析和运作的呢，他如何知道里面有个map只去初始化一次，而不是每条数据都运行一次呢？</div>2021-07-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/63/6e/6b971571.jpg" width="30px"><span>Z宇锤锤</span> 👍（6） 💬（1）<div>&#47;**
   * Create a TaskLocation from a string returned by getPreferredLocations.
   * These strings have the form executor_[hostname]_[executorid], [hostname], or
   * hdfs_cache_[hostname], depending on whether the location is cached.
   *&#47; 终于找到了榜一所说的location信息</div>2021-04-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/07/a6/662bcc6b.jpg" width="30px"><span>来世愿做友人 A</span> 👍（6） 💬（3）<div>第一题：因为是为每个 partition 建立一个task，所以在建立task之前，都会获取每个partition的位置偏好信息。首先判断 rdd 是否被缓存过，通过 rddId + splitIndex 组合成 blockId 判断。如果没有，判断preferredLocations，看起来是判断是否 checkpoint 过。如果还没有，向上获取父rdd，如果是窄依赖，循环上面的判断逻辑。这里想问个问题，代码里直到task分发，似乎没有看到关于shuffle的位置偏好。比如中间有个shuffle过程，shuffle结果写在磁盘小文件，是不是下个 stage 的 task 应该发到父 stage 的所在 executor 更合适？目前没看到这个逻辑，想问问老师</div>2021-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/0c/e3/b415984e.jpg" width="30px"><span>张笑笑</span> 👍（5） 💬（3）<div>吴老师，您给的这个案例中，第二个实现方式上使用了高阶函数，看了几次，确实还是没明白，为什么使用这种写法，它只在driver端做一次计算?为什么就省去了读取文件，创建字典的开小了，迷惑中...</div>2021-09-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/1d/22/f04cea4c.jpg" width="30px"><span>Fendora范东_</span> 👍（5） 💬（1）<div>关于任务调度:
默认情况下，会先调度process local那批tasks;然后依次是node,rack,any。

在调度了最契合locality的tasks后还有空闲executor。下一批task本来是有资源可用的，但最适合执行task的executor已被占用，此时会评估下一批tasks等待时间和在空闲executor执行数据传输时间，如果等待时间大于数据传输则直接调度到空闲executor，否则继续等待。

把wait参数设置为0，则可以不进行等待，有资源时直接调度执行

这块逻辑一直有点乱。磊哥看下哪有问题嘛？</div>2021-04-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/8c/0d/42e16041.jpg" width="30px"><span>白音</span> 👍（4） 💬（5）<div>示例中关于读文件没太理解想请教下老师。
Source.fromFile 用于读本地文件，所以用spark读文件不是应该用 sc.textFile 来从hdfs目录读取? 或者示例的意思是在跑这段代码之前已经将模板文件分发到了集群每个executor本地吗？ 
</div>2021-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/5c/d7/e4673fde.jpg" width="30px"><span>October</span> 👍（3） 💬（2）<div>老师，您提到如果taskScheduler采用Fair调度策略对不同stages进行调度，可以为不同的用户配置不同的调度池，刚开始这个地方有些不理解，同一个应用程序中，怎么会有不同的用户？ 于是查了一下官网，官网貌似说的是这里的用户不是程序提交的那个用户，这里的用户对应提交job的一个线程，不知道自己理解的是否正确。 另外，如果我的理解正确的话，在同一个应用程序中使用不同的线程提交job，这个使用方式，我目前还没有见过，请问老师，大概什么场景下，会用不同线程提交job？</div>2021-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/88/7f/97459eff.jpg" width="30px"><span>站在桥上看风景</span> 👍（2） 💬（1）<div>吴老师，FIFO与FAIR应该是在使用standalone时的情况是吧，如果使用yarn的话资源调度就是FIFO、Capacity Scheduler、Fair Scheduler这三个的选择了是吧</div>2021-08-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/48/ef/4750cb14.jpg" width="30px"><span>🚤</span> 👍（2） 💬（1）<div>如果是我来写Label Encoding的话，在模板数据量不大的情况下，我会第一时间把模板数据转成Map之后广播出去。
看了老师的正例，感觉其实和广播的意思是差不多的吧</div>2021-03-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/ea/20/78ab5f92.jpg" width="30px"><span>小学生敬亭山</span> 👍（2） 💬（1）<div>老师好，为什么第二个示例（也就是正例），建hashmap这个代码就一定是在driver端执行，然后代码再进入调度系统我不是太明白？
什么时候代码会在driver端执行？
</div>2021-03-26</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIX30nQ8op79Cv4IlYYEcIP7vB7Js9Ers80kbCnqoY5B4vqDhnRuiaeiaSfYsVsPRVBsnicVTKSRQwHg/132" width="30px"><span>Geek_eba94c</span> 👍（1） 💬（1）<div>请问文中第二段代码：“&#47;&#47;函数定义
val findIndex: (String) =&gt; (String) =&gt; Int = ”中，为什么要写两次“(String) =&gt; ”？公司刚上产品线，临时学的Scala，求大佬解答，谢谢！</div>2022-01-09</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJL0JbAgWUIbJedKq4zsohMNj9AVyknp1AaVjLV6bRFDn00sOCBBRPzQAvCoIGWdAfWrJhxSV2M5g/132" width="30px"><span>阳台</span> 👍（1） 💬（3）<div>老师，spark可以并行提交job吗？比如，现在一个应用有4个job,后三个依赖第一个job的结果，能不能让第一个job结束后，后三个job并行提交到集群里面执行。而不是顺序执行每一个job?
</div>2021-10-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/a7/8f/0d8e6d34.jpg" width="30px"><span>陈子</span> 👍（1） 💬（1）<div>老师，我是 Spark 新手，有个问题请教。对于在 HDFS 上的数据，是由多个 block 组成的，这些 block 及其副本散落在多个节点上，那么 SchedulerBackend 又是如何知道将哪个 Task 调度到哪个节点上来实现 Process Local的呢？对于其他非 HDFS 分布式存储上面的数据，Spark 也可以做到移动计算吗？</div>2021-09-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/d9/67/9bca6a6e.jpg" width="30px"><span>薛峰</span> 👍（1） 💬（1）<div>很有启发，谢谢磊哥，我也想问一下如果用python的话也需要同样的操作么？
比如
dic_file=&#47;path&#47;to&#47;dic_file
def func_lower(dic_file, keyword):
  load dic_file,
  find keyword
  return index


def func_higher(keyword):
  return func_lower(dic_file,keyword)</div>2021-09-06</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/PNmB3mOQ4jTSoDMGPwp5j8a2NL1Mibu4iaebBNnuDQltb2yZ3sygJpxTHuLrG9ewCDLEialorSK3pzXBCQ3JFCZPA/132" width="30px"><span>果子</span> 👍（1） 💬（2）<div>吴老师，有个不太理解的地方，stage之间的调度是根据Yarn中的FIFO或FAIRE调度器来调度的，但是stage之间的调度本身就是有顺序的啊，比如ResultStage要依赖于ShuffMapStage，只有ShuffMapStage执行完了才能执行ResultStage，他们两者之间本身就存在依赖关系，串行执行的，为什么还需要调度器呢指定调度规则呢，谁先调度不是本身就规定好的吗？这块我是哪里理解错了吗？</div>2021-08-08</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83erGLUqIRJ2gJXIDNhfXSp4vxeb7pibQcNt1Lpicbfsvzf0ILdNZrLDfLcKZXkTEhy8U0ewWDeZ0b5Pg/132" width="30px"><span>Geek_fb1b68</span> 👍（1） 💬（1）<div>看了这篇 总结是spark drive端coding尽量产生的是计算关系 让计算关系在excutor端lazy触发</div>2021-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg" width="30px"><span>西南偏北</span> 👍（1） 💬（1）<div>1. Task的本地性是由Partition分区的本地性来决定，因为task和partition是一对一的关系。根据源码，翻译一下自己觉得比较通俗的理解（如有错误还望老师指正）就是：如果是读取数据源（如HDFS），那么会尽可能在哪些已启动Executor且存在要读取数据的节点上来启动Task；如果是计算过程的中间结果数据（有可能在内存，也有可能在磁盘），会尽可能地在有空闲资源并满足条件的Executor&#47;节点上启动Task
2. 第二个问题中的场景没怎么接触过，要看存储环境和计算环境是不是相同的宿主机吗？</div>2021-05-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/df/e5/65e37812.jpg" width="30px"><span>快跑</span> 👍（1） 💬（1）<div>所以”数据不动代码动“仅仅说的是同个Stage的前提。如果不是一个Stage，必定有shffle，数据一定会动的。
这样子理解？</div>2021-04-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/be/93/247fb2c8.jpg" width="30px"><span>hel</span> 👍（1） 💬（1）<div>在spark on  yarn上spark向yarn申请资源，yarn是会返回所有空闲可用资源然后spark自己根据本地性原则来挑选的吗</div>2021-04-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/3c/64/09510f36.jpg" width="30px"><span>牛红灯</span> 👍（1） 💬（4）<div>老师,只有触发action算子的才在driver上运行吧,第二种方法中也没有提到是action呀,为什么读文件是在driver上呢</div>2021-03-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/d8/d5/00f31ac9.jpg" width="30px"><span>觉醒</span> 👍（1） 💬（5）<div>吴老师,
偏函数是将多个操作转换为一个操作了吗,
如果不使用偏函数,就会造成dag 将操作拆分成多个 stages
造成调度的负载升高,可以这样理解吗</div>2021-03-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/b2/ef/a0b79b16.jpg" width="30px"><span>欧阳硕</span> 👍（0） 💬（1）<div>例子中的两种代码其实从返回形式就可见一斑了：方法一根据driver端路径地址返回一个int，意思就是每次调用都需要全扫描该路径才能得到返回结果；而第二种方法返回的是一个从string到int的映射关系，也就是说调用只依赖传入的string，也就避免了全盘扫描.换句话说，等同于将这个集合在不同节点上的广播加调用的封装.</div>2022-03-03</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/icJzoUc02ECdBbFgGzVIwYfpRgL3TXuRRE5GsDqZFmAlAAm1KUQS1rHewgj5FB4TChovo3YaceicEZE2MgZJ1ftw/132" width="30px"><span>Geek_eb29a4</span> 👍（0） 💬（1）<div>&#39;’ 省去了扫描模板文件、建立字典的开销 &#39;&#39;
高阶函数为什么有这个效果？ 这个要参考什么学习资料？</div>2021-12-11</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/icJzoUc02ECdBbFgGzVIwYfpRgL3TXuRRE5GsDqZFmAlAAm1KUQS1rHewgj5FB4TChovo3YaceicEZE2MgZJ1ftw/132" width="30px"><span>Geek_eb29a4</span> 👍（0） 💬（1）<div>吴老师， 第二个是因为下面代码变化 吗？ 那解析下这两个分别带来什么提高吗？


val searchMap = lines.zip(0 until lines.size).toMap
(interest) =&gt; searchMap.getOrElse(interest, -1)

val partFunc = findIndex(filePath)</div>2021-12-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/cb/4f/7466a488.jpg" width="30px"><span>Pengyuan Li</span> 👍（0） 💬（1）<div>跪求pyspark代码， 完全看不懂scala</div>2021-12-09</li><br/>
</ul>