你好，我是吴磊。

上节课，我们探讨了性能调优的必要性，结论是：尽管Spark自身运行高效，但作为开发者，我们仍然需要对应用进行性能调优。

那么问题来了，性能调优该怎么做呢？面对成百上千行应用代码、近百个Spark配置项，我们该从哪里入手呢？我认为，要想弄清性能调优怎么入手，必须先得搞明白性能调优的本质是什么。

所以今天这节课，咱们就从一个先入为主的调优反例入手，带你一起探讨并归纳性能调优的本质是什么，最终帮你建立起系统化的性能调优方法论。

## 先入为主的反例

在典型的ETL场景中，我们经常需要对数据进行各式各样的转换，有的时候，因为业务需求太复杂，我们往往还需要自定义UDF（User Defined Functions）来实现特定的转换逻辑。但是，无论是Databricks的官方博客，还是网上浩如烟海的Spark技术文章，都警告我们尽量不要自定义UDF来实现业务逻辑，要尽可能地使用Spark内置的SQL functions。

在日常的工作中，我发现这些警告被反复地用于Code review中，Code reviewer在审查代码的时候，一旦遇到自定义的UDF，就提示开发的同学用SQL functions去重写业务逻辑，这几乎成了一种条件反射。
<div><strong>精选留言（15）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/11/5c/d7/e4673fde.jpg" width="30px"><span>October</span> 👍（24） 💬（23）<div>老师讲到可以通过运行时诊断来定位系统瓶颈，可借助于spark ui以及系统级监控工具，但是我依然不清楚怎样查看spark ui的各个指标，怎样查看每个应用程序的各种硬件负载，不知道老师后边的课程有没有相关内容</div>2021-03-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/fb/69/979deb1d.jpg" width="30px"><span>seed</span> 👍（20） 💬（3）<div>1. 还遇到的调优手段：直接从网上copy过来一些参数，在没有理解真正的原理的情况下，先怼上去，跑一下，任务时间缩短了就算调优了
2. 对于性能调优的收敛状态，需要量化；如何量化这些指标？
其实就是从我们需要调优的点出发；文中提到：从硬件的角度来看，计算负载划分为计算密集型、内存密集型和 IO 密集型。
首先需要确认我们的任务属于哪一类型的任务或者说任务的短板在哪一块
其次从Spark任务执行时长，系统的cpu&#47;memory&#47;io等方面按照任务类型有针对性的进行监控
然后从应用代码和Spark配置项两个方面入手进行调优
最后在每次调优后重点关注任务时间是否下降，对比下降前后系统的cpu&#47;memory&#47;io的使用量，就可以做到量化</div>2021-03-17</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKkpApOjdIb81ZHxeAup1IGH97eaD8oiawlCtUJdvct1AP6UfmmpYlE6r25tNM5cgOCgM3oAzpic5Aw/132" width="30px"><span>Sandy</span> 👍（10） 💬（1）<div>老师，已经学完课了，发现没有讲运行时诊断分析析定位性能瓶颈呢？</div>2021-07-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/e8/69/5c3be4c0.jpg" width="30px"><span>裘元飞</span> 👍（10） 💬（1）<div>希望老师可以稍微讲一讲例如spark UI等工具如何监控指标等，主要很多时候都不知道有这些工具的存在。</div>2021-03-18</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoribOUgcicu1sOqZZVtPqpSDSS43vicxW0GesxQeBRjUC47CzulKSzYNj2aMg9YOZDdjPdAZxS3jNcQ/132" width="30px"><span>Geek_32772e</span> 👍（9） 💬（1）<div>吴老师，我没听说过有文章说不建议使用UDF，您能给我发几个链接证实下吗？</div>2021-05-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/47/ba/d36340c1.jpg" width="30px"><span>Shockang</span> 👍（9） 💬（3）<div>王家林，段智华，夏阳编著的《Spark大数据商业实战三部曲》里面提到——大数据性能调优的本质是什么?答案是基于硬件的调优,即基于CPU、Memory、I&#47;O(Disk&#47;Network)基础上构建算法和性能调优! 无论是Hadoop,还是Spark,还是其他技术,都无法逃脱。  老师也在文章中提到——性能调优的最终目的，是在所有参与计算的硬件资源之间寻求协同与平衡，让硬件资源达到一种平衡、无瓶颈的状态。 我认为有异曲同工之妙！ </div>2021-03-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/d9/67/9bca6a6e.jpg" width="30px"><span>薛峰</span> 👍（4） 💬（1）<div>第一个估计大家都有过那样的经验
第二个问题，我用过两种方法：
1. 用Prometheus+grafana监控系统利用情况。结果意外发现spark不会自动清除应用目录，导致过段时间磁盘都被塞满了。不知道是不是因为spark配置的错误导致的？
2. 用不同的参数跑同样的数据N次，然后平均处理时间，看看哪种最短。但经常会发现这个运算时间有较大幅度的浮动，不知道是不是跟aws系统整体的忙闲有关。</div>2021-04-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/8e/a7/92d1b90e.jpg" width="30px"><span>浩然</span> 👍（2） 💬（1）<div>我想讨论一个问题。那个38分钟的执行结果，资源配置上很足，但是执行效率不好。能认为是把CPU用的太多了，资源调度有问题？比如CAS自旋锁以及锁升级？</div>2021-10-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/65/75/f9d7e8b7.jpg" width="30px"><span>L3nvy</span> 👍（2） 💬（1）<div>1. 不知道怎么分析性能瓶颈问题，按照自己的理解把业务逻辑Spark SQL重写了一遍，虽然时间下降了，但是引入了数据质量等问题。
2. 需要监控组件对机器的状态和系统metrics进行收集对比优化效果</div>2021-03-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg" width="30px"><span>西南偏北</span> 👍（1） 💬（1）<div>1. 最初在写Spark应用的时候，网上搜一些调优手段，动不动就是让增加内存、增加CPU，什么问题都是增加内存CPU
2. 如果是搭建的CDH平台的话，可以结合Spark WebUI和Cloudera Manager Web UI做一些监控资源的对比，比如任务运行时间、cpu使用率、内存使用率等指标。另外，也可以安装Prometheus+Grafana进行更精细化的监控。

希望老师在之后的篇章中，讲具体调优方法的时候，能多结合一下原理和源码来分析下为什么要这样调优。</div>2021-05-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/1d/22/f04cea4c.jpg" width="30px"><span>Fendora范东_</span> 👍（1） 💬（1）<div>磊哥说到了SQL functions指的是sparkSQL内置函数吧。
还提到了udf和sql functions的性能差异，那如果我用内置函数方式开发udf，理论上性能就是一样的？</div>2021-04-02</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKeaiat2pBEQlDDyUVvIAagP0zyUwEAHeaGEVaj9s3kl4AP4ZNsZqERSY0KCkIJK0n5Nh5s7X7pgmw/132" width="30px"><span>Gnnn</span> 👍（1） 💬（1）<div>简单的增加并行度很多时候是没有太大效果的</div>2021-03-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/68/86/3ef20498.jpg" width="30px"><span>西关八号</span> 👍（0） 💬（1）<div>希望老师可以稍微讲一讲spark UI等工具如何监控指标</div>2021-06-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/42/f3/e945e4ac.jpg" width="30px"><span>sparkjoy</span> 👍（0） 💬（1）<div>老师，spark作业运行的网络性能怎么监控？目前我们只有shuffle读写量和速率相关，还有其他手段吗？谢谢！</div>2021-03-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/ce/53/d6a1f585.jpg" width="30px"><span>光羽隼</span> 👍（0） 💬（1）<div>问题一：以前会从同时代码中直接复制配置项；直接在代码某些地方使用hint
问题二：性能调优的过程对于每个任务来说，情况不同，可能所使用的调优方式也不同，而且随着任务中使用的数据量变化，调优的方式也会随之变化。量化的点我觉得有两个，运行时长和稳定性。时长是否降低到合适的范围，任务在每天的运行过程中是否稳定</div>2023-10-13</li><br/>
</ul>