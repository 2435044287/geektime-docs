你好，我是吴磊。

在平衡不同硬件资源的时候，相比CPU、内存、磁盘，网络开销无疑是最拖后腿的那一个，这一点在处理延迟上表现得非常明显。

下图就是不同硬件资源的处理延迟对比结果，我们可以看到最小的处理单位是纳秒。你可能对纳秒没什么概念，所以为了方便对比，我把纳秒等比放大到秒。这样，其他硬件资源的处理延迟也会跟着放大。最后一对比我们会发现，网络延迟是以天为单位的！

![](https://static001.geekbang.org/resource/image/c1/a9/c1e4926d3748bdc98a5317fcf4e5b2a9.png?wh=1749%2A711 "不同硬件资源处理延迟对比")

因此，要想维持硬件资源之间的平衡，尽可能地降低网络开销是我们在性能调优中必须要做的。今天这一讲，我就按照数据进入系统的时间顺序，也就是数据读取、数据处理和数据传输的顺序，带你去分析和总结数据生命周期的不同阶段有效降低网络开销的方法。

## 数据读写

对于绝大多数应用来说，第一步操作都是从分布式文件系统读取数据源。Spark支持的数据源种类非常丰富，涉及的存储格式和存储系统可以说是五花八门。

![](https://static001.geekbang.org/resource/image/2a/c3/2a1e6190f6e746e97661bf6f09941cc3.jpeg?wh=622%2A825 "存储格式与存储系统")

这么多存储格式和外部存储系统交叉在一起又会有无数种组合，并且每一种组合都有它的应用场景。那么，我们该怎么判断网络开销会出现在哪些场景下呢？其实，**不管是什么文件格式，也不管是哪种存储系统，访问数据源是否会引入网络开销，取决于任务与数据的本地性关系，也就是任务的本地性级别**，它一共有4种：
<div><strong>精选留言（10）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/12/1d/22/f04cea4c.jpg" width="30px"><span>Fendora范东_</span> 👍（4） 💬（1）<div>有点疑问
 1.没有RDD缓存的情况下，是不是最好的任务级别是node_level，而且是最底下包含scan操作的tasks是这个级别？
因为:最开始数据全在磁盘，第一个stage生成的task本地性级别最好为node_level，后面的stage生成的task都是需要进行shuffle，最起码也是rack_node。
换句话说，是不是只有前一个action触发了RDD缓存操作，后一个action里面的任务才有可能是process_level呢？
2.当RDD被缓存了，由BlockManager进行管理，满足了「有个人或有个地方记录了什么数据存储在什么地方」，这样后续生成Task时就可以有process_local级别的任务出现了。
不知道理解的对吗？</div>2021-04-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/20/d6/b9513db0.jpg" width="30px"><span>kingcall</span> 👍（3） 💬（1）<div>DataFrame 要想实现map 端预聚合只能靠优化器自己了吧比较抽象层次比较高了，灵活度就降低了，但是RDD 的话还是可以自己实现实现的，虽然reduceBykey可以预聚合，但是在这个例子中不合适，不能替换collect_list，对于RDD 我们呢可以使用aggregateByKey
    def localDistinct(set: Set[String], b: String): mutable.Set[String] = {
      set.add(b)
      set
    }
    def combineDistinct(set1: Set[String], set2: Set[String]): mutable.Set[String] = {
      set1 ++ set2
    }
    rdd.map(o =&gt; (o.id, o.name)).aggregateByKey(Set[String]())(localDistinct, combineDistinct).foreach(println(_))</div>2021-04-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/0e/60/9b9e28f8.jpg" width="30px"><span>really_z</span> 👍（2） 💬（1）<div>老师，你好，想问一下本地性级别是在哪个环节确定的呢？</div>2021-07-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/d1/f6/d75afb79.jpg" width="30px"><span>在路上</span> 👍（1） 💬（1）<div>老师好。请教下，spark在申请executor时候有没有考虑读取数据时候的数据本地性呢，实际生产中集群特别大，在生成hadooprdd的时候大概率可能不能数据和executor在同一个机器甚至机架上吧？</div>2021-12-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/4e/29/adcb78e7.jpg" width="30px"><span>静心</span> 👍（1） 💬（1）<div>老师，文中的案例是要获取各个群组的去重兴趣列表，我觉得实现该需求就必须要基于groupId进行分组后再进行兴趣列表去重。那我们应该怎样在map端使用collect_set实现该需求以减少shuffle数据量呢？</div>2021-05-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg" width="30px"><span>西南偏北</span> 👍（1） 💬（1）<div>1. org.apache.spark.sql.functions中用来collect就两个函数，一个collect_list可以有重复元素，一个collect_set元素唯一
2. 好像没怎么理解问题的意思哈哈，聚合的话无非就是计数、就和、平均值、最大值最小值这些吗
3. cache的时候，数据以序列化的形式进行缓存（比如，StorageLevel.MEMORY_ONLY_SER），数据变小了，是不是也可以间接减小网络传输的开销，但是反序列化也会消耗更多的cpu</div>2021-05-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/f2/f5/b82f410d.jpg" width="30px"><span>Unknown element</span> 👍（0） 💬（1）<div>老师您好 我有几个问题：
1. 关于 Kryo Serializer 在哪里可以看到它已经支持的数据类型呢（就是不需要注册可以直接序列化）？
2. 我们是spark with hive的部署方式，脚本是用hive sql开发的，而不是 dataframe API，那在哪里可以找到hql中的函数&#47;语句和 dataframe API 中算子的对应关系呢？比如hql中count(a)在底层会被转化为reduceByKey去执行？
3. 对于 @在路上 同学的问题的回答，您好像是复制的上一节的一个回答，但是好像并没有解答他的问题呢。。我也比较好奇这个问题的答案是什么
谢谢老师！</div>2022-01-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/98/4d/582d24f4.jpg" width="30px"><span>To_Drill</span> 👍（0） 💬（1）<div>问题三: 对数据源进行压缩在读取数据阶段可以降低网络开销，在shuffle阶段落盘的时候采用压缩可以降低shuffle阶段的网络开销，不过CPU的负担就变重了，还是得结合具体的场景来抉择</div>2021-10-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/44/93/2d3d5868.jpg" width="30px"><span>Jay</span> 👍（0） 💬（2）<div>文中提到“&#39;RDD API使用频率越来越低”。
公司一直还用的是Rdd, 我也一直没学过spark sql。是否有必要切到spark sql呢？</div>2021-04-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/a2/4b/b72f724f.jpg" width="30px"><span>zxk</span> 👍（0） 💬（1）<div>问题一: reduceBykey 可以在 map 端预聚合
问题二：在 map 端聚合的场景，比如求某个 key 的数量，求和等，业务方面来看凡是预聚合不影响正确性的都可以先在 map 端做聚合
问题三: 在读取数据源阶段，可以尽可能将 executor 落在数据同节点上，实现node local，再次就是同个机架下，实现 rack local。数据Shuffle时，可以考虑使用Broadcast代替，或者先在 map 端预聚合减少数据量，以及只传输时用到的字段。</div>2021-04-26</li><br/>
</ul>