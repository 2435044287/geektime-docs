你好，我是吴磊。

从今天开始，我们就进入通用性能调优篇的学习了。这一篇，我们会从基本的开发原则、配置项、Shuffle以及硬件资源这四个方面，去学习一些通用的调优方法和技巧，它们会适用于所有的计算场景。

今天这一讲，我们先从应用开发的角度入手，去探讨开发阶段应该遵循的基础原则。**如果能在开发阶段就打好基础、防患于未然，业务应用的执行性能往往会有个不错的起点**。开发阶段就像学生时代的考卷，虽然有很难的拔高题，但只要我们稳扎稳打，答好送分的基础题，成绩往往不会太差。

这些“基础题”对应的就是工作中一些“常规操作”，比如Filter + Coalesce和用mapPartitions代替map，以及用ReduceByKey代替GroupByKey等等。我相信，你在日常的开发工作中肯定已经积累了不少。但是据我观察，很多同学在拿到这些技巧之后，都会不假思索地“照葫芦画瓢”。不少同学反馈：“试了之后怎么没效果啊？算了，反正能试的都试了，我也实在没有别的调优思路了，就这样吧”。

那么，这种情况该怎么办呢？我认为，最重要的原因可能是你积累的这些“常规操作”还没有形成体系。结合以往的开发经验，我发现这些“常规操作”可以归纳为三类：
<div><strong>精选留言（19）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/21/00/3f/a0f84788.jpg" width="30px"><span>Sean</span> 👍（31） 💬（1）<div>老师上文提到了&quot;使用 Parquet、ORC 等文件格式，去坐享谓词下推带来的数据读取效率&quot;,应该如何理解,莫非谓词下推依耐与于文件存储格式吗</div>2021-08-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/d4/78/66b3f2a2.jpg" width="30px"><span>斯盖丸</span> 👍（8） 💬（1）<div>老师如果两个超大表，但是一张表重复数据很多，那是不是先做distinct，再join会好一些？毕竟虽然distinct会shuffle但最后join的数据量也是成倍减少的</div>2021-03-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/65/0f/7b9f27f2.jpg" width="30px"><span>猿鸽君</span> 👍（5） 💬（1）<div>https:&#47;&#47;github.com&#47;apache&#47;spark&#47;pull&#47;21086。老师您好，请问老师知道这个可能是什么原因导致的吗？我用2.2.0版本就会出这个错。通过spark ui也看不到有task failed。看起来就像被强制终止了。</div>2021-05-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/94/7e/98c2a436.jpg" width="30px"><span>John.Xiong</span> 👍（4） 💬（1）<div>老师，您说的两个表通过把多个字段拼接后hash成一个字段关联，但是hash不是只有碰撞问题吗？万一两个不同组合弄成了一个hash值不是会导致问题吗？我对碰撞不太熟悉，可能说的不对，请老师指教
</div>2021-06-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/37/d0/26975fba.jpg" width="30px"><span>西南偏北</span> 👍（4） 💬（1）<div>其实老师总结的已经很全面了。这里推荐两个比较通用的调优小技巧：
1、 Spark默认使用的是Java serialization序列化方式，我们可以考虑使用Kryo serialization序列化的方式，不过会有一些限制，比如不是支持所有的序列化类型，需要手动注册要序列化的类。
2、 尽量使用占用空间小的数据结构。比如，能使用基本数据类型的就用基本数据类型，不要用对应的包装类（int——&gt;Integer），能用int的就不要用String，String占用的空间要大的多。</div>2021-05-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/5c/d7/e4673fde.jpg" width="30px"><span>October</span> 👍（4） 💬（5）<div>享受Tungsten带来的堆外内存的红利时，除了使用dataframe或dataset API之外，还需要在sparkconf中开启堆外内存吧</div>2021-03-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/90/c5/ee3d6247.jpg" width="30px"><span>Cohen</span> 👍（3） 💬（3）<div>老师，能否弄个GitHub 配套代码案例</div>2021-04-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/fd/86/09bf9657.jpg" width="30px"><span>蔡其斌</span> 👍（1） 💬（1）<div>为什么Spark AQE优化默认是关闭的</div>2022-03-03</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/o7oEtlsQ2VRiczVpDGO4GiaUFUT8p1nAbO2IUzWNM1nz3EHPkBJNicnO01Ah6X9oKWQ3Jiay7PUmxqRFNsu5ut2oEQ/132" width="30px"><span>balabala</span> 👍（1） 💬（1）<div>老师你好。您在单机思维中提到“类似这种忽视实例化 Util 操作的行为还有很多，比如用临时变量缓存数据转换的中间结果等等”。请问可以举例一下吗？</div>2021-10-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/22/8e/67/afb412fb.jpg" width="30px"><span>Sam</span> 👍（1） 💬（2）<div>磊哥好~ 请教个基础问题，文章有一段话：“用哈希算法生成一个固定长度的字节序列，把它作为新的 Join key”。我的理解是把右表的字段名用哈希算法形式拼接起来，我在想新的Join key怎么能跟左表的key保持关联关系呢？我在用join连接表的话，这个新的key起到作用关联的作用？

希望得到磊哥的解惑！~~</div>2021-06-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/23/b5/d4/147abdaa.jpg" width="30px"><span>乐意至极</span> 👍（1） 💬（3）<div>老师，你好。我在实际工作中遇到这个问题ERROR RetryingBlockFetcher: Exception while beginning fetch of 520 outstanding blocks (after 1 retries) java.io.IOException: Failed to connect to &lt;HOST&#47;IP&gt;:38000 持续了12小时
我有以下观察：
1，这个&lt;HOST&#47;IP&gt;上的Executor已经SUCCESS了
2，这个持续了12小时的task是process local
3，无长时间gc，也无明显倾斜

排查了很久。。希望老师能给点指点~</div>2021-03-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/87/4b/16ea3997.jpg" width="30px"><span>tiankonghewo</span> 👍（0） 💬（1）<div>两个distinct的疑问
spark sql在执行之前,不是有一个优化环节吗? 为什么这里不能自动优化掉?
filter应该是在优化范围内的,自动提升到最前边</div>2021-11-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/39/68/56dfc8c0.jpg" width="30px"><span>子兮</span> 👍（0） 💬（1）<div>老师，看了你的课，受益匪浅，每篇文章下的评论都很有价值，值得反复琢磨，期待老师有更多代码优化案例，如果有机会看到老师出源码讲解学习的课程就更好了</div>2021-10-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/d4/78/66b3f2a2.jpg" width="30px"><span>斯盖丸</span> 👍（0） 💬（1）<div>老师yarn上实际跑的资源总是和自己spark-submit里提交的资源不一样，会略小一些，这是为什么呢？</div>2021-04-01</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKerOHGs8VAMWj0ysxZpTPcARHEITiaH8YDJR7aoDNYhRpbLsZ0pJdJXIfzvR7u06iaKPBUoWfic5Zww/132" width="30px"><span>Geek_qsftko</span> 👍（0） 💬（1）<div>所以，开启AQE之后，就不用手动处理数据倾斜了？完全的扔给Spark是嘛</div>2021-03-31</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJN8s3YnzyDRCeg73yzglRgQgk581uIY1FRFO01GibMro4Mbxk58rRgulZTKrSGnd8ZD6RHY8uQj2A/132" width="30px"><span>蠟筆小噺</span> 👍（0） 💬（1）<div>在非Shuffle部分用RDD，在遇到Shufle部分调用toDF转换为DataFrame，这种方式可取吗？</div>2021-03-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/96/17/200c21f0.jpg" width="30px"><span>狗哭</span> 👍（1） 💬（0）<div>老师您好，用临时变量缓存数据中间结果是怎样的呢？为什么会有影响呢？</div>2022-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/87/4b/16ea3997.jpg" width="30px"><span>tiankonghewo</span> 👍（1） 💬（0）<div>https:&#47;&#47;www.cnblogs.com&#47;tgzhu&#47;p&#47;15211820.html
join分析：shuffle hash join、broadcast hash join
这篇文章讲的不错</div>2021-11-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/74/39/79d2fe9a.jpg" width="30px"><span>、for</span> 👍（0） 💬（0）<div>&quot;由于数据分布不均衡，其中 3 个分区的数据量很少。对 CPU 来说，这 3 个小分区产生的调度开销会是一笔不小的浪费&quot; 关于AQE开启之前这句话的理解：未开启AQE的话，shuffle后没生成的一个partition, 无论数据量大小，都会是一个task由executor的一条线程独立地去处理。对吗？</div>2023-11-30</li><br/>
</ul>