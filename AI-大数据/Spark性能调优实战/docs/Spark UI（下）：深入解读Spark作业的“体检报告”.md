你好，我是吴磊。

在上一讲，我们一起梳理了Spark UI的一级入口。其中Executors、Environment、Storage是详情页，开发者可以通过这3个页面，迅速地了解集群整体的计算负载、运行环境，以及数据集缓存的详细情况。而SQL、Jobs、Stages，更多地是一种罗列式的展示，想要了解其中的细节，还需要进入到二级入口。

沿用之前的比喻，身为“大夫”的开发者想要结合经验，迅速定位“病灶”，离不开各式各样的指标项。而今天要讲的二级入口，相比一级入口，内容会更加丰富、详尽。要想成为一名“临床经验丰富”的老医生，咱们先要做到熟练解读这些度量指标。

![图片](https://static001.geekbang.org/resource/image/56/d2/56563537c4e0ef597629d42618df21d2.png?wh=718x52 "Spark UI导航条：一级入口")

所谓二级入口，它指的是，**通过一次超链接跳转才能访问到的页面**。对于SQL、Jobs和Stages这3类入口来说，二级入口往往已经提供了足够的信息，基本覆盖了“体检报告”的全部内容。因此，尽管Spark UI也提供了少量的三级入口（需要两跳才能到达的页面），但是这些隐藏在“犄角旮旯”的三级入口，往往并不需要开发者去特别关注。

接下来，我们就沿着SQL -&gt; Jobs -&gt; Stages的顺序，依次地去访问它们的二级入口，从而针对全局DAG、作业以及执行阶段，获得更加深入的探索与洞察。
<div><strong>精选留言（10）</strong></div><ul>
<li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTL9ia0mXYEzfkZdhOAqnujnQSAcFY4atjHvzLrF2BeKiay1mPqwxHVszmpj0aSNZWSAnT8O2iblMB0SA/132" width="30px"><span>Geek_d50b3e</span> 👍（0） 💬（0）<div>我有个问题。我是2个大表关联shullfe 的时候看到很多executor都是空就executor 有数，倾斜了是怎么回事？</div>2022-03-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/77/16/96ef147f.jpg" width="30px"><span>王欢</span> 👍（6） 💬（1）<div>spark shuffle read中max和median的比值大小，可以衡量数据倾斜程度</div>2021-10-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/b7/40/979af7cc.jpg" width="30px"><span>敬彦辉</span> 👍（4） 💬（2）<div>Spill（Memory）和 Spill（Disk）这两个指标还是不太清楚，之前遇到过一个任务，最大执行时间的task，它的Spill(Memory)有3g，Spill(Disk)只有200m，这些数据是内存存了3g，内存存不下又溢出到磁盘吗？这种场景该怎么优化，老师帮忙给解答下</div>2021-10-22</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIO6eRuuA6V34kREveXkNaebicNzy3oUvEM3t48ehMRJIuCnYNe9B54VuAndjo1cZZ5ykHDHL8ZlhA/132" width="30px"><span>onee</span> 👍（4） 💬（2）<div>老师，有几个疑问。Peak memory是单个executor堆内存的使用峰值还是单executor内execution memory的使用峰值？其次，Peak memory Total是stage所有task的峰值之和吗？</div>2021-10-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/00/3f/a0f84788.jpg" width="30px"><span>Sean</span> 👍（3） 💬（2）<div>磊哥,有个疑问想要请教下,您说的到的 &quot;Peak memroy,某个Job在某个时刻对于集群内存的消耗,比然这个时刻不会包含所有task,而是这个时刻正在runing的task&quot; 对于这一点我个人理解为针对这个时刻因该是numActiveTasks最大时所消耗的内存,也即配置参数所示最大为6个axtivetask时的消耗peak memory是最大的(这个磊哥截图ui 上的配置executor=2,cores=3,和磊哥最开始表格里给出的executor=3g不一致)
如果这里理解没错的话,那么根据案例中peak memory=18.8GB来说,可调整executor.memroy=10G(18.8&#47;6≈3.13G,3.13 * 3 = 9.39G,当然这里我省略了Storage,User,Reserved的消耗) 我个人理解就是这样的,不知道是否正确,求磊哥解惑,感谢~</div>2021-10-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/00/3f/a0f84788.jpg" width="30px"><span>Sean</span> 👍（0） 💬（2）<div>问下磊哥,发现有的任务Peak Execution Memory为0这种情况会是什么原因导致呢?任务执行倒是正常</div>2021-10-25</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIO6eRuuA6V34kREveXkNaebicNzy3oUvEM3t48ehMRJIuCnYNe9B54VuAndjo1cZZ5ykHDHL8ZlhA/132" width="30px"><span>onee</span> 👍（0） 💬（1）<div>老师，sparksql执行计划页中的peak memory total(min,mid,max)，指的是peak execution memory吗？</div>2021-10-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/96/17/200c21f0.jpg" width="30px"><span>狗哭</span> 👍（0） 💬（1）<div>老师太给力了</div>2021-10-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/55/66/8cc4ee54.jpg" width="30px"><span>Geek_6048ff</span> 👍（2） 💬（0）<div>Event Timeline中空白比较多是代表啥意思呀</div>2022-06-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/c4/f7/3cff78f1.jpg" width="30px"><span>〆、维生素ゝ</span> 👍（0） 💬（0）<div>您好，请教一个问题，stage上的task数量可以精确计算出来吗？我的task read是空 会是啥原因呀

</div>2022-06-14</li><br/>
</ul>