你好，我是黄佳。

开源模型的微调大家耳熟能详，但是很少有人了解OpenAI的GPT模型也可以微调。今天我们就来探讨如何微调OpenAI的闭源模型，以及使用Function Calling进行特定领域微调的流程和要点。

OpenAI的GPT系列模型经过海量数据的预训练，已经具备了强大的自然语言理解和生成能力。但面对特定领域的应用场景，预训练模型难免会有知识盲区和表现欠佳的情况。这时候，我们就需要用特定领域的数据对模型进行微调，让模型更加贴合具体的任务需求。

微调后的模型可以更好地理解特定领域的术语、口吻和逻辑，生成更加准确、专业的内容。比如在法律领域微调后，模型可以更好地分析案情，援引法条，给出有说服力的法律意见。因此，微调 GPT 家族的模型还是能进一步拓展 OpenAI 这一系列模型的应用场景和落地空间。

## OpenAI 的 Fine-Tuning 基本流程

OpenAI为GPT-3.5系列的模型提供了 Fine-Tuning API，我们可以用自己的数据对模型进行微调，至于GPT-4系列的模型，只有gpt-4-0613可以进行实验性质的微调。

主要步骤如下：

1. 准备符合要求的微调数据集。微调数据要采用 JSONL 格式，每行代表一个训练样本。每个样本是一个 JSON 对象，主要包含以下字段：