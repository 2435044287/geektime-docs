你好，我是黄佳。

今天，我们来探索大语言模型在另一个传统自然语言处理应用场景中的突破，就是长文档的总结和评估，这也是大语言模型的一个重要应用方向。我们将探讨如何利用大语言模型的强大能力，实现高质量的文档总结，并对总结结果进行全面评估。

## 新一代大模型出现之前的文档总结

文档总结是一个经典课题。传统的文档总结方法通常基于统计学和信息检索理论，如提取关键词、句子排序等。这些方法虽然简单高效，但在处理长文档、复杂语义时往往力不从心。

老一代的大模型文档总结通常采用两种范式：文本抽取式（Extractive）和摘要生成式（Abstractive）。

- 抽取式方法是从原文中选取关键句作为摘要。比如基于BERT的文档总结就常常使用这个范式。
- 生成式方法则根据对原文的理解，生成新的摘要文本。比如基于初代GPT、T5、BART等生成式模型的文档总结就基于这个范式。

下面，让我带着你用一个经典“老”NLP模型 T5，来做一个论文的摘要总结。论文我们随便选择一个就可以了，这里，我选择的是 [Tiny Llama](https://arxiv.org/abs/2401.02385) 这篇论文，先看看它主要说了什么。

![图片](https://static001.geekbang.org/resource/image/09/7f/0934ef4b0f0d7faa77a3411a0b2cd27f.png?wh=1286x692)

这篇论文介绍的TinyLlama是一个1.1B参数的小型语言模型，在约1万亿Token上预训练了3个Epoch。它采用了Llama 2的架构和分词器，并利用了开源社区贡献的各种进展（如FlashAttention）以提高计算效率。尽管规模相对较小，但TinyLlama在一系列下游任务中表现出色，优于具有相似规模的现有开源语言模型。