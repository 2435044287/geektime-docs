你好，我是黄佳。

今天我们将探讨一个在生成式 AI 应用开发过程中至关重要的话题：如何利用 Moderation API 对生成内容进行审核，以确保内容的安全与合规性。

随着大语言模型的快速发展，开发者可以利用大模型提供的 API 接口快速构建各种智能应用，例如聊天机器人、内容生成平台等。然而，语言模型生成的内容并非总是符合我们的预期，有时甚至会包含一些不恰当、有害或违规的内容。这不仅会影响用户体验，还可能给企业带来法律和声誉风险。因此，对生成内容进行安全审核就显得尤为必要，而且是开发产品级别系统，或者把大模型投入生产时的必备环节。

OpenAI 提供的 Moderation API 为这一问题提供了一套简洁有效的解决方案。通过调用 Moderation API，我们可以自动检测文本中的各类风险内容，包括仇恨言论、威胁、色情、暴力等。Moderation API 基于一个经过海量数据训练的分类模型，可以准确识别出10多种类型的有害内容。

## 简单的 Moderation API 示例

使用 Moderation API 非常简单，只需向接口发送一个 HTTP 请求，并在请求体中包含待检测的文本即可。

以下是一个使用 Python 调用 Moderation API 的示例。