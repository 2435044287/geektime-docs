你好，我是徐文浩。今天这一讲，我们接着来学习GFS论文中第二个重要的设计决策，也就是根据实际的硬件情况来进行系统设计。

![图片](https://static001.geekbang.org/resource/image/8a/a3/8aaaa025cffe70a59925a4887ffae8a3.jpg?wh=1920x884)

大数据系统本就是为“性能”而生的，因为单台服务器已经满足不了我们的性能需要。所以我们需要通过搭建成百上千台服务器，组成一个大数据集群。然而，上千台服务器的集群一样有来自各种硬件性能的限制。

在单台服务器下，我们的硬件瓶颈常常是硬盘。而到了一个分布式集群里，我们又有了一个新的瓶颈，那就是**网络**。

那么在这一讲里，我们就来看看网络层面的硬件瓶颈，是如何影响了GFS的设计的。在学完这一讲之后，希望你能够理解，**任何一个系统设计，都需要考虑硬件性能**。并且学会在对自己的设计进行评估的时候，能够寻找到系统的硬件瓶颈在哪里。

## GFS的硬件配置

不知道你有没有想过，2003年的GFS是跑在什么样的硬件服务器上的呢？论文的第6部分还真的透露了一些信息给我们。Google拿来做微基准测试（Micro-Benchmark）的服务器集群的配置是这样的：

- 19台服务器、1台master、2台master的只读副本、16台chunkserver，以及另外16台GFS的客户端；
- 所有服务器的硬件配置完全相同，都是双核1.45 GHz的奔腾3处理器 + 2GB内存 + 两块80GB的5400rpm的机械硬盘 + 100 Mbps的全双工网卡。
- 然后把所有的19台GFS集群的机器放在一台交换机上，所有的16台GFS的客户端放在另外一台交换机上，两台交换机之间通过带宽是1Gbps的网线连接起来。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/1d/13/31ea1b0b.jpg" width="30px"><span>峰</span> 👍（24） 💬（1）<div>mysql利用b+出度打，层级底的特性，尽可能减少一次查询中随机io开销。
kafka利用磁盘顺序写入较随机写入快的特性，批量顺序写文件。
redis ignite 等内存数据库都基于内存性能远胜于磁盘等持久化外部存储，从而基于内存做存储系统。</div>2021-09-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/a9/12/e041e7b2.jpg" width="30px"><span>Ping</span> 👍（9） 💬（2）<div>能再解释下“南北大，东西小”是什么意思吗？</div>2021-09-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/f9/e6/47742988.jpg" width="30px"><span>webmin</span> 👍（8） 💬（1）<div>今天课程中关于网络优化的内容，基本是出自GFS论文中的3.2节Data Flow，我很好奇是因为老师有关于广告系统的开发经验，所以能从一个300个单词左右的小节中看出这么丰富的信息，还是老师有其它的分析框架或辨识方法？还望老师抽时间传授。

另加一个注解流水线（pipeline）式的网络传输是有效利用了网络是全双工的原理，即左手进右手出，左右各100Mb。</div>2021-09-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/8f/60/be0a8805.jpg" width="30px"><span>陈迪</span> 👍（7） 💬（1）<div>思考一个问题，20年过去了，硬件环境已经哪些发生了根本性的变化？现代的分布式文件系统应该什么样的？</div>2021-09-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/66/8f/02be926d.jpg" width="30px"><span>在路上</span> 👍（2） 💬（1）<div>徐老师好，GFS论文3.2 Data Flow中提到“Without networkcongestion, the ideal elapsed time for transferring B bytes to R replicas is B&#47;T + RL where T is the network throughput and L is latency to transfer bytes between two machines. Our network links are typically 100 Mbps (T), and L is far below 1 ms. Therefore, 1 MB can ideally be distributed in about 80 ms.”

我不明白的是RL部分的计算，为什么L&lt;1ms，L的大小和要传输的数据大小无关吗？为什么不是B&#47;T1 + R*B&#47;T2，T1表示客户端到GFS的网速，T2表示GFS集群内的网速？希望能得到老师的指点。</div>2021-09-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/34/df/64e3d533.jpg" width="30px"><span>leslie</span> 👍（1） 💬（1）<div>UDP替代TCP去实现网络的传输，传完了就好了；监控而已-丢失了再传即可；不过当时忽略了一个关键问题-windows并不适合去用很多适合在linux下的软件，导致了备份和恢复的灾难性隐患。</div>2021-09-30</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIyPPFIyvytj0LJrpHicVrTqibuLWLWcR5VqzArSHZicwJYC6gKrIF6GTxx4MakS6xiaxZBCw8icCPB8wQ/132" width="30px"><span>Geek_2e6a7e</span> 👍（1） 💬（2）<div>阿里自研MaxCompute大规模集群计算有什么特别创新的地方么，这块有相关资料或者论文参考下么？</div>2021-09-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/62/b5/4159fa05.jpg" width="30px"><span>zhanyd</span> 👍（1） 💬（1）<div>适合自己的就是最好的，不一定要去追求什么高大上的技术，能够低成本满足需求的就是好方案。创新不一定是要创造出什么新东西， 把一些东西按适当的方式组合在一起也是创新。</div>2021-09-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/22/f4/9fd6f8f0.jpg" width="30px"><span>核桃</span> 👍（8） 💬（0）<div>这里其实是隐藏了一个功能，就是GFS能识别到机架上的服务器拓扑结构的，不然分配的时候是无法感知到到底哪个节点是离客户端比较近的。另外一般分配数据节点的时候，有时候客户端并不一定在集群内发起的，而是在外部的。那么这时候分配的原则也是两个节点可能会近点，但是第三个会远离，甚至在不同机房中。</div>2021-11-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/e7/8e/318cfde0.jpg" width="30px"><span>Spoon</span> 👍（2） 💬（0）<div>零拷贝，利用DMA避免了两次内核态和用户态的切换。</div>2022-09-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/09/dc/37f0ab16.jpg" width="30px"><span>香樟树</span> 👍（2） 💬（1）<div>抛个砖，分享一个MySQL关于磁盘IO的优化策略。大并发写入数据时磁盘IO是性能瓶颈，MySQL通过批量写（比如两个维度：攒够一定量的数据或者达到一定的时间间隔）来减少IO；同样的，大量并发读取数据时，磁盘IO也是性能瓶颈，MySQL通过连续读（将所需要的数据页以及与其相邻的数据页一起读入内存）来减少IO</div>2022-01-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/29/e2/5a/6696d429.jpg" width="30px"><span>音速起子代购</span> 👍（2） 💬（1）<div>请问一个问题，，chunk的副本位置关系不是由master掌握吗？那在复制过程中，由主副本如何转发通知次副本消息呢？主副本如何知道次副本的位置？</div>2021-10-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/43/24/3f9f7c70.jpg" width="30px"><span>zixuan</span> 👍（1） 💬（0）<div>snapshot不是直接复制各个副本，而是用了chunk引用数来做copy on write。</div>2021-12-29</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKJrOl63enWXCRxN0SoucliclBme0qrRb19ATrWIOIvibKIz8UAuVgicBMibIVUznerHnjotI4dm6ibODA/132" width="30px"><span>Helios</span> 👍（1） 💬（1）<div>请教一下老师，现在网络带宽还会成为设计的瓶颈么？</div>2021-10-23</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKJrOl63enWXCRxN0SoucliclBme0qrRb19ATrWIOIvibKIz8UAuVgicBMibIVUznerHnjotI4dm6ibODA/132" width="30px"><span>Helios</span> 👍（1） 💬（0）<div>“主副本自己会给这些请求排一个顺序，确保所有的数据写入是有一个固定顺序的”
并发保证顺序是很难得，尤其是在分布式的情况下，各个机器的clock可能不一致，同步NTP也有早晚，请教老师GFS是如何保证顺序呢</div>2021-10-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/b5/0b/df89c357.jpg" width="30px"><span>全有</span> 👍（1） 💬（2）<div>Pipeline式写入，其实会存在副本写入成功，主副本写入失败的情况，与我们常见的Es,Kafka 等里面的主副本概念流程是不一样的（优先写主)</div>2021-10-09</li><br/><li><img src="" width="30px"><span>Geek_88604f</span> 👍（1） 💬（0）<div>老师在前面的章节中有提到过，大数据的一个特点是用廉价的PC来代替大型机或小型机。那么所有相关的设计就会围绕这一点做文章，包括大数据的计算和存储。从计算层面来将，如何根据不同服务器的资源情况合理调度计算负载；存储层面来讲，通过先写缓存来提高写入速率，通过Append方式来提高吞吐，通过后台定期合并小文件来避免高的写入时延（copy on write和merge on read的权衡）等</div>2021-10-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1a/ee/1b/63b65812.jpg" width="30px"><span>张晓迪</span> 👍（0） 💬（0）<div>在第一步的时候，master是只返回存在哪几个chunkserver，还是同时会指定存在chunkserver的具体位置呀？</div>2023-09-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/59/af/d2107a67.jpg" width="30px"><span>二九幂加八</span> 👍（0） 💬（0）<div>与流水线技术对应的是普通的主备同步，数据是从Client到主，再从主到备这样单向流动

例如：有三个ChunkServer，分别是ChunkServer1、ChunkServer2、ChunkServer3，其中ChunkServer1是主在北京，ChunkServer2和ChunkServer3是备，在杭州

主备同步：Client -&gt; ChunkServer1 -&gt; ChunkServer2，ChunkServer1 -&gt; ChunkServer3，两次跨地域传输

流水线同步：Client -&gt; ChunkServer2&#47;3 -&gt; ChunkServer1，一次跨地域传输</div>2023-08-27</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/cabLXAUXiavXnEckAgo971o4l1CxP4L9wOV2eUGTyKBUicTib6gJyKV9iatM4GG1scz5Ym17GOzXWQEGzhE31tXUtQ/132" width="30px"><span>日就月将</span> 👍（0） 💬（0）<div>请教一下 控制流和数据流 具体是什么意思呢</div>2022-07-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2c/a3/40/73e71a52.jpg" width="30px"><span>攀峰2022</span> 👍（0） 💬（0）<div>chunkserver里面是不是数据元data element，我看您的课里使用元数据metadata描述的</div>2022-04-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/63/6e/6b971571.jpg" width="30px"><span>Z宇锤锤</span> 👍（0） 💬（0）<div>Kafka的数据零拷贝，数据不进入到用户态，直接从网卡转发出去。</div>2022-03-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/bb/cc/fac12364.jpg" width="30px"><span>xxx</span> 👍（0） 💬（1）<div>关于数据中心网络演进的知识，可以参考刘超的《趣谈网络协议》。另外这里的 Pipeline 我觉得用词不好，用“接力式传输”我觉得更传神一点😂</div>2022-02-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg" width="30px"><span>piboye</span> 👍（0） 💬（0）<div>老师，为什么写数据是先缓存再通过主副本控制写入磁盘？</div>2022-01-18</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJt6TyUk2YZXDQ5PMATLAL77b99ACVEhtLrs49koS8UHuiaaEUGKzLw7bThTMqCbSDXdwlW3uue2mw/132" width="30px"><span>Jeffery</span> 👍（0） 💬（0）<div>手机的刘海屏算不算基于硬件性能和瓶颈的设计呢？（屏下摄像头技术还不成熟）</div>2021-12-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/16/fc/3a98fe8d.jpg" width="30px"><span>强子</span> 👍（0） 💬（1）<div>老师，看文章的时候，有个细节没太明白：写入数据的时候，为什么要写入LRU的缓存区？是为了一个时效性问题么？还有一个问题就是缓存区写入完成之后，主节点会发送指令给两个副本节点进行固定顺序的写入，这个为什么要按照固定顺序呢？</div>2021-11-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/88/d7/07f8bc6c.jpg" width="30px"><span>sljoai</span> 👍（0） 💬（1）<div>请问一下：一般在就近选择chunckserver的时候，是依赖哪些条件来判断物理距离的远近的呢？ip,机架信息嘛？</div>2021-10-26</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKJrOl63enWXCRxN0SoucliclBme0qrRb19ATrWIOIvibKIz8UAuVgicBMibIVUznerHnjotI4dm6ibODA/132" width="30px"><span>Helios</span> 👍（0） 💬（0）<div>“然后，次副本 A 服务器再把数据传输给离自己“最近”的，在不同机架，但是处于同一个汇聚层交换机下的主副本服务器上；”
老师，为什么主副本服务器一定和次副本 A 服务器处于同一个汇聚层交换机呢？那要是次副本 B 服务器请求主副本服务器不就不在同一个汇聚层交换机了么</div>2021-10-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/1b/24/1006c208.jpg" width="30px"><span>火娃儿</span> 👍（0） 💬（0）<div>HBASE 就是 利用LSM ,用一定的 归并 门限来 逐步 合并 每次 写操作，达到门限再进行 写磁盘操作。</div>2021-10-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/3f/d1/b64975e6.jpg" width="30px"><span>Lebron</span> 👍（0） 💬（0）<div>老师，你贴的那篇文章我无法访问呢，有没有国内的链接，像你之前课程的那种PDF的链接？</div>2021-10-02</li><br/>
</ul>