你好，我是徐文浩。

通过上节课的学习，现在你已经知道MapReduce的编程模型是怎么回事儿了。对于开发者来说，你只需要写一个Map函数和一个Reduce函数，就能完成数据处理过程。具体这些任务用了多少服务器，遇到了失败是怎么解决的，你并不需要关心。

不过，要想学习如何搭建和改进分布式系统，了解MapReduce的底层原理必不可少。今天，我们就一起来看看MapReduce的框架干了什么。MapReduce这个“保姆”，为什么可以让你不需要处理复杂的分布式架构的问题。

## MapReduce框架的三个挑战

要想让写Map和Reduce函数的人不需要关心“分布式”的存在，那么MapReduce框架本身就需要解决好三个很重要的问题：

- 第一个，自然是如何做好各个服务器节点之间的“**协同**”，以及解决出现各种软硬件问题后的**“容错”**这两部分的设计。
- 第二个，是上一讲我们没怎么关心的**性能**问题。和我们在GFS论文里面讲过的一样，MapReduce框架一样非常容易遇到网络性能瓶颈。尽量充分利用MapReduce集群的计算能力，并让整个集群的性能可以随硬件的增加接近于线性增长，可以说是非常大的一个挑战。
- 最后一个，还是要回到**易用性**。Map函数和Reduce函数最终还是运行在多个不同的机器上的，并且在Map和Reduce函数中还会遇到各种千奇百怪的数据。当我们的程序在遭遇到奇怪的数据出错的时候，我们需要有办法来进行debug。
<div><strong>精选留言（17）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/15/66/8f/02be926d.jpg" width="30px"><span>在路上</span> 👍（15） 💬（0）<div>徐老师好，MapReduce的第一个问题后来通过SQL得到解决，编程界面更友好，第二个问题通过内存+硬盘混合存储得到了解决，内存保存中间数据更快，硬盘保存中间数据更稳定，中间数据丢失可以根据依赖的数据和逻辑重新生成。


回答老师的问题，如果不定制分区函数，数据会产生倾斜，那么可以给数据多的分区分配多一些Reduce程序，或者再次Hash。MapReduce在运行的最后阶段，会启动后备的Reduce程序，和运行较慢的Reduce程序处理同一个分区，哪个先完成就采用哪个结果，以此避免较慢的机器拖慢了整体处理时间。在最后的阶段，其实可以让MapReduce为一个分区启动多个Reduce程序，加速数据处理，减轻数据倾斜的影响。</div>2021-10-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/30/61/5b4c28fe.jpg" width="30px"><span>星语心愿</span> 👍（6） 💬（0）<div>数据倾斜源自于Key值分布不均，一方面数据源本身key值分布不均（仅以行号作为key值不存在这个问题），可以事先预处理key值，使其分布均匀，或者增大分区解决；另一方面在shuffle混洗后发生数据倾斜，写入磁盘时增加分区数，增加reduce的并发处理量，加速数据处理，减轻数据倾斜的影响。</div>2021-10-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/70/67/0c1359c2.jpg" width="30px"><span>qinsi</span> 👍（5） 💬（1）<div>坐时光机快进的话，现代的大数据框架大都提供了类似SQL的接口，于是任务的实现和优化就类似数据库中查询计划的生成和优化，对于使用者透明了</div>2021-10-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/15/8e/ae3304c2.jpg" width="30px"><span>demo</span> 👍（1） 💬（0）<div>如果只是定期的进行checkpoint那么从checkpoint恢复的时候不是会丢失数据吗? </div>2022-11-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/8f/60/be0a8805.jpg" width="30px"><span>陈迪</span> 👍（1） 💬（0）<div>尝试回答思考题：（首先应该是reduce任务存在数据倾斜，map不存在这个问题）
1. 论文中提到的思路：map端本地先算掉一波(combiner)，但要求计算任务满足结合律和交换律(commutative和associative)
2. 同样是论文中提到的思路：调参数，自动对倾斜的key任务，通过master，要求cluster manager分配更多的、等比例的资源
3. 猜想一波：还是在partition上做文章，自动对倾斜的key任务，添加一些参数，让这批key的record分开处理，再尝试聚合。但这个思路应该和本地combiner方法类似，对计算任务有要求。</div>2021-10-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4b/cd/185e5378.jpg" width="30px"><span>泊浮目</span> 👍（1） 💬（0）<div>如果让你在 MapReduce 框架层面解决好这一个问题，你觉得有什么好办法吗？——现在的做法都是SQL做声明，底层用CBO做优化。</div>2021-10-05</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/xfclWEPQ7szTZnKqnX9icSbgDWV0VAib3Cyo8Vg0OG3Usby88ic7ZgO2ho5lj0icOWI4JeJ70zUBiaTW1xh1UCFRPqA/132" width="30px"><span>Geek_6bdb4e</span> 👍（0） 💬（0）<div>这个combiner怎么感觉和reduce函数很像啊</div>2024-06-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/e7/8e/318cfde0.jpg" width="30px"><span>Spoon</span> 👍（0） 💬（0）<div>Spark有针对数据倾斜的自动平衡机制</div>2022-09-20</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/SAzVOPToVGWyQGjRqvzCXp4qibnQWBxicPokgfDrRgdibnYfuLv3784vgzH3QbEhw8ROhJZ5XBI1JAdAiaKsibKZ6XA/132" width="30px"><span>Joey</span> 👍（0） 💬（0）<div>针对于数据倾斜问题，在reduce前进行数据量预评估，对reduce进行重新分配，确保每个reduce的数据均衡</div>2022-08-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/93/d2/abb7bfe3.jpg" width="30px"><span>大包子</span> 👍（0） 💬（0）<div>分区不平衡时，加一层负载均衡的机制，重新分配一下任务</div>2022-06-04</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKJrOl63enWXCRxN0SoucliclBme0qrRb19ATrWIOIvibKIz8UAuVgicBMibIVUznerHnjotI4dm6ibODA/132" width="30px"><span>Helios</span> 👍（0） 💬（0）<div>感觉调度系统和Map Reduce里面的Master做的事情有些重合呢，比如将任务分为多少个、如何找到距离任务最近的分片，感觉两者谁做都可以呢。</div>2021-11-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/22/f4/9fd6f8f0.jpg" width="30px"><span>核桃</span> 👍（0） 💬（0）<div>看了大家的想法还有结合个人经验，其实现在很多的参数优化都是手动调参的，但是手动调节参数也是会带来非常大的心智负担，有时候很多参数还不是单一生效的，需要多个同时考虑才能有明显效果，这就是经验了，而如果可以引入一些深度学习框架或者神经网络那些进行训练的话，那么这里应该是可以实现一定程度上的参数自动优化的。但是目前业界有没有这个方法出现，我也不太了解。</div>2021-11-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/1d/13/31ea1b0b.jpg" width="30px"><span>峰</span> 👍（0） 💬（0）<div>mapper程序完成后，master搜集了所有mapper输出的信息，简单性的角度，mapper阶段可统计中间key出现的次数，对倾斜的key，由mapper搜集后，做一次再分区。</div>2021-10-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/92/7b/8c7e3e61.jpg" width="30px"><span>Monroe  He</span> 👍（0） 💬（0）<div>思考题：
步骤1  论文里说 combiner 与 reduce 的不同只在于 reduce 将结果写入到文件系统中，而 combiner 将结果传递给 reduce, 那是不是可以不用写 combiner 函数而直接在 map 之后使用 reduce 函数做一次局部 reduce, 然后再将结果collect到 reduce中做全局 reduce，以减少数据量，防止数据倾斜。
步骤2  全局reduce中，单机reduce 任务获取到一定数据量大小的数据后，就不在去抓取数据了，而是要求master分配另一台机器获取剩下的数据进行同样的reduce, 循环下去，最后再将相同的reduce做一次全局的reduce</div>2021-10-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/3f/d1/b64975e6.jpg" width="30px"><span>Lebron</span> 👍（0） 💬（0）<div>思考题个人解答：针对数据倾斜问题，我个人的想法是可以让MapReduce程序在Map之后，程序再将Reduce的work进程分配到倾斜数据量大的服务器或者其相近的服务器，这样在Reduce的时候就可以尽量不占用网络传输。从而不仅提高效率，也可以让“开发者”意识不到“分布式”本身的存在。</div>2021-10-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/3f/d1/b64975e6.jpg" width="30px"><span>Lebron</span> 👍（0） 💬（1）<div>徐老师，您在文章中提到：“除此之外，由于 MapReduce 程序的代码往往很小，通过把要执行的 MapReduce 程序，复制到数据所在的服务器上，就不用多花那 10 倍乃至 100 倍的网络传输量了。”这句话是在什么场景下会复制Map？如果数据所在的服务器上没有worker，是不是就不会复制过去了？以及您在worker节点的失效（Master Failure）和mster节点的失效（Worker Failure）这里写反了，应该是worker节点的失效（Worker Failure）和master节点的失效（Master Failure）。</div>2021-10-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（0） 💬（0）<div>我的想法是通过增加一层Partition层处理，来解决用 MapReduce 处理数据时候数据不平衡问题。Partition层把输出的数据分成 R 个不同的区域，R的值可以依据数据量的大小来确定，默认是1，也就是本地。如果数据大于一个block，按照 数据量&#47;block 来确定R的值。</div>2021-10-04</li><br/>
</ul>