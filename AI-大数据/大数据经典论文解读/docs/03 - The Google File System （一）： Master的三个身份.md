你好，我是徐文浩。从今天开始，我们就正式地来一起解读和学习大数据领域中，一些经典的论文。这节课，我们就从“[The Google File System](https://storage.googleapis.com/pub-tools-public-publication-data/pdf/035fc972c796d33122033a0614bc94cff1527999.pdf)”这篇论文开始。

这篇论文发表在2003年，现在来看，它算是一篇“老”论文了。然而在我第一次看到这篇论文的时候，它可代表着强大而神秘的黑科技。

在这篇论文发表之前，工业界的分布式系统最多也就是几十台服务器的MPI集群。而这篇GFS的论文一发表，一下子就拿出了一个运作在1000台服务器以上的分布式文件系统。并且这个文件系统，还会面临外部数百个并发访问的客户端，可以称得上是石破天惊。

当然，在18年后的今天，开源社区里的各种分布式系统，也都远比当初的GFS更加复杂、强大。回顾这篇18年前的论文，GFS可以说是“**技术上辉煌而工程上保守**”。说GFS技术上辉煌，是因为Google通过廉价的PC级别的硬件，搭建出了可以处理整个互联网网页数据的系统。而说GFS工程上保守，则是因为GFS没有“发明”什么特别的黑科技，而是在工程上做了大量的取舍（trade-off）。

## GFS的设计决策

在我看来，GFS定了三个非常重要的设计原则，这三个原则带来了很多和传统的分布式系统研究大相径庭的设计决策。但是这三个原则又带来了大量工程上的实用性，使得GFS的设计思路后续被Hadoop这样的系统快速借鉴并予以实现。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/15/66/8f/02be926d.jpg" width="30px"><span>在路上</span> 👍（39） 💬（4）<div>徐老师好，MIT 6.824的GFS那一讲的讲解框架是介绍分布式存储系统的矛盾、GFS的特点、内部结构和读写操作，一般介绍HDFS的书籍也是类似的流程。不过老师从简单性、考虑硬件性能、结合业务特点三个角度来谈GFS让我有了新的启发。在老师的鼓励下，今天我试着读了《The Google File System》的一部分，花了四个小时读完了INTRODUCTION和DESIGN OVERVIEW，体会到了一点论文的精辟，希望自己能坚持下去。

回到老师的问题，GFS client会缓存chunk对应的chunkserver地址，直到缓存信息过期或者文件重新打开。这种机制是否会读到过时的数据呢？论文中是这样说的，Since clients cache chunk locations, they may read from a stale replica before that information is refreshed ... as most of our files are append-only, a stale replica usually retures a premature end of chunk rather than outdated data. 也就是说，只会读不到最新的数据，不会读到过时的数据。

论文中的2.6.2 Chunk Locations讨论了chunk location的管理机制，chunkserver启动时上报chunk location information，之后再周期性上报。之所以这么设计，主要考虑两个原因。第一，消除master和chunkserver的同步问题，第二，chunkserver真正管理了chunk，对于chunk location拥有最终的话语权。</div>2021-09-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/52/40/e57a736e.jpg" width="30px"><span>pedro</span> 👍（14） 💬（2）<div>mit6.824在讲GFS的时候说，GFS并没有什么理论创新，但是它一下子搞了1000多台机器的集群，对其它论文而言完全是降维打击，然后它就被会议接收了。</div>2021-09-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/1d/13/31ea1b0b.jpg" width="30px"><span>峰</span> 👍（14） 💬（1）<div>
1. 为了减少master的压力，所以要缓存master上的元数据信息。应该会造成读过期数据，因为写入不可变，但支持追加写，对于追加写入的chunk的元数据，怎么同步到客户端缓存按照GFS简单性的原则怕是不想做了。

2. 每个chunkserver会上报自己拥有哪些chunk。原因的话，chunkserver必然有这个信息，如果master还持久化的话，突然冒出个数据一致性的问题得考虑，数据链路上也会更复杂。</div>2021-09-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/f9/e6/47742988.jpg" width="30px"><span>webmin</span> 👍（9） 💬（1）<div>1. GFS客户端会在读取数据时，把文件其余块的元数据缓存在本地，因为是追加写已写入成功的元数据短期不会变化，再者从空间局部性的原理出发，读部分块后，大概率会要接下来读这个文件余下块，所以提前装载元数据也算是一种优化预测吧；

2. master重启后，会让chunkserver上报自己管理的chunk的meta信息，这样做可以我想是考虑到了在master关闭期间chunkserver本身会发生一些变化，比如chunkserver的主备发生切换或者因为运维需要调整了chunkserver的IP地址等吧。</div>2021-09-26</li><br/><li><img src="" width="30px"><span>Geek_74dea9</span> 👍（5） 💬（1）<div>chunk的位置信息并不会持久化，而是在master启动的时候， 让chunk server汇报给master</div>2021-09-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/5e/f9/ca88bdb8.jpg" width="30px"><span>推推。</span> 👍（3） 💬（2）<div>想问一下 master 如何更新 chunk server的状态和数据呢 如果有 chunk server failed了 如何建立一个新的trunk server 呢</div>2021-09-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/5a/04/335e02fd.jpg" width="30px"><span>潇湘夜雨</span> 👍（1） 💬（1）<div>想请问下，看gfs三驾马车等论文需要啥前置知识吗，我正在学大数据相关技术与框架，对分布式不是很了解，看论文有点摸不着头脑</div>2021-09-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/f6/05/5c81abfd.jpg" width="30px"><span>不加y</span> 👍（0） 💬（1）<div>数据写入过程没有描述，老师数据写入的整体流程是什么样的？比如数据是三副本，三个副本的数据都写成功，才算是写成功吗？</div>2023-03-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/67/6e/f5ee46e8.jpg" width="30px"><span>海滨</span> 👍（0） 💬（1）<div>1. 客户端应该会缓存请求过的文件对应的chunk sever的元数据信息，这部分数据占用大小很小非常适合缓存，缓存之后可以减少对master server的压力。
缓存的数据是可能过时的，我觉得主要分2种情况，一种是文件chunk对应的chunk sever变了，这个时候文件chunk一旦请求不到重新向master重新请求更新就可以了；还有一种情况数据更新了，比如文件对应的chunk数变多了，这种情况应该在chunk sever有相关机制来校验这种情况吧。

2. 还没有读过论文，我猜测应该是chunk sever主动上报的方式来使master重新拿到这个数据的吧</div>2021-10-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1f/a5/13/5fbde43f.jpg" width="30px"><span>融冰</span> 👍（0） 💬（2）<div>1. 客户端会缓存文件和 chunkserver 的映射，这个缓存会在时效结束或者文件被重新打开的时候失效
2. chunk 存放在什么 chunkserver 这个由 chunkserver 自己维护，master 重启的时候会跟所有 chunkserver 获取对应存储的 chunk</div>2021-10-01</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoqEsRcQ5icwkgTDBX9JA8iaqohBdIGhxMXLFDSevEXqm5sAarw3hKeEHzxkoEJ5sx7plibcRPqmicAlQ/132" width="30px"><span>ROY</span> 👍（0） 💬（1）<div>客户机保存控制流而不是数据流，当chunk有更新等操作时，会客户端和chunkserver之间建立的链接失效，必须重新从master获取
master失败的时候是用log快速恢复当时的状态的，而chunkserver上存放什么元数据应该是通过轮询各个chunkserver得到的吧</div>2021-09-30</li><br/><li><img src="" width="30px"><span>Geek_648c55</span> 👍（0） 💬（3）<div>gfs写操作更新内存和记录操作日志就算完成了是吧。用顺序写的操作日志，代替磁盘的随机读写，提升性能。但是，文中提到的checkpoint是指什么，是指已完成刷盘的指令位置？</div>2021-09-26</li><br/><li><img src="" width="30px"><span>Geek_648c55</span> 👍（0） 💬（1）<div>所以 GFS 在写数据的时候，选择了流水线式的数据传输，而没有选择树形的数据传输方式。
什么是流水线式数据传输，什么又是树形数据传输？</div>2021-09-26</li><br/><li><img src="" width="30px"><span>毛毛酱</span> 👍（0） 💬（1）<div>问一个初级问题哈～ 老师说：“master 的数据都会通过操作日志和 Checkpoints 持久化在硬盘上”，具体是把什么数据持久化在硬盘上？ 比如，是“全路径文件名到多个 chunk handle 的映射关系“吗？这个不是在写请求时直接持久化在硬盘上吗？不是直接落盘的话，是采用的二段式提交？</div>2021-09-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/cc/58/c593587c.jpg" width="30px"><span>ahnselina</span> 👍（4） 💬（0）<div>徐老师好，有个疑问：
Shadow master分担读压力的角色为什么不直接用backup master来分担呢？</div>2022-05-01</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/cabLXAUXiavXnEckAgo971o4l1CxP4L9wOV2eUGTyKBUicTib6gJyKV9iatM4GG1scz5Ym17GOzXWQEGzhE31tXUtQ/132" width="30px"><span>日就月将</span> 👍（1） 💬（0）<div>我想请教一下，文中说的GFS 在写数据的时候，选择了流水线式的数据传输，而没有选择树形的数据传输方式。这两种传输方式的区别是什么，有什么资料可以了解一下这两种方式呢？</div>2022-07-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/43/24/3f9f7c70.jpg" width="30px"><span>zixuan</span> 👍（1） 💬（3）<div>Shadow master分担读压力的角色为什么不能直接用backup master来承担呢？</div>2021-12-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/21/f5/39/4f3e5c0c.jpg" width="30px"><span>~~五浩~~</span> 👍（1） 💬（2）<div>多个backup master同步操作，如何做到数据一致的，其实又是一个大问题！没有强一致算法，靠简单的二阶段提交，恐怕不行</div>2021-11-05</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIKVicSvNf6OFvv4m3ibfsYCIUxic41kODPa9cuGUJjPcBtryLBDljalIVUiaJKlkGEJtOMZ03XSFlx1w/132" width="30px"><span>fuyu</span> 👍（1） 💬（0）<div>不过，为了让集群中的其他 chunkserver 以及客户端不用感知这个变化，GFS 通过一个规范名称（Canonical Name）来指定 master，而不是通过 IP 地址或者 Mac 地址。这样，一旦要切换 master，这个监控程序只需要修改 DNS 的别名，就能达到目的。有了这个机制，GFS 的 master 就从之前的可恢复（Recoverable），进化成了能够快速恢复（Fast Recovery）。


这个没明白什么意思？如果是域名，SDK 肯定会有缓存时间，没明白Canonical Name是什么意思</div>2021-11-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/51/c1/e7a0f04d.jpg" width="30px"><span>JonSlow</span> 👍（0） 💬（0）<div>一个想法：分布式业务系统中，同步复制&#47;异步复制可以根据业务场景来灵活选择，一致性要求高的业务应当使用同步复制（比如支付）；一致性要求一般的业务可以使用异步复制（如商品推荐）</div>2024-10-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/38/16/eb/162ef2ba.jpg" width="30px"><span>DDD_</span> 👍（0） 💬（0）<div>master的三个身份，请一句话总结，文档中只显式声明了第一个身份</div>2023-07-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/15/8e/ae3304c2.jpg" width="30px"><span>demo</span> 👍（0） 💬（1）<div>Master和BackupMaster是同步复制的 Master挂了的时候为什么不去读BackMaster而去读ShadowMaster? 
</div>2022-11-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/55/99/4bdadfd3.jpg" width="30px"><span>Chloe</span> 👍（0） 💬（0）<div>刚学了两天，很喜欢老师的风格。课程内容刚刚好，即讲明白了来龙去脉，又激发了读原著的兴趣，谢谢老师</div>2022-06-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/95/ac/ff011d99.jpg" width="30px"><span>Chao</span> 👍（0） 💬（0）<div>1. 为了减少chuckserver之间的traffic，每个chunkserver需要缓存chunk的metadata，以及chunk的hash code，这样如果有更改的话可以直接比较hash code，如果一致，就代表不需要更新
2. master重新启动之后会ping每个chunk server，然后chunk server返回它自身缓存的metadada</div>2022-06-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/39/ca/cdc58834.jpg" width="30px"><span>黄金果</span> 👍（0） 💬（0）<div>猜测:客户端希望读取数据的时候, 会询问 master 自己目标文件的 metadata, 猜测为了提高效率会缓存这部分数据
是否有可能会访问到过期的老数据?
有可能, 数据在后续的时间中有可能被别的用户操作

文件系统中的数据可以怎么操作呢? 
修改文件内容- 貌似不支持修改文件内容吧
删除文件- 拿着老的 metadata 无法访问到数据, 影响不大
删除之后在添加文件-拿着老的 metadata 无法访问到数据, 但是文件实际存在内存中, 有影响

如何解决这个问题呢?
是否可以考虑为metadata 添加版本号, 客户端去 chunkserver 拿数据的时候发现版本比较落后可以去 master 获取最新的数据

有不对的地方还望指正,多谢</div>2022-02-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/db/bc/286e72d2.jpg" width="30px"><span>阿橦木</span> 👍（0） 💬（1）<div>客户端读取文件时，只发送文件名称和路径不可以吗？为何需要发送offset和length？</div>2022-01-13</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIVR2wY9icec2CGzZ4VKPdwK2icytM5k1tHm08qSEysFOgl1y7lk2ccDqSCvzibHufo2Cb9c2hjr0LIg/132" width="30px"><span>dahai</span> 👍（0） 💬（0）<div>关于为什么不启动备份master,而是启动影子master.原因是影子master是热数据，可以直接启动被使用，而备份master有部分需要重放的日志，无法立即启动。是这样么？</div>2021-12-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/47/00/3202bdf0.jpg" width="30px"><span>piboye</span> 👍（0） 💬（0）<div>nvm内存，是可以加速这个master的性能吧</div>2021-12-25</li><br/><li><img src="" width="30px"><span>Geek_4c2e3e</span> 👍（0） 💬（0）<div>课后思考题：
1:客户端缓存了chunk locations，可能会读到过时的数据，这个过时窗口受缓存项超时时间和下次打开文件的时机影响。原文：Since clients cache chunk locations, they may read from a stale replica before that information is refreshed. This window is limited by the cache entry’s timeout and the next open of the file, which purges from the cache all chunk information for that file.
2.轮询chunkserver。原文：The master does not keep a persistent record of which chunkservers have a replica of a given chunk. It simply polls chunkservers for that information at startup.</div>2021-11-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/24/33/bcf37f50.jpg" width="30px"><span>阿甘</span> 👍（0） 💬（0）<div>master跟chunkserver之间没有心跳之类的协作吗？不会对挂掉的chunkserver进行映射修改或者数据迁移吗？</div>2021-10-21</li><br/>
</ul>