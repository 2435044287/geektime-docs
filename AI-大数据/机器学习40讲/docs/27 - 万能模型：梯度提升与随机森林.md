上一篇文章中我和你分享了提升法和装袋法这两种典型的集成方法，它们都可以用在决策树模型上，对多棵不同的树进行组合。然而直接使用这两种集成方法只是初级的策略，将它们的强化版用在决策树上可以得到更加强大的万能模型，也就是梯度提升决策树和随机森林。

**梯度提升**（gradient boosting）的思想来源于对提升方法的推广。显式的提升方法本身可以解释为对一个合适的损失函数的优化，如果将损失函数的选择扩展为任意的可微函数，并将提升方法和最优化中的梯度下降（gradient descent）结合起来，得到的就是梯度提升。

梯度提升将提升方法视为函数式的迭代梯度下降算法，通过迭代地选择指向负梯度方向的函数，也就是弱学习器来优化整个函数空间上的代价函数。在AdaBoost中，每个弱学习器的短板通过权重的加强得以凸显；而在梯度提升中，凸显的方式被替换成了梯度。

要理解梯度提升方法的妙处，还是要先从回归问题说起。在解决回归问题时，模型的输出$f({\\bf x})$和真实值$y$之间的差值$h({\\bf x}) = y - f({\\bf x})$被称为残差（residual），它表示了数据中模型所不能刻画的那些部分。

传统的单一模型对残差无能为力，可集成方法的引入给处理残差提供了新的思路，那就是用新的基学习器去拟合残差，作为对上一个模型的修正。将拟合真实值$y$和拟合残差$h$的模型集成起来，可以获得更加精确的拟合结果。
<div><strong>精选留言（9）</strong></div><ul>
<li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83er6OV33jHia3U6Y6xwm9BryshBqapb8iaQCf3P4RUxIxiakfEdEzDEPy5QR6sjCjqj7CNgz6Lyj8rPYA/132" width="30px"><span>小博</span> 👍（4） 💬（1）<div>老师，请问梯度提升这里的提升具体体现在哪里呢？只是残差的拟合吗？还有梯度提升是在函数空间的优化和梯度下降是在参数空间的优化这两个说法怎么理解呢</div>2018-08-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/87/86/6dc4ffaf.jpg" width="30px"><span>Ophui</span> 👍（2） 💬（1）<div>在训练数据中想刻意的增加某些特征的权重，有什么办法么？</div>2018-08-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/92/64/e1fe7ad3.jpg" width="30px"><span>hayley</span> 👍（0） 💬（1）<div>什么情况下选RF，什么情况下选GBDT呢？</div>2018-10-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（0） 💬（1）<div>Practical Lessons from Predicting Clicks on Ads at Facebook</div>2018-08-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（0） 💬（1）<div>王老师，我对于Facebook 在其广告系统中使用的GBDT+LR的融合方法在LR这一步的输入有些困惑。

传统的LR模型，输入就是权重与特征值相乘求和再放入sigmoid函数中。

GBDT在Facebook广告系统预测点击的那篇论文中，我的理解是这样的。假设有5棵树，每棵树的节点数可能是不同的(根据文章中的一个简单例子)。假设我们5棵树的叶子节点数分别是2，3，2，4，3，合计有14个叶子节点。其中一个训练样本在5棵树的输出结果是[0, 1]，[0, 1, 0]，[1, 0]，[0, 0, 1, 0]，[0, 0, 1]。把树的输出结果作为LR的输入时是相当于每个样本看成有14个特征，每个特征只有0和1两种取值，然后求这14个特征的权重令最后的LR模型的预测输出和训练样本的真实结果值，取值为0，1(代表点击或未点击)的误差最小化吗？或者LR模型的输入特征是5个，对应5棵GBDT树的输出结果，如果这样，5棵树的叶子节点数不同时，权重如果只是一个标量，貌似没法求和得到一个标量值。

谢谢。</div>2018-08-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg" width="30px"><span>ifelse</span> 👍（1） 💬（0）<div>随机性太强，已经没法精确解析</div>2023-06-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg" width="30px"><span>ifelse</span> 👍（0） 💬（0）<div>学习打卡</div>2023-06-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/63/8d/bddef9bf.jpg" width="30px"><span>Geek_4b73dd</span> 👍（0） 💬（0）<div>老师，对于分歧分解还有一些疑问，不知道对不对。如果我理解正确的话，和而不同是只每个基分类器需要有不同的结果，但同样也要使得和真实值比较接近。举例来说，假设二分类问题有11个基分类器，如果按照majority voting来得到集成结果的话，在结果为正确的情况下（Y ＝1），最大化分歧就是11个基分类器最好是有6个是1，或者6个是0；而最小化E（均方误差）也就是11个基分类器都是1；所以这其实也只是bias variance trade off，并不一定是基分类器之间越independent越好对不对？谢谢老师啦</div>2018-12-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（0） 💬（0）<div>性能的提高可以通过把数据映射到高维，层次化，或者老师讲授的局部化等方法来实现。这些数学变换未必都有直观可解释的属性，属性组合及划分或变换方式对应。

我们的理解程度和变换对于复杂问题的解决能力在不少场景下就是不易同时满足的，除非我们对一些事物的认知提高到一个更宏观或微观的新层次。</div>2018-08-21</li><br/>
</ul>