从今天开始，专栏将进入统计机器学习模块。虽然统计机器学习中千姿百态的模型让人眼花缭乱，但究其本原，它们都来源于最原始的**线性回归**（linear regression）。

在我看来，**线性模型最大的优点不是便于计算，而是便于解释**。它能以简洁明了的方式清晰体现出输入的变化如何导致输出的变化。正所谓“一生二，二生三，三生万物”，将不同的改进方式融入线性模型的基本思想中，就可以得到各种巧夺天工的复杂方法。

在第一季“人工智能基础课”专栏中，我介绍了线性回归的原理，证明了当噪声满足正态分布时，基于最小二乘法（least squares）的线性回归和最大似然估计是等价的。

[《机器学习 | 简约而不简单：线性回归》](https://time.geekbang.org/column/article/1865)

这次我们换个角度，来看看**最小二乘法的几何意义**。之前，线性回归的数学表达式被写成$f({\\bf x}) = {\\bf w} ^ T {\\bf x} = \\sum\_{i = 0}^{n} w\_i \\cdot x\_i$。但在讨论几何意义时，这个表达式要被改写成

$$ f({\\bf x}) = 1 \\cdot \\beta\_0 + \\sum\\limits\_{j = 1}^n x\_j \\cdot \\beta\_j = {\\bf x} ^ T {\\boldsymbol \\beta}$$

可别小看这个简单的写法变化，从列向量$\\bf x$到行向量${\\bf x} ^ T$的改变就像矩阵的左乘和右乘一样具有不同的意义。
<div><strong>精选留言（11）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/3c/1f/3948a3c6.jpg" width="30px"><span>paradox</span> 👍（2） 💬（1）<div>老师
x.T 就变成了 N×(n+1) ，每一行都是一个样本，那么x.T*β不也是一个样本作为一个整体么？
实在想不通，谢谢指点</div>2018-08-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（2） 💬（1）<div>估计出的系数是观察数据的统计值。在做了数据分布的假设后，有较大的概率这些系数能让某个特定赛季的观测到的真实数据的某种误差最小，但系数并不是一组完全确定不变的值，它会收到训练数据的影响。(1)由线性回归假设得到的估计值和真实值之间的误差在不同赛季的数据是可变的，为了使某个赛季的的计算误差最小，计算出来的系数会不同；(2)不同赛季的数据中的噪声是不同的，也会影响计算出来的最优系数。

如果文中列出的统计值在不同赛季的数据集上表现都比较好，即期望的计算估计值发生的概率较大，并且估计出的系数的上下置信区间重合的比例较高，我的理解是这个估计出的系数的准确性比较好，反之这个系数的准确性不太理想。</div>2018-07-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/05/1b/fc1aa0ac.jpg" width="30px"><span>王大伟</span> 👍（0） 💬（1）<div>请问老师，标准误是如何计算的？</div>2018-09-27</li><br/><li><img src="" width="30px"><span>BGu</span> 👍（0） 💬（1）<div>您好，您在多元回归例子中看了F stats 的数值大小，但是否应该用f stats的p值得出结论？</div>2018-08-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/26/f9/2a7d80a3.jpg" width="30px"><span>itzzy</span> 👍（0） 💬（1）<div>老师github上代码能加些注释吗？感谢！</div>2018-06-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/88/ec/1460179b.jpg" width="30px"><span>我心飞扬</span> 👍（0） 💬（1）<div>当输出被写成 wTxwTx{\bf w} ^ T {\bf ...

极客时间版权所有: https:&#47;&#47;time.geekbang.org&#47;column&#47;article&#47;9789?device=geekTime.android

不懂，误差一直分布在不同变量上的啊</div>2018-06-28</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTIouX2Ixsdk8LpLVjyWdSVaibHORAzJAKoibdTp46r257BJSy3ia1GCPo4WicFtFdnOjU4DVucz6rDTRw/132" width="30px"><span>子非鱼</span> 👍（2） 💬（0）<div>老师。你讲的F统计量的看法跟我在统计学中学的不一样。统计学中教我们的不是直接看大小，而是对比相应的显著性水平和样本自由度产生的临界值。也就是看F统计量的p值是否小于我们拟定的显著性水平，这与我所学相悖，产生疑惑。望指教</div>2020-06-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/0e/39/174741d1.jpg" width="30px"><span>特种流氓</span> 👍（0） 💬（1）<div>老师 虽然统计机器学习中千姿百态的模型让人眼花缭乱，但究其本原 它们都来源于最原始的线性回归 这个怎么理解呢</div>2021-02-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg" width="30px"><span>建强</span> 👍（0） 💬（0）<div>个人理解：系数的准确性是相对的，不同的样本数据构造出的模型不一致，系数应该也是不一样的，系数的准确性应该只是相对于构造模型的样本而言是准确的，但不同的样本构造出的模型不可能是完全一致的，虽然这些样本可能满足同一分布，但拟合过程中受噪声影响，不同的样本所受的噪声影响也不一致，因此，模型的误差也是不一样的，所以系数只能相对于构造模型的样本来说是准确的。

以上是个人的一点肤浅理解，请老师指正。</div>2021-01-24</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTLicy0x4gnyq5kAicuribaUiagxYibceV730C2SNiaia713krJ7c1BBkyhX07KiaIO7WeicOeBSTBfP9JIHBKA/132" width="30px"><span>Geek_e1bb7a</span> 👍（0） 💬（0）<div>王老师，我对于你这篇的分享不以为然。
因为你这选择的是球员评分与球队胜率之间的关系，但是球员的当场得分是与球队当场的胜负紧密关联的，也就是说你做了这么多的机器学习，可能我只需要做个胜利队伍球员平均分和失败队伍的平均分就能完美解释做了这么多机器学习之后的出的结论了。而且分析出来的相关度比较高的前锋和后卫两个环节不就正对应着得分和失球么？这当然直接影响到当场比赛的结果了，所以我觉得算了这么多内容反而说明了这个评分系统只是对当场比赛的一个补充说明，您本文的这套计算逻辑无法佐证这套体系的靠谱程度</div>2020-05-28</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/g1icQRbcv1QvJ5U8Cqk0ZqMH5PcMTXcZ8TpS5utE4SUzHcnJA3FYGelHykpzTfDh55ehE8JO9Zg9VGSJW7Wxibxw/132" width="30px"><span>杨家荣</span> 👍（0） 💬（0）<div>极客时间
21天打卡行动 49&#47;21
&lt;&lt;机器学习40讲&#47;11&gt;&gt;实验设计
今日所学:
1,线性模型最大的优点不是便于计算，而是便于解释。
2,计算高维空间上的输出结果在由所有属性共同定义的低维空间上的正交投影（orthogonal projection）。
3,足球数据网站 WhoScored 
4,线性回归的一个特例，它特殊在输出的因变量只与单个的输入自变量存在线性关系，这种模型被称为简单线性回归（simple linear regression）;
5,一般的情况是因变量由多个自变量共同决定，对这些自变量同时建模就是多元线性回归（multivariate linear regression）。
6,模型虽然具有足够的精确性，却缺乏关于精确性的合理解释。
7,机器学习只看重结果
重点:
线性回归拟合的是高维空间上的输出结果在由所有属性共同定义的低维空间上的正交投影；
简单线性回归的统计意义可以用 t 统计量和 p 值等指标描述；
多元线性回归的统计意义可以用 F 统计量描述，但回归结果可能缺乏对模型的解释能力；
机器学习与统计学的区别在于机器学习重于预测，统计学则重于解释。</div>2020-02-05</li><br/>
</ul>