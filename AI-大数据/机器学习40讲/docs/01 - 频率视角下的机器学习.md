在“人工智能基础课”中我曾提到，“概率”（probability）这个基本概念存在着两种解读方式，它们分别对应着**概率的频率学派**（Frequentist）和**贝叶斯学派**（Bayesian）。而解读方式上的差异也延伸到了以概率为基础的其他学科，尤其是机器学习之中。

根据机器学习领域的元老汤姆·米切尔（Tom M. Mitchell）的定义，机器学习（machine learning）是一门研究通过计算的手段利用经验来改善系统自身性能的学科。

现如今，几乎所有的经验都以数据的形式出现，因而机器学习的任务也就变成了基于已知数据构造概率模型，反过来再运用概率模型对未知数据进行预测与分析。如此一来，关于概率的不同认识无疑会影响到对模型的构建与解释。

可在概率的应用上，频率学派和贝叶斯学派的思路呈现出天壤之别，这种思维上的差异也让两派的拥护者势同水火，都视另一方为异端邪说。正因如此，在这个专栏的前两篇文章中，我将首先和你理清频率学派与贝叶斯学派对概率的不同观点，为接下来**从不同的角度理解机器学习的各种算法**打下扎实的基础。

下面这个流传已久的笑话，不经意间对频率学派和贝叶斯学派的区别给出了形象的解释：有个病人找医生看病，医生检查之后对他说：“你这病说得上是九死一生，但多亏到我这里来看了。不瞒你说，在你之前我已经看了九个得一同样病的患者，结果他们都死了，那你这第十个就一定能看得好啦，妥妥的！”

如果病人脑子没事，肯定就从这个糊涂医生那里跑了。显然，医生在看待概率时秉持的是频率主义的观点，但却是个蹩脚的频率主义者。之所以说他是频率主义者，是因为他对九死一生的理解就是十次手术九次失败一次成功；说他蹩脚则是因为他不懂频率学派的基础，区区九个病人就让他自以为掌握了生死的密码。

归根到底，**频率学派口中的概率表示的是事件发生频率的极限值**，它只有在无限次的独立重复试验之下才有绝对的精确意义。在上面的例子中，如果非要从频率的角度解释“九死一生”的话，这个10%的概率只有在样本容量为无穷大时才有意义。因此即使“九死一生”的概率的确存在，它也不能确保第十个病人的康复。

**在频率学派眼中，当重复试验的次数趋近于无穷大时，事件发生的频率会收敛到真实的概率之上。这种观点背后暗含了一个前提，那就是概率是一个确定的值，并不会受单次观察结果的影响。**

将一枚均匀的硬币抛掷10次，结果可能是10次都是正面，也可能10次都是反面，写成频率的话就对应着0%和100%这两个极端，代表着最大范围的波动。可如果将抛掷次数增加到100次，出现正面的次数依然会发生变化，但波动的范围更可能会收缩到40%到60%之间。再将抛掷次数增加到1000，10000的话，频率波动的现象不会消失，但波动的范围会进一步收缩到越来越小的区间之内。

基于以上的逻辑，把根据频率计算概率的过程反转过来，就是频率统计估计参数的过程。**频率统计理论的核心在于认定待估计的参数是固定不变的常量，讨论参数的概率分布是没有意义的；而用来估计参数的数据是随机的变量，每个数据都是参数支配下一次独立重复试验的结果。由于参数本身是确定的，那频率的波动就并非来源于参数本身的不确定性，而是由有限次观察造成的干扰而导致**。

这可以从两个角度来解释：一方面，根据这些不精确的数据就可以对未知参数的精确取值做出有效的推断；另一方面，数据中包含的只是关于参数不完全的信息，所以从样本估计整体就必然会产生误差。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/11/87/cc/8b94c0d3.jpg" width="30px"><span>Geek_e2d0qt</span> 👍（84） 💬（1）<div>按照频率学派，由最大似然估计写出似然函数L=p^5(1-p)^3,令一阶导=0得出p=5&#47;8，Bob要连赢三局才能反败为胜，则Bob获胜的概率为（3&#47;8）^3。
</div>2018-06-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/55/26/c77853e0.jpg" width="30px"><span>Tiger</span> 👍（43） 💬（2）<div>分享个人的学习总结，不对的地方请老师指正：
    频率主义认为参数本身是固定的，只是我们不知道，而数据是关于参数的不完全的信息，这就需要我们通过某种手段（比如极大似然法）利用数据找到最优参数。又由于数据是随机的，所以每使用一组不同的数据，找到的参数都不同，但这与参数本身是固定的并不矛盾。这是因为受噪声等因素的影响，数据并非参数的真实反映（否则就可以把固定的参数找到），存在风险，而要计算风险，需要已知数据的真实分布，而数据的真实分布又依赖于参数，这似乎就陷入了一个“先有鸡还是先有蛋”的悖论，为了解决这个悖论，引入经验风险，用训练数据的分布替代真实分布，使得风险可以被计算（这时的风险就称为经验风险），那么通过最小化经验风险就可以找出最优的参数。</div>2019-01-07</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEL2wE4k0RxhvTOFu179WngoHIOQvIyoltqZlA1MHMlv7ALDWKyx4dOOLc9zcMuzdRbIAiahvcSQ0aA/132" width="30px"><span>Ares</span> 👍（6） 💬（3）<div>老师，先对L求对数，再对对数求一阶导的过程有么？另外为什么令一阶导=0什么意义？</div>2018-12-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/e3/a7/c1d476ba.jpg" width="30px"><span>velly</span> 👍（5） 💬（1）<div>参数定义是什么，不怎么理解。</div>2018-09-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/33/07/8f351609.jpg" width="30px"><span>JustDoDT</span> 👍（3） 💬（1）<div>上代码：python3 安装sympy包，pip install sympy
from sympy import *
# 定义符号p
p = Symbol(&#39;p&#39;)
L = p**5 * (1-p)**3
# 求导
d_L = diff(L, p)
# 解方程
res = solve(d_L, p)
# res = [0, 5&#47;8, 1]</div>2019-09-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/b5/4d/dd5cb7a0.jpg" width="30px"><span>游戏人生</span> 👍（3） 💬（1）<div>求解似然函数的对数，就可以将乘法运算转换为加法运算，中(θ_i-θ)^2&#47;2σ^2 多了一个1&#47;2吧，应该是

(θ_i-θ)^2&#47;σ^2，不是log⁡L  是ln⁡L吧。

</div>2019-05-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/52/a1/56622f4e.jpg" width="30px"><span>晴子</span> 👍（3） 💬（1）<div>L=p^5(1-p)^3, 对L求一阶导，怎么求出P=3&#47;8</div>2018-10-15</li><br/><li><img src="" width="30px"><span>never_giveup</span> 👍（3） 💬（1）<div>说下个人的对最后问题理解，p是待估计的参数 ，5:3是给出的数据。最大似然使在p条件下产生数据的可能性最大，进而求极值算出p。</div>2018-06-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/de/89/b25759e5.jpg" width="30px"><span>明臻</span> 👍（2） 💬（1）<div>置信区间的概率是不是写错了，应该是1-阿尔法。</div>2018-10-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/ab/4e/82e9657c.jpg" width="30px"><span>jeff</span> 👍（2） 💬（1）<div>九死一生 ，我看到的是医生治疗成功率是0
</div>2018-06-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/f0/42/7728d4f5.jpg" width="30px"><span>艿艿</span> 👍（2） 💬（1）<div>第二小节有点难……</div>2018-06-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/9c/94/341f55a4.jpg" width="30px"><span>朱沛</span> 👍（1） 💬（1）<div>大学数学没学好的是不是应该先补数学？</div>2018-06-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8c/90/2c16f7aa.jpg" width="30px"><span>洪漫楷</span> 👍（1） 💬（1）<div>没有图帮助理解的吗</div>2018-06-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/88/e2/002b04c6.jpg" width="30px"><span>.Yang</span> 👍（1） 💬（1）<div>我勒个去，看到一半跟不上了</div>2018-06-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/e4/4a/63e46022.jpg" width="30px"><span>WS</span> 👍（0） 💬（1）<div>观测数据sita的概率分布式子，看不懂，能解释一下吗？</div>2019-05-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/3a/29/b12c0f7c.jpg" width="30px"><span>浓眉和叶孤橙</span> 👍（0） 💬（2）<div>王老师，您好，我想问下，我现在学习概率图模型很吃力，有没有比较好的学习资料推荐，适合初学者？谢谢王老师</div>2019-04-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/2c/d8/442c13dc.jpg" width="30px"><span>李先生</span> 👍（0） 💬（1）<div>从理论上说，在功率有限的条件下，高斯噪声的信源熵最大，因而带来的不确定性也就越大，换句话说，这是最恶劣的噪声；
(为什么功率有限，就是高斯噪声的信源熵最大呢？)</div>2019-03-21</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/qsmAdOC3R3twep9xwiboiaNGlZ9dtY5NQZibVTKSpkwd6l63kicv3v5vSW3oO0erfxACL679azGTwEBkxfKNxs0VkQ/132" width="30px"><span>土土</span> 👍（0） 💬（1）<div>感觉有点听不懂，好多名词不会，不知道是不是概率论没学的原因，不知道是不是概率论没学的原因</div>2019-01-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/64/86/f5a9403a.jpg" width="30px"><span>yang</span> 👍（0） 💬（1）<div>老师，我非科班毕业两年，现在从事Java开发，可以考机器学习或者AI的研究生吗？ 求回复，谢谢🙏！</div>2018-12-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/88/ec/1460179b.jpg" width="30px"><span>我心飞扬</span> 👍（0） 💬（1）<div>既然噪声的概率分布就是因变量的概率分布，那直接检查一下因变量是不是服从正态分布是不是就可以了，为什么还要对噪声做假设呢</div>2018-07-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/fd/96/44641d9e.jpg" width="30px"><span>向阳</span> 👍（0） 💬（1）<div>3*3*3&#47;（8*8*8）</div>2018-07-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/88/ec/1460179b.jpg" width="30px"><span>我心飞扬</span> 👍（0） 💬（1）<div>请问假设噪声是高斯，问什么发生概率要写成正态，假设噪声高斯，发生概率其他不行吗</div>2018-06-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/ee/d9/84d44bc8.jpg" width="30px"><span>快乐的小傻子</span> 👍（12） 💬（0）<div>数学是基础，概率论和统计学要补补咯</div>2018-06-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/93/ec/985675c8.jpg" width="30px"><span>小高</span> 👍（6） 💬（0）<div>看来真的得好好补补数学了、看到数学公式一脸懵</div>2018-11-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/36/e7/c9eda4e7.jpg" width="30px"><span>stonyliu</span> 👍（3） 💬（1）<div>看了下有不少人说跟不上或者要去补课，感觉是每一句话都对，但前后逻辑衔接并不强。比如说医生的例子是两个学派区别的形象说明。但看完例子，道理我都懂，频率和概率的区别也懂了，但两个学派的区别到底是什么？就是频率和概率的区别吗，继续懵逼中。。</div>2020-07-07</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/g1icQRbcv1QvJ5U8Cqk0ZqMH5PcMTXcZ8TpS5utE4SUzHcnJA3FYGelHykpzTfDh55ehE8JO9Zg9VGSJW7Wxibxw/132" width="30px"><span>杨家荣</span> 👍（2） 💬（0）<div>极客时间
21天打卡行动 39&#47;21
&lt;&lt;机器学习40讲&#47;01&gt;&gt;频率视角下的机器学习
今日所学:
1,“概率”（probability）这个基本概念存在着两种解读方式，它们分别对应着概率的频率学派（Frequentist）和贝叶斯学派（Bayesian）;
2,机器学习（machine learning）是一门研究通过计算的手段利用经验来改善系统自身性能的学科;
3,频率学派口中的概率表示的是事件发生频率的极限值，它只有在无限次的独立重复试验之下才有绝对的精确意义;
4,概率是一个确定的值，并不会受单次观察结果的影响。
5,频率统计理论的核心在于认定待估计的参数是固定不变的常量，讨论参数的概率分布是没有意义的；而用来估计参数的数据是随机的变量，每个数据都是参数支配下一次独立重复试验的结果;
6,解释：一方面，根据这些不精确的数据就可以对未知参数的精确取值做出有效的推断；另一方面，数据中包含的只是关于参数不完全的信息，所以从样本估计整体就必然会产生误差。
7,统计学的核⼼任务之一是根据从总体中抽取出的样本，也就是数据来估计未知的总体参数。参数的最优估计可以通过样本数据的分布，也就是采样分布;
8,频率统计最常使用的最优化方法，就是最大似然估计（maximum likelihood estimation）。
9,如何来度量作为随机变量的估计值和作为客观常量的真实值之间的偏差呢？置信区间（confidence interval）就是频率学派给出的答案。
10,置信区间的意义在于划定了真值的取值范围，真实的参数会以一定的概率 α 落入根据样本计算出的置信区间之内;
11,频率主义解决统计问题的基本思路如下：参数是确定的，数据是随机的，利用随机的数据推断确定的参数，得到的结果也是随机的;
12,将频率主义“参数确定，数据随机”的思路应用在机器学习当中，得到的就是统计机器学习;
13,和参数相关的信息全部来源于数据，输出的则是未知参数唯一的估计结果，这是统计机器学习的核心特征。
14,经验风险（empirical risk），用训练数据的经验分布替换掉原始表达式中数据的真实分布;
重点:
1,频率学派认为概率是随机事件发生频率的极限值；
2, 频率学派执行参数估计时，视参数为确定取值，视数据为随机变量；
3,频率学派主要使用最大似然估计法，让数据在给定参数下的似然概率最大化；
4,频率学派对应机器学习中的统计学习，以经验风险最小化作为模型选择的准则。</div>2020-01-26</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/5e/4e/85502e98.jpg" width="30px"><span>balance</span> 👍（0） 💬（0）<div>“把根据频率计算概率的过程反转过来，就是频率统计估计参数的过程”这句怎么理解</div>2024-05-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/4e/b4/982ce293.jpg" width="30px"><span> 🇼   🇯</span> 👍（0） 💬（0）<div>看来得好好复习概率论相关数学知识 几个表达式就看懵逼了 别说求一阶导这些了</div>2023-06-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg" width="30px"><span>ifelse</span> 👍（0） 💬（0）<div>学习打卡，干货满满</div>2023-05-25</li><br/><li><img src="" width="30px"><span>Geek_1d1d6e</span> 👍（0） 💬（0）<div>L=p**5（1-p）**3  求对数 INL=5INLp+3INL（1-p）求导 dINp&#47;dp = 5&#47;p-3&#47;（1-p） 最大值 趋向0 变成5&#47;p=3&#47;1-p 计算得p等于5&#47;8 那么bob赢的概率就是1-5&#47;8=3&#47;8</div>2023-05-05</li><br/>
</ul>