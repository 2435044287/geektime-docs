在上一讲中我提到，深度学习既可以用于解释也可以用于预测。在实际中，这两个功能通常被组合使用，解释功能可以看作编码器，对高维信息进行低维重构；预测功能则可以看作解码器，将低维重构恢复成高维信息。

这样的两个深度网络级连起来，就形成了**编码-解码结构**（encoder-decoder model）。这种结构在诸如语音、文本、图像等高维数据的处理中应用广泛，取得了良好的效果。

编解码的思想来源于信息论，是信息传输与处理的基础理论之一。但在通信中，编解码的对象是底层的语法结构，也就是对携带信息的符号进行编码，通过数据压缩实现信息的高效传输，但输出的符号本身与其所表达的含义并无关联。

在深度学习中，编解码的操作更多在语义层面完成，无论是文本还是图像，**编解码的目的都是重新构造数据的表示方式，简化学习任务的难度**。

在最初的尝试中，编码器和解码器并不是分开的，而是存在于单个的深度网络中，这种深度结构就是自编码器。

**自编码器**（autoencoder）属于生成模型，它的作用是**以无监督的学习方式学到数据集的稀疏表示，从而给数据降维**。显然，它和前面介绍过的主成分分析殊途同归。可以证明，如果自编码器只有一个线性隐藏层，同时使用均方误差作为损失函数，那么$k$个隐藏神经元的权重系数就代表了输入数据的$k$个主成分。
<div><strong>精选留言（2）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（4） 💬（1）<div>特征工程更依赖于调试者的经验，对问题的理解。不同的调试水平对结果的影响大。

特征学习对于图像，语言处理，语音这些特征组合巨量，处理方式复杂的领域可以自动化特征抽取和转换的过程。就是在除Google的顶尖大公司和学术领域之外，实现一个有效的应用于真实商业环境的模型周期我估计不短。</div>2018-08-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg" width="30px"><span>ifelse</span> 👍（0） 💬（0）<div>学习打卡</div>2023-06-09</li><br/>
</ul>