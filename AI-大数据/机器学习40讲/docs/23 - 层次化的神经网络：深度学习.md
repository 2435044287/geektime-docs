虽然只是对生物神经网络的低水平模仿，人工神经网络却给机器学习打开了一扇全新的大门。自适应的特性让它能够灵活地更新参数，非线性则赋予它具有更加强大的表达能力。曾经的阿喀琉斯之踵——异或问题也随着隐藏层的引入迎刃而解，由原始特征重构而成的导出特征使多层感知器摆脱了对数据集线性可分的限制，呈现在神经网络前方的是大有可为的广阔天地。

神经网络最重要的正名出现在1989年，美国学者乔治·塞本科（George Cybenko）证明了神经网络以对数几率作为激活函数时的通用逼近定理。

简而言之，**通用逼近定理**（universal approximation theorem）说的是如果一个前馈神经网络（feed-forwad neural network）具有单个隐藏层，隐藏层就可以利用有限个神经元来逼近定义在实数集上的任意连续函数。

1991年，奥地利学者库尔特·霍尔尼克（Kurt Hornik）又证明了通用逼近特性并不取决于激活函数的选择，而是由多层前馈网络自身的架构决定，这就为神经网络的性能提供了坚实的理论依据。

每一个隐藏神经元都能够生成线性的分类边界，在不同的局部选取不同的线性边界，拼接起来的就是全局层面非规则的形状，这就是通用逼近定理说明的主要问题。
<div><strong>精选留言（4）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（4） 💬（2）<div>除了图像处理和自然语言处理这2个领域在我们的日常生活中感知到并能较明白地解释给外行听，其他领域的深度学习怎么既能通俗地解释清楚又能和商业价值建立联系是我们普通人学习和使用深度学习当下的主要困惑。毕竟不能为老板创造看得见的商业价值的事很难在商业环境得到持续的支持。

图像处理和自然语言处理则有不少的专业知识，工具或模块需要学习才能在工业界完成应用，对于普通人来说门槛比一般的机器学习更高。没有看明白的事我个人保持一定怀疑。深度学习肯定有价值，但是不是什么应用领域都能通过深度学习为企业创造更高价值，而不仅是估值。什么阶段，什么场景下合适这是我们很多人和团队领导者需要想得更清楚的问题。</div>2018-08-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c1/a7/5e66d331.jpg" width="30px"><span>林彦</span> 👍（3） 💬（0）<div>深度学习还有一个应用领域是语音，掌握的门槛也不低</div>2018-08-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg" width="30px"><span>ifelse</span> 👍（0） 💬（0）<div>学习打卡</div>2023-06-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/51/86/b5fd8dd8.jpg" width="30px"><span>建强</span> 👍（0） 💬（0）<div>想请教一下老师，阿尔法狗是深度神经网络的典型应用吗，老师能不能大致讲一下它的原理，一直对这个比较好奇。</div>2021-06-20</li><br/>
</ul>