你好，我是黄佳。

欢迎来到零基础实战机器学习。在前面几节课中，我们已经学习了两种优化机器学习模型的方法，一种是做各种特征工程，让特征集更适合模型；另一种是防止过拟合，让模型不用“那么”精确。

这两种方式的优化角度不同，特征工程是从数据预处理的角度，给出更高质量的数据，而防止过拟合则是在模型训练的过程中，控制模型的复杂度。其实，除此之外，我们还可以从模型的验证和评估环节入手，来优化模型性能。

## 交叉验证：小数据集的资源复用

你知道，在样本充足的情况下，我们会随机将数据分为3个部分：训练集、验证集和测试集。其中，训练集用来训练模型，验证集用来模型调优，测试集用来评估模型性能。

不过，你还记不记得我们在[第1讲](https://time.geekbang.org/column/article/413057)中介绍监督学习的时候，我说过有标签的数据是非常难以获得的。本来就很有限的数据集还要被拆成训练集、测试集和验证集，真是让人特别舍不得。

而且，我们知道数据集越大，就越不容易出现过拟合的现象。那么，我们如何利用较小的数据集，从而达到较大数据集的效果呢？这就需要交叉验证。

交叉验证的基本思想是这样的：将训练数据集分为k等份，其中k-1份用作训练集，单独的那一份用作验证集，整个过程重复k次，这也通常称作k折。这样就最大程度重复地使用了训练集中的数据，每一个数据都既做了训练，又做了测试，从而在最大程度上提高模型性能的可信度。
<div><strong>精选留言（10）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/15/66/8f/02be926d.jpg" width="30px"><span>在路上</span> 👍（3） 💬（1）<div>佳哥好，交叉验证会得到多个模型，在预测数据时，是把多个模型的预测值加总求平均值吗？</div>2021-09-22</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/rZ4LbfVYHpVxdibIvO5EyLwHDicm3R8EkjeibXTv91kMGP7hkNFbZ7NibPjEibVqRO2rXWkTLB96jNUM70RhuyD15GA/132" width="30px"><span>Siyige2727</span> 👍（3） 💬（2）<div>老师好，我按照下面的设置，跑出的结果，为什么验证集上的分数很低呢？
GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=10,
             param_grid={&#39;bootstrap&#39;: [True, False],
                         &#39;criterion&#39;: [&#39;mse&#39;, &#39;mae&#39;],
                         &#39;max_depth&#39;: [3, 5, 6, 10, 12, None],
                         &#39;max_features&#39;: [&#39;auto&#39;, &#39;sqrt&#39;],
                         &#39;min_samples_leaf&#39;: [2, 3, 5, 7, 10],
                         &#39;min_samples_split&#39;: [2, 5, 8, 10],
                         &#39;n_estimators&#39;: [50]},
             scoring=&#39;r2&#39;, verbose=1)

训练集上的R平方分数-调参后的随机森林: 0.8541
测试集上的R平方分数-调参后的随机森林: 0.0481</div>2021-09-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/38/4f/61/018352d4.jpg" width="30px"><span>静静呀</span> 👍（1） 💬（1）<div>老师我的网格搜索报错了，ValueError: Unknown label type: &#39;continuous&#39;，能帮我看看是什么原因吗
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import train_test_split
X = df_LTV.drop([&#39;用户码&#39;,&#39;年度LTV&#39;],axis=1) #特征集
y = df_LTV[&#39;年度LTV&#39;] #标签集
# 拆分成训练集和测试集 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)
model_rfr = RandomForestClassifier() # 随机森林模型
# 对随机森林算法进行参数优化
rf_param_grid = {&quot;max_depth&quot;: [None],
                  &quot;max_features&quot;: [3, 5, 12],
                  &quot;min_samples_split&quot;: [2, 5, 10],
                  &quot;min_samples_leaf&quot;: [3, 5, 10],
                  &quot;bootstrap&quot;: [False],
                  &quot;n_estimators&quot; :[100,300],
                  &quot;criterion&quot;: [&quot;gini&quot;]}
model_rfr_gs = GridSearchCV(model_rfr,
                            param_grid = rf_param_grid, cv=3,
                            scoring=&quot;r2&quot;, n_jobs= 10, verbose = 1)
model_rfr_gs.fit(X_train, y_train) </div>2023-11-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/a3/d6/c0d0cb25.jpg" width="30px"><span>刘成</span> 👍（0） 💬（1）<div>完成一个阶段了，坚持学完</div>2024-04-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/bf/6f/1916fba0.jpg" width="30px"><span>贝贝</span> 👍（0） 💬（1）<div>留脚印</div>2024-03-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/0f/45/1f6a4b0c.jpg" width="30px"><span>Vincent</span> 👍（0） 💬（1）<div>老师你好，关于 CV 有个疑问，CV 是用来评估模型的，而不是用来训练的。如果我们评估出最优的算法，后续用什么方式训练模型呢？把训练集和验证集合并来训练？</div>2024-01-05</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEKSVuNarJuDhBSvHY0giaq6yriceEBKiaKuc04wCYWOuso50noqDexaPJJibJN7PHwvcQppnzsDia1icZkw/132" width="30px"><span>Matthew</span> 👍（0） 💬（1）<div>作业3的代码：

# 创建模型
from sklearn.ensemble import RandomForestRegressor
model_rfr = RandomForestRegressor()

# 对随机森林算法进行参数优化
rfr_param_grid = {&#39;bootstrap&#39;: [True, False],
                 &#39;max_depth&#39;: [10, 50, 100, None],
                 &#39;max_features&#39;: [&#39;auto&#39;, &#39;sqrt&#39;],
                 &#39;min_samples_leaf&#39;: [1, 2, 4],
                 &#39;min_samples_split&#39;: [2, 5, 10],
                 &#39;n_estimators&#39;: [50, 500, 2000]}

# 导入 网格搜索 工具
from sklearn.model_selection import GridSearchCV 
model_rfr_gs = GridSearchCV(model_rfr,
                            param_grid = rfr_param_grid, cv = 3,
                            scoring=&quot;r2&quot;, n_jobs= 10, verbose = 1)
model_rfr_gs.fit(X_train, y_train) # 用优化后的参数拟合训练数据集
print(&quot; GridSearchCV 最佳参数组合:&quot;, model_rfr_gs.best_params_)

# 导入 随机搜索 工具
from sklearn.model_selection import RandomizedSearchCV
model_rfr_rs = RandomizedSearchCV(model_rfr, 
                                  param_distributions = rfr_param_grid, cv = 3, 
                                  n_iter = 10, 
                                  scoring=&quot;r2&quot;, n_jobs= 10, verbose = 1)
model_rfr_rs.fit(X_train, y_train) # 用优化后的参数拟合训练数据集
print(&quot; RandomizedSearchCV 最佳参数组合:&quot;, model_rfr_rs.best_params_)

from sklearn.metrics import r2_score,   median_absolute_error #导入Sklearn评估模块
print(&quot;GridSearchCV：&quot;)
print(&#39;训练集上的R平方分数-调参后的随机森林: %0.4f&#39; % r2_score(y_train, model_rfr_gs.predict(X_train)))
print(&#39;测试集上的R平方分数-调参后的随机森林: %0.4f&#39; % r2_score(y_test, model_rfr_gs.predict(X_test)))

print(&quot;RandomizedSearchCV：&quot;)
print(&#39;训练集上的R平方分数-调参后的随机森林: %0.4f&#39; % r2_score(y_train, model_rfr_rs.predict(X_train)))
print(&#39;测试集上的R平方分数-调参后的随机森林: %0.4f&#39; % r2_score(y_test, model_rfr_rs.predict(X_test)))</div>2023-06-04</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEKSVuNarJuDhBSvHY0giaq6yriceEBKiaKuc04wCYWOuso50noqDexaPJJibJN7PHwvcQppnzsDia1icZkw/132" width="30px"><span>Matthew</span> 👍（0） 💬（1）<div># 留一法分折 LeaveOneOut
loo = LeaveOneOut()
for fold_, (train_index, test_index) in enumerate(loo.split(df_LTV)):
    X_train = df_LTV.iloc[train_index].drop([&#39;年度LTV&#39;],axis=1) #训练集X
    X_test = df_LTV.iloc[test_index].drop([&#39;年度LTV&#39;],axis=1) #验证集X
    y_train = df_LTV.iloc[train_index][&#39;年度LTV&#39;] #训练集y
    y_test = df_LTV.loc[test_index][&#39;年度LTV&#39;] #验证集y 
    model_lr.fit(X_train, y_train) #训练模型
    # print(f&quot;第{fold_}折验证集R2分数：{r2_score(y_test, model_lr.predict(X_test))}&quot;) 
    print(f&quot;第{fold_}折验证集的真值：{y_test.values[0]} ,预测值：{model_lr.predict(X_test)[0]}&quot;) 

# 留多法分折 LeavePOut
lpo = LeavePOut(p=10)   
for fold_, (train_index, test_index) in enumerate(lpo.split(df_LTV)):
    X_train = df_LTV.iloc[train_index].drop([&#39;年度LTV&#39;],axis=1) #训练集X
    X_test = df_LTV.iloc[test_index].drop([&#39;年度LTV&#39;],axis=1) #验证集X
    y_train = df_LTV.iloc[train_index][&#39;年度LTV&#39;] #训练集y
    y_test = df_LTV.loc[test_index][&#39;年度LTV&#39;] #验证集y 
    model_lr.fit(X_train, y_train) #训练模型
    print(f&quot;第{fold_}折验证集R2分数：{r2_score(y_test, model_lr.predict(X_test))}&quot;) </div>2023-06-03</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEKSVuNarJuDhBSvHY0giaq6yriceEBKiaKuc04wCYWOuso50noqDexaPJJibJN7PHwvcQppnzsDia1icZkw/132" width="30px"><span>Matthew</span> 👍（0） 💬（1）<div>作业2的代码：

# 创建模型
from sklearn.linear_model import LinearRegression
model_lr = LinearRegression()

# 导入K折工具
from sklearn.model_selection import KFold 
from sklearn.model_selection import RepeatedKFold
from sklearn.model_selection import LeaveOneOut 
from sklearn.model_selection import LeavePOut

# 导入R2分数评估工具
from sklearn.metrics import r2_score 

# 普通的 KFold 方法
kf5 = KFold(n_splits=5, shuffle=False) #5折
for fold_, (train_index, test_index) in enumerate(kf5.split(df_LTV)): 
    # print(train_index, test_index)
    X_train = df_LTV.iloc[train_index].drop([&#39;年度LTV&#39;],axis=1) #训练集X
    X_test = df_LTV.iloc[test_index].drop([&#39;年度LTV&#39;],axis=1) #验证集X
    y_train = df_LTV.iloc[train_index][&#39;年度LTV&#39;] #训练集y
    y_test = df_LTV.loc[test_index][&#39;年度LTV&#39;] #验证集y 
    model_lr.fit(X_train, y_train) #训练模型
    print(f&quot;第{fold_}折验证集R2分数：{r2_score(y_test, model_lr.predict(X_test))}&quot;) 

# 重复 K 折 RepeatedKFold
rkf5 = RepeatedKFold(n_splits=5, n_repeats=10) # 5折，重复10次
for fold_, (train_index, test_index) in enumerate(rkf5.split(df_LTV)):
    X_train = df_LTV.iloc[train_index].drop([&#39;年度LTV&#39;],axis=1) #训练集X
    X_test = df_LTV.iloc[test_index].drop([&#39;年度LTV&#39;],axis=1) #验证集X
    y_train = df_LTV.iloc[train_index][&#39;年度LTV&#39;] #训练集y
    y_test = df_LTV.loc[test_index][&#39;年度LTV&#39;] #验证集y 
    model_lr.fit(X_train, y_train) #训练模型
    print(f&quot;第{fold_}折验证集R2分数：{r2_score(y_test, model_lr.predict(X_test))}&quot;) </div>2023-06-03</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEKSVuNarJuDhBSvHY0giaq6yriceEBKiaKuc04wCYWOuso50noqDexaPJJibJN7PHwvcQppnzsDia1icZkw/132" width="30px"><span>Matthew</span> 👍（0） 💬（1）<div>作业1的代码和结果：

# 创建模型
from sklearn.linear_model import Lasso
model_lasso = Lasso() #创建Lasso回归模型

# 交叉验证
from sklearn.model_selection import cross_validate # 导入交叉验证工具
cv = 3
scores = cross_validate(model_lasso, X, y, cv=cv, scoring=(&#39;r2&#39;, &#39;neg_mean_squared_error&#39;), return_train_score=True)

for i in range(cv):
    print(f&quot;第{i+1}折验证集的fit_time：{scores[&#39;fit_time&#39;][i]} &quot;)
    print(f&quot;第{i+1}折验证集的score_time：{scores[&#39;score_time&#39;][i]} &quot;)
    print(f&quot;第{i+1}折验证集的test_r2：{scores[&#39;test_r2&#39;][i]} &quot;)
    print(f&quot;第{i+1}折验证集的train_r2：{scores[&#39;train_r2&#39;][i]} &quot;)
    print(f&quot;第{i+1}折验证集的test_neg_mean_squared_error：{-scores[&#39;test_neg_mean_squared_error&#39;][i]} &quot;)
    print(f&quot;第{i+1}折验证集的train_neg_mean_squared_error：{-scores[&#39;train_neg_mean_squared_error&#39;][i]} &quot;)
    print(&quot;\n&quot;)
--------------------------------------------------------------------
第1折验证集的fit_time：0.000865936279296875 
第1折验证集的score_time：0.0006310939788818359 
第1折验证集的test_r2：0.5509442176019284 
第1折验证集的train_r2：0.49295429721273365 
第1折验证集的test_neg_mean_squared_error：36374278.87442617 
第1折验证集的train_neg_mean_squared_error：3931052.5016323677 


第2折验证集的fit_time：0.0009672641754150391 
第2折验证集的score_time：0.0004417896270751953 
第2折验证集的test_r2：-0.547095575701684 
第2折验证集的train_r2：0.756077640106148 
第2折验证集的test_neg_mean_squared_error：19259422.630117264 
第2折验证集的train_neg_mean_squared_error：10686185.198631434 


第3折验证集的fit_time：0.000530242919921875 
第3折验证集的score_time：0.0004150867462158203 
第3折验证集的test_r2：0.0975132893938776 
第3折验证集的train_r2：0.6571299228574952 
第3折验证集的test_neg_mean_squared_error：2236906.201517424 
第3折验证集的train_neg_mean_squared_error：16312807.147477873 </div>2023-06-02</li><br/>
</ul>