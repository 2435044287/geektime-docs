你好，我是黄佳。欢迎来到零基础实战机器学习。

上一讲中，我们通过逻辑回归和深度学习神经网络两种模型，判断了会员流失的可能性，准确率大概在78%左右。我想考一考你，这个准确率是否能够反映出模型的分类性能？

也许你会回答，看起来没什么问题啊。但是，如果我告诉你，对于这个数据集来说，即使不用任何机器学习模型，我闭着眼睛也能够达到70%以上的预测准确率。你会不会吓一跳，说，这怎么可能呢？

其实，如果你仔细观察一下这个数据集已经流失和留存下来的会员比例，就会发现，在这个数据集中，留下的会员是73%，而已经离开的会员占27%。

![](https://static001.geekbang.org/resource/image/1c/72/1ca4d96d0bc5bf49a2bdyy6883028672.jpg?wh=2000x1193 "流失与否？")

这也就是说，如果我直接提出一个模型，**判断所有的会员都会留存，那我这个模型的预测准确率就是73%**。所以说，要达到70%以上的预测准确率，真的是没有什么难度。

我再举一个极端一点的例子，在银行客户欺诈行为的检测系统中，存在欺诈行为的客户可能不到万分之一。那么，一个模型只要预测所有的客户都没有欺诈行为，这个模型的准确率就能达99.999%。

然而，这样的模型没有任何意义。因为**我们的目标不是判断出这9999个正常客户，而是要想法设法找出那万分之一的异常客户。**所以，对于我们这个问题来说，如何精确定位那23%的可能流失的客户，才是关键所在。
<div><strong>精选留言（4）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/16/b2/a9/791d0f5e.jpg" width="30px"><span>王平</span> 👍（2） 💬（1）<div>一个样本集合只能算出一个TPR和FPR，那为什么会能有多个点形成曲线呢</div>2023-02-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/15/66/8f/02be926d.jpg" width="30px"><span>在路上</span> 👍（0） 💬（1）<div>佳哥好，我认为今天的内容关键在于理解“预测值和真值共同组成的矩阵”，查准率、查全率和ROC曲线都是基于这个矩阵计算。我喜欢用真阳、假阳、真阴、假阴来理解这个矩阵，因为读医学相关内容时常看到“假阳性”一词。查准率是所有预测值为阳性的样本中确实是阳性的比率，查全率是所有实际值为阳性的样本中被预测为阳性的比率。假阳性就是没病的被当成了有病的，查准率就是1-假阳性概率。</div>2021-10-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/24/e2/83/e2888084.jpg" width="30px"><span>谦</span> 👍（0） 💬（2）<div>佳哥，对于不平衡数据集，训练的时候会不会容易造成模型更倾向于把比例较大的分类分对呢？因为训练的时候是降低整体损失，比例较大的分类对损失的贡献度应该更大，最后变成了模型更倾向于把比例较大的分对？</div>2021-10-04</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/S02BExph3FUJz2BiaKUSfrr8qwZqLlLzmk9CufCicoO4CwkMNFkByl7TshSaFcFK1OCnM1EY9nQsl8WgWFPh7foQ/132" width="30px"><span>Geek_b64f09</span> 👍（0） 💬（0）<div>老师好，我对这个不是太理解：“当阈值为1时，我们预测所有样本都为负类，这时FPR和TPR都是0”。我认为当阈值为1的时候，TP, FP都是0，但是FN好像也是0，这样的话，FPR可以等于0，但是TPR成了0除以0，好像没有意义。不知道这个理解是哪里不合适，希望老师指教，谢谢。</div>2024-01-24</li><br/>
</ul>