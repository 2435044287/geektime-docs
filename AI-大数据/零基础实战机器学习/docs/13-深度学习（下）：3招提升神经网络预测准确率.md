你好，我是黄佳。欢迎来到零基础实战机器学习。

在前面两讲中，我们创建了CNN和RNN两个常用的深度神经网络模型。今天，我们来专门谈一谈神经网络的优化，让前两讲中所创建的网络模型拥有更好的性能。

关于性能优化，我们不是第一次讲了，在[第8讲](https://time.geekbang.org/column/article/418354)到[第10讲](https://time.geekbang.org/column/article/419746)中，我们对应普通的机器学习模型，讲了三个阶段的性能调优：

- 在数据处理阶段，我们介绍了特征工程对于模型性能的重要性；
- 在模型训练阶段，我们介绍了过拟合的危害以及如何避免过拟合；
- 在测试评估阶段，我们介绍了交叉验证以及参数调优的方法。

其实，深度学习的性能优化和其它普通的机器学习模型类似，我们也可以从数据处理、网络模型本身，以及如何对神经网络进行参数调优这三个主要方面去考虑。

## 数据方面的考量：图像数据增广

我们已经知道，要提高模型的性能，数据方面的考量就是提升数据的“质”和“量”。那么，提升“质”，就是做好特征工程。不过你知道，神经网络对特征工程的要求是比较低的，因为神经网络本身就可以完成特征提取。

那怎么增加数据的“量”呢？我们都清楚，有标签的数据搜集起来真是太困难了，尤其是带标签的图片数据。那有没有什么方法能够在只有这么多图片的情况下，来提升我们[第11讲](https://time.geekbang.org/column/article/420372)中那个鲜花图片分类网络的性能呢？
<div><strong>精选留言（4）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/15/66/8f/02be926d.jpg" width="30px"><span>在路上</span> 👍（5） 💬（3）<div>佳哥好，听完这讲我有两个问题。第一，从“神经网络中的局部最低点”这张图来看，很容易看出哪个点是全局最低点，在任意时刻模型的数据都是确定的，也就是这张图代表的函数是确定的，为什么神经网络的参数不能直接根据函数找到全局最低点呢？第二，如果我在事后都不能解释Adam优化器为什么比RMSProp更优，那指不定那天我又要调整参数了，这个过程听着怎么一点都不智能。</div>2021-09-27</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEKSVuNarJuDhBSvHY0giaq6yriceEBKiaKuc04wCYWOuso50noqDexaPJJibJN7PHwvcQppnzsDia1icZkw/132" width="30px"><span>Matthew</span> 👍（0） 💬（1）<div>在看这个专栏前，我把李沐大神的《动手学深度学习》啃了一段时间，再来看专栏的11-13讲，还是有点感觉得。李沐大神的课程有从零实现的部分，而这个专栏侧重于调用API，相得益彰。</div>2023-06-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/37/7e/abb7bfe3.jpg" width="30px"><span>iff</span> 👍（0） 💬（2）<div>老师，您好，LSTM预测某一数据时（时间序列数据），发现训练集和测试集中预测值和真实值之间均存在延迟现象，请问一下，这是什么原因，怎么解决？</div>2021-09-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/44/ac/5868870a.jpg" width="30px"><span>Clive</span> 👍（0） 💬（0）<div>感觉时间序列的预测是滞后偏移的值</div>2024-06-23</li><br/>
</ul>