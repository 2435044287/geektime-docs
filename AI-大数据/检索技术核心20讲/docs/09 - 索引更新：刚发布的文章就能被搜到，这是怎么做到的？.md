你好，我是陈东。

在前面的课程中，我们讲到，倒排索引是许多检索系统的核心实现方案。比如，搜索引擎对万亿级别网页的索引，就是使用倒排索引实现的。我们还讲到，对于超大规模的网页建立索引会非常耗时，工业界往往会使用分布式技术来并行处理。

对于发布较久的网页，搜索引擎可以有充足的时间来构建索引。但是一些新的网页和文章，往往发布了几分钟就可以被用户搜索到。这又是怎么做到的呢？今天，我们就来聊一聊这个问题。

## 工业界如何更新内存中的索引？

我们先来看这么一个问题：如果现在有一个小规模的倒排索引，它能完全加载在内存中。当有新文章进入内存的时候，倒排索引该如何更新呢？这个问题看似简单，但是实现起来却非常复杂。

我们能想到最直接的解决思路是，只要解析新文章有哪些关键词，然后将文章ID加入倒排表中关键词对应的文档列表即可。没错，在没有其他用户使用的情况下，这样的方法是可行的。但如果你有过一定的工程经验，你就会知道，在实际应用中，必然会有多个用户同时访问这个索引。

这个时候，如果我们直接更新倒排索引，就可能造成用户访问错误，甚至会引发程序崩溃。因此，一般来说，我们会对倒排表加上“读写锁”，然后再更新。但是，加上“锁”之后会带来频繁的读写锁切换，整个系统的检索效率会比无锁状态有所下降。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/54/9a/76c0af70.jpg" width="30px"><span>每天晒白牙</span> 👍（16） 💬（1）<div>第一时间看到这个思考题，我没啥思路，看了大家的留言和老师的回复，学到了，把老师的回复总结了起来
为什么在增量索引中，对于要删除的数据没有像 LSM 树那样一样在索引中直接做删除标记，而是额外增加一个删除列表？
1.倒排所以和 kv 存储还是有不一样的地方，倒排索引的 posting list 元素有很多，每个元素都做删除标记代价较大
2.一个文档可能存在多个 key，所以一个文档都要修改删除标记的话，读写很频繁，加班性能下降
3.加标记也没什么用处，因为在对 postlist 做合并的过程中，数据都是全部存在的，只有在最后和全量索引合并时才进行真正的删除操作，这样可能还没有把要删除的元素放到一个删除列表中，在最后做交集更高效</div>2020-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/fa/f7/91ac44c5.jpg" width="30px"><span>Mq</span> 👍（11） 💬（3）<div>看不懂滚动合并机制，老师能结合具体数据分析下，例如我今天增加了几个网页，有倒排索引关键字的value都要加上这个网页，这个滚动合并的流程是咋样的。</div>2020-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg" width="30px"><span>奕</span> 👍（8） 💬（1）<div>对于结尾的问题：我在补偿一下，除了上面说的原因还有就是，一个文档 会有多个 key， 也不可能对文档包含的每个 key 进行文档标记</div>2020-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/9a/0a/922615cf.jpg" width="30px"><span>PhilZhang</span> 👍（7） 💬（2）<div>在滚动合并得例子中，如果此时有1个全量索引，5个周级索引，6个天级索引，1个增量索引，此时一次查询就要汇集1+5+6+1一共13个索引得结果是吧，另外为了保证读写分离，每个索引都要保存两份。不知道我的理解是否正确。</div>2020-05-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/96/47/93838ff7.jpg" width="30px"><span>青鸟飞鱼</span> 👍（6） 💬（6）<div>还是有点疑惑，可能太笨了？双缓存情况下，假如更新的索引中id有1，3，5，7...，同时规定更新一个索引，AB读写指针交换一次。假如A开始为写指针，最后更新的结果为A(1,5...)B(3,7...)还是A(1,3,5,7....)B(1,3,5,7.…)</div>2020-04-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/b6/7b/bebb4587.jpg" width="30px"><span>Impressw</span> 👍（5） 💬（1）<div>学到了很多，最近正好遇到了频繁更新索引，为什么能实时被检索到，速度又不会变慢的问题，看了这篇文章茅塞顿开，不过还是想问下，在大规模数据索引，频繁更新，真的能保证实时的情况下，完成更新索引吗</div>2020-05-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/40/1e/910aef6a.jpg" width="30px"><span>兰柯一梦</span> 👍（4） 💬（1）<div>如果在doc的正排字段中做标记删除是不是也可以呢？ 这样等各个索引进行合并的时候，看doc对应的正排的删除标记，如果是删除状态那边直接丢掉</div>2020-04-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/0f/70/cdef7a3d.jpg" width="30px"><span>Joe Black</span> 👍（3） 💬（1）<div>请问下对于Double Buffer机制，当索引A处于只读，索引B可更新时，两者访问都可以不加锁；假设每次对索引A的读访问会耗费一定时间，当B更新完毕后，通过原子操作把当前索引设为B，但是我们必须等待所有对A的读操作都结束了才能同步更新A。那么这个等待该如何处理呢？不使用锁怎么样才能知道对A的读取都完成了呢？</div>2020-06-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/de/d3/2aa0177f.jpg" width="30px"><span>paulhaoyi</span> 👍（2） 💬（1）<div>合并的三种方法，感觉一二是三的特殊情况，分别是只有一层和两层的三。不知道这么理解对不对？</div>2020-05-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/96/47/93838ff7.jpg" width="30px"><span>青鸟飞鱼</span> 👍（2） 💬（1）<div>双缓存机制有个疑问，假如A更新了一个数据1，B也需要更新数据1，这个如何保证呢？</div>2020-04-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg" width="30px"><span>范闲</span> 👍（2） 💬（1）<div>1.如果增加一个删除标记，相当于增量索引的每个内容都有这样一个标记，随着增量的数量变大，内存占用会更高。
2.利用删除列表就不会有这样的问题，同样可以避免加锁。</div>2020-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/48/ee/96a7d638.jpg" width="30px"><span>西西弗与卡夫卡</span> 👍（2） 💬（1）<div>用删除列表而不是打删除标记，可以避免对增量索引加锁</div>2020-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/ef/89/e1f9ed28.jpg" width="30px"><span>设置</span> 👍（1） 💬（1）<div>hi，大佬，请教一个问题：删除的id维持一个删除的列表，item的新增和修改操作都有可能导致一个id变为有效，那么每次消费到item新增或者修改的消息都要去check下delete list。我感觉全量+增量索引的delete list这块问不是很懂。</div>2021-10-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/42/c3/921a9e0e.jpg" width="30px"><span>cleverxiao</span> 👍（1） 💬（1）<div>双缓冲机制中，A负责读B负责写，一段时间后转换角色，B负责读A负责写，那么实在切换角色的时候进行AB间数据同步的么？</div>2021-05-28</li><br/><li><img src="" width="30px"><span>奇奇</span> 👍（1） 💬（3）<div>双缓冲区难道就不需要加锁了吗？假如更新B，这个时候指向A的指针切向B，请问如何保持A和B的一致性？不然这个时候有人更新A，但是B的更新还没有同步到A，这不就不一致了吗？还是只能加锁啊</div>2020-07-15</li><br/><li><img src="" width="30px"><span>CBGSIMON</span> 👍（1） 💬（1）<div>针对第三种方案的理解：最终合并到全量的索引中还是要全量遍历，但设计了这样的层级后，就减少了这样的频率。
小的和小的合并，等小的达到一定程度再和大的合并

没看出第2个相对第1个优化在哪里？
第2个不也是要重建全量索引么？如果不是重建，是在原来的全量索引上更新，那更新的时候又要加写锁吧？</div>2020-05-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/1d/13/31ea1b0b.jpg" width="30px"><span>峰</span> 👍（1） 💬（1）<div>对这个问题，老师故意在文章里说的很含糊，只说了个记录删除列表的思路😜。
lsm之所以可以和删除标记一起存，核心在于类似kv存，删除标记和对应的v是共享k的，所以要拿是会一起拿出来，就可以判断数据这个时候存在不存在，相当于拿到了值的变迁历史。
而这个场景，删除文档，对文档集合而言，也可以添加个删除标记，但对于索引而言，它涉及到很多关键字的poslist里对它的指向，这要一个个都加上吗，如果删除的不多，显然还不如最后返回的时候做一个全局的deletelist判断。</div>2020-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4e/1b/f4b786b9.jpg" width="30px"><span>飞翔</span> 👍（0） 💬（1）<div>话说老师 为了保证高可用 比如天级索引 是不是要复制三份 在三个机器上呀 这个过程是怎么实现的？</div>2021-10-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4e/1b/f4b786b9.jpg" width="30px"><span>飞翔</span> 👍（0） 💬（1）<div>如果 增量索引机器down了 增量索引 不久消失了？</div>2021-10-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/9a/64/ad837224.jpg" width="30px"><span>Christmas</span> 👍（0） 💬（1）<div>想起来hbase tired compaction 还有各种监控系统的最近一天。最近3天。最近一周，最近一个月，最近一年的数据优化压缩机制</div>2021-03-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/23/c2/5c/791d0f5e.jpg" width="30px"><span>易企秀-郭彦超</span> 👍（0） 💬（1）<div>滚动合并 按不同时间周期合并的方式 没有解决合并去重和合并删除的问题</div>2021-01-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/43/c5/288c59ab.jpg" width="30px"><span>造梦师</span> 👍（0） 💬（3）<div>1 如果只是进行数据状态的更新 应该不用加锁吧
2 如果索引都存到了磁盘上 怎么保证相应时间呢</div>2020-08-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/df/0e/4e2b06d5.jpg" width="30px"><span>流浪在寂寞古城</span> 👍（0） 💬（1）<div>目前还没接触过那么大的检索场景。索引的操作无非是增、删、改、查。看到滚动合并法，查询的时候是每一个索引都要去召回吗？如果是update，在天级索引加上这个doc，召回、合并索引的时候取时间最新的吗？</div>2020-06-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/3a/82/1ff83a38.jpg" width="30px"><span>牛牛</span> 👍（0） 💬（1）<div>看到`双缓冲`的实现、感觉跟redis的rehash思想有点儿类似 ?
redis 进行rehash的是启用 ht[1], 然后一步步在添加的过程中搬移原ht[0]的数据、同时标记搬移的位置, 等到数据搬移完成、就将 ht[1] 切为 ht[0], 同时释放ht[0], 申请新的ht[1] 为下次rehash做准备

双缓冲是, 更新B索引、保证A索引只读, 更新完成后A&#47;B互换, 损耗就是双倍内存消耗, 不适合大量数据场景(不过也是一种无锁设计)</div>2020-05-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/f7/5b/d2e7c2c4.jpg" width="30px"><span>时隐时现</span> 👍（0） 💬（1）<div>老师好，有2个问题：
1、删除列表的结构是什么样的？我理解的删除分2种，删除关键字和删除文档。前者只需要将对应的kv提取即可，代价很小。后者还是需要根据文档关键字遍历(二分查找)每个posting list，这一操作并不比打deleted标签小，只是在查询时可以优先读取delete list，这样省去了增量索引和全量索引的归并代价。
2、滚动合并
需要和磁盘上的天索引合并，此时天索引要不要加锁，如果有查询怎么办？莫非还要对天索引复制一份执行读写分离？</div>2020-05-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg" width="30px"><span>奕</span> 👍（0） 💬（1）<div>在滚动合并方案中，查询也要一级一级的进行查询， 先查增量索引---&gt; 天级索引----&gt; 周级索引---&gt; 最后是权量索引。 这个的话查询的链路增加了好多，查询的效率会降低多少？</div>2020-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg" width="30px"><span>奕</span> 👍（0） 💬（1）<div>为什么在增量索引的方案中，对于删除的数据，我们不是像 LSM 树一样在索引中直接做删除标记，而是额外增加一个删除列表？
这个我认为 ，删除的数据相对全量的数据是非常少的，如果用删除标记，那么全部的数据都要进行标记，这样大量的没有删除的数据都会有个未删除的标志，极大的浪费空间资源</div>2020-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/52/40/e57a736e.jpg" width="30px"><span>pedro</span> 👍（0） 💬（1）<div>按照索引的高性能选择，全量索性是只读的，而增量索引和删除项是可读可写的，所以不会选择在索引上添加删除项，会拉低系统效率。</div>2020-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（0） 💬（1）<div>在滚动更新中，周索引往全量索引更新的时候，需要加锁操作么？</div>2020-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg" width="30px"><span>ifelse</span> 👍（0） 💬（0）<div>一个很重要的工业设计思想，就是读写分离。--记下来</div>2023-04-11</li><br/>
</ul>