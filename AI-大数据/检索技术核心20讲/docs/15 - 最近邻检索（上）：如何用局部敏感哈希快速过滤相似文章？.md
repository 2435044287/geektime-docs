你好，我是陈东。

在搜索引擎和推荐引擎中，往往有很多文章的内容是非常相似的，它们可能只有一些修饰词不同。如果在搜索结果或者推荐结果中，我们将这些文章不加过滤就全部展现出来，那用户可能在第一页看到的都是几乎相同的内容。这样的话，用户的使用体验就会非常糟糕。因此，在搜索引擎和推荐引擎中，对相似文章去重是一个非常重要的环节。

对相似文章去重，本质上就是把相似的文章都检索出来。今天，我们就来聊聊如何快速检索相似的文章。

## 如何在向量空间中进行近邻检索？

既然是要讨论相似文章的检索，那我们就得知道，一篇文章是怎么用计算机能理解的形式表示出来的，以及怎么计算两篇文章的相似性。最常见的方式就是使用**向量空间模型**（Vector Space Model）。所谓向量空间模型，就是将所有文档中出现过的所有关键词都提取出来。如果一共有n个关键词，那每个关键词就是一个维度，这就组成了一个n维的向量空间。

那一篇文档具体该如何表示呢？我们可以假设，一篇文章中有k（0&lt;k&lt;=n）个关键词，如果第k个关键词在这个文档中的权重是w，那这个文档在第k维上的值就是w。一般来说，我们会以一个关键词在这篇文档中的TF-IDF值作为w的值。而如果文章不包含第k个关键词，那它在第k维上的值就是0，那我们也可以认为这个维度的权重就是0。这样，我们就可以用一个n维的向量来表示一个文档了，也就是&lt;w1,w2,w3,……wn&gt;。这样一来，每一个文档就都是n维向量空间中的一个点。  
![](https://static001.geekbang.org/resource/image/f4/78/f486531c01fd62d0cfbc529f58fd1878.jpg?wh=1920%2A1080 "一个文档的向量化表示")
<div><strong>精选留言（17）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/de/d3/2aa0177f.jpg" width="30px"><span>paulhaoyi</span> 👍（11） 💬（1）<div>感觉局部敏感hash和深度学习中的embedding好相近啊，都是临近点的向量表示很相近。不知道应用中有没有相互替换的场景。</div>2020-04-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（10） 💬（1）<div>与simHash类似的还有个minHash，查了资料对比了下，貌似是minHash对于权重处理不是很好，而且处理时候因为要计算多个hash函数，占用更多CPU资源，而superminhash在处理速度上更胜一筹。不知理解是否正确？

讨论问题：
1. 最开始想法是对于4位不同，采用5段分割，但是对于64bit，5段不能整除。可以增大分割的段数，可采用8段分割来计算。
2. 暂时没想到其它具体应用</div>2020-04-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg" width="30px"><span>奕</span> 👍（7） 💬（2）<div>对于思考题：
1：利用抽屉性原理，可以分为 5段保证，至少有一段是相等的，但是我看下面的老师评论说，最好分为 8段，但是这样的话相似度准确性是不是会降低很多？  因为分为 8段 的话至少要有 4个是相等的， 还是分为8段的时候进行了特殊处理？
2: 还可以对其他东西，比如图片，歌曲进行特征向量提取，再利用局部敏感哈希函数，这里还不用考虑语义上的相似</div>2020-05-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4d/49/28e73b9c.jpg" width="30px"><span>明翼</span> 👍（4） 💬（2）<div>这篇文章干货很多，这是很好的思路。说下我的理解，局部敏感hash关注点在于保持相似性的原文hash也相似，我一般用hash多是检验是否修改过了，或者判断是否存在比如布隆过滤器。谷歌的那个算法更是让我开了眼界，通过计算词的hash得到64bit序列，为叠加权重将0改成-1，我们如果不修改那和权重相乘的结果是0，叠加成文章权重的时候，权重很小的关键词和权重很大的关键词在这一位的影响是一样的了，然后将所有的关键词叠加保证了大权重关键词影响大，比如大关键词在一位中为-1，那最终结果很可能这一位为负数，最终为了方便比较可以说做了另外一个映射，映射成0和1这种64位比特流，因为这样和二进制对应。后面的海明距离的就更巧妙了，分割数据看成多个段，回答下问题吧：
1. 海明距离4为区分度，那分割成五段的话，至少有一段是完全相同的，不过这样分割不太好分割，分割成8段，我理解的过程为0-7为一组8-15 16-23一次类推分成8个组后，每个组都有8位，那每组就有16个不同的key因为2*8，后面postlist为哪些文章的哪些位对应这组key，查询文章过来后，找到相同的key的所有文章，这样我们得到8组文章，然后既然距离为4，我们可以每两个组求交集，每求三次仍然保留的满足条件，抽出来作为结果集，这个求的过程好好设计。
2.  这种算法可以用在推荐爱好相似的好友上，比如我们给用户打不同的标签，所有的标签组成一个文章，按照上述算法求相近的用户，推荐为好友；相似路径是不是可以，我们把一段距离之间的几个关键经过点标记出来作为词，然后比较相似性。图片音乐这种也适合；图书如果打上标签，或者用图书关键词也合适</div>2020-05-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/57/4f/6fb51ff1.jpg" width="30px"><span>奕</span> 👍（3） 💬（3）<div>每一个文档都根据比特位划分为 4 段，以每一段的 16 个比特位的值作为 Key，建立 4 个倒排索引
-------------------------------
这里是怎么 以 16 个比特位的值作为 Key 建立倒排索引的呢？ 怎么把文档分配到这四个 posting list 中的？ 这里没有理解

还有下面的分段查询的图中，怎么每个倒排索引里面 还有以key建的倒排索引？ 这里的key是每一段的 位取值吗？0- 2^16-1 个倒排索引？</div>2020-05-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg" width="30px"><span>范闲</span> 👍（3） 💬（1）<div>1.距离相近的点比距离相远的点更容易发生Hash碰撞，这是局部敏感哈希的理论根据
2. LSH family有hyperplane和crosspoltye的，同样SimHash也是一种方法
3.文章中的例子都是关键词的，实际上现在可以做成embedding的比较吧，这样关键信息的丢失会更少
4.所有的ANN相关算法，都是建立在对全空间的不断划分上，将全空间划分为若干子空间，然后在子空间里搜索最近邻.

思考题目:
1.如果4位以内的不同，都可以认为比较相似，那么划分的时候64位应该划分成8段比较合适。

2.除了文章，其他的embedding的相似性求解也可以。
</div>2020-04-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/45/8f/a56b2214.jpg" width="30px"><span>innocent</span> 👍（2） 💬（1）<div>请问老师，业界主流的文本相似度计算就是采用局部哈希么</div>2020-05-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/4f/3f/6f62f982.jpg" width="30px"><span>wangkx</span> 👍（2） 💬（1）<div>通过学习这一讲，我联想到了虚拟内存到物理内存的页表映射方法。在映射时，虚拟内存的高位用于从映射到物理内存，低位作为偏移量，然后得到真实的物理地址。

老师，我联想的对吗？</div>2020-05-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/23/79/ed/b8486f49.jpg" width="30px"><span>Ignite</span> 👍（1） 💬（1）<div>由于每个比特位只有 0 和 1 这 2 个值，一共有 64 个比特位，也就一共有 2*64 共 128 个不同的 Key。为啥是2*64而不是2^64</div>2021-10-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/22/e3/510b69f9.jpg" width="30px"><span>benny</span> 👍（1） 💬（1）<div>分八段后，要找至少四段相同的吧？这块处理有啥特殊技巧？</div>2020-06-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/f7/5b/d2e7c2c4.jpg" width="30px"><span>时隐时现</span> 👍（1） 💬（1）<div>多谢老师的精彩分享，有2个小问题：
1、SimHash的前4步都可以理解，但是最后一步 “将最终得到的编码中大于 0 的值变为 1，小于等于 0 的变为 0。这样，编码 &lt;5,1,-1,5, 1&gt; 就会被转换为 &lt;1,1,0,1,1&gt;。”
似懂非懂，多少还是不太能理解，这样当真不会让最高权重的关键词影响受损吗？那么2和9，最后都变成1，感觉9&quot;吃亏了&quot;,^—^...
2、还有1个小问题，SimHash表示的hash编码，在计算过程中，&lt;3,3,-3,3,3&gt;，会不会出现单个数值变成2位甚至是3位数的情况，如果会，在算法具体实现时，每个数值用1bit还是1byte来表示？</div>2020-05-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/23/66/413c0bb5.jpg" width="30px"><span>LDxy</span> 👍（1） 💬（2）<div>当关键词是几万乃至百万级别时，文档的向量空间可能是一个上万维甚至是百万维的超高维空间，使用 k-d 树就更难以完成检索工作了。
——这是不是就是万维网这个名称的由来？</div>2020-04-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/c5/af/174261ab.jpg" width="30px"><span>armatrix</span> 👍（0） 💬（1）<div>“由于每个比特位只有 0 和 1 这 2 个值，一共有 64 个比特位，也就一共有 2*64 共 128 个不同的 Key”这个应该是2^64个？</div>2021-10-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/cd/db/7467ad23.jpg" width="30px"><span>Bachue Zhou</span> 👍（0） 💬（1）<div>我对局部敏感哈希还是抱有怀疑，这个和二分搜索不同，二分搜索每次比较都能排除掉一半的数据，但是随机划分超平面却不一定，可能一开始 n 较小的时候，每次划分都能排除近一半的可能，但随着 n 的提高，排除的概率越来越低，我无法计算当 n 要达到什么程度的时候，两点哈希相同距离确实较近的概率能高于百分之九十九。</div>2020-12-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/f7/5b/d2e7c2c4.jpg" width="30px"><span>时隐时现</span> 👍（0） 💬（1）<div>
刚刚发了2个小问题，系统还没放出来，再追加第3个小问题，希望老师有空解答一下。
3、这种依靠关键词过滤查找相似文章的算法，能不能用到论文放抄袭上？但是一篇论文有太多的字和关键字，就算用SimHash和抽屉优化，也要对每个字或者关键字挨个比对一遍吗？有没有更优化的算法？</div>2020-05-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg" width="30px"><span>ifelse</span> 👍（1） 💬（0）<div>学习打卡，干货满满</div>2023-04-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/99/79/74d4f24f.jpg" width="30px"><span>anker</span> 👍（0） 💬（0）<div>1. 对于 SimHash，如果将海明距离在 4 之内的文章都定义为相似的，那我们应该将哈希值分为几段进行索引和查询呢？
答：k = 4时，可以采取分割为八份，为啥不选择5呢，CPU计算对于2的倍数计算天然友好。
分割为八份的时候，posting list 可以采取B+树存储，进行多路归并，把N路中，相同的key才需要进行海明距离的计算，可以减少很多计算量

2.SimHash 的算法能否应用到文章以外的其他对象？你能举个例子吗？
答：可以处理人的声音识别用于刑侦技术</div>2021-08-09</li><br/>
</ul>