你好，我是陈东。

对基于内容或者属性的检索场景，我们可以使用倒排索引完成高效的检索。但是，在一些超大规模的数据应用场景中，比如搜索引擎，它会对万亿级别的网站进行索引，生成的倒排索引会非常庞大，根本无法存储在内存中。这种情况下，我们能否像B+树或者LSM树那样，将数据存入磁盘呢？今天，我们就来聊一聊这个问题。

## 如何生成大于内存容量的倒排索引？

我们先来回顾一下，对于能够在内存中处理的小规模的文档集合，我们是如何生成基于哈希表的倒排索引的。步骤如下：

1. 给每个文档编号，作为它们的唯一标识，并且排好序；
2. 顺序扫描每一个文档，将当前扫描的文档中的所有内容生成&lt;关键字，文档ID，关键字位置&gt;数据对，并将所有的&lt;关键字，文档ID，关键字位置&gt;这样的数据对，都以关键字为key存入倒排表（位置信息如果不需要可以省略）；
3. 重复第2步，直到处理完所有文档。这样就生成一个基于内存的倒排索引。  
   ![](https://static001.geekbang.org/resource/image/2c/0d/2ccc78df6ebbd4d716318d5113fa090d.jpg?wh=1920%2A679)

内存中生成倒排索引

对于大规模的文档集合，如果我们能将它分割成多个小规模文档集合，是不是就可以在内存中建立倒排索引了呢？这些存储在内存中的小规模文档的倒排索引，最终又是怎样变成一个完整的大规模的倒排索引存储在磁盘中的呢？这两个问题，你可以先思考一下，然后我们一起来看工业界是怎么做的。
<div><strong>精选留言（14）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/84/39/c8772466.jpg" width="30px"><span>无形</span> 👍（14） 💬（1）<div>评论里提到用数组来存储字典，不太清楚这个字典的key和value是什么，这个涉及怎么存储，如果是ID到key，我想到用连续空间来存储，按这种结构id|length|value，先对ID排好序，length是key的长度，value是key的值，这样存储紧凑，没有浪费空间，这样查找key就可以根据ID找key，不匹配可以跳过length的长度，提高效率，如果对这片连续空间创建索引，用数组实现，数组里存储的是ID|偏移量，偏移量是相对连续空间地址的距离，可以实现二分查找；如果是key到ID的映射，类似上面的结构，按照length、key字典序排序好……有点复杂还没完全想好</div>2020-04-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/1d/13/31ea1b0b.jpg" width="30px"><span>峰</span> 👍（11） 💬（2）<div>存储效率优化想象中就两条路，第一是压缩，像老师说到的fst，对关键字集合的压缩。第二就是除了要存的数据，尽量别存些有的没的，比如我就用连续内存空间存词典中的每一项，是不是最省空间的，是但是变长怎么找，那再加个数组存词典中每一项的地址(
当然注意有序，当然稀疏索引也不是不能接受)。那你更新代价很高呀，那就把上述两个结构分成块存。这查找效率又不行了，那我多加几层索引，树就来啦，得出结论tradeoff真可怕。。。。</div>2020-04-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/1d/de/62bfa83f.jpg" width="30px"><span>aoe</span> 👍（5） 💬（3）<div>今天才知道“前缀树”是一种压缩算法，原来只知道有这样一个数据结构……有兴趣小伙伴可以自己实现一下https:&#47;&#47;leetcode-cn.com&#47;problems&#47;implement-trie-prefix-tree&#47;

占用内存空间更小的数据结构：可以采用类似“布隆过滤器”的设计，创建一个bit型的数组，1GB内存大约可以存放85亿的key。

实现思路：
1. 创建一个bit数组
2. 需要搜索的关键字通过Hash算法映射到数组的索引位置
 2.1. 索引位置 已使用值 = 1，未使用值 = 0 （缺点：根据“鸽巢原理”未能解决Hash冲突）
 2.2. Hash算法简单实现（使用余数定理）：（搜索关键字 转 数字）% 数组长度（约85亿）

1GB存85亿的key计算推导：

bit: 计算机中的最小存储单元 
1byte包含8bits  
1KB=1024Byte    KB是千字节
1MB=1024KB      MB是兆  
1GB=1024MB      GB是千兆 
1TB=1024GB      TB是千千兆

1GB = 1024MB 
    = 1024 * 1024KB 
    = 1024 * 1024 * 1024Byte
    = 1024 * 1024 * 1024 * 8bit
    = 8,589,934,592
    ≈ 85亿
    
也可以使用工具直接转换：https:&#47;&#47;www.bejson.com&#47;convert&#47;filesize&#47;</div>2020-04-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/c3/48/3a739da6.jpg" width="30px"><span>天草二十六</span> 👍（5） 💬（1）<div>es倒排索引铺垫到现在差不多讲完了，真棒的梳理思路</div>2020-04-14</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/77/61/adf1c799.jpg" width="30px"><span>KL3</span> 👍（4） 💬（1）<div>请问老师，对倒排文件的检索，为了提高效率将词典加载到内存，并用哈希表组织，那哈希表的key是String，value是pos（文档列表在硬盘中的位置）吗？</div>2020-05-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/19/70/67/0c1359c2.jpg" width="30px"><span>qinsi</span> 👍（4） 💬（3）<div>不是很明白存储关键词对应的字符串的作用。

1. 配图里的word是指关键字，string是指关键字所在的字符串吗？string是否可以理解为word所处的context？能否有些具体的例子呢？
2. 存入磁盘上的临时文件时只存了string而没有存word？那么在合并文件时word的信息是从哪来的呢？
3. 如果不存string，而只是根据word来做排序与合并的话，会有什么不好的后果吗？
</div>2020-04-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/5f/e5/54325854.jpg" width="30px"><span>范闲</span> 👍（4） 💬（1）<div>在无压缩的情况下:
对于Hash表的存储而言，数据量大的是value，是内容。

数组当然可以直接存储，但是内容太大的情况下，占用的连续内存太大了，可能会导致内存申请失败。

对于二叉树而言，内容的内存占用并没有减少，但是求交集的操作比链表复杂些。</div>2020-04-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/84/39/c8772466.jpg" width="30px"><span>无形</span> 👍（3） 💬（6）<div>看到评论里有提到前缀树，我有点疑问，如果字典的key只英文字母，如abcd可以用0123来表示，但是key如果还包含各种中英文符号、中文、韩文以及特殊字符等，怎么处理？

我还有两个问题，
1.对于根据关键词检索出来的文档，假如结果集达到百万千万级，怎么实现快速对结果集的排序？
2.对于已有的文档已经生成了key及对应的全量的文档列表，现在又有了新的文档，生成新的文档列表，全量的和新的文档列表怎么去合并？什么时候去合并？</div>2020-04-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/4d/49/28e73b9c.jpg" width="30px"><span>明翼</span> 👍（0） 💬（1）<div>首先老师说hash表比较大，我们无法加入到内存中，hash表一般来说key比较小，那么假如我们hash表是按照拉链法来解决冲突，在持久化磁盘中，按照槽位的顺序保存 ，每一行即一个 [ 槽位，key，list(value)]
，由于不是每个槽位都有值，没有值的槽位key空着。我们可以在内存中，保存key和槽位的对应，以一个和槽位一样大小的数组，这样槽位和大hash表里面的槽位对应，值保存这个槽位的行在文件中的位置，来查询的时候，对要查询的数据计算hash值%槽位，得到的结果去内存中的数组中对应的位去找，找到再到文件找，找不到，就没有；如果key仍然很多，也无法用内存保存起来，可以只保存有值的key，数组中为结构体，里面含有有值的槽位，还有这个槽位在文件中的位置，查找的时候，用二分法查找；如果保留key也保存不下，那就试试用B+树，可以只保留几层，那就不用文件了，非叶子节点保存的是有值的槽位，用二分法很容易搜索，叶子节点为真正的槽位对应的值的list，不过这样的性能要差些，这样一变还是哈希表吗，哈哈</div>2020-04-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/26/eb/d7/90391376.jpg" width="30px"><span>ifelse</span> 👍（1） 💬（0）<div>学习了，干货满满</div>2023-04-10</li><br/><li><img src="" width="30px"><span>Geek_7b1aa5</span> 👍（0） 💬（0）<div>思考：倒排索引的dict如果能全部加载进内存，就会大幅提升效率，在hash表无法存入内存的情况，是否能用其他内存空间占用更小的数据结构，来将词典完全加载到内存，有序数组和二叉树是否可行？想要节省空间，哈希表中的key应该是每个词项的hash值，而value是这个词项的字符串以及postlist指针（需要一个结构体）主要是value占用的空间比较多。

可以考虑数组的连续空间存储
● 首先思路就是使用一个数组，每个数组元素存（结构体|length)，但是结构体中的string词项是变长的，因此开辟数组空间只能以最长的为准，这样导致空间的浪费。
● 改进的思路就是使用可变长的char数组紧凑的存储（结构体），顺序查找是比较慢的，然后在使用一个int数组建立索引，每个元素都是int类型，存储结构体的hash值，指向char对应数组元素位置。</div>2024-06-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2a/2e/e8/e00c02de.jpg" width="30px"><span>迪马</span> 👍（0） 💬（0）<div>倒排索引是怎么实现范围检索的？</div>2022-11-09</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/24/33/bcf37f50.jpg" width="30px"><span>阿甘</span> 👍（0） 💬（0）<div>老师你上面提到的最后给出的解决方案：词典文件 + 倒排文件的方式。是不是一个search要走两次IO啊。一次是根据内存的term index找到该term在磁盘中的词典文件的pos，从而捞出term对应的posting list的pos，然后再根据这个pos从磁盘中的倒排文件捞出最终的posting list？</div>2022-07-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1d/a3/8e/518835da.jpg" width="30px"><span>无昂</span> 👍（0） 💬（1）<div>对于一些&quot;黑产&quot;造出来的一些“违规词”，这次违规词在分词的时候，分词组件并不能很好的识别把这些词分成一个词，这样搜索的效果会大打折扣，这样的问题该如何解决呢？</div>2022-02-05</li><br/>
</ul>