你好，我是胜辉。

“实战一：TCP真实案例解密篇”刚刚结束。在过去的十几讲里，我们全面回顾了TCP的各种技术细节，从握手到挥手，从重传等容错机制，到传输速度等效率机制，应该说也是对我们的TCP知识做了一个全面的“体检”。如果你发现自己对TCP的掌握还有不少漏洞，也别着急，可以回头复习一下相应部分的内容，或者在留言区提问，我会给你解答。

从这节课开始，我们要进入网络排查的“实战二：应用层真实案例解密篇”了。今天要给你讲解的是一个关于Nginx的排查案例。

## Nginx的499状态码是怎么回事？

你肯定听说过Nginx，或者经常用到它。作为一个高性能的HTTP和反向代理服务器，Nginx不管是用来搭建Web Server，还是用作负载均衡都很合适，并且它可供配置的日志字段也很丰富，从各类HTTP头部到内部的性能数据都有。

不过，你在日常维护Nginx时有没有遇到过这种情况：**在Nginx的访问日志中，存在499状态码的日志。**但是常见的4xx家族的状态码只有400、401、403、404等，这个499并未在HTTP的RFC文档中定义，是不是很奇怪？

这个499错误日志，在流量较大的场景下，特别是面向Internet的Web站点场景下还是很常见的 。但如果你遇到过，第一感觉可能会是一头雾水，不知道499这个状态码具体是用来干啥的，因为确实跟其他的400系列状态码太不同了。
<div><strong>精选留言（24）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/16/b4/94/2796de72.jpg" width="30px"><span>追风筝的人</span> 👍（13） 💬（1）<div>看老师的解密就像福尔摩斯在探案  精彩（改善客户端到服务端的网络质量）</div>2022-03-01</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（3） 💬（1）<div>文中的抓包文件显示 POST请求，Packet size limited during capture: HTTP truncated。这个原因是IP包头里Length是348，而实际的包体小于这个值，所有wireshark才有此显示吧？

另外，HTTP 协议就是这样规定的，数据的先后顺序是：先 header（包含 method、URL、headers），后 body。而我测试了下抓包POST请求，在body不大的情况下，body和header在一个数据包里；而body过大的话，产生分片，此时第一个数据包包含了header以及部分body。请问老师，在POST请求里，存在第一个数据包只包含header，而第二个数据包含有body的情况么？</div>2022-03-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（2） 💬（2）<div>请问老师客户端在报文6发送了fin，而服务器在报文8收到http body，这个报文8是由于客户端内核超时重传报文导致的吧？
客户端对于服务器报文10的fin，回复rst，是不是因为报文10的seq number不合法导致的呢？</div>2022-02-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/37/a0/032d0828.jpg" width="30px"><span>上杉夏香</span> 👍（1） 💬（2）<div>有两个问题，想要询问老师。
1、client在包6已经发送FIN，为啥包8还能发送数据呢？FIN不就是意味着发送端不再拥有发送能力了吗？我能想到的答案就是，这个包8是client在发送包6之前就发送的，只不过经过漫长的路由，才到达server端。

2、关于包8被server端标记为『重传』的标志。因为包是在server端抓取的，就算client确实在不断的重发，对于server来说，它不知道。可是它依然标记为『重传』。那么我觉得它一定有做出如此判断的依据，我能想到的答案是：1、时间；2、包6的seq超过包8.但是最终wireshark为何如此做出判断，那就得看它的源代码了？</div>2022-08-13</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/1e/4c/d6416f57.jpg" width="30px"><span>salt</span> 👍（1） 💬（1）<div>6号报文带了Fin 。7号报文回的不是Fin +ack 而是dup ack。这是因为dup ack的优先级更高？ 这样设计的原因是什么？</div>2022-04-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/48/35/2fe03602.jpg" width="30px"><span>简</span> 👍（1） 💬（1）<div>499的排查思路总结（麻烦老师帮忙看看是否正确）：

1、前&#47;后端设置超时不对导致。

譬如后端某接口后端需要3秒，而前端设置的请求超时时间小于3秒，那么会导致大量请求被客户端主动关闭，从而引发大量 NGINX 499。一般根据业务重设前端的请求超时时间即可，这种情况下：单独窗口访问接口、LB机器、后端机器、数据库机器等...负载、慢日志可能都是显示都正常的。
该情况一般多见于新对接功能对整体超时时间不熟悉的情况下，感觉倒是不太常见。</div>2022-03-12</li><br/><li><img src="" width="30px"><span>Geek_1bca66</span> 👍（0） 💬（1）<div>Nginx 499是Nginx自身定义的状态码&#xff0c;并非任何RFC中定义的HTTP状态码。它表示的是“Nginx收到完整的HTTP request前&#xff08;或者已经接收到完整的request但还没来得及发送HTTP response前&#xff09;&#xff0c;客户端试图关闭TCP连接”这种反常情况。
老师您好&#xff0c;根据499的定义&#xff0c;假如网络链路没有问题&#xff0c;但是服务端的处理时间比较长&#xff08;比如应用的算法有问题&#xff09;&#xff0c;是不是也会导致499呢&#xff1f;</div>2024-03-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/34/cf/0a316b48.jpg" width="30px"><span>蝴蝶</span> 👍（0） 💬（1）<div>如果先去看 nginx 的 499 的介绍，是不是就能更快的定位问题了，哈哈</div>2022-11-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/2e/0c/b6180a5f.jpg" width="30px"><span>风铃</span> 👍（0） 💬（1）<div>老师你好，看了这么多的资料了，有个疑惑的问题，tcpdump 抓包的方式，很多参数，怎么来判断使用哪些参数抓包合理了，希望解答下，感谢</div>2022-11-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/f8/ed/9fd5ed8f.jpg" width="30px"><span>Jack</span> 👍（0） 💬（2）<div>请教一下老师，wireshark抓到报文之后Follow Tcp Stream显示的都是乱码，这个怎么解决呢</div>2022-03-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/f8/ed/9fd5ed8f.jpg" width="30px"><span>Jack</span> 👍（0） 💬（1）<div>root用户登录机器使用wireshark抓包时报这个错误The temporary file to which the capture would be saved (&quot;&#47;tmpy&#47;
wireshark_eth0_20220328155843_EYvwXW.pcapng&quot;) could not be
opened: Permission denied.  这个怎么解决呢</div>2022-03-29</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/48/35/2fe03602.jpg" width="30px"><span>简</span> 👍（0） 💬（2）<div>2、LB 机器问题导致
在 LB 机器上手动的请求一下要访问的接口，LB代理异常或网络抖动也会导致LB通过内网请求后端服务时超时，从而引发客户端主动关闭请求，导致 LB Nginx 大量的 499。
这个场景，多数由于网络抖动或运维人员进行网络调整之后导致。</div>2022-03-12</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKmXoYDRv98a9GEoJccTovtWH928eN9N6ZN0fibiamEVbpGwpAzuRmhEbI2sUZa6Hur7utDYMXYrIHw/132" width="30px"><span>小白</span> 👍（0） 💬（1）<div>如何判断，post请求是否发送了body。我记得之前的列子中MTU那节。我也没看到那个post请求的body已发送呀。</div>2022-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/9d/0f/eb8f8422.jpg" width="30px"><span>bingo</span> 👍（0） 💬（1）<div>报文的时间有点乱，看得有点懵逼</div>2022-02-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/e4/79/0f0114ba.jpg" width="30px"><span>taochao_zs</span> 👍（0） 💬（1）<div>1 触发快速重传条件是再丢失报文段之后有3次以上的新报文段，4号报文段后只有6号报文段未达到重传条件。
2 消息网关应该是出现timeout之类的消息日志（由于丢包+网关超时设置）。</div>2022-02-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/8f/cf/890f82d6.jpg" width="30px"><span>那时刻</span> 👍（0） 💬（2）<div>问题一，应该是需要客户端收到三个dupack，才能触发快速重传
问题二，消息网管那里因为5秒超时，状态码可能是504 Gateway timeout</div>2022-02-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/7f/d3/b5896293.jpg" width="30px"><span>Realm</span> 👍（0） 💬（2）<div>试着回答下

1）7号报文之上的6号报文，是网关发出的，带有fin标志位，按老师之前分享的，发出fin后，表示我可接受数据，即使收到服务端重传的请求，但不会发数据了，所以网关不会重传；

2 ）网关收到400的错误日志；</div>2022-02-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/25/66/4835d92e.jpg" width="30px"><span>潘政宇</span> 👍（0） 💬（3）<div>第4个报文，发送http header，为什么不标注为http请求，而是psh ack呢</div>2022-02-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/48/35/2fe03602.jpg" width="30px"><span>简</span> 👍（3） 💬（0）<div>3、后端服务异常导致

这个是情况最复杂多样也是最难排查定位的，因为这种情况并单纯是 499 往往还伴有随之而来来的 502&#47;503&#47;504 情况。

一般来说：前端请求超时设置 &gt; LB请求后端超时设置 &gt; 后端服务超时设置，但是大部分应该都不会令 “前端请求超时设置 &gt; LB请求后端超时设置”，因为前端请求超时设置是根据用户不同业务场景设置不同超时时间的，而 LB请求后端的超时时间 是针对所有转发请求的。

若后端服务中的某一环出现硬盘&#47;CPU&#47;内存等资源不足，在高流量情况下会产生流量堆积，从而呈现出：后端先出现大量的 504，LB 机器间歇的出现大量504和499，最后出现大量的 502&#47;503 的情况。（这种情况是否应该：先重启一下服务重置一下资源的占用情况，保证后续的服务能正常响应，缩短影响时间？？）

1). 人为因素：查看网络出入口带宽情况，看看在最近的时间内站点是否有大量的流量涌入导致了流量堆积，从而导致机器负载飙升。
①. 恶意攻击：有日志平台可以快速看一下是否是同一个IP或UA，针对IP&#47;UA迅速屏蔽掉对应的请求。
②. 正常流量：新接入了流量渠道导致流量一下子增加。有没有限流措施可以实施？能否快速横向扩增机器来抗住流量的涌入？如果都不行，先暂时下掉流量渠道

2). 非人为因素：自底向上排查到底是服务哪一环出现问题？
数据库--&gt;缓存--&gt;业务机器，因为下层问题都会导致上层受影响，如果一开始就从上层排查，情况会特别棘手。
①. 数据库机器负载：查看是否有频繁的IO写入操作？查看是否索引问题导致大量慢日志？是否因为缓存雪崩&#47;缓存穿透&#47;缓存击穿，导致缓存失效从而流量查询直接到了数据库？
②. 缓存机器负载：IO&#47;内存情况-看key的使用效率和IO操作？big key问题导致内存不足？往往是缓存的数据结构设计不正确导致
③. 业务机器负载：是否有代码逻辑不合理，导致业务机器有大量的IO处理、内存溢出...等情况？

非人为因素，没有固定的解决办法，往往需要在各个环节都做出调整，譬如：数据库添加合适的索引、针对热点查询增加正确的缓存结构、业务代码进行调整（如：避免在循环中查询数据&#47;缓存）</div>2022-03-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/36/8b/7a/ec36ff82.jpg" width="30px"><span>原则</span> 👍（0） 💬（0）<div>1. 第 7 个报文是 DupAck，为什么没有触发快速重传呢？

因为要三个 DupAck，才会触发快速重传。

2. 消息网关那头的应用日志应该不是 499，那会是什么样的日志呢？

消息网关的日志大概率是接收超时。</div>2023-06-09</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJcwXucibksEYRSYg6icjibzGa7efcMrCsGec2UwibjTd57icqDz0zzkEEOM2pXVju60dibzcnQKPfRkN9g/132" width="30px"><span>Geek_93970d</span> 👍（0） 💬（1）<div>6 号报文的 seq num 是 777, tcp len 是 0，但是 next seq 为啥是 778 呢？</div>2023-04-03</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJcwXucibksEYRSYg6icjibzGa7efcMrCsGec2UwibjTd57icqDz0zzkEEOM2pXVju60dibzcnQKPfRkN9g/132" width="30px"><span>Geek_93970d</span> 👍（0） 💬（0）<div>在关闭流程里，客户端发送 fin 并收到服务端回复的 ack 后，客户端进入了 fin-wait2，这时候客户端是不会再向服务端发送数据了，可是在这个案例里，客户在收到 ack 后过了 16s 也就是在第 21s 由8号报文重发了丢失的数据包，请问，这个现象这是因为服务端回复的 ack 不是期望的 ack 导致的吗？（服务端的7号报文回复 Ack=309，而服务端期望回复的 Ack=778）</div>2023-04-03</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJJFo2Ro3AztpqqBUWZASkNbWic7YwKqsFTcXwrcekAl9z5XKiagg5TicHDeHNlavUjTg5FNgojg4H8g/132" width="30px"><span>阿强</span> 👍（0） 💬（0）<div>10号报文21s从服务端发出，也就是在消息网关发出fin后的16s后再发出，此时消息网关的应用层代码来看，tcp连接应该已经断开了，服务端返回的http状态码400等信息，消息网关的应用层应该是收不到吧，所以消息网关那头的应用日志，只能知道是http超时然后自己规定一个状态码，并不会获取到服务端的400状态码吧？</div>2022-11-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/48/35/2fe03602.jpg" width="30px"><span>简</span> 👍（0） 💬（0）<div>对于上述还有：还有可能是TCP的连接句柄不足等情况导致，这个之前遇到过，时间太久已经忘记当时的关注结果~期待老师能补充一下。（由于评论有字数限制...所以分了几种情况写）</div>2022-03-12</li><br/>
</ul>