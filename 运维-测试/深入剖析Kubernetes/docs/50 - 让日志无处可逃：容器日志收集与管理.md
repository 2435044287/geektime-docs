你好，我是张磊。今天我和你分享的主题是：让日志无处可逃之容器日志收集与管理。

在前面的文章中，我为你详细讲解了 Kubernetes 的核心监控体系和自定义监控体系的设计与实现思路。而在本篇文章里，我就来为你详细介绍一下Kubernetes 里关于容器日志的处理方式。

首先需要明确的是，Kubernetes 里面对容器日志的处理方式，都叫作cluster-level-logging，即：这个日志处理系统，与容器、Pod以及Node的生命周期都是完全无关的。这种设计当然是为了保证，无论是容器挂了、Pod 被删除，甚至节点宕机的时候，应用的日志依然可以被正常获取到。

而对于一个容器来说，当应用把日志输出到 stdout 和 stderr 之后，容器项目在默认情况下就会把这些日志输出到宿主机上的一个 JSON 文件里。这样，你通过 kubectl logs 命令就可以看到这些容器的日志了。

上述机制，就是我们今天要讲解的容器日志收集的基础假设。而如果你的应用是把文件输出到其他地方，比如直接输出到了容器里的某个文件里，或者输出到了远程存储里，那就属于特殊情况了。当然，我在文章里也会对这些特殊情况的处理方法进行讲述。

而 Kubernetes 本身，实际上是不会为你做容器日志收集工作的，所以为了实现上述cluster-level-logging，你需要在部署集群的时候，提前对具体的日志方案进行规划。而 Kubernetes 项目本身，主要为你推荐了三种日志方案。
<div><strong>精选留言（24）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/0f/be/41/e3ece193.jpg" width="30px"><span>lovelife</span> 👍（51） 💬（1）<div>如果每秒日志量很大时，直接输出到容器的stdout和stderr,很容易就把系统日志配额用满，因为对系统默认日志工具是针对单服务(例如docker)而不是进程进行限额的，最终导致的结果就是日志被吞掉。解决办法一个是增加配额，一个是给容器挂上存储，将日志输出到存储上。当然日志量大也要考虑写日志时过多的磁盘读写导致整个节点的整体性能下降。</div>2018-12-17</li><br/><li><img src="" width="30px"><span>ch_ort</span> 👍（17） 💬（1）<div> Kubernetes项目的监控体系现在已经被Prometheus&quot;一统&quot;，而Prometheus与Kuberentes类似，也是来自Google内部系统的设计理念。

Prometheus项目工作的核心：通过pull方式拉取监控对象的metric数据，存储到时序数据库中供后续检索。
时序数据库的特点：支持大批量写入、高性能搜索、聚合。
基于这样的核心，Prometheus剩下的组件就是用来配合这套机制运行，比如
Pushgateway: 允许被监控对象以Push的方式向Prometheus推送数据
Alertmanager：根据Metrics信息灵活地设置报警
Grafana：活动配置监控数据可视化页面

Kubernetes借助Promethus监控体系，可以提供Custom Metrics的能力，即自定义指标。Custom Metrics借助Aggregator APIServer扩展机制来实现，即对APIServer的请求，会先经过Aggreator来转发，它会根据URL来决定把请求转发给自定义的Custom Metrics APIServer，还是Kubernetes的APIServer。有了这样的体系，就可以方便的实现自定义指标的感知了
比如，现在启动了一个Custom Metrics APIServer，它对应的url是custom.metrics.k8s.io，当我需要获取某一个Pod内的自定义指标（例：http_requests）：

    https:&#47;&#47;&lt;apiserver_ip&gt;&#47;apis&#47;custom-metrics.metrics.k8s.io&#47;v1beta1&#47;namespaces&#47;default&#47;pods&#47;sample-metrics-app&#47;http_requests 

 这个请求就会被Custom Metrics APIServer接收，然后它就会去Promethus里查询名叫sample-metrics-app这个pod的http_requests指标。而Promethus可以通过定期访问Pod的一个API来采集这个指标。

Kubernetes对容器日志的处理方式都叫做cluster-level-logging。容器默认情况下会把日志输出到宿主机上的一个JSON文件，这样，通过kubectl logs命令就可以看到这些容器的日志了。

Kuberentes提供了三种日志收集方案：
（1）logging agent:  pod会默认日志通过stdout&#47;stderr输出到宿主机的一个目录，宿主机上以DaemonSet启动一个logging-agent，这个logging-agent定期将日志转存到后端。
优势： 1)对Pod无侵入 2)一个node只需要一个agent 3）可以通过kubectl logs查看日志
劣势： 必须将日志输出到stdout&#47;stderr
（2) sidecar模式： pod将日志输出到一个容器目录，同pod内启动一个sidecar读取这些日志输出到stdout&#47;stderr，后续就跟方案1）一样了。
优势：1）sidecar跟主容器是共享Volume的，所以cpu和内存损耗不大。2）可以通过kubectl logs查看日志
劣势：机器上实际存了两份日志，浪费磁盘空间，因此不建议使用
（3）sidercar模式2：pod将日志输出到一个容器文件，同pod内启动一个sidecar读取这个文件并直接转存到后端存储。
优势：部署简单，宿主机友好
劣势：1） 这个sidecar容器很可能会消耗比较多的资源，甚至拖垮应用容器。2）通过kubectl logs是看不到任何日志输出的。
</div>2020-12-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/a0/bb/2e204da1.jpg" width="30px"><span>Hammer_T</span> 👍（15） 💬（2）<div>想问一下老师，如果一个容器里的日志有很多种，都输出到 stdout，收集的时候还能分得清是哪个吗？</div>2019-01-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/23/52/66/3e4d4846.jpg" width="30px"><span>includestdio.h</span> 👍（10） 💬（0）<div>公司目前采用的方案三，promtail 以sidecar方式运行在应用Pod中，日志通过promtail发到Loki ，最后再用 Grafana 展示</div>2022-04-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/a9/9b/61b5fc4c.jpg" width="30px"><span>fraηz</span> 👍（9） 💬（7）<div>filebeat作为sidecar容器采集主应用容器日志，然后发送到ELK存储日志，这样可行吗？</div>2019-11-07</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/2a/a5/625c0a2e.jpg" width="30px"><span>hhhh</span> 👍（7） 💬（0）<div>日志文件大小会很快增加，当时我到了nginx访问日志半小时就好几G，由于没给日志文件挂载存储，docker的文件目录会很快就增大了，引发了磁盘使用报警。</div>2019-12-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/15/a6/723854ee.jpg" width="30px"><span>姜戈</span> 👍（7） 💬（2）<div>阿里的log-pilot是个不错的选择</div>2018-12-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/b6/8e/bc83bcae.jpg" width="30px"><span>曹顺详</span> 👍（6） 💬（1）<div>老师好，请教一下，在应用代码层就指定日志存储后端这种解决方案有没有示例说一下。优缺点是什么？比如说是不是会增加应用的资源消耗？</div>2020-06-02</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoCl6Nxf9oW9sDOoibA7p8lKf0jqjPeDszqI4e7iavicQHtbtyibHIhLibyXYAaT02l7GRQvM9BJUxh6yQ/132" width="30px"><span>昀溪</span> 👍（5） 💬（3）<div>老师，我们遇到一个问题也和日志有关，我们的POD都设置了limits，但是由于K8S统计POD的内存是包含缓存的，我们的POD日志输出是输出到一个文件，该文件是通过挂载emptydir的方式来做，然后使用阿里云的日志服务来收集。这里就面临一个问题，日志虽然采集走了，但是日志文件还留在目录里，它也会被算在POD的内存使用量里面，这就很容易造成OOM，请问这个问题应该怎么来处理，有没有什么思路提供一下。当然我们也会清理日志目录，比如一天前的，但是当天的日志如果很大依然会被算在POD的内存里。</div>2020-08-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/c3/10/3f18e402.jpg" width="30px"><span>王景迁</span> 👍（4） 💬（5）<div>为什么第3种方案sidecar容器会消耗很多资源？</div>2019-05-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/5e/4b/c95a8500.jpg" width="30px"><span>谈修竹</span> 👍（4） 💬（0）<div>最近在Istio，里面的Mixer好像可以支持多种Observability能力，包括Logging</div>2019-04-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/c7/05/19c5c255.jpg" width="30px"><span>微末凡尘</span> 👍（3） 💬（1）<div>我们公司目前的日志收集方案：在同一个pod中再起一个logstash容器，读取应用容器的日志，存储到redis中，然后宿主机启动一个logstash服务，从redis中读取数据存入文件中，为什么不把直接日志文件直接挂载到远程目录文件中呢？因为相同的pod有好几个，如果日志文件同时挂载到同一个文件可能会造成死锁。</div>2021-02-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c3/93/ed8127d6.jpg" width="30px"><span>zik_kinbun</span> 👍（3） 💬（0）<div>我们采用kafka进行存储，特定程序再判断转发到ES</div>2019-08-23</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/37/3b/495e2ce6.jpg" width="30px"><span>陈斯佳</span> 👍（2） 💬（0）<div>第五十课:让日志无处可逃:容器日志收集与管理

Kubernetes 里面对容器日志的处理方式，都叫作 cluster-level-logging，即：这个日志处理系统，与容器、Pod 以及 Node 的生命周期都是完全无关的。

而对于一个容器来说，当应用把日志输出到 stdout 和 stderr 之后，容器项目在默认情况下就会把这些日志输出到宿主机上的一个 JSON 文件里。

三种日志方案:
第一种，在 Node 上部署 logging agent，将日志文件转发到后端存储里保存起来。这种方案的不足之处就在于，它要求应用输出的日志，都必须是直接输出到容器的 stdout 和 stderr 里。
第二种，就是对这种特殊情况的一个处理，即：当容器的日志只能输出到某些文件里的时候，我们可以通过一个 sidecar 容器把这些日志文件重新输出到 sidecar 的 stdout 和 stderr 上，这样就能够继续使用第一种方案了。
第三种方案，就是通过一个 sidecar 容器，直接把应用的日志文件发送到远程存储里面去。</div>2021-11-09</li><br/><li><img src="" width="30px"><span>Geek_4df222</span> 👍（1） 💬（0）<div>思考题1：
k8s pod 里的容器输出到 stdout、stderr 的日志会被默认写到 &#47;var&#47;log&#47;pods 目录文件下，当日志文件巨大，且 &#47;var&#47;log 共享宿主机主磁盘时，可能会把主磁盘打满，影响宿主机正常运行。因此，最好是将 &#47;var&#47;log&#47;pods 挂载独立的磁盘。

思考题2：
这篇介绍的1、2两种方案是如何将日志输出到stdout，这个完全可以作为业务容器接入的规范，让业务方来遵守吧。
在我们的系统里，采用 loki 作为容器日志方案，查询日志可以通过 loki 接口。
</div>2023-08-27</li><br/><li><img src="" width="30px"><span>ch_ort</span> 👍（1） 💬（0）<div> Kubernetes项目的监控体系现在已经被Prometheus&quot;一统&quot;，而Prometheus与Kuberentes类似，也是来自Google内部系统的设计理念。

Prometheus项目工作的核心：通过pull方式拉取监控对象的metric数据，存储到时序数据库中供后续检索。
时序数据库的特点：支持大批量写入、高性能搜索、聚合。
基于这样的核心，Prometheus剩下的组件就是用来配合这套机制运行，比如
Pushgateway: 允许被监控对象以Push的方式向Prometheus推送数据
Alertmanager：根据Metrics信息灵活地设置报警
Grafana：活动配置监控数据可视化页面

Kubernetes借助Promethus监控体系，可以提供Custom Metrics的能力，即自定义指标。Custom Metrics借助Aggregator APIServer扩展机制来实现，即对APIServer的请求，会先经过Aggreator来转发，它会根据URL来决定把请求转发给自定义的Custom Metrics APIServer，还是Kubernetes的APIServer。有了这样的体系，就可以方便的实现自定义指标的感知了
比如，现在启动了一个Custom Metrics APIServer，它对应的url是custom.metrics.k8s.io，当我需要获取某一个Pod内的自定义指标（例：http_requests）：

    https:&#47;&#47;&lt;apiserver_ip&gt;&#47;apis&#47;custom-metrics.metrics.k8s.io&#47;v1beta1&#47;namespaces&#47;default&#47;pods&#47;sample-metrics-app&#47;http_requests 

 这个请求就会被Custom Metrics APIServer接收，然后它就会去Promethus里查询名叫sample-metrics-app这个pod的http_requests指标。而Promethus可以通过定期访问Pod的一个API来采集这个指标。

Kubernetes对容器日志的处理方式都叫做cluster-level-logging。容器默认情况下会把日志输出到宿主机上的一个JSON文件，这样，通过kubectl logs命令就可以看到这些容器的日志了。

Kuberentes提供了三种日志收集方案：
（1）logging agent:  pod默认会将日志通过stdout&#47;stderr输出到宿主机的一个目录，宿主机上以DaemonSet启动一个logging-agent，这个logging-agent定期将日志转存到后端。
优势： 1)对Pod无侵入 2)一个node只需要一个agent 3）可以通过kubectl logs查看日志
劣势： 必须将日志输出到stdout&#47;stderr
（2) sidecar模式： pod将日志输出到一个容器目录，同pod内启动一个sidecar读取这些日志输出到stdout&#47;stderr，后续就跟方案1）一样了。
优势：1）sidecar跟主容器是共享Volume的，所以cpu和内存损耗不大。2）可以通过kubectl logs查看日志
劣势：机器上实际存了两份日志，浪费磁盘空间，因此不建议使用
（3）sidercar模式2：pod将日志输出到一个容器文件，同pod内启动一个sidecar读取这个文件并直接转存到后端存储。
优势：部署简单，宿主机友好
</div>2021-01-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/2d/24/28acca15.jpg" width="30px"><span>DJH</span> 👍（1） 💬（0）<div>张老师，请教一个问题：对于容器宿主机（或者说K8S的Node），一般文件系统分配的方案是怎样的？对于生产环境的Node，Container运行和存放镜像的文件系统一般需要多大？</div>2018-12-17</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/32/4b/02/55afd15d.jpg" width="30px"><span>AlphÉe</span> 👍（0） 💬（0）<div>应用容器将日志输出到文件，日志目录挂载到node，再启动一个 sidecar 容器运行 logging agent采集node上所有的日志文件，写入后端如clickhouse，这样的方案怎么样呢？</div>2024-12-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/20/c3/94/e89ebc50.jpg" width="30px"><span>神毓逍遥</span> 👍（0） 💬（0）<div>这篇实用性不错</div>2021-11-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/28/89/b4/3a07938c.jpg" width="30px"><span>SIMON LEE_啟明</span> 👍（0） 💬（0）<div>老師你好，请问有需要管理K8s本身的日志吗？比方说持久化存储kubelet或apiServer的日志，用作日后运维。</div>2021-06-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/2e/8b/32a8c5a0.jpg" width="30px"><span>卡特</span> 👍（0） 💬（1）<div>张老师：
可否同时结合方案1和方案3；
假设我有一个pod,里面有应用容器，日志收集sidecar容器；
1.应用容器的日志输出到stdout,stderr,会落到宿主机上的某个目录的某个文件中；
2.我的日志收集sidercar容器直接把第1步的日志文件作为输入源，转发到远程的loggingbackend服务中；

以上假设是否可行？如果可行，是不是解决了方案1和方案3的缺点？

</div>2021-02-18</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTKzbriccqBJoZ7q6lLsqZGrz6PTbHbVlxNI97bYPxnJDjBgDWYhpuquibuicqW0pwBlIQPQwmjb0eHyQ/132" width="30px"><span>InfoQ_1165acf8e7fe</span> 👍（0） 💬（0）<div>请问，当日志量很大的时候，直接将日志输出到容器 stdout 和 stderr 上，有没有什么隐患呢？有没有解决办法呢？

老师回答一下呗</div>2020-08-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/16/96/1538f36c.jpg" width="30px"><span>随意门</span> 👍（0） 💬（1）<div>请问，如何在部署Kubernetes时候，开启日志的rotate功能？</div>2019-09-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/a9/47/3718cf90.jpg" width="30px"><span>微leng</span> 👍（0） 💬（0）<div>问老师一个问题，我在看pod的CPU监控信息时，prometheus显示的是占用CPU的时长，怎么判断当前pod的CPU的负载呢？</div>2018-12-18</li><br/>
</ul>