你好，我是倪朋飞。

上一节，我们学习了碰到分布式拒绝服务（DDoS）的缓解方法。简单回顾一下，DDoS 利用大量的伪造请求，导致目标服务要耗费大量资源，来处理这些无效请求，进而无法正常响应正常用户的请求。

由于 DDoS 的分布式、大流量、难追踪等特点，目前确实还没有方法，能够完全防御 DDoS 带来的问题，我们只能设法缓解 DDoS 带来的影响。

比如，你可以购买专业的流量清洗设备和网络防火墙，在网络入口处阻断恶意流量，只保留正常流量进入数据中心的服务器。

在 Linux 服务器中，你可以通过内核调优、DPDK、XDP 等多种方法，增大服务器的抗攻击能力，降低 DDoS 对正常服务的影响。而在应用程序中，你可以利用各级缓存、 WAF、CDN 等方式，缓解 DDoS 对应用程序的影响。

不过要注意，如果 DDoS 的流量，已经到了 Linux 服务器中，那么，即使应用层做了各种优化，网络服务的延迟一般还是会比正常情况大很多。

所以，在实际应用中，我们通常要让 Linux 服务器，配合专业的流量清洗以及网络防火墙设备，一起来缓解这一问题。

除了 DDoS 会带来网络延迟增大外，我想，你肯定见到过不少其他原因导致的网络延迟，比如

- 网络传输慢，导致延迟；
- Linux 内核协议栈报文处理慢，导致延迟；
- 应用程序数据处理慢，导致延迟等等。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/12/64/05/6989dce6.jpg" width="30px"><span>我来也</span> 👍（18） 💬（1）<div>[D40打卡]
我之前理解的网络延迟分三部分：客户端到服务端，服务端逻辑处理，服务端到客户端到耗时。

其中服务端逻辑处理的耗时是跟自身程序有关的，另外两个耗时跟宽带服务提供商有关，想更短的耗时就得加钱：选更优的线路或者在靠近客户端的地方加入口。

目前我们线上程序是可以推算出单次响应的时间的，因为在出入口的地方有记录。不管中间经过了多少服务的处理，都可以算出总的耗时。

我们在客户端中也加了汇报功能，在客户端的某些消息中会汇报 客户端实际发送请求-&gt;收到服务端响应 的时间差。这样便于我们确认客户端的网络状况。

从本文中，第一次见到了 Nagle 算法。也知道了服务端关闭icmp时怎么用tcp&#47;udp测试网络延迟。

文中的内容也是跌宕起伏，分析着怎么还是客户端的问题，客户端访问另外一个服务还是好的。原来是服务端程序也有问题，一个巴掌拍不响。😂
</div>2019-02-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/8c/2b/3ab96998.jpg" width="30px"><span>青石</span> 👍（10） 💬（1）<div>网上查了Nagle算法的定义：任意时刻，最多只能有一个未被确认的小段。所谓“小段”，指的是小于MSS尺寸的数据块，所谓“未被确认”，是指一个数据块发送出去后，没有收到对方发送的ACK确认该数据已收到。

对比80端口和8080端口的报文，80端口的报文中，响应消息再发送完header后立刻发送body部分；8080端口的报文，响应消息再发送完header后，需要获得ACK响应后，才会发送body部分。

8080端口报文中server端在获得到ACK响应后才发送body部分，就是因为Nagle算法必须确认这个数据块被收到的原因。client在40ms后发送ACK是因为客户端没有开启TCP_QUICKACK的缘故。

请问老师，这样理解，对吗？</div>2019-03-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/3a/6e/e39e90ca.jpg" width="30px"><span>大坏狐狸</span> 👍（6） 💬（1）<div>额 第二次居然curl不通了。。18.04 的防火墙是ufw ,需要ufw allow 80&#47;tcp
</div>2019-05-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/9e/a3/0bfaaf13.jpg" width="30px"><span>楚</span> 👍（6） 💬（1）<div>你好，我在网络编程中遇到一个问题，
我们用go语言做的服务调用其他HTTP服务器，发现HTTP请求中卡住，概率非常低。
然后我看了发现write，返回eagain，然后就等待epoll通知描述符是否可用，这个时候发现等了很久很久都不可用。netstata看了下，TCP写buffer有数据但是没有满，等了很久也貌似发生不出去，有重传，但是还是传不出去。直接达到rto次数内核中断连接。
我们只能将rto改很小让内核中断连接。
请问这种情况一般都是由什么原因引起的呢？
</div>2019-02-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/57/d8/425e1b0a.jpg" width="30px"><span>小虾米</span> 👍（5） 💬（1）<div>我记得之前碰到的延迟ack是200ms，这个是可以配置的吗？</div>2019-02-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/9b/ba/333b59e5.jpg" width="30px"><span>Linuxer</span> 👍（3） 💬（1）<div>案例中能设置客户端的TCP_QUICKACK解决吗？</div>2019-02-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/97/7d/791d0f5e.jpg" width="30px"><span>蚂蚁吃大象</span> 👍（2） 💬（1）<div>您好，请教下。我通过客户端直接访问服务器，平均响应延迟是30ms，经过nginx代理响应延迟是200ms，我使用的ngx+lua，业务逻辑是先查询worker进程的缓存，没有再查redis，再没有查mysql，现在lua层面可以优化的已经优化了，平均响应延迟还是170ms,不知道通过什么工具能定位具体哪里导致响应延迟慢呢？谢谢！</div>2019-06-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/93/43/0e84492d.jpg" width="30px"><span>Maxwell</span> 👍（2） 💬（1）<div>为什么执行strace -f wrk --latency -c 100 -t 2 --timeout 2 http:&#47;&#47;192.168.126.136:8080&#47;，输出结果中并没有TCP_NODELAY配置选项呢？</div>2019-03-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/9b/ba/333b59e5.jpg" width="30px"><span>Linuxer</span> 👍（2） 💬（1）<div>同一套环境碰到一个低并发高延时，高并发低延时得的问题，请问倪老师像这种问题该如何排查?</div>2019-02-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/5c/cb/3ebdcc49.jpg" width="30px"><span>怀特</span> 👍（2） 💬（2）<div>traceroute 会在路由的每一跳发送三个包，并在收到响应后，输出往返延时。如果无响应或者响应超时（默认 5s），就会输出一个星号。
----这个地方，还有些不明白，希望老师能在这里再解释几句
</div>2019-02-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/ca/79/139615aa.jpg" width="30px"><span>Magic Star Trace</span> 👍（0） 💬（1）<div>请问：物理机centos 7 ，kvm 上虚拟机 丢包不稳定是什么问题导致的呢？
time 延迟很不稳定</div>2019-08-25</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/73/99/eb99b2cb.jpg" width="30px"><span>坤丰</span> 👍（0） 💬（1）<div>不考虑磁盘问题，tcpdump 长期在生产环境打开，会有什么不良的影响吗？会影响到网络性能吗？如何去评估这样的问题</div>2019-05-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/9e/a3/0bfaaf13.jpg" width="30px"><span>楚</span> 👍（0） 💬（1）<div>你好，但是每次出问题都要等到重传15次。而且write buffer都不变。
应该不是简单超时吧。</div>2019-03-05</li><br/><li><img src="https://wx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEKQMM4m7NHuicr55aRiblTSEWIYe0QqbpyHweaoAbG7j2v7UUElqqeP3Ihrm3UfDPDRb1Hv8LvPwXqA/132" width="30px"><span>ninuxer</span> 👍（0） 💬（1）<div>打卡day42
案例中的问题，可能我通过抓包仔细看后，能得出ack有异常，但是没办法跟客户端默认的ack延时发送，以及nginx的tcp_nodelay联系起来～😂</div>2019-02-26</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTL9hlAIKQ1sGDu16oWLOHyCSicr18XibygQSMLMjuDvKk73deDlH9aMphFsj41WYJh121aniaqBLiaMNg/132" width="30px"><span>腾达</span> 👍（0） 💬（4）<div>为什么我无法出现延迟40ms左右的情况？ 我都是按照老师的步骤来的。我的nginx端（VM1）是ubuntu 18.04，跟老师版本一样的，VM2端是Ubuntu16，wrk，curl工作在此。我用wrk跑三个nginx（分别是good，nginx-latency，nginx-nodelay）差不多，Latency  Avg在   90ms，有时候，反而还是nginx-latency最好。我观察了包的顺序，确实如课程所说的那样(老师能否将本课中说抓的包一起上传到github？)
我的三个nginx的配置如下：

good的配置：
http {
    include       &#47;etc&#47;nginx&#47;mime.types;
    default_type  application&#47;octet-stream;

    log_format  main  &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;
                      &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;
                      &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;;

    access_log  &#47;var&#47;log&#47;nginx&#47;access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;

    include &#47;etc&#47;nginx&#47;conf.d&#47;*.conf;
}


nginx-nodelay的配置：
http {
    include       &#47;etc&#47;nginx&#47;mime.types;
    default_type  application&#47;octet-stream;

    log_format  main  &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;
                      &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;
                      &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;;

    access_log  &#47;var&#47;log&#47;nginx&#47;access.log  main;

    sendfile        on;
    tcp_nopush     off;
    tcp_nodelay     on;

    keepalive_timeout  65;

    #gzip  on;

    include &#47;etc&#47;nginx&#47;conf.d&#47;*.conf;
}


nginx-latency的配置：
http {
    include       &#47;etc&#47;nginx&#47;mime.types;
    default_type  application&#47;octet-stream;

    log_format  main  &#39;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#39;
                      &#39;$status $body_bytes_sent &quot;$http_referer&quot; &#39;
                      &#39;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#39;;

    access_log  &#47;var&#47;log&#47;nginx&#47;access.log  main;

    sendfile        on;
    tcp_nopush     off;
    tcp_nodelay    off;

    keepalive_timeout  65;

    #gzip  on;

    include &#47;etc&#47;nginx&#47;conf.d&#47;*.conf;
}



</div>2019-02-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/9a/64/ad837224.jpg" width="30px"><span>Christmas</span> 👍（20） 💬（0）<div>以前经常看到tcp no delay的socket设置，一直不求甚解，这次终于懂了，nagle算法</div>2019-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/20/52/11/af170b65.jpg" width="30px"><span>骑驴找你</span> 👍（5） 💬（0）<div>40ms最小延迟确认是有一个算法的，那我自己的centos8举例：
&#47;usr&#47;src&#47;kernels&#47;4.18.0-80.el8.x86_64+debug&#47;include&#47;net&#47;tcp.h文件中记录了这个变量&#47;宏的定义：
#define TCP_DELACK_MAX  ((unsigned)(HZ&#47;5))      &#47;* maximal time to delay before sending an ACK *&#47;
#if HZ &gt;= 100
#define TCP_DELACK_MIN  ((unsigned)(HZ&#47;25))     &#47;* minimal time to delay before sending an ACK *&#47;
HZ的值可以利用老师之前讲过的软中断相关知识计算出来，即相隔10s计算&#47;proc&#47;interrupts里面的中断次数变化，两次做差再除以10就是每秒的中断数，我这边计算出来的值是1005，那么HZ就应该是1000，所以1000&#47;25=40ms</div>2020-09-25</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/MibOYDxw9TDxwBuTyI79AoHlJGeUFiabGtUmdeiaMrjxFy3FXmNFTIAVxrESMojrReIDbhOib4os01uBZdbMBZGCVg/132" width="30px"><span>微微</span> 👍（5） 💬（2）<div>遇到一个问题，backlog设置的很大，有22w，但是用ss -ltn命令查看这个监听端口的Send-Q和Recv-Q都是0，但是用命令netstat -s|egrep &quot;listen|LISTEN&quot;的溢出值一直在上升，统计这个端口的连接数还不到5000，请问可能会是什么原因？</div>2019-10-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/82/3d/356fc3d6.jpg" width="30px"><span>忆水寒</span> 👍（4） 💬（0）<div>本文是一个很好的案例，条理清晰，。抛砖引玉，我分享一个分析tcp断连的案例分析：https:&#47;&#47;mp.weixin.qq.com&#47;s&#47;XS3Jnn3Xl4_12gzg0zrSTA</div>2021-08-01</li><br/><li><img src="https://wx.qlogo.cn/mmopen/vi_32/DYAIOgq83eqtXSgThiaEiaEqqic5YIJ7v469nCM3VXiccOJ4SxbYjW91ciczuYYEzcTVtYWaWXaokZqShuLdKsXjnFA/132" width="30px"><span>Geek_b85295</span> 👍（3） 💬（1）<div>老师，这个案例中，为什么第一个请求没有延迟，第二个请求才开始有延迟</div>2021-06-10</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/f6/24/547439f1.jpg" width="30px"><span>ghostwritten</span> 👍（2） 💬（0）<div>1. hping3 -c 3 -S -p 80 baidu.com
traceroute --tcp -p 80 -n baidu.com
2.  wrk --latency -c 100 -t 2 --timeout 2 http:&#47;&#47;192.168.0.30&#47;
3.  tcpdump -nn tcp port 8080 -w nginx.pcap
4. man tcp---TCP_QUICKACK,TCP_NODELAY
5. strace -f wrk --latency -c 100 -t 2 --timeout 2 http:&#47;&#47;192.168.0.30:8080&#47;
6. Nagle 算法，是 TCP 协议中用于减少小包发送数量的一种优化算法，它通过合并 TCP 小包,目的是为了提高实际带宽的利用率,
7.  Wireshark分析</div>2021-08-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/64/9b/d1ab239e.jpg" width="30px"><span>J.Smile</span> 👍（2） 💬（0）<div>很棒的一篇文章，让我串联起来陶辉老师课程中关于延迟确认 、nagle相关知识。也被科普了一波为什么一般生产环境的ping都被禁止了。</div>2020-08-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/18/93/38/71615300.jpg" width="30px"><span>DayDayUp</span> 👍（1） 💬（0）<div>老师，我在想，案例中的恰好是“延迟回复” + “Nagle 算法”的“偶遇”导致了这个延时，如果有大量数据包的情况下，那么一两个包可能是延迟的，如果有大量数据包的情况下应该就没有问题了吧。因为客户端会把所有ACK攒齐一起发送，而服务端也是将数据包的数据部分凑满发送。

感觉整体不会有特别大的时延。</div>2022-06-05</li><br/><li><img src="" width="30px"><span>Geek_392979</span> 👍（1） 💬（2）<div>老师，学了课程后， 面试的时候遇到一个问题: &quot;1000台服务器， 95%的服务器QPS正常(1000QPS), 其他的是2000QPS, cpu正常, 怎么排查？&quot;
我的思路是首先看平均负载， 如果平均负载高，看是什么导致的平局负载高。依次看各个CPU利用率，但题目里说CPU正常。然后能想到的就是：
1. sar -n DEV 2 10 看整个的网络收发情况
2. traceroute --tcp -p port -n xxx.xxx.com 看到目标服务的网络延时
3. pstack看目标服务器上的应用程序的调用堆栈，是不是阻塞在某个调用上
4. perf top分析目标应用程序

感觉这样的答案没有让面试官满意， 所以老师遇到这种问题应该怎么分析？ 到目标服务器的延时高和QPS低是正相关的吗？</div>2021-03-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/af/00/9b49f42b.jpg" width="30px"><span>skye</span> 👍（1） 💬（1）<div>那nagle算法用在什么情况下呢？</div>2019-05-06</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/Q3auHgzwzM78picDmK4b2roBGAqoLicqc5EPPbsPQWkb3xbMk6kDpft19DgeLEfBeekPlvFg2O5lrEXa0XdYhhng/132" width="30px"><span>Geek_e2b7bc</span> 👍（0） 💬（0）<div>客户端延迟40秒ACK，服务端因为nagle等待ACK后才会发下一个分组，所以延迟。解决方案：让服务端多发分组，客户端也可以快速桐应回复ACK了</div>2025-01-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1b/a3/4d/59390ba9.jpg" width="30px"><span>排骨</span> 👍（0） 💬（0）<div>当 Nagle 算法和延迟确认同时使用时，可能会产生所谓的 &quot;40ms 延迟问题&quot;：</div>2025-01-02</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/2b/6e/1d/3fef83ac.jpg" width="30px"><span>不一样的烟火</span> 👍（0） 💬（0）<div>
TCP_QUICKACK和TCP_NODELAY关系
TCP_QUICKACK 和 TCP_NODELAY 是 TCP socket 选项，用于不同的目的：

TCP_NODELAY: 这个选项关闭了 Nagle 算法，默认情况下，TCP 将等待更多的小段数据再发送，以减少网络中的小包数量，这个选项让数据尽快发送出去，但可能会增加小数据的延迟。

TCP_QUICKACK: 这个选项使得当 TCP 接收到一个段后，立即发送一个 ACK，而不是等待发送方的下一个段，这在某些情况下可以减少网络延迟。

TCP_QUICKACK 和 TCP_NODELAY 并不直接相关，它们是针对不同问题的解决方案：

TCP_NODELAY 主要用于减少发送的小数据包延迟。

TCP_QUICKACK 主要用于减少数据接收后的确认延迟。</div>2024-05-17</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/Q0j4TwGTfTJGXndj5N66z9BL1ic9GibZzWWgoVeWaWTL2XUnCYic7iba2kAEvN9WfjmlXELD5lqt8IJ1P023N5ZWicg/132" width="30px"><span>Geek_f93234</span> 👍（0） 💬（0）<div>为什么第一次请求和响应没有延迟，第二次请求才开始有延迟
</div>2023-05-30</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/0c/bf/863d440a.jpg" width="30px"><span>jaxzhai</span> 👍（0） 💬（0）<div>我们业务请求oracle遇到一个同样 延迟确认的问题，但我们客户端加上 TCP_NODELAY  还是同样的问题，现在不知道怎么弄了？</div>2021-12-27</li><br/>
</ul>