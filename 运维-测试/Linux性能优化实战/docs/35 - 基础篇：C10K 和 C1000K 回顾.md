你好，我是倪朋飞。

前面内容，我们学习了 Linux 网络的基础原理以及性能观测方法。简单回顾一下，Linux 网络基于 TCP/IP 模型，构建了其网络协议栈，把繁杂的网络功能划分为应用层、传输层、网络层、网络接口层等四个不同的层次，既解决了网络环境中设备异构的问题，也解耦了网络协议的复杂性。

基于 TCP/IP 模型，我们还梳理了 Linux 网络收发流程和相应的性能指标。在应用程序通过套接字接口发送或者接收网络包时，这些网络包都要经过协议栈的逐层处理。我们通常用带宽、吞吐、延迟、PPS 等来衡量网络性能。

今天，我们主要来回顾下经典的 C10K 和 C1000K 问题，以更好理解 Linux 网络的工作原理，并进一步分析，如何做到单机支持 C10M。

注意，C10K 和 C1000K 的首字母 C 是 Client 的缩写。C10K 就是单机同时处理 1 万个请求（并发连接1万）的问题，而 C1000K 也就是单机支持处理 100 万个请求（并发连接100万）的问题。

## C10K

[C10K 问题](http://www.kegel.com/c10k.html)最早由 Dan Kegel 在 1999年提出。那时的服务器还只是 32 位系统，运行着 Linux 2.2 版本（后来又升级到了 2.4 和 2.6，而 2.6 才支持 x86\_64），只配置了很少的内存（2GB）和千兆网卡。
<div><strong>精选留言（30）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/93/43/0e84492d.jpg" width="30px"><span>Maxwell</span> 👍（46） 💬（5）<div>一台机器不是只有65536个端口吗，每个网络请求都需要消耗一个端口，这样大于65536个请求会不会导致端口不够用呢？</div>2019-02-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/fb/1d/12c7c021.jpg" width="30px"><span>挺直腰板</span> 👍（24） 💬（3）<div>老师，很多人都说并发数不能超过65536，假如访问服务器80端口，服务器ip是183.3.226.35这个，客户端ip是58.62.30.2，超过65536端口如何显示，是这样183.3.226.35 58.62.30.2:80？单机最大并发的连接数据是多少？谢谢！</div>2019-03-31</li><br/><li><img src="" width="30px"><span>Geek_9815f1</span> 👍（13） 💬（3）<div>老师，redis的采用水平触发的epoll。 nginx 采用 垂直触发的epoll 。所以epoll跟 触发方式无关。老师，你的一言一语对于小白  都是圣经， 好好斟酌</div>2020-07-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/64/05/6989dce6.jpg" width="30px"><span>我来也</span> 👍（9） 💬（3）<div>[D35打卡]
09年那会,我所在公司的服务器端都是单进程+select.
后来把select换为了poll和epoll.
再后来还拆分成了多进程,N个网络收发层+M个业务处理层.
毕竟我们的情况是 业务处理的耗时远大于网络收发的耗时.
目前的网络收发层也只支持最大65530个并发连接,毕竟是单ip单端口的.
如果想支持更多并发连接,就另外再开一个进程.
并没有往C100K甚至是C1000K的方向上努力了.</div>2019-02-12</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c2/1f/343f2dec.jpg" width="30px"><span>9527</span> 👍（7） 💬（3）<div>没碰到单机一千万这么夸张的场景，想问下一千万连接这种场景下，一般机器是什么配置呢
按这么发展下去，以后会不会出现单机1亿连接，那样的话所有处理都得硬件来完成了吧</div>2019-02-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/b9/af/f59b4c7c.jpg" width="30px"><span>深海极光</span> 👍（6） 💬（1）<div>老师你好，您说到epoll 的边缘触发只在文件描述符可读或可写事件发生时才通知，那么应用程序就需要尽可能多地执行 I&#47;O，并要处理更多的异常事件，我有点不理解这个多执行IO是为什么？是指有一个文件描述符也就是链接可读或者可写时就通知应用程序一次，那么有100个链接同时都可读，就通知应用程序100次吗，应用程序拿到这100个都是可读的。并没有多的IO执行啥，还请老师解惑，谢谢！
</div>2019-03-19</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/ef/3e/9c3a8abc.jpg" width="30px"><span>杜嘉嘉</span> 👍（5） 💬（1）<div>老师，您好。我看IO模型这块老提到文件描述符，这个跟IO模型有啥关系呢？</div>2019-02-22</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/31/1a/fd82b2d5.jpg" width="30px"><span>Tachone</span> 👍（5） 💬（1）<div>推荐陈硕的 muduo网络库，就是采用reator模式(epoll)+线程池实现的，写的非常好</div>2019-02-12</li><br/><li><img src="" width="30px"><span>shawn</span> 👍（5） 💬（1）<div>我理解，流量大于十万就该用集群了吧，一堆小型机的维护和开发成本应该小于一个大家伙吧</div>2019-02-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/7c/59/26b1e65a.jpg" width="30px"><span>科学Jia</span> 👍（4） 💬（1）<div>老师，问题1： DPDK和XDP，是不是在qps不能上去的情况下都可以采用的方案？问题2：DPDK和XDP是linux需要额外配置的工具么？</div>2019-03-04</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/0f/c4/a5/716951be.jpg" width="30px"><span>dahey</span> 👍（3） 💬（1）<div>整个世界都在解决C10M的问题：http:&#47;&#47;highscalability.com&#47;blog&#47;2013&#47;5&#47;13&#47;the-secret-to-10-million-concurrent-connections-the-kernel-i.html</div>2019-02-12</li><br/><li><img src="" width="30px"><span>GeekCoder</span> 👍（2） 💬（1）<div>想问一下c10,c1000k,c10m这些都是基于什么服务器配置？比如怎么样的服务器实现了</div>2019-08-21</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/14/4f/4d5efcf9.jpg" width="30px"><span>k</span> 👍（2） 💬（1）<div>那性价比最高的C1000K方案是不是epoll多线程+dpdk？这样好像也不需要对硬件进行过多的优化</div>2019-07-03</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/16/55/b2/d70deacf.jpg" width="30px"><span>GaelYang</span> 👍（2） 💬（1）<div>原文中 C10K 和 C1000K 的首字母 C 是 Client的缩写。
C可能是concurrtently 的缩写 ？</div>2019-07-02</li><br/><li><img src="http://thirdwx.qlogo.cn/mmopen/vi_32/PiajxSqBRaELTaqicWVpIsOpha9icy6LLJrrd24lGlwsBYhBTkBUdGHIGFXRbyZicNbSafvhMATDBjX6NSGLam9bag/132" width="30px"><span>懵懂的Java</span> 👍（2） 💬（1）<div>老师你好，前段再多的请求数，如果后段数据库连接池设置的很小比如200最多并发不也就是200吗，不知道我理解的对不对</div>2019-05-24</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/5d/a2/c6fb8fb8.jpg" width="30px"><span>狗蛋儿</span> 👍（2） 💬（2）<div>想在这讨论一个问题？对于epoll，什么时候用ET？什么时候才用LT？据我所知，redis就是使用的LT，而nginx则用的是ET。</div>2019-02-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/17/1b/ab/a5f88914.jpg" width="30px"><span>kubxy</span> 👍（1） 💬（1）<div>老师，我是疑问是TCP连接和HTTP请求的关系，一万并发请求需要建立一万个TCP连接吗？即一个TCP连接同一个时间点只能发送一个HTTP请求，是这样吗？</div>2019-05-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/8c/2b/3ab96998.jpg" width="30px"><span>青石</span> 👍（1） 💬（1）<div>向老师咨询下，文中select、poll部分提到的文件描述符列表，是否可以理解为，每个客户端连接对应一个文件描述符，当有新的客户端连接时，就会将对应的文件描述符放到select、poll的文件描述符列表中中。

select的fd_setsize限制是1024，要支持C10K，至少需要100个进程&#47;线程处理请求，这样理解对吗？

</div>2019-03-16</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/35/25/bab760a1.jpg" width="30px"><span>好好学习</span> 👍（1） 💬（1）<div>DPDK适合五元组比较集中的高pps请求模型，在没有复用五元组的情况下貌似支持下比较差。</div>2019-03-09</li><br/><li><img src="https://wx.qlogo.cn/mmopen/vi_32/PiajxSqBRaEKQMM4m7NHuicr55aRiblTSEWIYe0QqbpyHweaoAbG7j2v7UUElqqeP3Ihrm3UfDPDRb1Hv8LvPwXqA/132" width="30px"><span>ninuxer</span> 👍（1） 💬（1）<div>打卡day37
此前waf上是有c1000k的场景的</div>2019-02-18</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/13/35/25/bab760a1.jpg" width="30px"><span>好好学习</span> 👍（1） 💬（1）<div>在UDP小包，上千client随机端口组合的情景下，对网络要求极高，特别在虚拟机环境下，DPDK解决不了，DPDK还是偏向吞吐率较高，四元组比较集中复用的情景。</div>2019-02-15</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/1e/28/40/1c1a34c7.jpg" width="30px"><span>向文超</span> 👍（0） 💬（1）<div>老师您好，应对高并发也需要调整关于打开文件数的参数，如ulimit -n或fs.file-max等。其中fs.file-max是控制系统中所有进程允许打开的文件总数。但我实际测试发现进程可以突破fs.file-max设置的总数限制，这是为什么呢？</div>2020-08-05</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/41/af/4307867a.jpg" width="30px"><span>JJj</span> 👍（0） 💬（1）<div>请问下在 poll内部，检查套接字状态不是用轮询方法吗？为什么时间复杂度是O（N）
</div>2019-07-06</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/10/92/01/c723d180.jpg" width="30px"><span>饼子</span> 👍（0） 💬（1）<div>没有遇到过尴尬，能不能自己模拟呢？</div>2019-02-20</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/b6/de/95dc7537.jpg" width="30px"><span>双</span> 👍（68） 💬（1）<div>select&#47;poll是LT模式，epoll缺省使用的也是水平触发模式（LT）。
目前业界对于ET的最佳实践大概就是Nginx了，单线程redis也是使用的LT
说下我对水平触发（LT）和边缘触发（ET）我的理解。
LT:文件描述符准备就绪时（FD关联的读缓冲区不为空，可读。写缓冲区还没满，可写），触发通知。
也就是你文中表述的&quot;只要文件描述符可以非阻塞地执行 I&#47;O ，就会触发通知...&quot;
ET:当FD关联的缓冲区发生变化时（例如：读缓冲区由空变为非空，有新数据达到，可读。写缓冲区满变有空间了，有数据被发送走，可写），触发通知，仅此一次
也就是你文中表述的&quot;只有在文件描述符的状态发生改变（也就是 I&#47;O 请求达到）时&quot;

</div>2019-04-08</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/12/04/8a/ff94bd60.jpg" width="30px"><span>涛涛</span> 👍（25） 💬（0）<div>10k并发：epoll+线程池；
100K：增加物理资源；
1000k：更高的系统优化（软件的功能交给专业硬件）；
10mk:dpdx xdp</div>2019-04-28</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/15/69/187b9968.jpg" width="30px"><span>南山</span> 👍（16） 💬（7）<div>网络一直是盲区，看完之后懂了一些，不懂的更多了。</div>2020-03-29</li><br/><li><img src="" width="30px"><span>zzyalbert</span> 👍（5） 💬（7）<div>为什么select是o（n^2）poll是o（n）？</div>2019-08-27</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/1b/ca/9afb89a2.jpg" width="30px"><span>Days</span> 👍（5） 💬（0）<div>总结：通过对C10K 和 C100K案例分析，总结了常见的IO模型实现框架，比较基础知识补充！</div>2019-02-11</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/14/64/9b/d1ab239e.jpg" width="30px"><span>J.Smile</span> 👍（2） 💬（0）<div>- C10K 问题解决：基于 I&#47;O 多路复用和请求处理的优化。
- C100k问题解决：还是基于 C10K 的这些理论，epoll 配合线程池，再加上 CPU、内存和网络接口的性能和容量提升。
- C1000K 的解决方法：本质上还是构建在 epoll 的非阻塞 I&#47;O 模型上。只不过，除了 I&#47;O 模型之外，还需要从应用程序到 Linux 内核、再到 CPU、内存和网络等各个层次的深度优化，特别是需要借助硬件，来卸载那些原来通过软件处理的大量功能。
- C10M的解决办法：在 C1000K 问题中，各种软件、硬件的优化很可能都已经做到头了，究其根本，还是 Linux 内核协议栈做了太多太繁重的工作。从网卡中断带来的硬中断处理程序开始，到软中断中的各层网络协议处理，最后再到应用程序，这个路径实在是太长了，就会导致网络包的处理优化，到了一定程度后，就无法更进一步了。要解决这个问题，最重要就是跳过内核协议栈的冗长路径，把网络包直接送到要处理的应用程序那里去。这里有两种常见的机制，DPDK 和 XDP。
</div>2020-08-15</li><br/>
</ul>