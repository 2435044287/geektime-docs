你好，我是展晓凯。今天我们来一起学习使用软件编码器来编码H264的方法。

[上一节课](https://time.geekbang.org/column/intro/100117601?tab=catalog)我们学习了视频编码的基础知识，重点讲解了H264编码中的基本概念。在了解了视频编码和H264编码的基础知识之后，这节课我们就可以基于FFmpeg来书写一个编码H264的工具类，把摄像头采集下来的YUV数据编码成可播放的H264码流。

在移动平台上只要兼容性没有问题、清晰度相差不大，**性能**肯定是第一个要考虑的因素。iOS平台，因为硬件编码器的兼容性比较好，基本上用不到libx264这些软件编码器，所以这节课的实例只需要运行在Android平台上，结构图也会以Android平台为基础进行绘制。不过编码部分的代码都是使用C++来书写的，是跨平台的。如果你在iOS平台有需要的话，可以直接使用这个工具类。这个工具类的输入是一张纹理，输出是H264的裸流，接下来我们开始学习吧。

## 编码适配器

编码模块的输入我们[上一节课](https://time.geekbang.org/column/intro/100117601?tab=catalog)讲过，就是摄像头预览控制器中渲染到屏幕上的纹理ID。因为下节课我们还会学习各平台硬件编码器的使用，所以这节课我们会把重点放到软件编码器上。首先抽象出一个接口，基于这个接口，我们会有一个软件编码器的实现和一个硬件编码器的实现。在摄像头预览的控制器里是怎么和编码器模块交互的？我们一起来看下。
<div><strong>精选留言（2）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg" width="30px"><span>peter</span> 👍（0） 💬（1）<div>请教老师几个问题：
Q1：实现硬件编码器，是模拟硬件编码吗？
文中提到“基于这个接口，我们会有一个软件编码器的实现和一个硬件编码器的实现”，
硬件编码是由硬件实现，不需要实现啊。这里是指模拟硬件吗？
Q2：编码线程和纹理拷贝线程有同步、通信关系吗？
Q3：“纹理拷贝线程”的一个功能是“建立OpenGL线程”，是两个线程吗？
理解1：一个线程，“建立OpenGL线程”就是建立“纹理拷贝线程”。
理解2：两个线程，“纹理拷贝线程”是一个线程，该线程会创建另外一个“OpenGL线程”。
Q4：“OpenGL线程”是特殊的与OpenGL相关的线程吗？
理解1：就是普通线程，其作用是执行OpenGL操作。
理解2：与OpenGL库有关，需要调用OpenGL库来创建该线程。
Q4：视频队列是用Android SDK的队列吗？还是自己写的队列？
Q5：离屏渲染的Surface是Java层的还是Native层的？
Q6：“YUY2”是笔误吗？应该是“YUV2”吧。
Q7：最后写入的h264文件，是二进制文件吗？</div>2022-08-31</li><br/><li><img src="https://static001.geekbang.org/account/avatar/00/11/9f/f6/7431e82e.jpg" width="30px"><span>xueerfei007</span> 👍（0） 💬（0）<div>老师您好，我最近在使用ffmpeg编码工业相机sdk提供的raw帧数据。目前编码后，视频的时间与原始视频流对不上，编码长度比录制时长多了一倍。猜测可能与pts&#47;dts的设置有关。这个需要如何设置，或者有什么方法定位到问题的具体原因？</div>2023-08-05</li><br/>
</ul>