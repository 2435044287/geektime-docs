你好，我是展晓凯。今天我们来一起学习视频录制器的最后一部分，让它跑起来。

[上一节课](https://time.geekbang.org/column/article/565950)我们一起实现了视频录制器中的底层模块，现在音频模块已经把音频编码为AAC数据放到AAC的音频队列里了，视频模块也已经把视频编码为H264的数据放到了H264的队列里。那这节课我们就需要把这两个队列里的压缩数据封装到一个MP4文件里，让整个视频录制器跑起来。

这节课我们也会分成两部分来讲解，第一部分是实现Muxer模块，这部分的职责是把压缩后的音视频数据封装成MP4格式并写入文件中，第二部分学习整个录制器的中控系统，用来管理各个模块的生命周期和数据流转，让整个录制器项目跑起来。下面就先进入第一部分的学习吧。

## Muxer模块

音频帧和视频帧都编码完毕之后，接下来就要把它们封装到一个容器里，比如MP4、FLV、RMVB、AVI等，录制器架构是通过一个Muxer模块来完成这个职责的。[上一节课](https://time.geekbang.org/column/article/565950)中的AAC和H264这两个队列就是Muxer模块的输入，那这个模块的输出又是什么？在我们现在的场景下就是磁盘上的一个MP4文件，当然也可以是网络流媒体服务器，那就成为直播场景的推流器了。

注意，这个模块也需要有一个自己单独的线程，我们叫它Muxer线程。由于不想影响采集以及实时耳返和预览的过程，所以在编码时单独抽取出一个线程。那为什么我们又要为封装和文件流输出（对应于FFmpeg的Muxer层和Protocol层）单独抽取出一个线程来呢？
<div><strong>精选留言（2）</strong></div><ul>
<li><img src="https://static001.geekbang.org/account/avatar/00/10/25/87/f3a69d1b.jpg" width="30px"><span>peter</span> 👍（1） 💬（1）<div>请教老师几个问题啊：
Q1：init方法的参数中没有“视频编码格式”。
文中对于init方法的解释中提到“包括视频宽、高、帧率以及比特率、视频编码格式（默认为 H264 格式”。
但是，init方法原型中并没有编码格式的参数。笔误吗？

Q2：视频流的上下文中，time_base.den和time_base_num是什么意思？

Q3：音频流的上下文中，为什么没有关于时间的设置？

Q4：音频流的codec_name是怎么确定的？
avcodec_find_encoder_by_name(codec_name); 其中的codec_name是怎么确定的？

Q5：前面曾经请教过老师“混音”的问题。这个词是我自己想的，是不是这个术语用得不对？其实，我说的“混音”，就是指将两个音频叠加在一起，播放出来后能同时听到两个声音。这种情况，通用的术语叫什么？ “合成”吗？FFmpeg有这个功能吗？</div>2022-09-12</li><br/><li><img src="https://thirdwx.qlogo.cn/mmopen/vi_32/DYAIOgq83eoZ5NZbtUUJV426Bs5xflO20BjapfRZSwtHkLqPlVuDqcAyrotkWVky74EMEbAbsMc85ZxxCs1nPw/132" width="30px"><span>xuyong</span> 👍（0） 💬（1）<div>请教老师一个问题，实际产品中。Android硬编硬解多，还是软编软解多。你们的产品是怎么做的？</div>2022-09-16</li><br/>
</ul>